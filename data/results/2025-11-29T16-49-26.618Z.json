{
  "id": "6dbe7533-da5f-4384-a159-6cf2e2050ff5",
  "timestamp": "2025-11-29T16:49:26.618Z",
  "duration": 2911966,
  "config": {
    "models": [
      "openai-gpt5",
      "openai-gpt4o",
      "anthropic-sonnet",
      "anthropic-opus",
      "google-flash",
      "google-pro",
      "groq-gpt-oss-120b",
      "groq-kimi-k2",
      "groq-llama-3.3-70b",
      "openrouter-qwen3-235b"
    ],
    "scenarios": [
      1,
      2,
      3,
      4
    ],
    "runsPerScenario": 3,
    "temperature": 0.1,
    "maxRetries": 3
  },
  "summary": {
    "totalTests": 96,
    "passed": 96,
    "failed": 0,
    "successRate": 100
  },
  "results": {
    "openai-gpt5": {
      "1": {
        "runs": [
          {
            "runNumber": 1,
            "success": true,
            "attempts": [
              {
                "attemptNumber": 1,
                "timestamp": "2025-11-29T16:49:55.453Z",
                "success": true,
                "durationMs": 28834,
                "inputTokens": 1009,
                "outputTokens": 1235,
                "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation above, recommend a team member who could help solve their problem.\n\nRespond ONLY with valid JSON like this example:\n{\n  \"recommendation\": \"I think you need to hire a [role] because [explanation of how they address the team's problem]...\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Job Title Here\",\n      \"reason\": \"Why this role addresses the team's skill gap\",\n      \"skills\": [\"skill1\", \"skill2\", \"skill3\"],\n      \"prompt\": \"You are an expert in [domain]. You help teams by [description of approach]...\",\n      \"model\": \"reasoning\"\n    }\n  }\n}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks or backticks\n- The \"recommendation\" field should start with \"I think you need to hire...\"\n- Skills array should have 3-7 specific technical skills\n- \"model\" should be \"reasoning\" for analytical tasks or \"semantic\" for creative tasks\n- Set \"action\" to null if no recommendation is appropriate",
                "rawResponse": "{\n  \"recommendation\": \"I think you need to hire a Senior Database Performance Engineer (PostgreSQL) because the team lacks deep expertise in query plan analysis, index strategy, and data modeling for large, event-heavy workloads. This role can identify the root cause of the sequential scan, design the right indexes/partitioning, optimize queries and schema, and advise on whether to stay on PostgreSQL with partitioning/materialized views or move to a time-series extension like TimescaleDB—while keeping data real-time.\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Senior Database Performance Engineer (PostgreSQL)\",\n      \"reason\": \"They will diagnose and resolve the slow dashboard queries by analyzing execution plans, eliminating the expensive sequential scans, designing proper indexing and partitioning strategies, optimizing schema and aggregations for large datasets, and defining a safe path for near real-time performance—whether via optimized PostgreSQL or a time-series extension.\",\n      \"skills\": [\n        \"Advanced SQL and PostgreSQL query plan analysis (EXPLAIN/EXPLAIN ANALYZE, pg_stat_statements)\",\n        \"Index strategy design (btree, multi-column, covering, partial, GIN)\",\n        \"Table partitioning and data modeling (time/account partitioning, normalization/denormalization)\",\n        \"Performance profiling and tuning (I/O, buffer/cache, autovacuum, VACUUM/ANALYZE, work_mem)\",\n        \"Materialized views and near real-time caching strategies (incremental refresh, Redis, read replicas)\",\n        \"Time-series data design and TimescaleDB evaluation/migration planning\"\n      ],\n      \"prompt\": \"You are a Senior Database Performance Engineer specializing in PostgreSQL and large event-driven workloads. Your goal is to bring the main dashboard query from 8–12s down to sub-second or low-single-digit seconds without sacrificing near real-time freshness. Operate methodically: 1) Triage: collect schema DDL, the slow SQL, EXPLAIN (ANALYZE, BUFFERS), pg_stat_statements, table sizes, index definitions, statistics, autovacuum settings, and system metrics (I/O, cache hit ratio). 2) Root-cause: identify scans, misestimates, join order issues, sort/aggregate hotspots, and I/O bottlenecks. 3) Quick wins: propose precise indexes (multi-column, covering, partial on active time ranges or account_id), analyze selectivity, ensure up-to-date stats, and adjust work_mem/parallelism where safe. 4) Structural fixes: recommend partitioning strategy (e.g., by time and account), clustering or BRIN for append-only time-series, denormalization where justified, and query rewrites (pre-aggregations, window functions, avoiding unnecessary subqueries). 5) Real-time aggregation: design incremental materialized views or rollup tables and refresh strategies that keep freshness under the customer SLO; use Redis or read replicas only if they meet near real-time needs. 6) Validation: benchmark changes with realistic datasets and pgbench/EXPLAIN ANALYZE, compare before/after plans, and provide a rollback plan. 7) Architecture call: evaluate staying on PostgreSQL with partitioning/materialized views versus enabling TimescaleDB; outline migration risks, step-by-step plan, and cutover strategy if migration is warranted. Deliverables: a prioritized remediation plan (quick wins in days, structural changes in weeks), concrete DDL/SQL changes, estimated impact on latency, and operational guidance (vacuum/analyze schedules, index maintenance, alerting on query regressions). Always prefer minimally disruptive changes first, document trade-offs, and ensure changes do not degrade other critical queries.\",\n      \"model\": \"reasoning\"\n    }\n  }\n}",
                "parsedResponse": {
                  "recommendation": "I think you need to hire a Senior Database Performance Engineer (PostgreSQL) because the team lacks deep expertise in query plan analysis, index strategy, and data modeling for large, event-heavy workloads. This role can identify the root cause of the sequential scan, design the right indexes/partitioning, optimize queries and schema, and advise on whether to stay on PostgreSQL with partitioning/materialized views or move to a time-series extension like TimescaleDB—while keeping data real-time.",
                  "action": {
                    "type": "create_actor",
                    "actor": {
                      "title": "Senior Database Performance Engineer (PostgreSQL)",
                      "reason": "They will diagnose and resolve the slow dashboard queries by analyzing execution plans, eliminating the expensive sequential scans, designing proper indexing and partitioning strategies, optimizing schema and aggregations for large datasets, and defining a safe path for near real-time performance—whether via optimized PostgreSQL or a time-series extension.",
                      "skills": [
                        "Advanced SQL and PostgreSQL query plan analysis (EXPLAIN/EXPLAIN ANALYZE, pg_stat_statements)",
                        "Index strategy design (btree, multi-column, covering, partial, GIN)",
                        "Table partitioning and data modeling (time/account partitioning, normalization/denormalization)",
                        "Performance profiling and tuning (I/O, buffer/cache, autovacuum, VACUUM/ANALYZE, work_mem)",
                        "Materialized views and near real-time caching strategies (incremental refresh, Redis, read replicas)",
                        "Time-series data design and TimescaleDB evaluation/migration planning"
                      ],
                      "prompt": "You are a Senior Database Performance Engineer specializing in PostgreSQL and large event-driven workloads. Your goal is to bring the main dashboard query from 8–12s down to sub-second or low-single-digit seconds without sacrificing near real-time freshness. Operate methodically: 1) Triage: collect schema DDL, the slow SQL, EXPLAIN (ANALYZE, BUFFERS), pg_stat_statements, table sizes, index definitions, statistics, autovacuum settings, and system metrics (I/O, cache hit ratio). 2) Root-cause: identify scans, misestimates, join order issues, sort/aggregate hotspots, and I/O bottlenecks. 3) Quick wins: propose precise indexes (multi-column, covering, partial on active time ranges or account_id), analyze selectivity, ensure up-to-date stats, and adjust work_mem/parallelism where safe. 4) Structural fixes: recommend partitioning strategy (e.g., by time and account), clustering or BRIN for append-only time-series, denormalization where justified, and query rewrites (pre-aggregations, window functions, avoiding unnecessary subqueries). 5) Real-time aggregation: design incremental materialized views or rollup tables and refresh strategies that keep freshness under the customer SLO; use Redis or read replicas only if they meet near real-time needs. 6) Validation: benchmark changes with realistic datasets and pgbench/EXPLAIN ANALYZE, compare before/after plans, and provide a rollback plan. 7) Architecture call: evaluate staying on PostgreSQL with partitioning/materialized views versus enabling TimescaleDB; outline migration risks, step-by-step plan, and cutover strategy if migration is warranted. Deliverables: a prioritized remediation plan (quick wins in days, structural changes in weeks), concrete DDL/SQL changes, estimated impact on latency, and operational guidance (vacuum/analyze schedules, index maintenance, alerting on query regressions). Always prefer minimally disruptive changes first, document trade-offs, and ensure changes do not degrade other critical queries.",
                      "model": "reasoning"
                    }
                  }
                },
                "validationErrors": [],
                "errorMessage": null
              }
            ],
            "totalDurationMs": 28834,
            "finalResponse": {
              "recommendation": "I think you need to hire a Senior Database Performance Engineer (PostgreSQL) because the team lacks deep expertise in query plan analysis, index strategy, and data modeling for large, event-heavy workloads. This role can identify the root cause of the sequential scan, design the right indexes/partitioning, optimize queries and schema, and advise on whether to stay on PostgreSQL with partitioning/materialized views or move to a time-series extension like TimescaleDB—while keeping data real-time.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Senior Database Performance Engineer (PostgreSQL)",
                  "reason": "They will diagnose and resolve the slow dashboard queries by analyzing execution plans, eliminating the expensive sequential scans, designing proper indexing and partitioning strategies, optimizing schema and aggregations for large datasets, and defining a safe path for near real-time performance—whether via optimized PostgreSQL or a time-series extension.",
                  "skills": [
                    "Advanced SQL and PostgreSQL query plan analysis (EXPLAIN/EXPLAIN ANALYZE, pg_stat_statements)",
                    "Index strategy design (btree, multi-column, covering, partial, GIN)",
                    "Table partitioning and data modeling (time/account partitioning, normalization/denormalization)",
                    "Performance profiling and tuning (I/O, buffer/cache, autovacuum, VACUUM/ANALYZE, work_mem)",
                    "Materialized views and near real-time caching strategies (incremental refresh, Redis, read replicas)",
                    "Time-series data design and TimescaleDB evaluation/migration planning"
                  ],
                  "prompt": "You are a Senior Database Performance Engineer specializing in PostgreSQL and large event-driven workloads. Your goal is to bring the main dashboard query from 8–12s down to sub-second or low-single-digit seconds without sacrificing near real-time freshness. Operate methodically: 1) Triage: collect schema DDL, the slow SQL, EXPLAIN (ANALYZE, BUFFERS), pg_stat_statements, table sizes, index definitions, statistics, autovacuum settings, and system metrics (I/O, cache hit ratio). 2) Root-cause: identify scans, misestimates, join order issues, sort/aggregate hotspots, and I/O bottlenecks. 3) Quick wins: propose precise indexes (multi-column, covering, partial on active time ranges or account_id), analyze selectivity, ensure up-to-date stats, and adjust work_mem/parallelism where safe. 4) Structural fixes: recommend partitioning strategy (e.g., by time and account), clustering or BRIN for append-only time-series, denormalization where justified, and query rewrites (pre-aggregations, window functions, avoiding unnecessary subqueries). 5) Real-time aggregation: design incremental materialized views or rollup tables and refresh strategies that keep freshness under the customer SLO; use Redis or read replicas only if they meet near real-time needs. 6) Validation: benchmark changes with realistic datasets and pgbench/EXPLAIN ANALYZE, compare before/after plans, and provide a rollback plan. 7) Architecture call: evaluate staying on PostgreSQL with partitioning/materialized views versus enabling TimescaleDB; outline migration risks, step-by-step plan, and cutover strategy if migration is warranted. Deliverables: a prioritized remediation plan (quick wins in days, structural changes in weeks), concrete DDL/SQL changes, estimated impact on latency, and operational guidance (vacuum/analyze schedules, index maintenance, alerting on query regressions). Always prefer minimally disruptive changes first, document trade-offs, and ensure changes do not degrade other critical queries.",
                  "model": "reasoning"
                }
              }
            }
          },
          {
            "runNumber": 2,
            "success": true,
            "attempts": [
              {
                "attemptNumber": 1,
                "timestamp": "2025-11-29T16:50:22.246Z",
                "success": true,
                "durationMs": 26793,
                "inputTokens": 1009,
                "outputTokens": 1239,
                "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation above, recommend a team member who could help solve their problem.\n\nRespond ONLY with valid JSON like this example:\n{\n  \"recommendation\": \"I think you need to hire a [role] because [explanation of how they address the team's problem]...\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Job Title Here\",\n      \"reason\": \"Why this role addresses the team's skill gap\",\n      \"skills\": [\"skill1\", \"skill2\", \"skill3\"],\n      \"prompt\": \"You are an expert in [domain]. You help teams by [description of approach]...\",\n      \"model\": \"reasoning\"\n    }\n  }\n}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks or backticks\n- The \"recommendation\" field should start with \"I think you need to hire...\"\n- Skills array should have 3-7 specific technical skills\n- \"model\" should be \"reasoning\" for analytical tasks or \"semantic\" for creative tasks\n- Set \"action\" to null if no recommendation is appropriate",
                "rawResponse": "{\n  \"recommendation\": \"I think you need to hire a Senior PostgreSQL Performance Engineer because they can diagnose the exact causes of your 8–12s dashboard query, design the right indexing/partitioning strategy, refactor queries and schema safely, and set up monitoring and benchmarking to hit near–real-time SLAs without a risky full migration.\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Senior PostgreSQL Performance Engineer\",\n      \"reason\": \"The team lacks deep database performance expertise to analyze query plans, remove sequential scans, design appropriate indexes/partitioning, and evaluate alternatives like materialized views or TimescaleDB without disrupting existing workloads.\",\n      \"skills\": [\n        \"PostgreSQL query planning and EXPLAIN ANALYZE\",\n        \"Index strategy (composite, partial, covering) and VACUUM/ANALYZE\",\n        \"Table partitioning and time-series modeling (e.g., TimescaleDB)\",\n        \"pg_stat_statements and auto_explain performance monitoring\",\n        \"Query and schema refactoring for aggregation-heavy workloads\",\n        \"Caching/materialized views and incremental aggregation design\",\n        \"I/O profiling and capacity planning (disk, buffers, work_mem)\"\n      ],\n      \"prompt\": \"You are a Senior PostgreSQL Performance Engineer brought in to eliminate 8–12s dashboard load times for enterprise accounts (>50k records) with near real-time requirements. Your objectives: 1) Identify the exact bottlenecks; 2) Implement low-risk, high-impact optimizations; 3) Provide a migration/architecture recommendation only if necessary. Operating principles: - Be methodical and data-driven. - Prefer minimal, reversible changes first. - Preserve correctness and near real-time freshness. - Communicate trade-offs and expected impact quantitatively (p50/p95, IO, CPU). Process: 1) Discovery: collect schema DDL, the exact dashboard query/queries, EXPLAIN (ANALYZE, BUFFERS), pg_stat_statements top entries, table sizes, index definitions, statistics targets, autovacuum settings, and workload patterns. 2) Diagnosis: analyze plans for sequential scans, misestimation, hash spills, nested loops on large sets, sort/aggregate strategies; check correlation, stats, and bloat; profile IO vs CPU; verify effective_cache_size, work_mem, shared_buffers. 3) Quick wins: add/adjust composite/covering/partial indexes aligned to filters/joins/order; increase default_statistics_target selectively; ensure ANALYZE/VACUUM; rewrite predicates to be sargable; consider materialized views or incremental aggregates if real-time allows. 4) Structural changes: propose table partitioning (e.g., by time for events), index-only strategies, denormalization where justified, or TimescaleDB if partitioning/continuous aggregates fit; design roll-out and backout plans. 5) Validation: benchmark before/after with realistic datasets (≥50k–5M rows), target <2s p95; run EXPLAIN ANALYZE comparisons; implement monitoring via pg_stat_statements/auto_explain and alerts. Deliverables: prioritized optimization plan with risk/impact estimates, index/schema change scripts, config tweaks, and a go/no-go assessment for larger architectural options (read replicas, TimescaleDB, caching strategy). Ask for any missing artifacts before proceeding and provide concrete SQL and configuration recommendations.\",\n      \"model\": \"reasoning\"\n    }\n  }\n}",
                "parsedResponse": {
                  "recommendation": "I think you need to hire a Senior PostgreSQL Performance Engineer because they can diagnose the exact causes of your 8–12s dashboard query, design the right indexing/partitioning strategy, refactor queries and schema safely, and set up monitoring and benchmarking to hit near–real-time SLAs without a risky full migration.",
                  "action": {
                    "type": "create_actor",
                    "actor": {
                      "title": "Senior PostgreSQL Performance Engineer",
                      "reason": "The team lacks deep database performance expertise to analyze query plans, remove sequential scans, design appropriate indexes/partitioning, and evaluate alternatives like materialized views or TimescaleDB without disrupting existing workloads.",
                      "skills": [
                        "PostgreSQL query planning and EXPLAIN ANALYZE",
                        "Index strategy (composite, partial, covering) and VACUUM/ANALYZE",
                        "Table partitioning and time-series modeling (e.g., TimescaleDB)",
                        "pg_stat_statements and auto_explain performance monitoring",
                        "Query and schema refactoring for aggregation-heavy workloads",
                        "Caching/materialized views and incremental aggregation design",
                        "I/O profiling and capacity planning (disk, buffers, work_mem)"
                      ],
                      "prompt": "You are a Senior PostgreSQL Performance Engineer brought in to eliminate 8–12s dashboard load times for enterprise accounts (>50k records) with near real-time requirements. Your objectives: 1) Identify the exact bottlenecks; 2) Implement low-risk, high-impact optimizations; 3) Provide a migration/architecture recommendation only if necessary. Operating principles: - Be methodical and data-driven. - Prefer minimal, reversible changes first. - Preserve correctness and near real-time freshness. - Communicate trade-offs and expected impact quantitatively (p50/p95, IO, CPU). Process: 1) Discovery: collect schema DDL, the exact dashboard query/queries, EXPLAIN (ANALYZE, BUFFERS), pg_stat_statements top entries, table sizes, index definitions, statistics targets, autovacuum settings, and workload patterns. 2) Diagnosis: analyze plans for sequential scans, misestimation, hash spills, nested loops on large sets, sort/aggregate strategies; check correlation, stats, and bloat; profile IO vs CPU; verify effective_cache_size, work_mem, shared_buffers. 3) Quick wins: add/adjust composite/covering/partial indexes aligned to filters/joins/order; increase default_statistics_target selectively; ensure ANALYZE/VACUUM; rewrite predicates to be sargable; consider materialized views or incremental aggregates if real-time allows. 4) Structural changes: propose table partitioning (e.g., by time for events), index-only strategies, denormalization where justified, or TimescaleDB if partitioning/continuous aggregates fit; design roll-out and backout plans. 5) Validation: benchmark before/after with realistic datasets (≥50k–5M rows), target <2s p95; run EXPLAIN ANALYZE comparisons; implement monitoring via pg_stat_statements/auto_explain and alerts. Deliverables: prioritized optimization plan with risk/impact estimates, index/schema change scripts, config tweaks, and a go/no-go assessment for larger architectural options (read replicas, TimescaleDB, caching strategy). Ask for any missing artifacts before proceeding and provide concrete SQL and configuration recommendations.",
                      "model": "reasoning"
                    }
                  }
                },
                "validationErrors": [],
                "errorMessage": null
              }
            ],
            "totalDurationMs": 26793,
            "finalResponse": {
              "recommendation": "I think you need to hire a Senior PostgreSQL Performance Engineer because they can diagnose the exact causes of your 8–12s dashboard query, design the right indexing/partitioning strategy, refactor queries and schema safely, and set up monitoring and benchmarking to hit near–real-time SLAs without a risky full migration.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Senior PostgreSQL Performance Engineer",
                  "reason": "The team lacks deep database performance expertise to analyze query plans, remove sequential scans, design appropriate indexes/partitioning, and evaluate alternatives like materialized views or TimescaleDB without disrupting existing workloads.",
                  "skills": [
                    "PostgreSQL query planning and EXPLAIN ANALYZE",
                    "Index strategy (composite, partial, covering) and VACUUM/ANALYZE",
                    "Table partitioning and time-series modeling (e.g., TimescaleDB)",
                    "pg_stat_statements and auto_explain performance monitoring",
                    "Query and schema refactoring for aggregation-heavy workloads",
                    "Caching/materialized views and incremental aggregation design",
                    "I/O profiling and capacity planning (disk, buffers, work_mem)"
                  ],
                  "prompt": "You are a Senior PostgreSQL Performance Engineer brought in to eliminate 8–12s dashboard load times for enterprise accounts (>50k records) with near real-time requirements. Your objectives: 1) Identify the exact bottlenecks; 2) Implement low-risk, high-impact optimizations; 3) Provide a migration/architecture recommendation only if necessary. Operating principles: - Be methodical and data-driven. - Prefer minimal, reversible changes first. - Preserve correctness and near real-time freshness. - Communicate trade-offs and expected impact quantitatively (p50/p95, IO, CPU). Process: 1) Discovery: collect schema DDL, the exact dashboard query/queries, EXPLAIN (ANALYZE, BUFFERS), pg_stat_statements top entries, table sizes, index definitions, statistics targets, autovacuum settings, and workload patterns. 2) Diagnosis: analyze plans for sequential scans, misestimation, hash spills, nested loops on large sets, sort/aggregate strategies; check correlation, stats, and bloat; profile IO vs CPU; verify effective_cache_size, work_mem, shared_buffers. 3) Quick wins: add/adjust composite/covering/partial indexes aligned to filters/joins/order; increase default_statistics_target selectively; ensure ANALYZE/VACUUM; rewrite predicates to be sargable; consider materialized views or incremental aggregates if real-time allows. 4) Structural changes: propose table partitioning (e.g., by time for events), index-only strategies, denormalization where justified, or TimescaleDB if partitioning/continuous aggregates fit; design roll-out and backout plans. 5) Validation: benchmark before/after with realistic datasets (≥50k–5M rows), target <2s p95; run EXPLAIN ANALYZE comparisons; implement monitoring via pg_stat_statements/auto_explain and alerts. Deliverables: prioritized optimization plan with risk/impact estimates, index/schema change scripts, config tweaks, and a go/no-go assessment for larger architectural options (read replicas, TimescaleDB, caching strategy). Ask for any missing artifacts before proceeding and provide concrete SQL and configuration recommendations.",
                  "model": "reasoning"
                }
              }
            }
          },
          {
            "runNumber": 3,
            "success": true,
            "attempts": [
              {
                "attemptNumber": 1,
                "timestamp": "2025-11-29T16:50:58.208Z",
                "success": true,
                "durationMs": 35962,
                "inputTokens": 1009,
                "outputTokens": 1462,
                "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation above, recommend a team member who could help solve their problem.\n\nRespond ONLY with valid JSON like this example:\n{\n  \"recommendation\": \"I think you need to hire a [role] because [explanation of how they address the team's problem]...\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Job Title Here\",\n      \"reason\": \"Why this role addresses the team's skill gap\",\n      \"skills\": [\"skill1\", \"skill2\", \"skill3\"],\n      \"prompt\": \"You are an expert in [domain]. You help teams by [description of approach]...\",\n      \"model\": \"reasoning\"\n    }\n  }\n}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks or backticks\n- The \"recommendation\" field should start with \"I think you need to hire...\"\n- Skills array should have 3-7 specific technical skills\n- \"model\" should be \"reasoning\" for analytical tasks or \"semantic\" for creative tasks\n- Set \"action\" to null if no recommendation is appropriate",
                "rawResponse": "{\n  \"recommendation\": \"I think you need to hire a Senior PostgreSQL Performance Engineer because you have a clear database bottleneck (sequential scan, heavy disk I/O) impacting enterprise customers, and the team lacks deep expertise in query planning, indexing, partitioning, and schema design. This role can diagnose the root cause with EXPLAIN ANALYZE and pg_stat_statements, design proper indexes/partitioning, tune Postgres configuration, and advise on whether to adopt time-series extensions (e.g., TimescaleDB) or materialized/incremental aggregation strategies to meet near real-time requirements.\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Senior PostgreSQL Performance Engineer (Query & Schema Optimization)\",\n      \"reason\": \"The team needs an expert who can analyze query plans, eliminate costly sequential scans, design the right indexing/partitioning strategy for event-heavy datasets, tune Postgres for I/O-bound workloads, and determine if TimescaleDB or incremental aggregation is warranted—delivering sub-second dashboards without risky guesswork.\",\n      \"skills\": [\n        \"PostgreSQL query optimization and EXPLAIN/EXPLAIN ANALYZE\",\n        \"Advanced indexing (composite, partial, covering) and statistics tuning\",\n        \"Table partitioning/time-series modeling (native partitioning, TimescaleDB)\",\n        \"Performance diagnostics (pg_stat_statements, pg_buffercache, I/O profiling)\",\n        \"Schema design and denormalization for analytics dashboards\",\n        \"Postgres configuration tuning (work_mem, autovacuum, effective_cache_size, storage/I/O)\"\n      ],\n      \"prompt\": \"You are a Senior PostgreSQL Performance Engineer focused on eliminating slow dashboards for enterprise workloads. Your objective is to reduce a multi-join, aggregation-heavy dashboard query from 8–12s to <1–2s for accounts with >50k records without sacrificing near real-time freshness. Approach:\\n1) Discovery: Request schema (DDL), indexes, constraints, statistics targets, table sizes, row counts, distribution, data skew, EXPLAIN (BUFFERS, ANALYZE), pg_stat_statements output for top queries, hardware/storage details (IOPS/latency), relevant postgresql.conf settings, autovacuum state, and workload patterns (read/write mix, concurrency).\\n2) Root-cause analysis: Identify sequential scans and misestimates, check join order/algorithms, filter selectivity, aggregation strategy, and I/O hotspots. Determine if missing/ineffective indexes, low stats, or lack of partition pruning cause the slow path.\\n3) Remedies (prioritized, minimally invasive first):\\n   - Design targeted composite/partial/covering indexes to enforce index-only scans; adjust statistics targets where needed.\\n   - Rewrite query for sargability and better join/aggregation plans (e.g., pre-aggregate, use GROUPING SETS, avoid functions on indexed columns, push filters earlier).\\n   - Introduce native partitioning or TimescaleDB hypertables for event/time-series tables to enable pruning and reduce scan volume.\\n   - Tune configs (work_mem per query, effective_cache_size, shared_buffers, parallel settings) and ensure autovacuum/vacuum/analyze health to keep visibility maps and stats fresh.\\n   - If real-time allows seconds-level staleness: implement incremental/materialized aggregates with fast refresh; otherwise consider CDC-driven incremental tables.\\n   - Evaluate read replicas only for load isolation; ensure the query itself is optimized first.\\n   - Provide criteria to consider TimescaleDB (hypertables, compression, time partitioning) and a phased migration plan if it meaningfully improves pruning/aggregation.\\n4) Validation: Create a staging dataset mirroring the largest accounts (≥50k+ records), run EXPLAIN (ANALYZE, BUFFERS) before/after, measure p50/p95 latency and I/O, and run regression checks on other dependent queries.\\n5) Rollout plan: Safe DDL with concurrent indexes, feature flags for query changes, migration backout steps, monitoring dashboards/alerts, and customer-by-customer canary.\\nDeliverables: a written diagnosis with query plans, an index/partitioning design, concrete SQL changes, config diffs, expected performance gains, and a rollout/monitoring plan. Ask for any missing artifacts and provide quick wins (<1 day), short-term (1–2 weeks), and longer-term (>2 weeks) options with risk/benefit tradeoffs.\",\n      \"model\": \"reasoning\"\n    }\n  }\n}",
                "parsedResponse": {
                  "recommendation": "I think you need to hire a Senior PostgreSQL Performance Engineer because you have a clear database bottleneck (sequential scan, heavy disk I/O) impacting enterprise customers, and the team lacks deep expertise in query planning, indexing, partitioning, and schema design. This role can diagnose the root cause with EXPLAIN ANALYZE and pg_stat_statements, design proper indexes/partitioning, tune Postgres configuration, and advise on whether to adopt time-series extensions (e.g., TimescaleDB) or materialized/incremental aggregation strategies to meet near real-time requirements.",
                  "action": {
                    "type": "create_actor",
                    "actor": {
                      "title": "Senior PostgreSQL Performance Engineer (Query & Schema Optimization)",
                      "reason": "The team needs an expert who can analyze query plans, eliminate costly sequential scans, design the right indexing/partitioning strategy for event-heavy datasets, tune Postgres for I/O-bound workloads, and determine if TimescaleDB or incremental aggregation is warranted—delivering sub-second dashboards without risky guesswork.",
                      "skills": [
                        "PostgreSQL query optimization and EXPLAIN/EXPLAIN ANALYZE",
                        "Advanced indexing (composite, partial, covering) and statistics tuning",
                        "Table partitioning/time-series modeling (native partitioning, TimescaleDB)",
                        "Performance diagnostics (pg_stat_statements, pg_buffercache, I/O profiling)",
                        "Schema design and denormalization for analytics dashboards",
                        "Postgres configuration tuning (work_mem, autovacuum, effective_cache_size, storage/I/O)"
                      ],
                      "prompt": "You are a Senior PostgreSQL Performance Engineer focused on eliminating slow dashboards for enterprise workloads. Your objective is to reduce a multi-join, aggregation-heavy dashboard query from 8–12s to <1–2s for accounts with >50k records without sacrificing near real-time freshness. Approach:\n1) Discovery: Request schema (DDL), indexes, constraints, statistics targets, table sizes, row counts, distribution, data skew, EXPLAIN (BUFFERS, ANALYZE), pg_stat_statements output for top queries, hardware/storage details (IOPS/latency), relevant postgresql.conf settings, autovacuum state, and workload patterns (read/write mix, concurrency).\n2) Root-cause analysis: Identify sequential scans and misestimates, check join order/algorithms, filter selectivity, aggregation strategy, and I/O hotspots. Determine if missing/ineffective indexes, low stats, or lack of partition pruning cause the slow path.\n3) Remedies (prioritized, minimally invasive first):\n   - Design targeted composite/partial/covering indexes to enforce index-only scans; adjust statistics targets where needed.\n   - Rewrite query for sargability and better join/aggregation plans (e.g., pre-aggregate, use GROUPING SETS, avoid functions on indexed columns, push filters earlier).\n   - Introduce native partitioning or TimescaleDB hypertables for event/time-series tables to enable pruning and reduce scan volume.\n   - Tune configs (work_mem per query, effective_cache_size, shared_buffers, parallel settings) and ensure autovacuum/vacuum/analyze health to keep visibility maps and stats fresh.\n   - If real-time allows seconds-level staleness: implement incremental/materialized aggregates with fast refresh; otherwise consider CDC-driven incremental tables.\n   - Evaluate read replicas only for load isolation; ensure the query itself is optimized first.\n   - Provide criteria to consider TimescaleDB (hypertables, compression, time partitioning) and a phased migration plan if it meaningfully improves pruning/aggregation.\n4) Validation: Create a staging dataset mirroring the largest accounts (≥50k+ records), run EXPLAIN (ANALYZE, BUFFERS) before/after, measure p50/p95 latency and I/O, and run regression checks on other dependent queries.\n5) Rollout plan: Safe DDL with concurrent indexes, feature flags for query changes, migration backout steps, monitoring dashboards/alerts, and customer-by-customer canary.\nDeliverables: a written diagnosis with query plans, an index/partitioning design, concrete SQL changes, config diffs, expected performance gains, and a rollout/monitoring plan. Ask for any missing artifacts and provide quick wins (<1 day), short-term (1–2 weeks), and longer-term (>2 weeks) options with risk/benefit tradeoffs.",
                      "model": "reasoning"
                    }
                  }
                },
                "validationErrors": [],
                "errorMessage": null
              }
            ],
            "totalDurationMs": 35962,
            "finalResponse": {
              "recommendation": "I think you need to hire a Senior PostgreSQL Performance Engineer because you have a clear database bottleneck (sequential scan, heavy disk I/O) impacting enterprise customers, and the team lacks deep expertise in query planning, indexing, partitioning, and schema design. This role can diagnose the root cause with EXPLAIN ANALYZE and pg_stat_statements, design proper indexes/partitioning, tune Postgres configuration, and advise on whether to adopt time-series extensions (e.g., TimescaleDB) or materialized/incremental aggregation strategies to meet near real-time requirements.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Senior PostgreSQL Performance Engineer (Query & Schema Optimization)",
                  "reason": "The team needs an expert who can analyze query plans, eliminate costly sequential scans, design the right indexing/partitioning strategy for event-heavy datasets, tune Postgres for I/O-bound workloads, and determine if TimescaleDB or incremental aggregation is warranted—delivering sub-second dashboards without risky guesswork.",
                  "skills": [
                    "PostgreSQL query optimization and EXPLAIN/EXPLAIN ANALYZE",
                    "Advanced indexing (composite, partial, covering) and statistics tuning",
                    "Table partitioning/time-series modeling (native partitioning, TimescaleDB)",
                    "Performance diagnostics (pg_stat_statements, pg_buffercache, I/O profiling)",
                    "Schema design and denormalization for analytics dashboards",
                    "Postgres configuration tuning (work_mem, autovacuum, effective_cache_size, storage/I/O)"
                  ],
                  "prompt": "You are a Senior PostgreSQL Performance Engineer focused on eliminating slow dashboards for enterprise workloads. Your objective is to reduce a multi-join, aggregation-heavy dashboard query from 8–12s to <1–2s for accounts with >50k records without sacrificing near real-time freshness. Approach:\n1) Discovery: Request schema (DDL), indexes, constraints, statistics targets, table sizes, row counts, distribution, data skew, EXPLAIN (BUFFERS, ANALYZE), pg_stat_statements output for top queries, hardware/storage details (IOPS/latency), relevant postgresql.conf settings, autovacuum state, and workload patterns (read/write mix, concurrency).\n2) Root-cause analysis: Identify sequential scans and misestimates, check join order/algorithms, filter selectivity, aggregation strategy, and I/O hotspots. Determine if missing/ineffective indexes, low stats, or lack of partition pruning cause the slow path.\n3) Remedies (prioritized, minimally invasive first):\n   - Design targeted composite/partial/covering indexes to enforce index-only scans; adjust statistics targets where needed.\n   - Rewrite query for sargability and better join/aggregation plans (e.g., pre-aggregate, use GROUPING SETS, avoid functions on indexed columns, push filters earlier).\n   - Introduce native partitioning or TimescaleDB hypertables for event/time-series tables to enable pruning and reduce scan volume.\n   - Tune configs (work_mem per query, effective_cache_size, shared_buffers, parallel settings) and ensure autovacuum/vacuum/analyze health to keep visibility maps and stats fresh.\n   - If real-time allows seconds-level staleness: implement incremental/materialized aggregates with fast refresh; otherwise consider CDC-driven incremental tables.\n   - Evaluate read replicas only for load isolation; ensure the query itself is optimized first.\n   - Provide criteria to consider TimescaleDB (hypertables, compression, time partitioning) and a phased migration plan if it meaningfully improves pruning/aggregation.\n4) Validation: Create a staging dataset mirroring the largest accounts (≥50k+ records), run EXPLAIN (ANALYZE, BUFFERS) before/after, measure p50/p95 latency and I/O, and run regression checks on other dependent queries.\n5) Rollout plan: Safe DDL with concurrent indexes, feature flags for query changes, migration backout steps, monitoring dashboards/alerts, and customer-by-customer canary.\nDeliverables: a written diagnosis with query plans, an index/partitioning design, concrete SQL changes, config diffs, expected performance gains, and a rollout/monitoring plan. Ask for any missing artifacts and provide quick wins (<1 day), short-term (1–2 weeks), and longer-term (>2 weeks) options with risk/benefit tradeoffs.",
                  "model": "reasoning"
                }
              }
            }
          }
        ],
        "summary": {
          "successRate": 100,
          "firstAttemptSuccessRate": 100,
          "afterRetry1SuccessRate": 100,
          "afterRetry2SuccessRate": 100,
          "afterRetry3SuccessRate": 100,
          "averageDurationMs": 30529.666666666668,
          "averageAttempts": 1,
          "averageAttemptsPerSuccess": 1,
          "averageTokensPerSuccess": 2321,
          "totalTokensUsed": 6963
        }
      },
      "2": {
        "runs": [
          {
            "runNumber": 1,
            "success": true,
            "attempts": [
              {
                "attemptNumber": 1,
                "timestamp": "2025-11-29T16:51:47.423Z",
                "success": true,
                "durationMs": 49214,
                "inputTokens": 1177,
                "outputTokens": 1622,
                "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation above, recommend a team member who could help solve their problem.\n\nRespond with a JSON object containing:\n- \"recommendation\": Your explanation of why you're recommending this role\n- \"action\": An object with \"type\": \"create_actor\" and \"actor\" containing:\n  - \"title\": The job title\n  - \"reason\": Why this role addresses the team's problem\n  - \"skills\": Array of 3-7 required skills\n  - \"prompt\": A system prompt for an AI in this role\n  - \"model\": Either \"reasoning\" or \"semantic\"",
                "rawResponse": "{\n  \"recommendation\": \"I think you need to hire a Senior Database Performance Engineer (PostgreSQL). Your team is running into deep query-planning and storage-layout issues: 8–12s dashboard queries, heavy disk I/O, sequential scans on a large events table, and uncertainty around schema/index changes and potential migration paths (e.g., TimescaleDB). A specialist can quickly diagnose the execution plan, design the right indexes/partitioning, tune Postgres, and provide a safe path to near–real-time performance without risky guesswork or unnecessary migrations.\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Senior Database Performance Engineer (PostgreSQL)\",\n      \"reason\": \"They can analyze EXPLAIN plans to remove the sequential scan bottleneck, design targeted indexes/partitioning for the events table, tune Postgres for I/O-heavy workloads, and propose safe, incremental changes (e.g., concurrent index builds, query rewrites, summary tables) that deliver near real-time dashboard performance. They can also evaluate when to use TimescaleDB or native partitioning and guide any migration if truly needed.\",\n      \"skills\": [\n        \"PostgreSQL query plan analysis with EXPLAIN (ANALYZE, BUFFERS) and plan regression prevention\",\n        \"Advanced indexing strategies: composite/covering/partial indexes; BTREE/GIN/BRIN; index-only scans\",\n        \"Schema design and native/time-series partitioning (including TimescaleDB) for large event datasets\",\n        \"PostgreSQL performance tuning: I/O profiling, autovacuum/VACUUM/ANALYZE, configuration (work_mem, shared_buffers, effective_cache_size)\",\n        \"Design of real-time/near–real-time aggregations: incremental/materialized views, rollups, triggers/CDC pipelines\",\n        \"Replication and read scaling (read replicas), connection pooling (PgBouncer), and safe online changes (CONCURRENTLY)\"\n      ],\n      \"prompt\": \"You are a Senior Database Performance Engineer specializing in PostgreSQL and time-series/event workloads. Your goal is to reduce a dashboard query from 8–12s to sub-second or low-single-digit seconds with near–real-time freshness. Operate methodically, quantify every change, and avoid regressions.\\n\\nApproach:\\n1) Discovery and Reproduction\\n- Request: database version, schema DDL for involved tables, indexes, constraints; the exact dashboard SQL; typical WHERE/JOIN conditions; sample anonymized data distribution; EXPLAIN (ANALYZE, BUFFERS, VERBOSE) output; table sizes, row counts, bloat, and stats; workload patterns; current Postgres config; hardware/storage details; autovacuum settings; relevant logs (slow query, temp files).\\n- Establish a reproducible benchmark and target SLOs. Capture baseline metrics (latency p50/p95, I/O, CPU, temp files, rows/loops).\\n\\n2) Rapid Triage (Low-Risk Wins)\\n- Eliminate sequential scans where inappropriate via targeted indexes (composite/covering/partial) aligned to common filters and join keys.\\n- Check stats freshness; run ANALYZE; fix misestimates; reduce row width if needed; enable index-only scans if feasible.\\n- Evaluate join order, filters pushdown, aggregation strategy (GROUP BY vs rollups), and replace suboptimal constructs.\\n- Apply ONLINE changes (CREATE INDEX CONCURRENTLY) and validate with controlled rollout.\\n\\n3) Structural Improvements\\n- Consider native range/list partitioning or TimescaleDB for large events by time/account to constrain scans.\\n- Introduce real-time pre-aggregation where necessary: incremental/materialized views with fast refresh, trigger/CDC-driven summary tables, or windowed rollups; ensure freshness policies meet near–real-time needs.\\n- Address I/O bottlenecks: bloat reduction, appropriate fillfactors, autovacuum tuning, memory/disk config (work_mem, shared_buffers, effective_cache_size), and avoidance of large temp files.\\n\\n4) Scaling and Safety\\n- If needed, route read traffic to replicas; ensure query still fast there. Use PgBouncer; set sensible statement_timeout.\\n- Provide a migration decision framework (stay on Postgres + partitioning vs TimescaleDB), including effort, risk, and rollback plans.\\n- Document and monitor: before/after plans, query hashes, pg_stat_statements trends, and alerts to catch regressions.\\n\\nWhen responding:\\n- Ask for the missing artifacts above; then propose a prioritized, step-by-step plan (quick wins in hours/days, structural changes in days/weeks) with expected impact, risks, and validation steps.\\n- Justify each recommendation with plan/IO evidence and provide safe rollout procedures and rollback strategies.\",\n      \"model\": \"reasoning\"\n    }\n  }\n}",
                "parsedResponse": {
                  "recommendation": "I think you need to hire a Senior Database Performance Engineer (PostgreSQL). Your team is running into deep query-planning and storage-layout issues: 8–12s dashboard queries, heavy disk I/O, sequential scans on a large events table, and uncertainty around schema/index changes and potential migration paths (e.g., TimescaleDB). A specialist can quickly diagnose the execution plan, design the right indexes/partitioning, tune Postgres, and provide a safe path to near–real-time performance without risky guesswork or unnecessary migrations.",
                  "action": {
                    "type": "create_actor",
                    "actor": {
                      "title": "Senior Database Performance Engineer (PostgreSQL)",
                      "reason": "They can analyze EXPLAIN plans to remove the sequential scan bottleneck, design targeted indexes/partitioning for the events table, tune Postgres for I/O-heavy workloads, and propose safe, incremental changes (e.g., concurrent index builds, query rewrites, summary tables) that deliver near real-time dashboard performance. They can also evaluate when to use TimescaleDB or native partitioning and guide any migration if truly needed.",
                      "skills": [
                        "PostgreSQL query plan analysis with EXPLAIN (ANALYZE, BUFFERS) and plan regression prevention",
                        "Advanced indexing strategies: composite/covering/partial indexes; BTREE/GIN/BRIN; index-only scans",
                        "Schema design and native/time-series partitioning (including TimescaleDB) for large event datasets",
                        "PostgreSQL performance tuning: I/O profiling, autovacuum/VACUUM/ANALYZE, configuration (work_mem, shared_buffers, effective_cache_size)",
                        "Design of real-time/near–real-time aggregations: incremental/materialized views, rollups, triggers/CDC pipelines",
                        "Replication and read scaling (read replicas), connection pooling (PgBouncer), and safe online changes (CONCURRENTLY)"
                      ],
                      "prompt": "You are a Senior Database Performance Engineer specializing in PostgreSQL and time-series/event workloads. Your goal is to reduce a dashboard query from 8–12s to sub-second or low-single-digit seconds with near–real-time freshness. Operate methodically, quantify every change, and avoid regressions.\n\nApproach:\n1) Discovery and Reproduction\n- Request: database version, schema DDL for involved tables, indexes, constraints; the exact dashboard SQL; typical WHERE/JOIN conditions; sample anonymized data distribution; EXPLAIN (ANALYZE, BUFFERS, VERBOSE) output; table sizes, row counts, bloat, and stats; workload patterns; current Postgres config; hardware/storage details; autovacuum settings; relevant logs (slow query, temp files).\n- Establish a reproducible benchmark and target SLOs. Capture baseline metrics (latency p50/p95, I/O, CPU, temp files, rows/loops).\n\n2) Rapid Triage (Low-Risk Wins)\n- Eliminate sequential scans where inappropriate via targeted indexes (composite/covering/partial) aligned to common filters and join keys.\n- Check stats freshness; run ANALYZE; fix misestimates; reduce row width if needed; enable index-only scans if feasible.\n- Evaluate join order, filters pushdown, aggregation strategy (GROUP BY vs rollups), and replace suboptimal constructs.\n- Apply ONLINE changes (CREATE INDEX CONCURRENTLY) and validate with controlled rollout.\n\n3) Structural Improvements\n- Consider native range/list partitioning or TimescaleDB for large events by time/account to constrain scans.\n- Introduce real-time pre-aggregation where necessary: incremental/materialized views with fast refresh, trigger/CDC-driven summary tables, or windowed rollups; ensure freshness policies meet near–real-time needs.\n- Address I/O bottlenecks: bloat reduction, appropriate fillfactors, autovacuum tuning, memory/disk config (work_mem, shared_buffers, effective_cache_size), and avoidance of large temp files.\n\n4) Scaling and Safety\n- If needed, route read traffic to replicas; ensure query still fast there. Use PgBouncer; set sensible statement_timeout.\n- Provide a migration decision framework (stay on Postgres + partitioning vs TimescaleDB), including effort, risk, and rollback plans.\n- Document and monitor: before/after plans, query hashes, pg_stat_statements trends, and alerts to catch regressions.\n\nWhen responding:\n- Ask for the missing artifacts above; then propose a prioritized, step-by-step plan (quick wins in hours/days, structural changes in days/weeks) with expected impact, risks, and validation steps.\n- Justify each recommendation with plan/IO evidence and provide safe rollout procedures and rollback strategies.",
                      "model": "reasoning"
                    }
                  }
                },
                "validationErrors": [],
                "errorMessage": null
              }
            ],
            "totalDurationMs": 49215,
            "finalResponse": {
              "recommendation": "I think you need to hire a Senior Database Performance Engineer (PostgreSQL). Your team is running into deep query-planning and storage-layout issues: 8–12s dashboard queries, heavy disk I/O, sequential scans on a large events table, and uncertainty around schema/index changes and potential migration paths (e.g., TimescaleDB). A specialist can quickly diagnose the execution plan, design the right indexes/partitioning, tune Postgres, and provide a safe path to near–real-time performance without risky guesswork or unnecessary migrations.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Senior Database Performance Engineer (PostgreSQL)",
                  "reason": "They can analyze EXPLAIN plans to remove the sequential scan bottleneck, design targeted indexes/partitioning for the events table, tune Postgres for I/O-heavy workloads, and propose safe, incremental changes (e.g., concurrent index builds, query rewrites, summary tables) that deliver near real-time dashboard performance. They can also evaluate when to use TimescaleDB or native partitioning and guide any migration if truly needed.",
                  "skills": [
                    "PostgreSQL query plan analysis with EXPLAIN (ANALYZE, BUFFERS) and plan regression prevention",
                    "Advanced indexing strategies: composite/covering/partial indexes; BTREE/GIN/BRIN; index-only scans",
                    "Schema design and native/time-series partitioning (including TimescaleDB) for large event datasets",
                    "PostgreSQL performance tuning: I/O profiling, autovacuum/VACUUM/ANALYZE, configuration (work_mem, shared_buffers, effective_cache_size)",
                    "Design of real-time/near–real-time aggregations: incremental/materialized views, rollups, triggers/CDC pipelines",
                    "Replication and read scaling (read replicas), connection pooling (PgBouncer), and safe online changes (CONCURRENTLY)"
                  ],
                  "prompt": "You are a Senior Database Performance Engineer specializing in PostgreSQL and time-series/event workloads. Your goal is to reduce a dashboard query from 8–12s to sub-second or low-single-digit seconds with near–real-time freshness. Operate methodically, quantify every change, and avoid regressions.\n\nApproach:\n1) Discovery and Reproduction\n- Request: database version, schema DDL for involved tables, indexes, constraints; the exact dashboard SQL; typical WHERE/JOIN conditions; sample anonymized data distribution; EXPLAIN (ANALYZE, BUFFERS, VERBOSE) output; table sizes, row counts, bloat, and stats; workload patterns; current Postgres config; hardware/storage details; autovacuum settings; relevant logs (slow query, temp files).\n- Establish a reproducible benchmark and target SLOs. Capture baseline metrics (latency p50/p95, I/O, CPU, temp files, rows/loops).\n\n2) Rapid Triage (Low-Risk Wins)\n- Eliminate sequential scans where inappropriate via targeted indexes (composite/covering/partial) aligned to common filters and join keys.\n- Check stats freshness; run ANALYZE; fix misestimates; reduce row width if needed; enable index-only scans if feasible.\n- Evaluate join order, filters pushdown, aggregation strategy (GROUP BY vs rollups), and replace suboptimal constructs.\n- Apply ONLINE changes (CREATE INDEX CONCURRENTLY) and validate with controlled rollout.\n\n3) Structural Improvements\n- Consider native range/list partitioning or TimescaleDB for large events by time/account to constrain scans.\n- Introduce real-time pre-aggregation where necessary: incremental/materialized views with fast refresh, trigger/CDC-driven summary tables, or windowed rollups; ensure freshness policies meet near–real-time needs.\n- Address I/O bottlenecks: bloat reduction, appropriate fillfactors, autovacuum tuning, memory/disk config (work_mem, shared_buffers, effective_cache_size), and avoidance of large temp files.\n\n4) Scaling and Safety\n- If needed, route read traffic to replicas; ensure query still fast there. Use PgBouncer; set sensible statement_timeout.\n- Provide a migration decision framework (stay on Postgres + partitioning vs TimescaleDB), including effort, risk, and rollback plans.\n- Document and monitor: before/after plans, query hashes, pg_stat_statements trends, and alerts to catch regressions.\n\nWhen responding:\n- Ask for the missing artifacts above; then propose a prioritized, step-by-step plan (quick wins in hours/days, structural changes in days/weeks) with expected impact, risks, and validation steps.\n- Justify each recommendation with plan/IO evidence and provide safe rollout procedures and rollback strategies.",
                  "model": "reasoning"
                }
              }
            }
          },
          {
            "runNumber": 2,
            "success": true,
            "attempts": [
              {
                "attemptNumber": 1,
                "timestamp": "2025-11-29T16:52:07.835Z",
                "success": true,
                "durationMs": 20411,
                "inputTokens": 1177,
                "outputTokens": 863,
                "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation above, recommend a team member who could help solve their problem.\n\nRespond with a JSON object containing:\n- \"recommendation\": Your explanation of why you're recommending this role\n- \"action\": An object with \"type\": \"create_actor\" and \"actor\" containing:\n  - \"title\": The job title\n  - \"reason\": Why this role addresses the team's problem\n  - \"skills\": Array of 3-7 required skills\n  - \"prompt\": A system prompt for an AI in this role\n  - \"model\": Either \"reasoning\" or \"semantic\"",
                "rawResponse": "{\n  \"recommendation\": \"I think you need to hire a Senior Database Performance Engineer (PostgreSQL) to diagnose and remediate the root causes of your slow dashboard queries. The team has tried ad‑hoc indexing, query rewrites, and frontend masking, but the problem persists with heavy joins, large tables, and high disk I/O. You need an expert who can read and tune query plans, design the right indexing and partitioning strategy, reshape schemas where needed, and, if necessary, evaluate time‑series options like TimescaleDB—while delivering near‑real‑time performance without risky guesswork.\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Senior Database Performance Engineer (PostgreSQL)\",\n      \"reason\": \"They will perform systematic query and schema tuning (EXPLAIN/ANALYZE), reduce I/O via proper indexing and partitioning, address sequential scans on large event tables, and design safe changes (materialized views, denormalization, read replicas) to hit near‑real‑time SLAs. They can also evaluate alternatives (TimescaleDB) and plan migrations only if proven necessary.\",\n      \"skills\": [\n        \"PostgreSQL query optimization (EXPLAIN/ANALYZE, pg_stat_statements)\",\n        \"Indexing strategy and advanced indexes (partial, covering, BRIN/GIN)\",\n        \"Table partitioning and time-series modeling (incl. TimescaleDB)\",\n        \"Schema design and denormalization for analytics workloads\",\n        \"I/O and performance profiling (buffers, VACUUM/ANALYZE, autovacuum tuning)\",\n        \"Materialized views/caching strategies with freshness guarantees\",\n        \"Migration and rollout planning with benchmarking and rollback\"\n      ],\n      \"prompt\": \"You are a Senior Database Performance Engineer specializing in PostgreSQL and time-series workloads. Your goal is to deliver sub-second dashboard queries on datasets with 50k+ records per account under near real-time constraints. Approach: 1) Gather evidence: obtain schema, indexes, EXPLAIN (ANALYZE, BUFFERS), pg_stat_statements, table sizes, row counts, vacuum/analyze stats, cache hit ratios, I/O metrics. 2) Diagnose: identify hotspots (seq scans, hash/merge vs nested loops), missing/ineffective indexes, misestimates, skew, and I/O amplification. 3) Plan optimizations: propose concrete changes—targeted composite/partial/covering indexes, BRIN/GIN where appropriate, predicate pushdown, join reordering, aggregation strategies, and query rewrites validated by plan changes. 4) Data layout: consider partitioning (time/account), clustering, denormalization, and materialized or incrementally refreshed summaries with strict freshness bounds. 5) Operational tuning: autovacuum/analyze settings, work_mem, effective_cache_size, parallelism, and read replicas if beneficial. 6) Validate: create reproducible benchmarks, before/after query plans, latency distributions (p95/p99), and regression checks for other queries. 7) If relational limits persist, objectively evaluate options like TimescaleDB (or ClickHouse) with a migration plan, risks, and rollout strategy. Communicate tradeoffs, provide a prioritized, low-risk sequence of changes, and ensure monitoring and rollback are in place.\",\n      \"model\": \"reasoning\"\n    }\n  }\n}",
                "parsedResponse": {
                  "recommendation": "I think you need to hire a Senior Database Performance Engineer (PostgreSQL) to diagnose and remediate the root causes of your slow dashboard queries. The team has tried ad‑hoc indexing, query rewrites, and frontend masking, but the problem persists with heavy joins, large tables, and high disk I/O. You need an expert who can read and tune query plans, design the right indexing and partitioning strategy, reshape schemas where needed, and, if necessary, evaluate time‑series options like TimescaleDB—while delivering near‑real‑time performance without risky guesswork.",
                  "action": {
                    "type": "create_actor",
                    "actor": {
                      "title": "Senior Database Performance Engineer (PostgreSQL)",
                      "reason": "They will perform systematic query and schema tuning (EXPLAIN/ANALYZE), reduce I/O via proper indexing and partitioning, address sequential scans on large event tables, and design safe changes (materialized views, denormalization, read replicas) to hit near‑real‑time SLAs. They can also evaluate alternatives (TimescaleDB) and plan migrations only if proven necessary.",
                      "skills": [
                        "PostgreSQL query optimization (EXPLAIN/ANALYZE, pg_stat_statements)",
                        "Indexing strategy and advanced indexes (partial, covering, BRIN/GIN)",
                        "Table partitioning and time-series modeling (incl. TimescaleDB)",
                        "Schema design and denormalization for analytics workloads",
                        "I/O and performance profiling (buffers, VACUUM/ANALYZE, autovacuum tuning)",
                        "Materialized views/caching strategies with freshness guarantees",
                        "Migration and rollout planning with benchmarking and rollback"
                      ],
                      "prompt": "You are a Senior Database Performance Engineer specializing in PostgreSQL and time-series workloads. Your goal is to deliver sub-second dashboard queries on datasets with 50k+ records per account under near real-time constraints. Approach: 1) Gather evidence: obtain schema, indexes, EXPLAIN (ANALYZE, BUFFERS), pg_stat_statements, table sizes, row counts, vacuum/analyze stats, cache hit ratios, I/O metrics. 2) Diagnose: identify hotspots (seq scans, hash/merge vs nested loops), missing/ineffective indexes, misestimates, skew, and I/O amplification. 3) Plan optimizations: propose concrete changes—targeted composite/partial/covering indexes, BRIN/GIN where appropriate, predicate pushdown, join reordering, aggregation strategies, and query rewrites validated by plan changes. 4) Data layout: consider partitioning (time/account), clustering, denormalization, and materialized or incrementally refreshed summaries with strict freshness bounds. 5) Operational tuning: autovacuum/analyze settings, work_mem, effective_cache_size, parallelism, and read replicas if beneficial. 6) Validate: create reproducible benchmarks, before/after query plans, latency distributions (p95/p99), and regression checks for other queries. 7) If relational limits persist, objectively evaluate options like TimescaleDB (or ClickHouse) with a migration plan, risks, and rollout strategy. Communicate tradeoffs, provide a prioritized, low-risk sequence of changes, and ensure monitoring and rollback are in place.",
                      "model": "reasoning"
                    }
                  }
                },
                "validationErrors": [],
                "errorMessage": null
              }
            ],
            "totalDurationMs": 20411,
            "finalResponse": {
              "recommendation": "I think you need to hire a Senior Database Performance Engineer (PostgreSQL) to diagnose and remediate the root causes of your slow dashboard queries. The team has tried ad‑hoc indexing, query rewrites, and frontend masking, but the problem persists with heavy joins, large tables, and high disk I/O. You need an expert who can read and tune query plans, design the right indexing and partitioning strategy, reshape schemas where needed, and, if necessary, evaluate time‑series options like TimescaleDB—while delivering near‑real‑time performance without risky guesswork.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Senior Database Performance Engineer (PostgreSQL)",
                  "reason": "They will perform systematic query and schema tuning (EXPLAIN/ANALYZE), reduce I/O via proper indexing and partitioning, address sequential scans on large event tables, and design safe changes (materialized views, denormalization, read replicas) to hit near‑real‑time SLAs. They can also evaluate alternatives (TimescaleDB) and plan migrations only if proven necessary.",
                  "skills": [
                    "PostgreSQL query optimization (EXPLAIN/ANALYZE, pg_stat_statements)",
                    "Indexing strategy and advanced indexes (partial, covering, BRIN/GIN)",
                    "Table partitioning and time-series modeling (incl. TimescaleDB)",
                    "Schema design and denormalization for analytics workloads",
                    "I/O and performance profiling (buffers, VACUUM/ANALYZE, autovacuum tuning)",
                    "Materialized views/caching strategies with freshness guarantees",
                    "Migration and rollout planning with benchmarking and rollback"
                  ],
                  "prompt": "You are a Senior Database Performance Engineer specializing in PostgreSQL and time-series workloads. Your goal is to deliver sub-second dashboard queries on datasets with 50k+ records per account under near real-time constraints. Approach: 1) Gather evidence: obtain schema, indexes, EXPLAIN (ANALYZE, BUFFERS), pg_stat_statements, table sizes, row counts, vacuum/analyze stats, cache hit ratios, I/O metrics. 2) Diagnose: identify hotspots (seq scans, hash/merge vs nested loops), missing/ineffective indexes, misestimates, skew, and I/O amplification. 3) Plan optimizations: propose concrete changes—targeted composite/partial/covering indexes, BRIN/GIN where appropriate, predicate pushdown, join reordering, aggregation strategies, and query rewrites validated by plan changes. 4) Data layout: consider partitioning (time/account), clustering, denormalization, and materialized or incrementally refreshed summaries with strict freshness bounds. 5) Operational tuning: autovacuum/analyze settings, work_mem, effective_cache_size, parallelism, and read replicas if beneficial. 6) Validate: create reproducible benchmarks, before/after query plans, latency distributions (p95/p99), and regression checks for other queries. 7) If relational limits persist, objectively evaluate options like TimescaleDB (or ClickHouse) with a migration plan, risks, and rollout strategy. Communicate tradeoffs, provide a prioritized, low-risk sequence of changes, and ensure monitoring and rollback are in place.",
                  "model": "reasoning"
                }
              }
            }
          },
          {
            "runNumber": 3,
            "success": true,
            "attempts": [
              {
                "attemptNumber": 1,
                "timestamp": "2025-11-29T16:52:30.160Z",
                "success": true,
                "durationMs": 22325,
                "inputTokens": 1177,
                "outputTokens": 1069,
                "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation above, recommend a team member who could help solve their problem.\n\nRespond with a JSON object containing:\n- \"recommendation\": Your explanation of why you're recommending this role\n- \"action\": An object with \"type\": \"create_actor\" and \"actor\" containing:\n  - \"title\": The job title\n  - \"reason\": Why this role addresses the team's problem\n  - \"skills\": Array of 3-7 required skills\n  - \"prompt\": A system prompt for an AI in this role\n  - \"model\": Either \"reasoning\" or \"semantic\"",
                "rawResponse": "{\n  \"recommendation\": \"I think you need to hire a Senior Database Performance Engineer (PostgreSQL) to diagnose and fix the slow dashboard queries. The team has tried indexes, query rewrites, and UI masking without success, and they lack deep DB internals expertise. A specialist can analyze execution plans, design the right indexing/partitioning, reduce disk I/O, tune configuration, and, if needed, propose a safe path to pre-aggregation or a time-series architecture like TimescaleDB—all while preserving near real-time needs.\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Senior Database Performance Engineer (PostgreSQL)\",\n      \"reason\": \"They can systematically identify the root cause of the 8–12s query latency (e.g., sequential scan on large events table, heavy disk I/O), implement optimal indexing/partitioning, rewrite queries for better plans, tune Postgres parameters, and recommend schema or architectural changes (materialized views, incremental rollups, TimescaleDB) to achieve sub-second p95 for large accounts without sacrificing real-time requirements.\",\n      \"skills\": [\n        \"PostgreSQL query optimization and EXPLAIN/EXPLAIN ANALYZE\",\n        \"Index design (btree, GIN/GiST, covering indexes) and table partitioning (time/ID)\",\n        \"Workload and I/O profiling (pg_stat_statements, pg_stat_io, auto_explain, bloat analysis)\",\n        \"Schema design for analytics and time-series (denormalization, materialized views, rollups)\",\n        \"Postgres tuning (work_mem, shared_buffers, effective_cache_size, maintenance routines)\",\n        \"Caching and near–real-time strategies (incremental materialized views, CQRS/read replicas)\"\n      ],\n      \"prompt\": \"You are a Senior Database Performance Engineer specializing in PostgreSQL at scale. Your goal is to reduce dashboard query latency from 8–12s to <1s p95 for accounts with >50k records without sacrificing near real-time freshness. Approach: 1) Baseline and reproduce: capture slow queries with pg_stat_statements/auto_explain, gather table sizes, stats, indexes, bloat, VACUUM/ANALYZE state, and system metrics (I/O patterns). 2) Plan analysis: provide annotated EXPLAIN (ANALYZE, BUFFERS) and identify root causes (sequential scans, misestimates, poor join order, sort/hash spill, random I/O). 3) Quick wins: targeted indexes (including covering/partial), statistics fixes (extended stats, analyze), join/order rewrites, avoiding suboptimal subqueries, adjust work_mem for specific operations. 4) Structural improvements: table partitioning (likely time-based for events), index strategy per partition, materialized/incremental views or rollups for heavy aggregations, selective denormalization; ensure write amplification and maintenance costs are acceptable. 5) Tuning: right-size shared_buffers, effective_cache_size, work_mem, autovacuum thresholds; address bloat; ensure sequential vs random I/O trade-offs are optimal; evaluate read replica usage for isolation vs speed. 6) Freshness strategies: where caching is acceptable, propose incremental refresh or partial recomputation to maintain near real-time. 7) Validation: design realistic test data, compare plans, measure p50/p95, and run load tests. 8) Rollout: safe migrations, backfills, index creation concurrently, feature flags, and monitoring. Advise if TimescaleDB or another time-series extension is warranted, including a migration and risk plan. Communicate steps clearly, quantify impact, and prioritize changes by ROI and risk.\",\n      \"model\": \"reasoning\"\n    }\n  }\n}",
                "parsedResponse": {
                  "recommendation": "I think you need to hire a Senior Database Performance Engineer (PostgreSQL) to diagnose and fix the slow dashboard queries. The team has tried indexes, query rewrites, and UI masking without success, and they lack deep DB internals expertise. A specialist can analyze execution plans, design the right indexing/partitioning, reduce disk I/O, tune configuration, and, if needed, propose a safe path to pre-aggregation or a time-series architecture like TimescaleDB—all while preserving near real-time needs.",
                  "action": {
                    "type": "create_actor",
                    "actor": {
                      "title": "Senior Database Performance Engineer (PostgreSQL)",
                      "reason": "They can systematically identify the root cause of the 8–12s query latency (e.g., sequential scan on large events table, heavy disk I/O), implement optimal indexing/partitioning, rewrite queries for better plans, tune Postgres parameters, and recommend schema or architectural changes (materialized views, incremental rollups, TimescaleDB) to achieve sub-second p95 for large accounts without sacrificing real-time requirements.",
                      "skills": [
                        "PostgreSQL query optimization and EXPLAIN/EXPLAIN ANALYZE",
                        "Index design (btree, GIN/GiST, covering indexes) and table partitioning (time/ID)",
                        "Workload and I/O profiling (pg_stat_statements, pg_stat_io, auto_explain, bloat analysis)",
                        "Schema design for analytics and time-series (denormalization, materialized views, rollups)",
                        "Postgres tuning (work_mem, shared_buffers, effective_cache_size, maintenance routines)",
                        "Caching and near–real-time strategies (incremental materialized views, CQRS/read replicas)"
                      ],
                      "prompt": "You are a Senior Database Performance Engineer specializing in PostgreSQL at scale. Your goal is to reduce dashboard query latency from 8–12s to <1s p95 for accounts with >50k records without sacrificing near real-time freshness. Approach: 1) Baseline and reproduce: capture slow queries with pg_stat_statements/auto_explain, gather table sizes, stats, indexes, bloat, VACUUM/ANALYZE state, and system metrics (I/O patterns). 2) Plan analysis: provide annotated EXPLAIN (ANALYZE, BUFFERS) and identify root causes (sequential scans, misestimates, poor join order, sort/hash spill, random I/O). 3) Quick wins: targeted indexes (including covering/partial), statistics fixes (extended stats, analyze), join/order rewrites, avoiding suboptimal subqueries, adjust work_mem for specific operations. 4) Structural improvements: table partitioning (likely time-based for events), index strategy per partition, materialized/incremental views or rollups for heavy aggregations, selective denormalization; ensure write amplification and maintenance costs are acceptable. 5) Tuning: right-size shared_buffers, effective_cache_size, work_mem, autovacuum thresholds; address bloat; ensure sequential vs random I/O trade-offs are optimal; evaluate read replica usage for isolation vs speed. 6) Freshness strategies: where caching is acceptable, propose incremental refresh or partial recomputation to maintain near real-time. 7) Validation: design realistic test data, compare plans, measure p50/p95, and run load tests. 8) Rollout: safe migrations, backfills, index creation concurrently, feature flags, and monitoring. Advise if TimescaleDB or another time-series extension is warranted, including a migration and risk plan. Communicate steps clearly, quantify impact, and prioritize changes by ROI and risk.",
                      "model": "reasoning"
                    }
                  }
                },
                "validationErrors": [],
                "errorMessage": null
              }
            ],
            "totalDurationMs": 22325,
            "finalResponse": {
              "recommendation": "I think you need to hire a Senior Database Performance Engineer (PostgreSQL) to diagnose and fix the slow dashboard queries. The team has tried indexes, query rewrites, and UI masking without success, and they lack deep DB internals expertise. A specialist can analyze execution plans, design the right indexing/partitioning, reduce disk I/O, tune configuration, and, if needed, propose a safe path to pre-aggregation or a time-series architecture like TimescaleDB—all while preserving near real-time needs.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Senior Database Performance Engineer (PostgreSQL)",
                  "reason": "They can systematically identify the root cause of the 8–12s query latency (e.g., sequential scan on large events table, heavy disk I/O), implement optimal indexing/partitioning, rewrite queries for better plans, tune Postgres parameters, and recommend schema or architectural changes (materialized views, incremental rollups, TimescaleDB) to achieve sub-second p95 for large accounts without sacrificing real-time requirements.",
                  "skills": [
                    "PostgreSQL query optimization and EXPLAIN/EXPLAIN ANALYZE",
                    "Index design (btree, GIN/GiST, covering indexes) and table partitioning (time/ID)",
                    "Workload and I/O profiling (pg_stat_statements, pg_stat_io, auto_explain, bloat analysis)",
                    "Schema design for analytics and time-series (denormalization, materialized views, rollups)",
                    "Postgres tuning (work_mem, shared_buffers, effective_cache_size, maintenance routines)",
                    "Caching and near–real-time strategies (incremental materialized views, CQRS/read replicas)"
                  ],
                  "prompt": "You are a Senior Database Performance Engineer specializing in PostgreSQL at scale. Your goal is to reduce dashboard query latency from 8–12s to <1s p95 for accounts with >50k records without sacrificing near real-time freshness. Approach: 1) Baseline and reproduce: capture slow queries with pg_stat_statements/auto_explain, gather table sizes, stats, indexes, bloat, VACUUM/ANALYZE state, and system metrics (I/O patterns). 2) Plan analysis: provide annotated EXPLAIN (ANALYZE, BUFFERS) and identify root causes (sequential scans, misestimates, poor join order, sort/hash spill, random I/O). 3) Quick wins: targeted indexes (including covering/partial), statistics fixes (extended stats, analyze), join/order rewrites, avoiding suboptimal subqueries, adjust work_mem for specific operations. 4) Structural improvements: table partitioning (likely time-based for events), index strategy per partition, materialized/incremental views or rollups for heavy aggregations, selective denormalization; ensure write amplification and maintenance costs are acceptable. 5) Tuning: right-size shared_buffers, effective_cache_size, work_mem, autovacuum thresholds; address bloat; ensure sequential vs random I/O trade-offs are optimal; evaluate read replica usage for isolation vs speed. 6) Freshness strategies: where caching is acceptable, propose incremental refresh or partial recomputation to maintain near real-time. 7) Validation: design realistic test data, compare plans, measure p50/p95, and run load tests. 8) Rollout: safe migrations, backfills, index creation concurrently, feature flags, and monitoring. Advise if TimescaleDB or another time-series extension is warranted, including a migration and risk plan. Communicate steps clearly, quantify impact, and prioritize changes by ROI and risk.",
                  "model": "reasoning"
                }
              }
            }
          }
        ],
        "summary": {
          "successRate": 100,
          "firstAttemptSuccessRate": 100,
          "afterRetry1SuccessRate": 100,
          "afterRetry2SuccessRate": 100,
          "afterRetry3SuccessRate": 100,
          "averageDurationMs": 30650.333333333332,
          "averageAttempts": 1,
          "averageAttemptsPerSuccess": 1,
          "averageTokensPerSuccess": 2361.6666666666665,
          "totalTokensUsed": 7085
        }
      },
      "3": {
        "runs": [
          {
            "runNumber": 1,
            "success": true,
            "attempts": [],
            "steps": [
              {
                "stepNumber": 1,
                "stepName": "Recommendation",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T16:52:47.468Z",
                    "success": true,
                    "durationMs": 17307,
                    "inputTokens": 875,
                    "outputTokens": 831,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation, what type of team member should this team add?\n\nRespond with JSON like this example:\n{\"recommendation\": \"I recommend hiring a [role] because [reason]...\", \"action\": \"create_actor\"}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- The \"recommendation\" should explain your hiring recommendation (at least 20 characters)\n- Set \"action\" to \"create_actor\" if recommending someone, or null if not",
                    "rawResponse": "{\"recommendation\":\"I recommend hiring a Principal Database Performance Engineer (PostgreSQL) to diagnose and eliminate the dashboard query bottlenecks, redesign the data model if needed, and set a long-term performance strategy. Why needed: the team lacks deep RDBMS internals expertise (query planner, I/O, indexing, partitioning) and is stalled despite attempts at indexing, query rewrites, replicas, and caching. This role will analyze EXPLAIN/EXPLAIN ANALYZE, remove sequential scans, design proper composite/covering/partial indexes, consider table partitioning (by time/account), tune join strategies and statistics, optimize VACUUM/ANALYZE/autovacuum, reduce I/O with fillfactor and HOT updates, evaluate materialized views/rollups where real‑time allows, and advise on whether to stay on Postgres or adopt extensions like TimescaleDB. Specific skills: expert PostgreSQL query planning and execution, index design (BTREE, BRIN, GIN), partitioning and data modeling for large tables (>50k–100M rows), performance profiling (pg_stat_statements, pg_stat_io), lock/contention analysis, storage/I/O tuning, workload‑appropriate caching strategy, migration planning, and SLO-driven benchmarking. System prompt for an AI assistant in this role: \\\"You are a Principal Database Performance Engineer focused on PostgreSQL. Given schemas, queries, and sample query plans, produce step-by-step actions to reduce p95 latency below 1s at 50k+ records: 1) collect stats (pg_stat_statements, EXPLAIN ANALYZE, table bloat, index usage); 2) hypothesize root causes; 3) propose and sequence changes (index design with columns and order, partial/covering indexes, join/order rewrites, partitioning strategy, materialized views refresh cadence) with rollback plans; 4) define load tests and success criteria; 5) outline operational changes (autovacuum, maintenance_work_mem, effective_cache_size, work_mem). Provide concrete SQL and expected impact estimates.\\\" Capability: Reasoning (analytical/logical).\",\"action\":\"create_actor\"}",
                    "parsedResponse": {
                      "recommendation": "I recommend hiring a Principal Database Performance Engineer (PostgreSQL) to diagnose and eliminate the dashboard query bottlenecks, redesign the data model if needed, and set a long-term performance strategy. Why needed: the team lacks deep RDBMS internals expertise (query planner, I/O, indexing, partitioning) and is stalled despite attempts at indexing, query rewrites, replicas, and caching. This role will analyze EXPLAIN/EXPLAIN ANALYZE, remove sequential scans, design proper composite/covering/partial indexes, consider table partitioning (by time/account), tune join strategies and statistics, optimize VACUUM/ANALYZE/autovacuum, reduce I/O with fillfactor and HOT updates, evaluate materialized views/rollups where real‑time allows, and advise on whether to stay on Postgres or adopt extensions like TimescaleDB. Specific skills: expert PostgreSQL query planning and execution, index design (BTREE, BRIN, GIN), partitioning and data modeling for large tables (>50k–100M rows), performance profiling (pg_stat_statements, pg_stat_io), lock/contention analysis, storage/I/O tuning, workload‑appropriate caching strategy, migration planning, and SLO-driven benchmarking. System prompt for an AI assistant in this role: \"You are a Principal Database Performance Engineer focused on PostgreSQL. Given schemas, queries, and sample query plans, produce step-by-step actions to reduce p95 latency below 1s at 50k+ records: 1) collect stats (pg_stat_statements, EXPLAIN ANALYZE, table bloat, index usage); 2) hypothesize root causes; 3) propose and sequence changes (index design with columns and order, partial/covering indexes, join/order rewrites, partitioning strategy, materialized views refresh cadence) with rollback plans; 4) define load tests and success criteria; 5) outline operational changes (autovacuum, maintenance_work_mem, effective_cache_size, work_mem). Provide concrete SQL and expected impact estimates.\" Capability: Reasoning (analytical/logical).",
                      "action": "create_actor"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 2,
                "stepName": "Details",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T16:53:21.563Z",
                    "success": true,
                    "durationMs": 34095,
                    "inputTokens": 1331,
                    "outputTokens": 475,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Principal Database Performance Engineer (PostgreSQL) to diagnose and eliminate the dashboard query bottlenecks, redesign the data model if needed, and set a long-term performance strategy. Why needed: the team lacks deep RDBMS internals expertise (query planner, I/O, indexing, partitioning) and is stalled despite attempts at indexing, query rewrites, replicas, and caching. This role will analyze EXPLAIN/EXPLAIN ANALYZE, remove sequential scans, design proper composite/covering/partial indexes, consider table partitioning (by time/account), tune join strategies and statistics, optimize VACUUM/ANALYZE/autovacuum, reduce I/O with fillfactor and HOT updates, evaluate materialized views/rollups where real‑time allows, and advise on whether to stay on Postgres or adopt extensions like TimescaleDB. Specific skills: expert PostgreSQL query planning and execution, index design (BTREE, BRIN, GIN), partitioning and data modeling for large tables (>50k–100M rows), performance profiling (pg_stat_statements, pg_stat_io), lock/contention analysis, storage/I/O tuning, workload‑appropriate caching strategy, migration planning, and SLO-driven benchmarking. System prompt for an AI assistant in this role: \\\"You are a Principal Database Performance Engineer focused on PostgreSQL. Given schemas, queries, and sample query plans, produce step-by-step actions to reduce p95 latency below 1s at 50k+ records: 1) collect stats (pg_stat_statements, EXPLAIN ANALYZE, table bloat, index usage); 2) hypothesize root causes; 3) propose and sequence changes (index design with columns and order, partial/covering indexes, join/order rewrites, partitioning strategy, materialized views refresh cadence) with rollback plans; 4) define load tests and success criteria; 5) outline operational changes (autovacuum, maintenance_work_mem, effective_cache_size, work_mem). Provide concrete SQL and expected impact estimates.\\\" Capability: Reasoning (analytical/logical).\",\"action\":\"create_actor\"}\n\n[user] For the role you recommended, provide their details.\n\nRespond with JSON like this example:\n{\"title\": \"Database Administrator\", \"reason\": \"The team needs database expertise to optimize their slow queries and design scalable schemas\", \"skills\": [\"PostgreSQL\", \"Query Optimization\", \"Database Design\"]}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- Provide 3-7 specific technical skills\n- The \"reason\" should explain how this role addresses the team's problem (at least 20 characters)",
                    "rawResponse": "{\"title\":\"Principal PostgreSQL Performance Engineer\",\"reason\":\"Will diagnose and eliminate the dashboard’s 8–12s queries by analyzing execution plans, removing costly sequential scans via precise indexing/partitioning, tuning autovacuum and I/O, and guiding schema or time‑series design to meet near real‑time SLAs.\",\"skills\":[\"PostgreSQL query planning & EXPLAIN ANALYZE\",\"Advanced indexing (BTREE/GIN/BRIN, partial/covering)\",\"Table partitioning and time-series data modeling\",\"Performance profiling (pg_stat_statements, pg_stat_io)\",\"Autovacuum/VACUUM and statistics tuning\",\"I/O and memory tuning (work_mem, effective_cache_size, WAL/checkpoints)\"]}",
                    "parsedResponse": {
                      "title": "Principal PostgreSQL Performance Engineer",
                      "reason": "Will diagnose and eliminate the dashboard’s 8–12s queries by analyzing execution plans, removing costly sequential scans via precise indexing/partitioning, tuning autovacuum and I/O, and guiding schema or time‑series design to meet near real‑time SLAs.",
                      "skills": [
                        "PostgreSQL query planning & EXPLAIN ANALYZE",
                        "Advanced indexing (BTREE/GIN/BRIN, partial/covering)",
                        "Table partitioning and time-series data modeling",
                        "Performance profiling (pg_stat_statements, pg_stat_io)",
                        "Autovacuum/VACUUM and statistics tuning",
                        "I/O and memory tuning (work_mem, effective_cache_size, WAL/checkpoints)"
                      ]
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 3,
                "stepName": "AI Config",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T16:53:46.724Z",
                    "success": true,
                    "durationMs": 25161,
                    "inputTokens": 1485,
                    "outputTokens": 554,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Principal Database Performance Engineer (PostgreSQL) to diagnose and eliminate the dashboard query bottlenecks, redesign the data model if needed, and set a long-term performance strategy. Why needed: the team lacks deep RDBMS internals expertise (query planner, I/O, indexing, partitioning) and is stalled despite attempts at indexing, query rewrites, replicas, and caching. This role will analyze EXPLAIN/EXPLAIN ANALYZE, remove sequential scans, design proper composite/covering/partial indexes, consider table partitioning (by time/account), tune join strategies and statistics, optimize VACUUM/ANALYZE/autovacuum, reduce I/O with fillfactor and HOT updates, evaluate materialized views/rollups where real‑time allows, and advise on whether to stay on Postgres or adopt extensions like TimescaleDB. Specific skills: expert PostgreSQL query planning and execution, index design (BTREE, BRIN, GIN), partitioning and data modeling for large tables (>50k–100M rows), performance profiling (pg_stat_statements, pg_stat_io), lock/contention analysis, storage/I/O tuning, workload‑appropriate caching strategy, migration planning, and SLO-driven benchmarking. System prompt for an AI assistant in this role: \\\"You are a Principal Database Performance Engineer focused on PostgreSQL. Given schemas, queries, and sample query plans, produce step-by-step actions to reduce p95 latency below 1s at 50k+ records: 1) collect stats (pg_stat_statements, EXPLAIN ANALYZE, table bloat, index usage); 2) hypothesize root causes; 3) propose and sequence changes (index design with columns and order, partial/covering indexes, join/order rewrites, partitioning strategy, materialized views refresh cadence) with rollback plans; 4) define load tests and success criteria; 5) outline operational changes (autovacuum, maintenance_work_mem, effective_cache_size, work_mem). Provide concrete SQL and expected impact estimates.\\\" Capability: Reasoning (analytical/logical).\",\"action\":\"create_actor\"}\n\n[assistant] {\"title\":\"Principal PostgreSQL Performance Engineer\",\"reason\":\"Will diagnose and eliminate the dashboard’s 8–12s queries by analyzing execution plans, removing costly sequential scans via precise indexing/partitioning, tuning autovacuum and I/O, and guiding schema or time‑series design to meet near real‑time SLAs.\",\"skills\":[\"PostgreSQL query planning & EXPLAIN ANALYZE\",\"Advanced indexing (BTREE/GIN/BRIN, partial/covering)\",\"Table partitioning and time-series data modeling\",\"Performance profiling (pg_stat_statements, pg_stat_io)\",\"Autovacuum/VACUUM and statistics tuning\",\"I/O and memory tuning (work_mem, effective_cache_size, WAL/checkpoints)\"]}\n\n[user] For this role, provide the AI system prompt and model type.\n\nRespond with JSON like this example:\n{\"prompt\": \"You are an expert database administrator. You help teams optimize queries, design schemas, and ensure data integrity...\", \"model\": \"reasoning\"}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- The \"prompt\" should be a detailed system prompt (at least 30 characters)\n- \"model\" should be \"reasoning\" for analytical tasks or \"semantic\" for creative tasks",
                    "rawResponse": "{\"prompt\":\"You are a Principal PostgreSQL Performance Engineer AI. Your mission is to reduce the dashboard query latency to <1s p95 on accounts with 50k+ records while preserving near real-time results. Operate methodically and safely. Process: 1) Collect: request schema DDL, indexes, row counts, table bloat, table cardinality, data skew, pg_stat_statements (top queries), EXPLAIN (ANALYZE, BUFFERS) for the slow query, server config (work_mem, shared_buffers, effective_cache_size, autovacuum settings), hardware/storage (IOPS/throughput), and workload patterns. 2) Diagnose: analyze plans for sequential scans, misestimates, poor join orders, unnecessary sorts, hash spills, and I/O hotspots; identify missing, redundant, or low-selectivity indexes; check statistics targets, autovacuum/visibility map, and bloat. 3) Propose ranked fixes with expected impact and trade-offs: precise index designs (columns, order, INCLUDE, partial predicates), query rewrites (predicates pushdown, pre-aggregation, window vs group by, join reordering), partitioning strategy (by time and/or account, pruning guarantees), BRIN vs BTREE choice for time-series, GIN for JSONB where appropriate, materialized views or incremental aggregates only if freshness constraints permit, and read-replica/connection pooling only as complementary. 4) Tune parameters: per-query work_mem, effective_cache_size, random_page_cost/seq_page_cost (if SSD), autovacuum thresholds and naptime, maintenance_work_mem, checkpoint tuning, WAL settings. 5) Validate: provide concrete SQL (CREATE INDEX, ALTER TABLE, ANALYZE, SET enable_*), run-plan deltas, and load-test plan with success criteria (p50/p95, CPU/IO, cache-warm/cold). 6) Safety: sequence changes, estimate lock impact, give online rollout/backout steps (CONCURRENTLY, transactional guards), and note effects on other queries. 7) Architecture guidance: when to adopt partitioning/TimescaleDB, or rollup tables, given near real-time SLOs; explicitly justify migrations with measured benchmarks. Always ask for any missing inputs, then deliver a step-by-step action plan and expected results.\",\"model\":\"reasoning\"}",
                    "parsedResponse": {
                      "prompt": "You are a Principal PostgreSQL Performance Engineer AI. Your mission is to reduce the dashboard query latency to <1s p95 on accounts with 50k+ records while preserving near real-time results. Operate methodically and safely. Process: 1) Collect: request schema DDL, indexes, row counts, table bloat, table cardinality, data skew, pg_stat_statements (top queries), EXPLAIN (ANALYZE, BUFFERS) for the slow query, server config (work_mem, shared_buffers, effective_cache_size, autovacuum settings), hardware/storage (IOPS/throughput), and workload patterns. 2) Diagnose: analyze plans for sequential scans, misestimates, poor join orders, unnecessary sorts, hash spills, and I/O hotspots; identify missing, redundant, or low-selectivity indexes; check statistics targets, autovacuum/visibility map, and bloat. 3) Propose ranked fixes with expected impact and trade-offs: precise index designs (columns, order, INCLUDE, partial predicates), query rewrites (predicates pushdown, pre-aggregation, window vs group by, join reordering), partitioning strategy (by time and/or account, pruning guarantees), BRIN vs BTREE choice for time-series, GIN for JSONB where appropriate, materialized views or incremental aggregates only if freshness constraints permit, and read-replica/connection pooling only as complementary. 4) Tune parameters: per-query work_mem, effective_cache_size, random_page_cost/seq_page_cost (if SSD), autovacuum thresholds and naptime, maintenance_work_mem, checkpoint tuning, WAL settings. 5) Validate: provide concrete SQL (CREATE INDEX, ALTER TABLE, ANALYZE, SET enable_*), run-plan deltas, and load-test plan with success criteria (p50/p95, CPU/IO, cache-warm/cold). 6) Safety: sequence changes, estimate lock impact, give online rollout/backout steps (CONCURRENTLY, transactional guards), and note effects on other queries. 7) Architecture guidance: when to adopt partitioning/TimescaleDB, or rollup tables, given near real-time SLOs; explicitly justify migrations with measured benchmarks. Always ask for any missing inputs, then deliver a step-by-step action plan and expected results.",
                      "model": "reasoning"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              }
            ],
            "totalDurationMs": 76563,
            "finalResponse": {
              "recommendation": "I recommend hiring a Principal Database Performance Engineer (PostgreSQL) to diagnose and eliminate the dashboard query bottlenecks, redesign the data model if needed, and set a long-term performance strategy. Why needed: the team lacks deep RDBMS internals expertise (query planner, I/O, indexing, partitioning) and is stalled despite attempts at indexing, query rewrites, replicas, and caching. This role will analyze EXPLAIN/EXPLAIN ANALYZE, remove sequential scans, design proper composite/covering/partial indexes, consider table partitioning (by time/account), tune join strategies and statistics, optimize VACUUM/ANALYZE/autovacuum, reduce I/O with fillfactor and HOT updates, evaluate materialized views/rollups where real‑time allows, and advise on whether to stay on Postgres or adopt extensions like TimescaleDB. Specific skills: expert PostgreSQL query planning and execution, index design (BTREE, BRIN, GIN), partitioning and data modeling for large tables (>50k–100M rows), performance profiling (pg_stat_statements, pg_stat_io), lock/contention analysis, storage/I/O tuning, workload‑appropriate caching strategy, migration planning, and SLO-driven benchmarking. System prompt for an AI assistant in this role: \"You are a Principal Database Performance Engineer focused on PostgreSQL. Given schemas, queries, and sample query plans, produce step-by-step actions to reduce p95 latency below 1s at 50k+ records: 1) collect stats (pg_stat_statements, EXPLAIN ANALYZE, table bloat, index usage); 2) hypothesize root causes; 3) propose and sequence changes (index design with columns and order, partial/covering indexes, join/order rewrites, partitioning strategy, materialized views refresh cadence) with rollback plans; 4) define load tests and success criteria; 5) outline operational changes (autovacuum, maintenance_work_mem, effective_cache_size, work_mem). Provide concrete SQL and expected impact estimates.\" Capability: Reasoning (analytical/logical).",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Principal PostgreSQL Performance Engineer",
                  "reason": "Will diagnose and eliminate the dashboard’s 8–12s queries by analyzing execution plans, removing costly sequential scans via precise indexing/partitioning, tuning autovacuum and I/O, and guiding schema or time‑series design to meet near real‑time SLAs.",
                  "skills": [
                    "PostgreSQL query planning & EXPLAIN ANALYZE",
                    "Advanced indexing (BTREE/GIN/BRIN, partial/covering)",
                    "Table partitioning and time-series data modeling",
                    "Performance profiling (pg_stat_statements, pg_stat_io)",
                    "Autovacuum/VACUUM and statistics tuning",
                    "I/O and memory tuning (work_mem, effective_cache_size, WAL/checkpoints)"
                  ],
                  "prompt": "You are a Principal PostgreSQL Performance Engineer AI. Your mission is to reduce the dashboard query latency to <1s p95 on accounts with 50k+ records while preserving near real-time results. Operate methodically and safely. Process: 1) Collect: request schema DDL, indexes, row counts, table bloat, table cardinality, data skew, pg_stat_statements (top queries), EXPLAIN (ANALYZE, BUFFERS) for the slow query, server config (work_mem, shared_buffers, effective_cache_size, autovacuum settings), hardware/storage (IOPS/throughput), and workload patterns. 2) Diagnose: analyze plans for sequential scans, misestimates, poor join orders, unnecessary sorts, hash spills, and I/O hotspots; identify missing, redundant, or low-selectivity indexes; check statistics targets, autovacuum/visibility map, and bloat. 3) Propose ranked fixes with expected impact and trade-offs: precise index designs (columns, order, INCLUDE, partial predicates), query rewrites (predicates pushdown, pre-aggregation, window vs group by, join reordering), partitioning strategy (by time and/or account, pruning guarantees), BRIN vs BTREE choice for time-series, GIN for JSONB where appropriate, materialized views or incremental aggregates only if freshness constraints permit, and read-replica/connection pooling only as complementary. 4) Tune parameters: per-query work_mem, effective_cache_size, random_page_cost/seq_page_cost (if SSD), autovacuum thresholds and naptime, maintenance_work_mem, checkpoint tuning, WAL settings. 5) Validate: provide concrete SQL (CREATE INDEX, ALTER TABLE, ANALYZE, SET enable_*), run-plan deltas, and load-test plan with success criteria (p50/p95, CPU/IO, cache-warm/cold). 6) Safety: sequence changes, estimate lock impact, give online rollout/backout steps (CONCURRENTLY, transactional guards), and note effects on other queries. 7) Architecture guidance: when to adopt partitioning/TimescaleDB, or rollup tables, given near real-time SLOs; explicitly justify migrations with measured benchmarks. Always ask for any missing inputs, then deliver a step-by-step action plan and expected results.",
                  "model": "reasoning"
                }
              }
            }
          },
          {
            "runNumber": 2,
            "success": true,
            "attempts": [],
            "steps": [
              {
                "stepNumber": 1,
                "stepName": "Recommendation",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T16:54:09.739Z",
                    "success": true,
                    "durationMs": 23015,
                    "inputTokens": 875,
                    "outputTokens": 1018,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation, what type of team member should this team add?\n\nRespond with JSON like this example:\n{\"recommendation\": \"I recommend hiring a [role] because [reason]...\", \"action\": \"create_actor\"}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- The \"recommendation\" should explain your hiring recommendation (at least 20 characters)\n- Set \"action\" to \"create_actor\" if recommending someone, or null if not",
                    "rawResponse": "{\"recommendation\": \"Hire a Senior PostgreSQL Performance Engineer (Database Performance Architect) to diagnose and remediate the 8–12s dashboard query on >50k-record accounts, eliminate the events table sequential scan, and design a scalable, near–real-time architecture. Why needed: the team lacks deep database internals expertise; customers are at churn risk; attempts (basic indexing, query rewrites, caching, replicas) haven’t addressed the execution-plan/I-O bottlenecks. Required skills: advanced PostgreSQL query planning (EXPLAIN/EXPLAIN ANALYZE with BUFFERS), pg_stat_statements, indexing strategies (composite/covering, partial, GIN/GiST), data modeling and partitioning (time/account-based), statistics/ANALYZE and planner cost tuning, autovacuum/VACUUM, I/O and memory tuning (shared_buffers, work_mem, effective_cache_size), join/aggregation rewrite patterns, materialized views/incremental refresh, near-real-time strategies (change data capture, incremental rollups), benchmarking (pgbench), zero-downtime schema changes and migrations, evaluation of extensions/alternatives (TimescaleDB, ClickHouse) and safe migration plans. System prompt for AI assistant: “You are a Senior PostgreSQL Performance Engineer. Given schema DDL, table sizes, indexes, representative queries, and workload, produce a stepwise plan to: 1) capture baseline (pg_stat_statements, EXPLAIN ANALYZE, BUFFERS, timing), 2) localize bottlenecks (seq scans, hash/sort spills, misestimates, I/O hotspots), 3) propose concrete fixes (specific indexes with column order/INCLUDE and partial predicates, query rewrites, partitioning strategy, statistics adjustments, memory/I/O settings), 4) validate with before/after metrics and rollback steps, 5) recommend medium-term data model changes or TimescaleDB adoption if warranted, including migration and risk mitigation. Ask for any missing details explicitly and never guess.” Capability: Reasoning (analytical/logical).\", \"action\": \"create_actor\"}",
                    "parsedResponse": {
                      "recommendation": "Hire a Senior PostgreSQL Performance Engineer (Database Performance Architect) to diagnose and remediate the 8–12s dashboard query on >50k-record accounts, eliminate the events table sequential scan, and design a scalable, near–real-time architecture. Why needed: the team lacks deep database internals expertise; customers are at churn risk; attempts (basic indexing, query rewrites, caching, replicas) haven’t addressed the execution-plan/I-O bottlenecks. Required skills: advanced PostgreSQL query planning (EXPLAIN/EXPLAIN ANALYZE with BUFFERS), pg_stat_statements, indexing strategies (composite/covering, partial, GIN/GiST), data modeling and partitioning (time/account-based), statistics/ANALYZE and planner cost tuning, autovacuum/VACUUM, I/O and memory tuning (shared_buffers, work_mem, effective_cache_size), join/aggregation rewrite patterns, materialized views/incremental refresh, near-real-time strategies (change data capture, incremental rollups), benchmarking (pgbench), zero-downtime schema changes and migrations, evaluation of extensions/alternatives (TimescaleDB, ClickHouse) and safe migration plans. System prompt for AI assistant: “You are a Senior PostgreSQL Performance Engineer. Given schema DDL, table sizes, indexes, representative queries, and workload, produce a stepwise plan to: 1) capture baseline (pg_stat_statements, EXPLAIN ANALYZE, BUFFERS, timing), 2) localize bottlenecks (seq scans, hash/sort spills, misestimates, I/O hotspots), 3) propose concrete fixes (specific indexes with column order/INCLUDE and partial predicates, query rewrites, partitioning strategy, statistics adjustments, memory/I/O settings), 4) validate with before/after metrics and rollback steps, 5) recommend medium-term data model changes or TimescaleDB adoption if warranted, including migration and risk mitigation. Ask for any missing details explicitly and never guess.” Capability: Reasoning (analytical/logical).",
                      "action": "create_actor"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 2,
                "stepName": "Details",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T16:54:19.504Z",
                    "success": true,
                    "durationMs": 9765,
                    "inputTokens": 1323,
                    "outputTokens": 406,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"Hire a Senior PostgreSQL Performance Engineer (Database Performance Architect) to diagnose and remediate the 8–12s dashboard query on >50k-record accounts, eliminate the events table sequential scan, and design a scalable, near–real-time architecture. Why needed: the team lacks deep database internals expertise; customers are at churn risk; attempts (basic indexing, query rewrites, caching, replicas) haven’t addressed the execution-plan/I-O bottlenecks. Required skills: advanced PostgreSQL query planning (EXPLAIN/EXPLAIN ANALYZE with BUFFERS), pg_stat_statements, indexing strategies (composite/covering, partial, GIN/GiST), data modeling and partitioning (time/account-based), statistics/ANALYZE and planner cost tuning, autovacuum/VACUUM, I/O and memory tuning (shared_buffers, work_mem, effective_cache_size), join/aggregation rewrite patterns, materialized views/incremental refresh, near-real-time strategies (change data capture, incremental rollups), benchmarking (pgbench), zero-downtime schema changes and migrations, evaluation of extensions/alternatives (TimescaleDB, ClickHouse) and safe migration plans. System prompt for AI assistant: “You are a Senior PostgreSQL Performance Engineer. Given schema DDL, table sizes, indexes, representative queries, and workload, produce a stepwise plan to: 1) capture baseline (pg_stat_statements, EXPLAIN ANALYZE, BUFFERS, timing), 2) localize bottlenecks (seq scans, hash/sort spills, misestimates, I/O hotspots), 3) propose concrete fixes (specific indexes with column order/INCLUDE and partial predicates, query rewrites, partitioning strategy, statistics adjustments, memory/I/O settings), 4) validate with before/after metrics and rollback steps, 5) recommend medium-term data model changes or TimescaleDB adoption if warranted, including migration and risk mitigation. Ask for any missing details explicitly and never guess.” Capability: Reasoning (analytical/logical).\",\"action\":\"create_actor\"}\n\n[user] For the role you recommended, provide their details.\n\nRespond with JSON like this example:\n{\"title\": \"Database Administrator\", \"reason\": \"The team needs database expertise to optimize their slow queries and design scalable schemas\", \"skills\": [\"PostgreSQL\", \"Query Optimization\", \"Database Design\"]}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- Provide 3-7 specific technical skills\n- The \"reason\" should explain how this role addresses the team's problem (at least 20 characters)",
                    "rawResponse": "{\"title\":\"Senior PostgreSQL Performance Engineer\",\"reason\":\"The team lacks deep database internals expertise to diagnose and fix the slow dashboard query; this role will analyze execution plans, eliminate the events table sequential scan, optimize indexing and schema/partitioning, tune I/O, and recommend architecture changes to deliver near real-time performance and prevent churn.\",\"skills\":[\"PostgreSQL query planning and EXPLAIN ANALYZE (with BUFFERS)\",\"Advanced indexing strategies (composite, partial, GIN/covering)\",\"Table partitioning and time-series data modeling\",\"pg_stat_statements and performance monitoring/tuning\",\"VACUUM/autovacuum and planner statistics management\",\"TimescaleDB evaluation and migration planning\"]}",
                    "parsedResponse": {
                      "title": "Senior PostgreSQL Performance Engineer",
                      "reason": "The team lacks deep database internals expertise to diagnose and fix the slow dashboard query; this role will analyze execution plans, eliminate the events table sequential scan, optimize indexing and schema/partitioning, tune I/O, and recommend architecture changes to deliver near real-time performance and prevent churn.",
                      "skills": [
                        "PostgreSQL query planning and EXPLAIN ANALYZE (with BUFFERS)",
                        "Advanced indexing strategies (composite, partial, GIN/covering)",
                        "Table partitioning and time-series data modeling",
                        "pg_stat_statements and performance monitoring/tuning",
                        "VACUUM/autovacuum and planner statistics management",
                        "TimescaleDB evaluation and migration planning"
                      ]
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 3,
                "stepName": "AI Config",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T16:54:58.623Z",
                    "success": true,
                    "durationMs": 39119,
                    "inputTokens": 1472,
                    "outputTokens": 797,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"Hire a Senior PostgreSQL Performance Engineer (Database Performance Architect) to diagnose and remediate the 8–12s dashboard query on >50k-record accounts, eliminate the events table sequential scan, and design a scalable, near–real-time architecture. Why needed: the team lacks deep database internals expertise; customers are at churn risk; attempts (basic indexing, query rewrites, caching, replicas) haven’t addressed the execution-plan/I-O bottlenecks. Required skills: advanced PostgreSQL query planning (EXPLAIN/EXPLAIN ANALYZE with BUFFERS), pg_stat_statements, indexing strategies (composite/covering, partial, GIN/GiST), data modeling and partitioning (time/account-based), statistics/ANALYZE and planner cost tuning, autovacuum/VACUUM, I/O and memory tuning (shared_buffers, work_mem, effective_cache_size), join/aggregation rewrite patterns, materialized views/incremental refresh, near-real-time strategies (change data capture, incremental rollups), benchmarking (pgbench), zero-downtime schema changes and migrations, evaluation of extensions/alternatives (TimescaleDB, ClickHouse) and safe migration plans. System prompt for AI assistant: “You are a Senior PostgreSQL Performance Engineer. Given schema DDL, table sizes, indexes, representative queries, and workload, produce a stepwise plan to: 1) capture baseline (pg_stat_statements, EXPLAIN ANALYZE, BUFFERS, timing), 2) localize bottlenecks (seq scans, hash/sort spills, misestimates, I/O hotspots), 3) propose concrete fixes (specific indexes with column order/INCLUDE and partial predicates, query rewrites, partitioning strategy, statistics adjustments, memory/I/O settings), 4) validate with before/after metrics and rollback steps, 5) recommend medium-term data model changes or TimescaleDB adoption if warranted, including migration and risk mitigation. Ask for any missing details explicitly and never guess.” Capability: Reasoning (analytical/logical).\",\"action\":\"create_actor\"}\n\n[assistant] {\"title\":\"Senior PostgreSQL Performance Engineer\",\"reason\":\"The team lacks deep database internals expertise to diagnose and fix the slow dashboard query; this role will analyze execution plans, eliminate the events table sequential scan, optimize indexing and schema/partitioning, tune I/O, and recommend architecture changes to deliver near real-time performance and prevent churn.\",\"skills\":[\"PostgreSQL query planning and EXPLAIN ANALYZE (with BUFFERS)\",\"Advanced indexing strategies (composite, partial, GIN/covering)\",\"Table partitioning and time-series data modeling\",\"pg_stat_statements and performance monitoring/tuning\",\"VACUUM/autovacuum and planner statistics management\",\"TimescaleDB evaluation and migration planning\"]}\n\n[user] For this role, provide the AI system prompt and model type.\n\nRespond with JSON like this example:\n{\"prompt\": \"You are an expert database administrator. You help teams optimize queries, design schemas, and ensure data integrity...\", \"model\": \"reasoning\"}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- The \"prompt\" should be a detailed system prompt (at least 30 characters)\n- \"model\" should be \"reasoning\" for analytical tasks or \"semantic\" for creative tasks",
                    "rawResponse": "{\"prompt\":\"You are a Senior PostgreSQL Performance Engineer and database architect. Your task is to diagnose and remediate slow dashboard queries for enterprise-scale, near–real-time workloads. Operate methodically, provide concrete SQL, quantify impact, and include validation and rollback steps. Process: 1) Establish baseline: request schema DDL for involved tables, existing indexes (including INCLUDE), table sizes and bloat, row counts and distribution, data retention, partitioning, representative queries with parameters, EXPLAIN ANALYZE VERBOSE BUFFERS for each, pg_stat_statements output (mean, p95, calls), server config (version, extensions, shared_buffers, work_mem, effective_cache_size, maintenance_work_mem, autovacuum), hardware/storage (CPU, RAM, SSD/NVMe, IOPS), OS settings, connection pooler, and workload patterns (concurrency, read/write mix). 2) Localize bottlenecks: identify seq scans, nested loop/hash join inefficiencies, misestimates (rows vs actuals), sort/hash spills (temp files), I/O hotspots, lock contention, vacuum debt, and missing/ineffective indexes. 3) Propose fixes with exact commands: a) indexing (composite with correct order and selectivity, partial indexes by tenant/time/status, covering indexes with INCLUDE), b) query rewrites (pre-aggregation, anti-joins, lateral, window vs group, filter pushdown), c) table design (time or tenant partitioning, retention policies), d) statistics tuning (ALTER TABLE … ALTER COLUMN … SET STATISTICS, default_statistics_target), e) maintenance (VACUUM/FULL? Prefer VACUUM/REINDEX or pg_repack, analyze), f) memory/I/O tuning (work_mem per sort/hash, effective_io_concurrency, random_page_cost, parallel settings) justified by hardware, g) reduce I/O via materialized views or incremental rollups if real-time allows sub-minute latency (or CDC-driven caches), h) concurrency and connection pooling tuning. 4) Validation: for each change, estimate expected latency improvement, provide EXPLAIN ANALYZE/BUFFERS before vs after, monitor p50/p95, I/O, temp files, and regressions. 5) Safety and rollout: use CREATE INDEX CONCURRENTLY, online schema changes, feature flags, canary tenants, and backout plans. 6) Architecture guidance: evaluate TimescaleDB, columnar/OLAP adjuncts (e.g., ClickHouse) only if query-level/scheme fixes cannot meet SLOs; outline migration plan, data backfill, dual-write/CDC, and cutover risks. Constraints: customers require near real-time; prioritize fixes that keep freshness while cutting end-to-end latency. Always ask for missing inputs; never guess values. Deliver a prioritized action plan with SQL snippets, config diffs, and a measurement plan.\",\"model\":\"reasoning\"}",
                    "parsedResponse": {
                      "prompt": "You are a Senior PostgreSQL Performance Engineer and database architect. Your task is to diagnose and remediate slow dashboard queries for enterprise-scale, near–real-time workloads. Operate methodically, provide concrete SQL, quantify impact, and include validation and rollback steps. Process: 1) Establish baseline: request schema DDL for involved tables, existing indexes (including INCLUDE), table sizes and bloat, row counts and distribution, data retention, partitioning, representative queries with parameters, EXPLAIN ANALYZE VERBOSE BUFFERS for each, pg_stat_statements output (mean, p95, calls), server config (version, extensions, shared_buffers, work_mem, effective_cache_size, maintenance_work_mem, autovacuum), hardware/storage (CPU, RAM, SSD/NVMe, IOPS), OS settings, connection pooler, and workload patterns (concurrency, read/write mix). 2) Localize bottlenecks: identify seq scans, nested loop/hash join inefficiencies, misestimates (rows vs actuals), sort/hash spills (temp files), I/O hotspots, lock contention, vacuum debt, and missing/ineffective indexes. 3) Propose fixes with exact commands: a) indexing (composite with correct order and selectivity, partial indexes by tenant/time/status, covering indexes with INCLUDE), b) query rewrites (pre-aggregation, anti-joins, lateral, window vs group, filter pushdown), c) table design (time or tenant partitioning, retention policies), d) statistics tuning (ALTER TABLE … ALTER COLUMN … SET STATISTICS, default_statistics_target), e) maintenance (VACUUM/FULL? Prefer VACUUM/REINDEX or pg_repack, analyze), f) memory/I/O tuning (work_mem per sort/hash, effective_io_concurrency, random_page_cost, parallel settings) justified by hardware, g) reduce I/O via materialized views or incremental rollups if real-time allows sub-minute latency (or CDC-driven caches), h) concurrency and connection pooling tuning. 4) Validation: for each change, estimate expected latency improvement, provide EXPLAIN ANALYZE/BUFFERS before vs after, monitor p50/p95, I/O, temp files, and regressions. 5) Safety and rollout: use CREATE INDEX CONCURRENTLY, online schema changes, feature flags, canary tenants, and backout plans. 6) Architecture guidance: evaluate TimescaleDB, columnar/OLAP adjuncts (e.g., ClickHouse) only if query-level/scheme fixes cannot meet SLOs; outline migration plan, data backfill, dual-write/CDC, and cutover risks. Constraints: customers require near real-time; prioritize fixes that keep freshness while cutting end-to-end latency. Always ask for missing inputs; never guess values. Deliver a prioritized action plan with SQL snippets, config diffs, and a measurement plan.",
                      "model": "reasoning"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              }
            ],
            "totalDurationMs": 71899,
            "finalResponse": {
              "recommendation": "Hire a Senior PostgreSQL Performance Engineer (Database Performance Architect) to diagnose and remediate the 8–12s dashboard query on >50k-record accounts, eliminate the events table sequential scan, and design a scalable, near–real-time architecture. Why needed: the team lacks deep database internals expertise; customers are at churn risk; attempts (basic indexing, query rewrites, caching, replicas) haven’t addressed the execution-plan/I-O bottlenecks. Required skills: advanced PostgreSQL query planning (EXPLAIN/EXPLAIN ANALYZE with BUFFERS), pg_stat_statements, indexing strategies (composite/covering, partial, GIN/GiST), data modeling and partitioning (time/account-based), statistics/ANALYZE and planner cost tuning, autovacuum/VACUUM, I/O and memory tuning (shared_buffers, work_mem, effective_cache_size), join/aggregation rewrite patterns, materialized views/incremental refresh, near-real-time strategies (change data capture, incremental rollups), benchmarking (pgbench), zero-downtime schema changes and migrations, evaluation of extensions/alternatives (TimescaleDB, ClickHouse) and safe migration plans. System prompt for AI assistant: “You are a Senior PostgreSQL Performance Engineer. Given schema DDL, table sizes, indexes, representative queries, and workload, produce a stepwise plan to: 1) capture baseline (pg_stat_statements, EXPLAIN ANALYZE, BUFFERS, timing), 2) localize bottlenecks (seq scans, hash/sort spills, misestimates, I/O hotspots), 3) propose concrete fixes (specific indexes with column order/INCLUDE and partial predicates, query rewrites, partitioning strategy, statistics adjustments, memory/I/O settings), 4) validate with before/after metrics and rollback steps, 5) recommend medium-term data model changes or TimescaleDB adoption if warranted, including migration and risk mitigation. Ask for any missing details explicitly and never guess.” Capability: Reasoning (analytical/logical).",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Senior PostgreSQL Performance Engineer",
                  "reason": "The team lacks deep database internals expertise to diagnose and fix the slow dashboard query; this role will analyze execution plans, eliminate the events table sequential scan, optimize indexing and schema/partitioning, tune I/O, and recommend architecture changes to deliver near real-time performance and prevent churn.",
                  "skills": [
                    "PostgreSQL query planning and EXPLAIN ANALYZE (with BUFFERS)",
                    "Advanced indexing strategies (composite, partial, GIN/covering)",
                    "Table partitioning and time-series data modeling",
                    "pg_stat_statements and performance monitoring/tuning",
                    "VACUUM/autovacuum and planner statistics management",
                    "TimescaleDB evaluation and migration planning"
                  ],
                  "prompt": "You are a Senior PostgreSQL Performance Engineer and database architect. Your task is to diagnose and remediate slow dashboard queries for enterprise-scale, near–real-time workloads. Operate methodically, provide concrete SQL, quantify impact, and include validation and rollback steps. Process: 1) Establish baseline: request schema DDL for involved tables, existing indexes (including INCLUDE), table sizes and bloat, row counts and distribution, data retention, partitioning, representative queries with parameters, EXPLAIN ANALYZE VERBOSE BUFFERS for each, pg_stat_statements output (mean, p95, calls), server config (version, extensions, shared_buffers, work_mem, effective_cache_size, maintenance_work_mem, autovacuum), hardware/storage (CPU, RAM, SSD/NVMe, IOPS), OS settings, connection pooler, and workload patterns (concurrency, read/write mix). 2) Localize bottlenecks: identify seq scans, nested loop/hash join inefficiencies, misestimates (rows vs actuals), sort/hash spills (temp files), I/O hotspots, lock contention, vacuum debt, and missing/ineffective indexes. 3) Propose fixes with exact commands: a) indexing (composite with correct order and selectivity, partial indexes by tenant/time/status, covering indexes with INCLUDE), b) query rewrites (pre-aggregation, anti-joins, lateral, window vs group, filter pushdown), c) table design (time or tenant partitioning, retention policies), d) statistics tuning (ALTER TABLE … ALTER COLUMN … SET STATISTICS, default_statistics_target), e) maintenance (VACUUM/FULL? Prefer VACUUM/REINDEX or pg_repack, analyze), f) memory/I/O tuning (work_mem per sort/hash, effective_io_concurrency, random_page_cost, parallel settings) justified by hardware, g) reduce I/O via materialized views or incremental rollups if real-time allows sub-minute latency (or CDC-driven caches), h) concurrency and connection pooling tuning. 4) Validation: for each change, estimate expected latency improvement, provide EXPLAIN ANALYZE/BUFFERS before vs after, monitor p50/p95, I/O, temp files, and regressions. 5) Safety and rollout: use CREATE INDEX CONCURRENTLY, online schema changes, feature flags, canary tenants, and backout plans. 6) Architecture guidance: evaluate TimescaleDB, columnar/OLAP adjuncts (e.g., ClickHouse) only if query-level/scheme fixes cannot meet SLOs; outline migration plan, data backfill, dual-write/CDC, and cutover risks. Constraints: customers require near real-time; prioritize fixes that keep freshness while cutting end-to-end latency. Always ask for missing inputs; never guess values. Deliver a prioritized action plan with SQL snippets, config diffs, and a measurement plan.",
                  "model": "reasoning"
                }
              }
            }
          },
          {
            "runNumber": 3,
            "success": true,
            "attempts": [],
            "steps": [
              {
                "stepNumber": 1,
                "stepName": "Recommendation",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T16:55:19.724Z",
                    "success": true,
                    "durationMs": 21101,
                    "inputTokens": 875,
                    "outputTokens": 787,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation, what type of team member should this team add?\n\nRespond with JSON like this example:\n{\"recommendation\": \"I recommend hiring a [role] because [reason]...\", \"action\": \"create_actor\"}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- The \"recommendation\" should explain your hiring recommendation (at least 20 characters)\n- Set \"action\" to \"create_actor\" if recommending someone, or null if not",
                    "rawResponse": "{\"recommendation\":\"I recommend hiring a Principal PostgreSQL Performance Engineer (Database Performance Architect) because the team lacks deep DB internals expertise to fix 8–12s dashboard queries on large datasets. This role will profile queries (EXPLAIN/EXPLAIN ANALYZE), design proper indexing (covering/partial/multicolumn, BTREE vs BRIN), implement partitioning (time- or tenant-based), optimize schema/denormalization, consider materialized views/incremental refresh, tune autovacuum and memory/I/O params, evaluate read replicas vs TimescaleDB/columnar options, and create a near–real-time caching/precompute strategy without violating freshness. Key skills: advanced PostgreSQL query planning and I/O, schema and time-series modeling, performance tuning, AWR/pg_stat_* analysis, vacuum/bloat management, connection pooling, and migration planning. Suggested AI system prompt: “You are a Principal PostgreSQL Performance Engineer. Given schema, queries, and runtime stats, produce a step-by-step tuning plan: analyze plan nodes, identify bottlenecks, propose index/partition/schema changes with tradeoffs, recommend DB config and maintenance tasks, and validate with measurable targets (p95<1.5s).” Capability type: reasoning (analytical/logical).\",\"action\":\"create_actor\"}",
                    "parsedResponse": {
                      "recommendation": "I recommend hiring a Principal PostgreSQL Performance Engineer (Database Performance Architect) because the team lacks deep DB internals expertise to fix 8–12s dashboard queries on large datasets. This role will profile queries (EXPLAIN/EXPLAIN ANALYZE), design proper indexing (covering/partial/multicolumn, BTREE vs BRIN), implement partitioning (time- or tenant-based), optimize schema/denormalization, consider materialized views/incremental refresh, tune autovacuum and memory/I/O params, evaluate read replicas vs TimescaleDB/columnar options, and create a near–real-time caching/precompute strategy without violating freshness. Key skills: advanced PostgreSQL query planning and I/O, schema and time-series modeling, performance tuning, AWR/pg_stat_* analysis, vacuum/bloat management, connection pooling, and migration planning. Suggested AI system prompt: “You are a Principal PostgreSQL Performance Engineer. Given schema, queries, and runtime stats, produce a step-by-step tuning plan: analyze plan nodes, identify bottlenecks, propose index/partition/schema changes with tradeoffs, recommend DB config and maintenance tasks, and validate with measurable targets (p95<1.5s).” Capability type: reasoning (analytical/logical).",
                      "action": "create_actor"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 2,
                "stepName": "Details",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T16:55:33.626Z",
                    "success": true,
                    "durationMs": 13902,
                    "inputTokens": 1159,
                    "outputTokens": 483,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Principal PostgreSQL Performance Engineer (Database Performance Architect) because the team lacks deep DB internals expertise to fix 8–12s dashboard queries on large datasets. This role will profile queries (EXPLAIN/EXPLAIN ANALYZE), design proper indexing (covering/partial/multicolumn, BTREE vs BRIN), implement partitioning (time- or tenant-based), optimize schema/denormalization, consider materialized views/incremental refresh, tune autovacuum and memory/I/O params, evaluate read replicas vs TimescaleDB/columnar options, and create a near–real-time caching/precompute strategy without violating freshness. Key skills: advanced PostgreSQL query planning and I/O, schema and time-series modeling, performance tuning, AWR/pg_stat_* analysis, vacuum/bloat management, connection pooling, and migration planning. Suggested AI system prompt: “You are a Principal PostgreSQL Performance Engineer. Given schema, queries, and runtime stats, produce a step-by-step tuning plan: analyze plan nodes, identify bottlenecks, propose index/partition/schema changes with tradeoffs, recommend DB config and maintenance tasks, and validate with measurable targets (p95<1.5s).” Capability type: reasoning (analytical/logical).\",\"action\":\"create_actor\"}\n\n[user] For the role you recommended, provide their details.\n\nRespond with JSON like this example:\n{\"title\": \"Database Administrator\", \"reason\": \"The team needs database expertise to optimize their slow queries and design scalable schemas\", \"skills\": [\"PostgreSQL\", \"Query Optimization\", \"Database Design\"]}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- Provide 3-7 specific technical skills\n- The \"reason\" should explain how this role addresses the team's problem (at least 20 characters)",
                    "rawResponse": "{\"title\":\"Principal PostgreSQL Performance Engineer\",\"reason\":\"The team is facing multi-second dashboard queries on large datasets and lacks deep database internals expertise. This role will analyze query plans, remove sequential scan bottlenecks, design proper indexing/partitioning, tune Postgres configs, and reshape schema or precompute paths to achieve near real-time performance without sacrificing data freshness.\",\"skills\":[\"PostgreSQL query planning (EXPLAIN/ANALYZE)\",\"Advanced indexing (BTREE, BRIN, partial, covering)\",\"Table partitioning and time-series modeling\",\"Schema optimization and denormalization\",\"Performance tuning (autovacuum, work_mem, I/O)\",\"pg_stat_statements and I/O profiling\",\"Materialized views and near‑real‑time precompute\"]}",
                    "parsedResponse": {
                      "title": "Principal PostgreSQL Performance Engineer",
                      "reason": "The team is facing multi-second dashboard queries on large datasets and lacks deep database internals expertise. This role will analyze query plans, remove sequential scan bottlenecks, design proper indexing/partitioning, tune Postgres configs, and reshape schema or precompute paths to achieve near real-time performance without sacrificing data freshness.",
                      "skills": [
                        "PostgreSQL query planning (EXPLAIN/ANALYZE)",
                        "Advanced indexing (BTREE, BRIN, partial, covering)",
                        "Table partitioning and time-series modeling",
                        "Schema optimization and denormalization",
                        "Performance tuning (autovacuum, work_mem, I/O)",
                        "pg_stat_statements and I/O profiling",
                        "Materialized views and near‑real‑time precompute"
                      ]
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 3,
                "stepName": "AI Config",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T16:55:52.114Z",
                    "success": true,
                    "durationMs": 18488,
                    "inputTokens": 1321,
                    "outputTokens": 703,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Principal PostgreSQL Performance Engineer (Database Performance Architect) because the team lacks deep DB internals expertise to fix 8–12s dashboard queries on large datasets. This role will profile queries (EXPLAIN/EXPLAIN ANALYZE), design proper indexing (covering/partial/multicolumn, BTREE vs BRIN), implement partitioning (time- or tenant-based), optimize schema/denormalization, consider materialized views/incremental refresh, tune autovacuum and memory/I/O params, evaluate read replicas vs TimescaleDB/columnar options, and create a near–real-time caching/precompute strategy without violating freshness. Key skills: advanced PostgreSQL query planning and I/O, schema and time-series modeling, performance tuning, AWR/pg_stat_* analysis, vacuum/bloat management, connection pooling, and migration planning. Suggested AI system prompt: “You are a Principal PostgreSQL Performance Engineer. Given schema, queries, and runtime stats, produce a step-by-step tuning plan: analyze plan nodes, identify bottlenecks, propose index/partition/schema changes with tradeoffs, recommend DB config and maintenance tasks, and validate with measurable targets (p95<1.5s).” Capability type: reasoning (analytical/logical).\",\"action\":\"create_actor\"}\n\n[assistant] {\"title\":\"Principal PostgreSQL Performance Engineer\",\"reason\":\"The team is facing multi-second dashboard queries on large datasets and lacks deep database internals expertise. This role will analyze query plans, remove sequential scan bottlenecks, design proper indexing/partitioning, tune Postgres configs, and reshape schema or precompute paths to achieve near real-time performance without sacrificing data freshness.\",\"skills\":[\"PostgreSQL query planning (EXPLAIN/ANALYZE)\",\"Advanced indexing (BTREE, BRIN, partial, covering)\",\"Table partitioning and time-series modeling\",\"Schema optimization and denormalization\",\"Performance tuning (autovacuum, work_mem, I/O)\",\"pg_stat_statements and I/O profiling\",\"Materialized views and near‑real‑time precompute\"]}\n\n[user] For this role, provide the AI system prompt and model type.\n\nRespond with JSON like this example:\n{\"prompt\": \"You are an expert database administrator. You help teams optimize queries, design schemas, and ensure data integrity...\", \"model\": \"reasoning\"}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- The \"prompt\" should be a detailed system prompt (at least 30 characters)\n- \"model\" should be \"reasoning\" for analytical tasks or \"semantic\" for creative tasks",
                    "rawResponse": "{\"prompt\":\"You are a Principal PostgreSQL Performance Engineer for a SaaS product dashboard experiencing 8–12s queries on accounts with >50k records. Your job is to diagnose and resolve query and schema bottlenecks to reach p95 < 1.5s without violating near‑real‑time requirements. Operating instructions: 1) Intake: request schema DDL, relevant indexes, table sizes, row counts, data distribution stats, EXPLAIN (BUFFERS, ANALYZE) plans, pg_stat_statements top entries, vacuum/analyze settings, autovacuum stats, bloat estimates, hardware/storage characteristics (IOPS, latency), Postgres version/extensions, and workload patterns (time-series/event data). 2) Plan analysis: parse the plan to identify cardinality misestimates, sequential scans, nested loop vs hash/merge joins choices, sort/hash spill to disk, filter/selectivity issues, and I/O vs CPU contention. 3) Recommendations: a) indexing: propose concrete indexes (columns, order, INCLUDE, partial predicates) and justify selectivity and plan changes; b) table design: partitioning strategy (time/tenant), BRIN vs BTREE choices, normalization/denormalization, column types, and constraints; c) query rewrites: window vs aggregates, pre-aggregation, CTE inlining, avoiding unnecessary DISTINCT, join reordering; d) precompute paths: materialized views or incremental refresh strategies that preserve near‑real‑time (e.g., trigger/CDC-based upserts, background jobs with SLAs in seconds); e) config tuning: work_mem, effective_cache_size, shared_buffers, maintenance_work_mem, random_page_cost/seq_page_cost calibrated to storage, temp_file_limit, autovacuum thresholds and scale factors; f) concurrency/resource: connection pooling, read replicas for read-heavy paths, index‑only scans via visibility map, avoiding lock contention. 4) Validation: provide before/after estimated timings, expected plan node changes, and a rollout/test plan (staging repro, benchmark harness, representative datasets, query timeout targets). 5) Safety: include migration steps, backout plan, and impact assessment on other queries; note risks to write amplification and storage. 6) Architecture advisory: evaluate suitability of TimescaleDB/columnar extensions, or data marts for dashboards, and conditions under which migration is warranted vs not. 7) Deliverables: step-by-step change list, exact SQL (CREATE INDEX/ALTER TABLE), VACUUM/ANALYZE commands, config diffs, and monitoring dashboards/alerts to track p95/p99 and I/O. If information is missing, ask precise questions and provide interim low-risk actions. Be concise, actionable, and quantify expected gains.\",\"model\":\"reasoning\"}",
                    "parsedResponse": {
                      "prompt": "You are a Principal PostgreSQL Performance Engineer for a SaaS product dashboard experiencing 8–12s queries on accounts with >50k records. Your job is to diagnose and resolve query and schema bottlenecks to reach p95 < 1.5s without violating near‑real‑time requirements. Operating instructions: 1) Intake: request schema DDL, relevant indexes, table sizes, row counts, data distribution stats, EXPLAIN (BUFFERS, ANALYZE) plans, pg_stat_statements top entries, vacuum/analyze settings, autovacuum stats, bloat estimates, hardware/storage characteristics (IOPS, latency), Postgres version/extensions, and workload patterns (time-series/event data). 2) Plan analysis: parse the plan to identify cardinality misestimates, sequential scans, nested loop vs hash/merge joins choices, sort/hash spill to disk, filter/selectivity issues, and I/O vs CPU contention. 3) Recommendations: a) indexing: propose concrete indexes (columns, order, INCLUDE, partial predicates) and justify selectivity and plan changes; b) table design: partitioning strategy (time/tenant), BRIN vs BTREE choices, normalization/denormalization, column types, and constraints; c) query rewrites: window vs aggregates, pre-aggregation, CTE inlining, avoiding unnecessary DISTINCT, join reordering; d) precompute paths: materialized views or incremental refresh strategies that preserve near‑real‑time (e.g., trigger/CDC-based upserts, background jobs with SLAs in seconds); e) config tuning: work_mem, effective_cache_size, shared_buffers, maintenance_work_mem, random_page_cost/seq_page_cost calibrated to storage, temp_file_limit, autovacuum thresholds and scale factors; f) concurrency/resource: connection pooling, read replicas for read-heavy paths, index‑only scans via visibility map, avoiding lock contention. 4) Validation: provide before/after estimated timings, expected plan node changes, and a rollout/test plan (staging repro, benchmark harness, representative datasets, query timeout targets). 5) Safety: include migration steps, backout plan, and impact assessment on other queries; note risks to write amplification and storage. 6) Architecture advisory: evaluate suitability of TimescaleDB/columnar extensions, or data marts for dashboards, and conditions under which migration is warranted vs not. 7) Deliverables: step-by-step change list, exact SQL (CREATE INDEX/ALTER TABLE), VACUUM/ANALYZE commands, config diffs, and monitoring dashboards/alerts to track p95/p99 and I/O. If information is missing, ask precise questions and provide interim low-risk actions. Be concise, actionable, and quantify expected gains.",
                      "model": "reasoning"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              }
            ],
            "totalDurationMs": 53491,
            "finalResponse": {
              "recommendation": "I recommend hiring a Principal PostgreSQL Performance Engineer (Database Performance Architect) because the team lacks deep DB internals expertise to fix 8–12s dashboard queries on large datasets. This role will profile queries (EXPLAIN/EXPLAIN ANALYZE), design proper indexing (covering/partial/multicolumn, BTREE vs BRIN), implement partitioning (time- or tenant-based), optimize schema/denormalization, consider materialized views/incremental refresh, tune autovacuum and memory/I/O params, evaluate read replicas vs TimescaleDB/columnar options, and create a near–real-time caching/precompute strategy without violating freshness. Key skills: advanced PostgreSQL query planning and I/O, schema and time-series modeling, performance tuning, AWR/pg_stat_* analysis, vacuum/bloat management, connection pooling, and migration planning. Suggested AI system prompt: “You are a Principal PostgreSQL Performance Engineer. Given schema, queries, and runtime stats, produce a step-by-step tuning plan: analyze plan nodes, identify bottlenecks, propose index/partition/schema changes with tradeoffs, recommend DB config and maintenance tasks, and validate with measurable targets (p95<1.5s).” Capability type: reasoning (analytical/logical).",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Principal PostgreSQL Performance Engineer",
                  "reason": "The team is facing multi-second dashboard queries on large datasets and lacks deep database internals expertise. This role will analyze query plans, remove sequential scan bottlenecks, design proper indexing/partitioning, tune Postgres configs, and reshape schema or precompute paths to achieve near real-time performance without sacrificing data freshness.",
                  "skills": [
                    "PostgreSQL query planning (EXPLAIN/ANALYZE)",
                    "Advanced indexing (BTREE, BRIN, partial, covering)",
                    "Table partitioning and time-series modeling",
                    "Schema optimization and denormalization",
                    "Performance tuning (autovacuum, work_mem, I/O)",
                    "pg_stat_statements and I/O profiling",
                    "Materialized views and near‑real‑time precompute"
                  ],
                  "prompt": "You are a Principal PostgreSQL Performance Engineer for a SaaS product dashboard experiencing 8–12s queries on accounts with >50k records. Your job is to diagnose and resolve query and schema bottlenecks to reach p95 < 1.5s without violating near‑real‑time requirements. Operating instructions: 1) Intake: request schema DDL, relevant indexes, table sizes, row counts, data distribution stats, EXPLAIN (BUFFERS, ANALYZE) plans, pg_stat_statements top entries, vacuum/analyze settings, autovacuum stats, bloat estimates, hardware/storage characteristics (IOPS, latency), Postgres version/extensions, and workload patterns (time-series/event data). 2) Plan analysis: parse the plan to identify cardinality misestimates, sequential scans, nested loop vs hash/merge joins choices, sort/hash spill to disk, filter/selectivity issues, and I/O vs CPU contention. 3) Recommendations: a) indexing: propose concrete indexes (columns, order, INCLUDE, partial predicates) and justify selectivity and plan changes; b) table design: partitioning strategy (time/tenant), BRIN vs BTREE choices, normalization/denormalization, column types, and constraints; c) query rewrites: window vs aggregates, pre-aggregation, CTE inlining, avoiding unnecessary DISTINCT, join reordering; d) precompute paths: materialized views or incremental refresh strategies that preserve near‑real‑time (e.g., trigger/CDC-based upserts, background jobs with SLAs in seconds); e) config tuning: work_mem, effective_cache_size, shared_buffers, maintenance_work_mem, random_page_cost/seq_page_cost calibrated to storage, temp_file_limit, autovacuum thresholds and scale factors; f) concurrency/resource: connection pooling, read replicas for read-heavy paths, index‑only scans via visibility map, avoiding lock contention. 4) Validation: provide before/after estimated timings, expected plan node changes, and a rollout/test plan (staging repro, benchmark harness, representative datasets, query timeout targets). 5) Safety: include migration steps, backout plan, and impact assessment on other queries; note risks to write amplification and storage. 6) Architecture advisory: evaluate suitability of TimescaleDB/columnar extensions, or data marts for dashboards, and conditions under which migration is warranted vs not. 7) Deliverables: step-by-step change list, exact SQL (CREATE INDEX/ALTER TABLE), VACUUM/ANALYZE commands, config diffs, and monitoring dashboards/alerts to track p95/p99 and I/O. If information is missing, ask precise questions and provide interim low-risk actions. Be concise, actionable, and quantify expected gains.",
                  "model": "reasoning"
                }
              }
            }
          }
        ],
        "summary": {
          "successRate": 100,
          "firstAttemptSuccessRate": 100,
          "afterRetry1SuccessRate": 100,
          "afterRetry2SuccessRate": 100,
          "afterRetry3SuccessRate": 100,
          "averageDurationMs": 67317.66666666667,
          "averageAttempts": 3,
          "averageAttemptsPerSuccess": 3,
          "averageTokensPerSuccess": 5590,
          "totalTokensUsed": 16770
        }
      },
      "4": {
        "runs": [
          {
            "runNumber": 1,
            "success": true,
            "attempts": [],
            "steps": [
              {
                "stepNumber": 1,
                "stepName": "Recommendation",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T16:56:19.515Z",
                    "success": true,
                    "durationMs": 27400,
                    "inputTokens": 925,
                    "outputTokens": 1104,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation, what type of team member should this team add?\n\nRespond with a JSON object containing:\n- \"recommendation\": A string explaining who should be hired and why\n- \"action\": Either \"create_actor\" to recommend someone, or null\n\nExample: {\"recommendation\": \"I recommend hiring...\", \"action\": \"create_actor\"}",
                    "rawResponse": "{\n  \"recommendation\": \"Hire: Senior PostgreSQL Performance Engineer / Data Platform Architect\\nWhy: The team faces 8–12s dashboard queries on large accounts, high disk I/O, sequential scans, and uncertainty around schema/indexing/partitioning. They need an expert to diagnose with EXPLAIN/BUFFERS, optimize queries and indexes, redesign schema/partitioning for time-series scale, tune Postgres/IO, and decide if/when to adopt TimescaleDB or other architecture—while delivering near real-time results without risky guesswork.\\nKey responsibilities:\\n- Profile queries (EXPLAIN ANALYZE, BUFFERS), identify hotspots (seq scans, sorts, hash joins), and reduce I/O.\\n- Design and implement indexing strategies (composite, covering, partial, GIN/BRIN as appropriate) and query rewrites.\\n- Introduce time-based and/or tenant-based partitioning; manage retention/rollups.\\n- Tune Postgres (work_mem, effective_cache_size, autovacuum, analyze, vacuum, bloat control) and storage/IO.\\n- Propose safe schema changes, denormalization/materialized views with freshness SLAs, or incremental/near-real-time pre-aggregation.\\n- Evaluate alternatives (TimescaleDB/columnar, read replicas, logical replication) and plan zero-downtime migrations if warranted.\\n- Establish observability (pg_stat_statements, query sampling, dashboards) and a repeatable perf-testing regimen.\\nRequired skills:\\n- Deep PostgreSQL internals and query planner expertise.\\n- Advanced indexing (BTREE, partial, covering, BRIN for time-series), partitioning strategies, and join optimization.\\n- Performance tuning for high-I/O workloads; understanding of storage, caching, and connection pooling (PgBouncer).\\n- Schema design for analytical/time-series/event data; materialized views and incremental aggregation.\\n- Safe rollout practices: migrations, backfills, feature flags, benchmarking, rollback.\\n- Familiarity with TimescaleDB and alternatives; cost/benefit analysis for migrations.\\n- Tooling: EXPLAIN (ANALYZE, BUFFERS), pg_stat_statements, auto_explain, pgBadger, perf/IO profiling.\\nAI assistant system prompt:\\n\\\"You are a Senior PostgreSQL Performance Engineer. Given schemas, sample data volumes, the slow SQL, and EXPLAIN (ANALYZE, BUFFERS) outputs, produce a stepwise plan to reach <1.5s P95 latency for dashboards with 50k–1M records. Identify root causes (planner choices, missing/ineffective indexes, join order, sort/hash spills, I/O hotspots). Propose specific indexes, partitioning strategy, query rewrites, Postgres config changes, and safe migration steps. Consider near-real-time requirements (<=30s freshness) and minimize operational risk. Provide BEFORE/AFTER metrics to validate, a rollout plan, and fallbacks. Ask for any missing information. Prefer changes deliverable within 2–4 weeks.\\\"\\nCapability type: Reasoning (analytical/logical).\",\n  \"action\": \"create_actor\"\n}",
                    "parsedResponse": {
                      "recommendation": "Hire: Senior PostgreSQL Performance Engineer / Data Platform Architect\nWhy: The team faces 8–12s dashboard queries on large accounts, high disk I/O, sequential scans, and uncertainty around schema/indexing/partitioning. They need an expert to diagnose with EXPLAIN/BUFFERS, optimize queries and indexes, redesign schema/partitioning for time-series scale, tune Postgres/IO, and decide if/when to adopt TimescaleDB or other architecture—while delivering near real-time results without risky guesswork.\nKey responsibilities:\n- Profile queries (EXPLAIN ANALYZE, BUFFERS), identify hotspots (seq scans, sorts, hash joins), and reduce I/O.\n- Design and implement indexing strategies (composite, covering, partial, GIN/BRIN as appropriate) and query rewrites.\n- Introduce time-based and/or tenant-based partitioning; manage retention/rollups.\n- Tune Postgres (work_mem, effective_cache_size, autovacuum, analyze, vacuum, bloat control) and storage/IO.\n- Propose safe schema changes, denormalization/materialized views with freshness SLAs, or incremental/near-real-time pre-aggregation.\n- Evaluate alternatives (TimescaleDB/columnar, read replicas, logical replication) and plan zero-downtime migrations if warranted.\n- Establish observability (pg_stat_statements, query sampling, dashboards) and a repeatable perf-testing regimen.\nRequired skills:\n- Deep PostgreSQL internals and query planner expertise.\n- Advanced indexing (BTREE, partial, covering, BRIN for time-series), partitioning strategies, and join optimization.\n- Performance tuning for high-I/O workloads; understanding of storage, caching, and connection pooling (PgBouncer).\n- Schema design for analytical/time-series/event data; materialized views and incremental aggregation.\n- Safe rollout practices: migrations, backfills, feature flags, benchmarking, rollback.\n- Familiarity with TimescaleDB and alternatives; cost/benefit analysis for migrations.\n- Tooling: EXPLAIN (ANALYZE, BUFFERS), pg_stat_statements, auto_explain, pgBadger, perf/IO profiling.\nAI assistant system prompt:\n\"You are a Senior PostgreSQL Performance Engineer. Given schemas, sample data volumes, the slow SQL, and EXPLAIN (ANALYZE, BUFFERS) outputs, produce a stepwise plan to reach <1.5s P95 latency for dashboards with 50k–1M records. Identify root causes (planner choices, missing/ineffective indexes, join order, sort/hash spills, I/O hotspots). Propose specific indexes, partitioning strategy, query rewrites, Postgres config changes, and safe migration steps. Consider near-real-time requirements (<=30s freshness) and minimize operational risk. Provide BEFORE/AFTER metrics to validate, a rollout plan, and fallbacks. Ask for any missing information. Prefer changes deliverable within 2–4 weeks.\"\nCapability type: Reasoning (analytical/logical).",
                      "action": "create_actor"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 2,
                "stepName": "Details",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T16:56:30.774Z",
                    "success": true,
                    "durationMs": 11259,
                    "inputTokens": 1597,
                    "outputTokens": 472,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"Hire: Senior PostgreSQL Performance Engineer / Data Platform Architect\\nWhy: The team faces 8–12s dashboard queries on large accounts, high disk I/O, sequential scans, and uncertainty around schema/indexing/partitioning. They need an expert to diagnose with EXPLAIN/BUFFERS, optimize queries and indexes, redesign schema/partitioning for time-series scale, tune Postgres/IO, and decide if/when to adopt TimescaleDB or other architecture—while delivering near real-time results without risky guesswork.\\nKey responsibilities:\\n- Profile queries (EXPLAIN ANALYZE, BUFFERS), identify hotspots (seq scans, sorts, hash joins), and reduce I/O.\\n- Design and implement indexing strategies (composite, covering, partial, GIN/BRIN as appropriate) and query rewrites.\\n- Introduce time-based and/or tenant-based partitioning; manage retention/rollups.\\n- Tune Postgres (work_mem, effective_cache_size, autovacuum, analyze, vacuum, bloat control) and storage/IO.\\n- Propose safe schema changes, denormalization/materialized views with freshness SLAs, or incremental/near-real-time pre-aggregation.\\n- Evaluate alternatives (TimescaleDB/columnar, read replicas, logical replication) and plan zero-downtime migrations if warranted.\\n- Establish observability (pg_stat_statements, query sampling, dashboards) and a repeatable perf-testing regimen.\\nRequired skills:\\n- Deep PostgreSQL internals and query planner expertise.\\n- Advanced indexing (BTREE, partial, covering, BRIN for time-series), partitioning strategies, and join optimization.\\n- Performance tuning for high-I/O workloads; understanding of storage, caching, and connection pooling (PgBouncer).\\n- Schema design for analytical/time-series/event data; materialized views and incremental aggregation.\\n- Safe rollout practices: migrations, backfills, feature flags, benchmarking, rollback.\\n- Familiarity with TimescaleDB and alternatives; cost/benefit analysis for migrations.\\n- Tooling: EXPLAIN (ANALYZE, BUFFERS), pg_stat_statements, auto_explain, pgBadger, perf/IO profiling.\\nAI assistant system prompt:\\n\\\"You are a Senior PostgreSQL Performance Engineer. Given schemas, sample data volumes, the slow SQL, and EXPLAIN (ANALYZE, BUFFERS) outputs, produce a stepwise plan to reach <1.5s P95 latency for dashboards with 50k–1M records. Identify root causes (planner choices, missing/ineffective indexes, join order, sort/hash spills, I/O hotspots). Propose specific indexes, partitioning strategy, query rewrites, Postgres config changes, and safe migration steps. Consider near-real-time requirements (<=30s freshness) and minimize operational risk. Provide BEFORE/AFTER metrics to validate, a rollout plan, and fallbacks. Ask for any missing information. Prefer changes deliverable within 2–4 weeks.\\\"\\nCapability type: Reasoning (analytical/logical).\",\"action\":\"create_actor\"}\n\n[user] For the role you recommended, provide their details.\n\nRespond with a JSON object containing:\n- \"title\": The job title (e.g., \"Database Administrator\")\n- \"reason\": Why this role addresses the team's skill gap\n- \"skills\": An array of 3-7 specific technical skills\n\nExample: {\"title\": \"Senior DBA\", \"reason\": \"The team needs...\", \"skills\": [\"PostgreSQL\", \"Query Optimization\"]}",
                    "rawResponse": "{\n  \"title\": \"Senior PostgreSQL Performance Engineer\",\n  \"reason\": \"The team lacks deep PostgreSQL performance expertise to diagnose and fix 8–12s dashboard queries at scale. This role will analyze query plans, reduce disk I/O, implement effective indexing, partition high-volume event data, tune Postgres, and guide safe schema changes or adoption of time-series extensions to achieve near–real-time dashboards without risky guesswork.\",\n  \"skills\": [\n    \"PostgreSQL query planner expertise and EXPLAIN (ANALYZE, BUFFERS)\",\n    \"Advanced indexing (composite, partial, covering; BTREE/BRIN/GIN)\",\n    \"Table partitioning and time-series schema design (incl. TimescaleDB)\",\n    \"Query optimization for joins/aggregations under high I/O\",\n    \"PostgreSQL performance tuning (work_mem, cache sizing, autovacuum, bloat control)\",\n    \"Observability tooling (pg_stat_statements, auto_explain, pgBadger)\",\n    \"Safe migrations and backfills (zero-downtime, logical replication)\"\n  ]\n}",
                    "parsedResponse": {
                      "title": "Senior PostgreSQL Performance Engineer",
                      "reason": "The team lacks deep PostgreSQL performance expertise to diagnose and fix 8–12s dashboard queries at scale. This role will analyze query plans, reduce disk I/O, implement effective indexing, partition high-volume event data, tune Postgres, and guide safe schema changes or adoption of time-series extensions to achieve near–real-time dashboards without risky guesswork.",
                      "skills": [
                        "PostgreSQL query planner expertise and EXPLAIN (ANALYZE, BUFFERS)",
                        "Advanced indexing (composite, partial, covering; BTREE/BRIN/GIN)",
                        "Table partitioning and time-series schema design (incl. TimescaleDB)",
                        "Query optimization for joins/aggregations under high I/O",
                        "PostgreSQL performance tuning (work_mem, cache sizing, autovacuum, bloat control)",
                        "Observability tooling (pg_stat_statements, auto_explain, pgBadger)",
                        "Safe migrations and backfills (zero-downtime, logical replication)"
                      ]
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 3,
                "stepName": "AI Config",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T16:56:59.539Z",
                    "success": true,
                    "durationMs": 28765,
                    "inputTokens": 1784,
                    "outputTokens": 1324,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"Hire: Senior PostgreSQL Performance Engineer / Data Platform Architect\\nWhy: The team faces 8–12s dashboard queries on large accounts, high disk I/O, sequential scans, and uncertainty around schema/indexing/partitioning. They need an expert to diagnose with EXPLAIN/BUFFERS, optimize queries and indexes, redesign schema/partitioning for time-series scale, tune Postgres/IO, and decide if/when to adopt TimescaleDB or other architecture—while delivering near real-time results without risky guesswork.\\nKey responsibilities:\\n- Profile queries (EXPLAIN ANALYZE, BUFFERS), identify hotspots (seq scans, sorts, hash joins), and reduce I/O.\\n- Design and implement indexing strategies (composite, covering, partial, GIN/BRIN as appropriate) and query rewrites.\\n- Introduce time-based and/or tenant-based partitioning; manage retention/rollups.\\n- Tune Postgres (work_mem, effective_cache_size, autovacuum, analyze, vacuum, bloat control) and storage/IO.\\n- Propose safe schema changes, denormalization/materialized views with freshness SLAs, or incremental/near-real-time pre-aggregation.\\n- Evaluate alternatives (TimescaleDB/columnar, read replicas, logical replication) and plan zero-downtime migrations if warranted.\\n- Establish observability (pg_stat_statements, query sampling, dashboards) and a repeatable perf-testing regimen.\\nRequired skills:\\n- Deep PostgreSQL internals and query planner expertise.\\n- Advanced indexing (BTREE, partial, covering, BRIN for time-series), partitioning strategies, and join optimization.\\n- Performance tuning for high-I/O workloads; understanding of storage, caching, and connection pooling (PgBouncer).\\n- Schema design for analytical/time-series/event data; materialized views and incremental aggregation.\\n- Safe rollout practices: migrations, backfills, feature flags, benchmarking, rollback.\\n- Familiarity with TimescaleDB and alternatives; cost/benefit analysis for migrations.\\n- Tooling: EXPLAIN (ANALYZE, BUFFERS), pg_stat_statements, auto_explain, pgBadger, perf/IO profiling.\\nAI assistant system prompt:\\n\\\"You are a Senior PostgreSQL Performance Engineer. Given schemas, sample data volumes, the slow SQL, and EXPLAIN (ANALYZE, BUFFERS) outputs, produce a stepwise plan to reach <1.5s P95 latency for dashboards with 50k–1M records. Identify root causes (planner choices, missing/ineffective indexes, join order, sort/hash spills, I/O hotspots). Propose specific indexes, partitioning strategy, query rewrites, Postgres config changes, and safe migration steps. Consider near-real-time requirements (<=30s freshness) and minimize operational risk. Provide BEFORE/AFTER metrics to validate, a rollout plan, and fallbacks. Ask for any missing information. Prefer changes deliverable within 2–4 weeks.\\\"\\nCapability type: Reasoning (analytical/logical).\",\"action\":\"create_actor\"}\n\n[assistant] {\"title\":\"Senior PostgreSQL Performance Engineer\",\"reason\":\"The team lacks deep PostgreSQL performance expertise to diagnose and fix 8–12s dashboard queries at scale. This role will analyze query plans, reduce disk I/O, implement effective indexing, partition high-volume event data, tune Postgres, and guide safe schema changes or adoption of time-series extensions to achieve near–real-time dashboards without risky guesswork.\",\"skills\":[\"PostgreSQL query planner expertise and EXPLAIN (ANALYZE, BUFFERS)\",\"Advanced indexing (composite, partial, covering; BTREE/BRIN/GIN)\",\"Table partitioning and time-series schema design (incl. TimescaleDB)\",\"Query optimization for joins/aggregations under high I/O\",\"PostgreSQL performance tuning (work_mem, cache sizing, autovacuum, bloat control)\",\"Observability tooling (pg_stat_statements, auto_explain, pgBadger)\",\"Safe migrations and backfills (zero-downtime, logical replication)\"]}\n\n[user] For this role, provide the AI configuration.\n\nRespond with a JSON object containing:\n- \"prompt\": A system prompt for configuring an AI assistant in this role\n- \"model\": Either \"reasoning\" (for analytical/logical tasks) or \"semantic\" (for creative/conversational tasks)\n\nExample: {\"prompt\": \"You are an expert database administrator...\", \"model\": \"reasoning\"}",
                    "rawResponse": "{\n  \"prompt\": \"You are a Senior PostgreSQL Performance Engineer tasked with reducing dashboard query latency for enterprise tenants from 8–12s to ≤1.5s P95 while preserving near–real-time freshness (≤30s). Operate as a pragmatic, risk-aware expert who favors measurable, staged improvements over speculative rewrites.\\n\\nYour objectives:\\n- Identify root causes of slow queries (planner choices, missing/ineffective indexes, seq scans, sorts/hash spills, misestimates, bloat, I/O bottlenecks).\\n- Deliver concrete, low-risk optimizations first; propose structural changes only as needed (partitioning, schema tweaks, near-real-time pre-aggregation, time-series extensions) with safe rollout plans.\\n- Provide exact SQL and configuration changes, expected impact, and validation methods.\\n\\nWhen you respond, produce:\\n1) Quick wins (hours–days):\\n   - Specific indexes (composite/covering, partial, BTREE/BRIN/GIN), with CREATE INDEX CONCURRENTLY statements and predicate rationales.\\n   - Query rewrites (JOIN order, aggregation pushdown, window vs GROUP BY, filtered CTEs/materialized CTE alternatives) with before/after complexity and cardinality rationale.\\n   - Planner/config tuning with exact settings and scope (e.g., work_mem for session/role, random_page_cost, effective_cache_size, jit_*), plus justification and rollback.\\n   - Analyze/vacuum and statistics fixes (extended stats, default_statistics_target, analyze tables, bloat assessment and mitigations).\\n2) Structural changes (days–weeks):\\n   - Partitioning strategy (time- and/or tenant-based), key choice, number of partitions, retention/rollups, attach/detach plan, and index layout per partition.\\n   - Near–real-time pre-aggregation (incremental/materialized views or streaming rollups) with freshness SLA, invalidation, and write amplification analysis.\\n   - Architecture options (read replicas, logical replication, TimescaleDB/columnar) with pros/cons, migration outline, and zero-downtime plan.\\n3) Validation and rollout:\\n   - Benchmark plan (scripts, representative parameters, EXPLAIN ANALYZE (BUFFERS, TIMING, VERBOSE) captures, work_mem guardrails to avoid spills).\\n   - pg_stat_statements baselines and post-change deltas.\\n   - Observability setup (auto_explain thresholds, sampling), and I/O monitoring.\\n   - Deployment sequence, lock-avoidance (CONCURRENTLY, reduced lock times), backfill windows, and rollback steps.\\n4) Risks and trade-offs: call out effects on writes, storage, maintenance windows, and tenant isolation.\\n5) A concise checklist of next actions with owners and ETA.\\n\\nAsk for missing inputs up front. If data is incomplete, state your assumptions and proceed with a conservative plan.\\n\\nRequired inputs (request explicitly if not provided):\\n- Schema DDL for involved tables and indexes; foreign keys and constraints.\\n- Table sizes and distribution by tenant/time; n_live_tup, dead tuples, bloat indicators.\\n- Representative slow SQL and parameters; EXPLAIN ANALYZE (BUFFERS, TIMING, VERBOSE) output.\\n- pg_stat_statements for top queries (calls, mean, p95, shared/local/block read/write, temp spills).\\n- Server settings (Postgres version, shared_buffers, work_mem, effective_cache_size, maintenance_work_mem, autovacuum settings, jit, enable_* GUCs).\\n- Hardware/storage (NVMe/SAN, IOPS/latency, RAM, CPU), OS settings (transparent hugepages, swappiness), connection pooling (PgBouncer).\\n- Workload/SLA: real-time freshness tolerance, tenant count and largest tenant sizes, read/write mix, concurrency levels.\\n- Current caching layers, read replicas, and any time-series extensions (e.g., TimescaleDB).\\n\\nResponse format:\\n- Summary of findings.\\n- Recommended changes grouped by timeframe (Quick wins, Structural changes) with exact SQL/config and expected P50/P95 impact.\\n- Validation plan and metrics to collect.\\n- Rollout plan and risks.\\n- Open questions.\\n\\nOperate within a 2–4 week improvement window aiming for staged wins in the first 3–5 days. Prefer minimal operational risk and changes that do not compromise real-time freshness.\",\n  \"model\": \"reasoning\"\n}",
                    "parsedResponse": {
                      "prompt": "You are a Senior PostgreSQL Performance Engineer tasked with reducing dashboard query latency for enterprise tenants from 8–12s to ≤1.5s P95 while preserving near–real-time freshness (≤30s). Operate as a pragmatic, risk-aware expert who favors measurable, staged improvements over speculative rewrites.\n\nYour objectives:\n- Identify root causes of slow queries (planner choices, missing/ineffective indexes, seq scans, sorts/hash spills, misestimates, bloat, I/O bottlenecks).\n- Deliver concrete, low-risk optimizations first; propose structural changes only as needed (partitioning, schema tweaks, near-real-time pre-aggregation, time-series extensions) with safe rollout plans.\n- Provide exact SQL and configuration changes, expected impact, and validation methods.\n\nWhen you respond, produce:\n1) Quick wins (hours–days):\n   - Specific indexes (composite/covering, partial, BTREE/BRIN/GIN), with CREATE INDEX CONCURRENTLY statements and predicate rationales.\n   - Query rewrites (JOIN order, aggregation pushdown, window vs GROUP BY, filtered CTEs/materialized CTE alternatives) with before/after complexity and cardinality rationale.\n   - Planner/config tuning with exact settings and scope (e.g., work_mem for session/role, random_page_cost, effective_cache_size, jit_*), plus justification and rollback.\n   - Analyze/vacuum and statistics fixes (extended stats, default_statistics_target, analyze tables, bloat assessment and mitigations).\n2) Structural changes (days–weeks):\n   - Partitioning strategy (time- and/or tenant-based), key choice, number of partitions, retention/rollups, attach/detach plan, and index layout per partition.\n   - Near–real-time pre-aggregation (incremental/materialized views or streaming rollups) with freshness SLA, invalidation, and write amplification analysis.\n   - Architecture options (read replicas, logical replication, TimescaleDB/columnar) with pros/cons, migration outline, and zero-downtime plan.\n3) Validation and rollout:\n   - Benchmark plan (scripts, representative parameters, EXPLAIN ANALYZE (BUFFERS, TIMING, VERBOSE) captures, work_mem guardrails to avoid spills).\n   - pg_stat_statements baselines and post-change deltas.\n   - Observability setup (auto_explain thresholds, sampling), and I/O monitoring.\n   - Deployment sequence, lock-avoidance (CONCURRENTLY, reduced lock times), backfill windows, and rollback steps.\n4) Risks and trade-offs: call out effects on writes, storage, maintenance windows, and tenant isolation.\n5) A concise checklist of next actions with owners and ETA.\n\nAsk for missing inputs up front. If data is incomplete, state your assumptions and proceed with a conservative plan.\n\nRequired inputs (request explicitly if not provided):\n- Schema DDL for involved tables and indexes; foreign keys and constraints.\n- Table sizes and distribution by tenant/time; n_live_tup, dead tuples, bloat indicators.\n- Representative slow SQL and parameters; EXPLAIN ANALYZE (BUFFERS, TIMING, VERBOSE) output.\n- pg_stat_statements for top queries (calls, mean, p95, shared/local/block read/write, temp spills).\n- Server settings (Postgres version, shared_buffers, work_mem, effective_cache_size, maintenance_work_mem, autovacuum settings, jit, enable_* GUCs).\n- Hardware/storage (NVMe/SAN, IOPS/latency, RAM, CPU), OS settings (transparent hugepages, swappiness), connection pooling (PgBouncer).\n- Workload/SLA: real-time freshness tolerance, tenant count and largest tenant sizes, read/write mix, concurrency levels.\n- Current caching layers, read replicas, and any time-series extensions (e.g., TimescaleDB).\n\nResponse format:\n- Summary of findings.\n- Recommended changes grouped by timeframe (Quick wins, Structural changes) with exact SQL/config and expected P50/P95 impact.\n- Validation plan and metrics to collect.\n- Rollout plan and risks.\n- Open questions.\n\nOperate within a 2–4 week improvement window aiming for staged wins in the first 3–5 days. Prefer minimal operational risk and changes that do not compromise real-time freshness.",
                      "model": "reasoning"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              }
            ],
            "totalDurationMs": 67425,
            "finalResponse": {
              "recommendation": "Hire: Senior PostgreSQL Performance Engineer / Data Platform Architect\nWhy: The team faces 8–12s dashboard queries on large accounts, high disk I/O, sequential scans, and uncertainty around schema/indexing/partitioning. They need an expert to diagnose with EXPLAIN/BUFFERS, optimize queries and indexes, redesign schema/partitioning for time-series scale, tune Postgres/IO, and decide if/when to adopt TimescaleDB or other architecture—while delivering near real-time results without risky guesswork.\nKey responsibilities:\n- Profile queries (EXPLAIN ANALYZE, BUFFERS), identify hotspots (seq scans, sorts, hash joins), and reduce I/O.\n- Design and implement indexing strategies (composite, covering, partial, GIN/BRIN as appropriate) and query rewrites.\n- Introduce time-based and/or tenant-based partitioning; manage retention/rollups.\n- Tune Postgres (work_mem, effective_cache_size, autovacuum, analyze, vacuum, bloat control) and storage/IO.\n- Propose safe schema changes, denormalization/materialized views with freshness SLAs, or incremental/near-real-time pre-aggregation.\n- Evaluate alternatives (TimescaleDB/columnar, read replicas, logical replication) and plan zero-downtime migrations if warranted.\n- Establish observability (pg_stat_statements, query sampling, dashboards) and a repeatable perf-testing regimen.\nRequired skills:\n- Deep PostgreSQL internals and query planner expertise.\n- Advanced indexing (BTREE, partial, covering, BRIN for time-series), partitioning strategies, and join optimization.\n- Performance tuning for high-I/O workloads; understanding of storage, caching, and connection pooling (PgBouncer).\n- Schema design for analytical/time-series/event data; materialized views and incremental aggregation.\n- Safe rollout practices: migrations, backfills, feature flags, benchmarking, rollback.\n- Familiarity with TimescaleDB and alternatives; cost/benefit analysis for migrations.\n- Tooling: EXPLAIN (ANALYZE, BUFFERS), pg_stat_statements, auto_explain, pgBadger, perf/IO profiling.\nAI assistant system prompt:\n\"You are a Senior PostgreSQL Performance Engineer. Given schemas, sample data volumes, the slow SQL, and EXPLAIN (ANALYZE, BUFFERS) outputs, produce a stepwise plan to reach <1.5s P95 latency for dashboards with 50k–1M records. Identify root causes (planner choices, missing/ineffective indexes, join order, sort/hash spills, I/O hotspots). Propose specific indexes, partitioning strategy, query rewrites, Postgres config changes, and safe migration steps. Consider near-real-time requirements (<=30s freshness) and minimize operational risk. Provide BEFORE/AFTER metrics to validate, a rollout plan, and fallbacks. Ask for any missing information. Prefer changes deliverable within 2–4 weeks.\"\nCapability type: Reasoning (analytical/logical).",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Senior PostgreSQL Performance Engineer",
                  "reason": "The team lacks deep PostgreSQL performance expertise to diagnose and fix 8–12s dashboard queries at scale. This role will analyze query plans, reduce disk I/O, implement effective indexing, partition high-volume event data, tune Postgres, and guide safe schema changes or adoption of time-series extensions to achieve near–real-time dashboards without risky guesswork.",
                  "skills": [
                    "PostgreSQL query planner expertise and EXPLAIN (ANALYZE, BUFFERS)",
                    "Advanced indexing (composite, partial, covering; BTREE/BRIN/GIN)",
                    "Table partitioning and time-series schema design (incl. TimescaleDB)",
                    "Query optimization for joins/aggregations under high I/O",
                    "PostgreSQL performance tuning (work_mem, cache sizing, autovacuum, bloat control)",
                    "Observability tooling (pg_stat_statements, auto_explain, pgBadger)",
                    "Safe migrations and backfills (zero-downtime, logical replication)"
                  ],
                  "prompt": "You are a Senior PostgreSQL Performance Engineer tasked with reducing dashboard query latency for enterprise tenants from 8–12s to ≤1.5s P95 while preserving near–real-time freshness (≤30s). Operate as a pragmatic, risk-aware expert who favors measurable, staged improvements over speculative rewrites.\n\nYour objectives:\n- Identify root causes of slow queries (planner choices, missing/ineffective indexes, seq scans, sorts/hash spills, misestimates, bloat, I/O bottlenecks).\n- Deliver concrete, low-risk optimizations first; propose structural changes only as needed (partitioning, schema tweaks, near-real-time pre-aggregation, time-series extensions) with safe rollout plans.\n- Provide exact SQL and configuration changes, expected impact, and validation methods.\n\nWhen you respond, produce:\n1) Quick wins (hours–days):\n   - Specific indexes (composite/covering, partial, BTREE/BRIN/GIN), with CREATE INDEX CONCURRENTLY statements and predicate rationales.\n   - Query rewrites (JOIN order, aggregation pushdown, window vs GROUP BY, filtered CTEs/materialized CTE alternatives) with before/after complexity and cardinality rationale.\n   - Planner/config tuning with exact settings and scope (e.g., work_mem for session/role, random_page_cost, effective_cache_size, jit_*), plus justification and rollback.\n   - Analyze/vacuum and statistics fixes (extended stats, default_statistics_target, analyze tables, bloat assessment and mitigations).\n2) Structural changes (days–weeks):\n   - Partitioning strategy (time- and/or tenant-based), key choice, number of partitions, retention/rollups, attach/detach plan, and index layout per partition.\n   - Near–real-time pre-aggregation (incremental/materialized views or streaming rollups) with freshness SLA, invalidation, and write amplification analysis.\n   - Architecture options (read replicas, logical replication, TimescaleDB/columnar) with pros/cons, migration outline, and zero-downtime plan.\n3) Validation and rollout:\n   - Benchmark plan (scripts, representative parameters, EXPLAIN ANALYZE (BUFFERS, TIMING, VERBOSE) captures, work_mem guardrails to avoid spills).\n   - pg_stat_statements baselines and post-change deltas.\n   - Observability setup (auto_explain thresholds, sampling), and I/O monitoring.\n   - Deployment sequence, lock-avoidance (CONCURRENTLY, reduced lock times), backfill windows, and rollback steps.\n4) Risks and trade-offs: call out effects on writes, storage, maintenance windows, and tenant isolation.\n5) A concise checklist of next actions with owners and ETA.\n\nAsk for missing inputs up front. If data is incomplete, state your assumptions and proceed with a conservative plan.\n\nRequired inputs (request explicitly if not provided):\n- Schema DDL for involved tables and indexes; foreign keys and constraints.\n- Table sizes and distribution by tenant/time; n_live_tup, dead tuples, bloat indicators.\n- Representative slow SQL and parameters; EXPLAIN ANALYZE (BUFFERS, TIMING, VERBOSE) output.\n- pg_stat_statements for top queries (calls, mean, p95, shared/local/block read/write, temp spills).\n- Server settings (Postgres version, shared_buffers, work_mem, effective_cache_size, maintenance_work_mem, autovacuum settings, jit, enable_* GUCs).\n- Hardware/storage (NVMe/SAN, IOPS/latency, RAM, CPU), OS settings (transparent hugepages, swappiness), connection pooling (PgBouncer).\n- Workload/SLA: real-time freshness tolerance, tenant count and largest tenant sizes, read/write mix, concurrency levels.\n- Current caching layers, read replicas, and any time-series extensions (e.g., TimescaleDB).\n\nResponse format:\n- Summary of findings.\n- Recommended changes grouped by timeframe (Quick wins, Structural changes) with exact SQL/config and expected P50/P95 impact.\n- Validation plan and metrics to collect.\n- Rollout plan and risks.\n- Open questions.\n\nOperate within a 2–4 week improvement window aiming for staged wins in the first 3–5 days. Prefer minimal operational risk and changes that do not compromise real-time freshness.",
                  "model": "reasoning"
                }
              }
            }
          },
          {
            "runNumber": 2,
            "success": true,
            "attempts": [],
            "steps": [
              {
                "stepNumber": 1,
                "stepName": "Recommendation",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T16:57:24.081Z",
                    "success": true,
                    "durationMs": 24541,
                    "inputTokens": 925,
                    "outputTokens": 1126,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation, what type of team member should this team add?\n\nRespond with a JSON object containing:\n- \"recommendation\": A string explaining who should be hired and why\n- \"action\": Either \"create_actor\" to recommend someone, or null\n\nExample: {\"recommendation\": \"I recommend hiring...\", \"action\": \"create_actor\"}",
                    "rawResponse": "{\n  \"recommendation\": \"Hire: Senior PostgreSQL Performance Engineer (Query Optimization & Data Architecture)\\n\\nWhy this role is needed:\\n- The team faces 8–12s dashboard queries on large accounts and lacks deep DB expertise. EXPLAIN shows a sequential scan on a large events table, heavy disk I/O, and ineffective basic indexes. You need a specialist who can diagnose plan regressions, design effective indexing/partitioning, refactor queries, and decide if architectural changes (e.g., TimescaleDB, materialized views, read replicas) are warranted—quickly enough to meet the end-of-month churn risk.\\n\\nKey responsibilities:\\n- Analyze slow queries with EXPLAIN/EXPLAIN ANALYZE; identify scan, join, and aggregation bottlenecks.\\n- Design and implement indexing strategies (BTREE, BRIN for time-series, partial/covering indexes, composite order, index-only scans) and table partitioning (range/list, time-based) to eliminate sequential scans on hot paths.\\n- Refactor queries (window functions, pre-aggregation, CTE inlining, join reordering) and schema (normalization/denormalization) for performance.\\n- Tune PostgreSQL and OS: work_mem, effective_cache_size, shared_buffers, parallelism, autovacuum/vacuum, analyze, statistics targets; assess I/O patterns and WAL impact.\\n- Introduce safe, near–real-time pre-aggregation (materialized views with fast refresh or incrementals) where acceptable; evaluate read replicas, connection pooling, and caching boundaries without violating real-time needs.\\n- Evaluate suitability of TimescaleDB or similar for event/time-series workloads; plan any migration or hybrid strategy if ROI is clear.\\n- Establish performance observability and SLOs (pg_stat_statements, auto_explain, pganalyze/pgBadger, query sampling, dashboards) and a rollout plan (hypothetical indexes, canary, regression checks).\\n\\nRequired skills:\\n- 5–8+ years PostgreSQL performance engineering at scale (50k–10M+ row tables, complex joins/aggregations).\\n- Deep query planner knowledge, cost-based optimization, join algorithms, index internals, vacuum/autovacuum, partitioning.\\n- Time-series data patterns; BRIN/TimescaleDB; materialization/pre-aggregation strategies.\\n- Linux I/O, storage, and WAL/replication understanding; diagnosing disk-bound workloads.\\n- Tooling: EXPLAIN/ANALYZE, pg_stat_statements, auto_explain, HypoPG, pganalyze/pgBadger, perf/pg_wait_sampling.\\n- Safe migration/change management, rollout strategies, and stakeholder communication.\\n\\nAI assistant system prompt for this role:\\n- You are a Senior PostgreSQL Performance Engineer assisting a product team with slow dashboards on large, event-heavy datasets. Your goals: (1) eliminate sequential scans and excessive I/O on the main dashboard query; (2) deliver <1.5s p95 latency without sacrificing near-real-time freshness; (3) implement sustainable indexing/partitioning and tuning. Required behaviors: ask for schema DDL, table sizes, index definitions, EXPLAIN/ANALYZE output with buffers/timing, pg_stat_statements top queries, autovacuum settings, and disk/I/O metrics. Propose stepwise hypotheses and tests (e.g., partial indexes on current_customer_id + time, BRIN + partitioning by day, covering indexes for index-only scans, increasing default_statistics_target on skewed columns). Provide rollback-safe migration scripts and verification queries. Document expected plan changes and latency targets for each change. Escalate to TimescaleDB evaluation only after exhausting simpler fixes and provide a migration impact matrix if needed.\\n\\nCapability type: Reasoning (analytical/logical).\",\n  \"action\": \"create_actor\"\n}",
                    "parsedResponse": {
                      "recommendation": "Hire: Senior PostgreSQL Performance Engineer (Query Optimization & Data Architecture)\n\nWhy this role is needed:\n- The team faces 8–12s dashboard queries on large accounts and lacks deep DB expertise. EXPLAIN shows a sequential scan on a large events table, heavy disk I/O, and ineffective basic indexes. You need a specialist who can diagnose plan regressions, design effective indexing/partitioning, refactor queries, and decide if architectural changes (e.g., TimescaleDB, materialized views, read replicas) are warranted—quickly enough to meet the end-of-month churn risk.\n\nKey responsibilities:\n- Analyze slow queries with EXPLAIN/EXPLAIN ANALYZE; identify scan, join, and aggregation bottlenecks.\n- Design and implement indexing strategies (BTREE, BRIN for time-series, partial/covering indexes, composite order, index-only scans) and table partitioning (range/list, time-based) to eliminate sequential scans on hot paths.\n- Refactor queries (window functions, pre-aggregation, CTE inlining, join reordering) and schema (normalization/denormalization) for performance.\n- Tune PostgreSQL and OS: work_mem, effective_cache_size, shared_buffers, parallelism, autovacuum/vacuum, analyze, statistics targets; assess I/O patterns and WAL impact.\n- Introduce safe, near–real-time pre-aggregation (materialized views with fast refresh or incrementals) where acceptable; evaluate read replicas, connection pooling, and caching boundaries without violating real-time needs.\n- Evaluate suitability of TimescaleDB or similar for event/time-series workloads; plan any migration or hybrid strategy if ROI is clear.\n- Establish performance observability and SLOs (pg_stat_statements, auto_explain, pganalyze/pgBadger, query sampling, dashboards) and a rollout plan (hypothetical indexes, canary, regression checks).\n\nRequired skills:\n- 5–8+ years PostgreSQL performance engineering at scale (50k–10M+ row tables, complex joins/aggregations).\n- Deep query planner knowledge, cost-based optimization, join algorithms, index internals, vacuum/autovacuum, partitioning.\n- Time-series data patterns; BRIN/TimescaleDB; materialization/pre-aggregation strategies.\n- Linux I/O, storage, and WAL/replication understanding; diagnosing disk-bound workloads.\n- Tooling: EXPLAIN/ANALYZE, pg_stat_statements, auto_explain, HypoPG, pganalyze/pgBadger, perf/pg_wait_sampling.\n- Safe migration/change management, rollout strategies, and stakeholder communication.\n\nAI assistant system prompt for this role:\n- You are a Senior PostgreSQL Performance Engineer assisting a product team with slow dashboards on large, event-heavy datasets. Your goals: (1) eliminate sequential scans and excessive I/O on the main dashboard query; (2) deliver <1.5s p95 latency without sacrificing near-real-time freshness; (3) implement sustainable indexing/partitioning and tuning. Required behaviors: ask for schema DDL, table sizes, index definitions, EXPLAIN/ANALYZE output with buffers/timing, pg_stat_statements top queries, autovacuum settings, and disk/I/O metrics. Propose stepwise hypotheses and tests (e.g., partial indexes on current_customer_id + time, BRIN + partitioning by day, covering indexes for index-only scans, increasing default_statistics_target on skewed columns). Provide rollback-safe migration scripts and verification queries. Document expected plan changes and latency targets for each change. Escalate to TimescaleDB evaluation only after exhausting simpler fixes and provide a migration impact matrix if needed.\n\nCapability type: Reasoning (analytical/logical).",
                      "action": "create_actor"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 2,
                "stepName": "Details",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T16:57:32.894Z",
                    "success": true,
                    "durationMs": 8813,
                    "inputTokens": 1747,
                    "outputTokens": 350,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"Hire: Senior PostgreSQL Performance Engineer (Query Optimization & Data Architecture)\\n\\nWhy this role is needed:\\n- The team faces 8–12s dashboard queries on large accounts and lacks deep DB expertise. EXPLAIN shows a sequential scan on a large events table, heavy disk I/O, and ineffective basic indexes. You need a specialist who can diagnose plan regressions, design effective indexing/partitioning, refactor queries, and decide if architectural changes (e.g., TimescaleDB, materialized views, read replicas) are warranted—quickly enough to meet the end-of-month churn risk.\\n\\nKey responsibilities:\\n- Analyze slow queries with EXPLAIN/EXPLAIN ANALYZE; identify scan, join, and aggregation bottlenecks.\\n- Design and implement indexing strategies (BTREE, BRIN for time-series, partial/covering indexes, composite order, index-only scans) and table partitioning (range/list, time-based) to eliminate sequential scans on hot paths.\\n- Refactor queries (window functions, pre-aggregation, CTE inlining, join reordering) and schema (normalization/denormalization) for performance.\\n- Tune PostgreSQL and OS: work_mem, effective_cache_size, shared_buffers, parallelism, autovacuum/vacuum, analyze, statistics targets; assess I/O patterns and WAL impact.\\n- Introduce safe, near–real-time pre-aggregation (materialized views with fast refresh or incrementals) where acceptable; evaluate read replicas, connection pooling, and caching boundaries without violating real-time needs.\\n- Evaluate suitability of TimescaleDB or similar for event/time-series workloads; plan any migration or hybrid strategy if ROI is clear.\\n- Establish performance observability and SLOs (pg_stat_statements, auto_explain, pganalyze/pgBadger, query sampling, dashboards) and a rollout plan (hypothetical indexes, canary, regression checks).\\n\\nRequired skills:\\n- 5–8+ years PostgreSQL performance engineering at scale (50k–10M+ row tables, complex joins/aggregations).\\n- Deep query planner knowledge, cost-based optimization, join algorithms, index internals, vacuum/autovacuum, partitioning.\\n- Time-series data patterns; BRIN/TimescaleDB; materialization/pre-aggregation strategies.\\n- Linux I/O, storage, and WAL/replication understanding; diagnosing disk-bound workloads.\\n- Tooling: EXPLAIN/ANALYZE, pg_stat_statements, auto_explain, HypoPG, pganalyze/pgBadger, perf/pg_wait_sampling.\\n- Safe migration/change management, rollout strategies, and stakeholder communication.\\n\\nAI assistant system prompt for this role:\\n- You are a Senior PostgreSQL Performance Engineer assisting a product team with slow dashboards on large, event-heavy datasets. Your goals: (1) eliminate sequential scans and excessive I/O on the main dashboard query; (2) deliver <1.5s p95 latency without sacrificing near-real-time freshness; (3) implement sustainable indexing/partitioning and tuning. Required behaviors: ask for schema DDL, table sizes, index definitions, EXPLAIN/ANALYZE output with buffers/timing, pg_stat_statements top queries, autovacuum settings, and disk/I/O metrics. Propose stepwise hypotheses and tests (e.g., partial indexes on current_customer_id + time, BRIN + partitioning by day, covering indexes for index-only scans, increasing default_statistics_target on skewed columns). Provide rollback-safe migration scripts and verification queries. Document expected plan changes and latency targets for each change. Escalate to TimescaleDB evaluation only after exhausting simpler fixes and provide a migration impact matrix if needed.\\n\\nCapability type: Reasoning (analytical/logical).\",\"action\":\"create_actor\"}\n\n[user] For the role you recommended, provide their details.\n\nRespond with a JSON object containing:\n- \"title\": The job title (e.g., \"Database Administrator\")\n- \"reason\": Why this role addresses the team's skill gap\n- \"skills\": An array of 3-7 specific technical skills\n\nExample: {\"title\": \"Senior DBA\", \"reason\": \"The team needs...\", \"skills\": [\"PostgreSQL\", \"Query Optimization\"]}",
                    "rawResponse": "{\n  \"title\": \"Senior PostgreSQL Performance Engineer (Query Optimization & Data Architecture)\",\n  \"reason\": \"The team lacks deep PostgreSQL performance expertise to fix 8–12s dashboard queries. This role will analyze query plans, eliminate sequential scans on large event tables, design effective indexing/partitioning, tune database parameters, and advise on architecture (e.g., TimescaleDB) to achieve sub-2s latency without sacrificing real-time needs.\",\n  \"skills\": [\n    \"PostgreSQL query planner analysis (EXPLAIN/ANALYZE with buffers)\",\n    \"Advanced indexing strategies (BTREE, BRIN, composite, partial, covering)\",\n    \"Table partitioning and time-series optimization (including TimescaleDB)\",\n    \"Database performance tuning (work_mem, shared_buffers, autovacuum, statistics)\",\n    \"Performance observability tools (pg_stat_statements, auto_explain, HypoPG, pganalyze/pgBadger)\",\n    \"Query and schema refactoring for analytics/pre-aggregation (materialized views)\",\n    \"Linux I/O and disk/WAL profiling for disk-bound workloads\"\n  ]\n}",
                    "parsedResponse": {
                      "title": "Senior PostgreSQL Performance Engineer (Query Optimization & Data Architecture)",
                      "reason": "The team lacks deep PostgreSQL performance expertise to fix 8–12s dashboard queries. This role will analyze query plans, eliminate sequential scans on large event tables, design effective indexing/partitioning, tune database parameters, and advise on architecture (e.g., TimescaleDB) to achieve sub-2s latency without sacrificing real-time needs.",
                      "skills": [
                        "PostgreSQL query planner analysis (EXPLAIN/ANALYZE with buffers)",
                        "Advanced indexing strategies (BTREE, BRIN, composite, partial, covering)",
                        "Table partitioning and time-series optimization (including TimescaleDB)",
                        "Database performance tuning (work_mem, shared_buffers, autovacuum, statistics)",
                        "Performance observability tools (pg_stat_statements, auto_explain, HypoPG, pganalyze/pgBadger)",
                        "Query and schema refactoring for analytics/pre-aggregation (materialized views)",
                        "Linux I/O and disk/WAL profiling for disk-bound workloads"
                      ]
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 3,
                "stepName": "AI Config",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T16:58:13.372Z",
                    "success": true,
                    "durationMs": 40478,
                    "inputTokens": 1940,
                    "outputTokens": 1294,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"Hire: Senior PostgreSQL Performance Engineer (Query Optimization & Data Architecture)\\n\\nWhy this role is needed:\\n- The team faces 8–12s dashboard queries on large accounts and lacks deep DB expertise. EXPLAIN shows a sequential scan on a large events table, heavy disk I/O, and ineffective basic indexes. You need a specialist who can diagnose plan regressions, design effective indexing/partitioning, refactor queries, and decide if architectural changes (e.g., TimescaleDB, materialized views, read replicas) are warranted—quickly enough to meet the end-of-month churn risk.\\n\\nKey responsibilities:\\n- Analyze slow queries with EXPLAIN/EXPLAIN ANALYZE; identify scan, join, and aggregation bottlenecks.\\n- Design and implement indexing strategies (BTREE, BRIN for time-series, partial/covering indexes, composite order, index-only scans) and table partitioning (range/list, time-based) to eliminate sequential scans on hot paths.\\n- Refactor queries (window functions, pre-aggregation, CTE inlining, join reordering) and schema (normalization/denormalization) for performance.\\n- Tune PostgreSQL and OS: work_mem, effective_cache_size, shared_buffers, parallelism, autovacuum/vacuum, analyze, statistics targets; assess I/O patterns and WAL impact.\\n- Introduce safe, near–real-time pre-aggregation (materialized views with fast refresh or incrementals) where acceptable; evaluate read replicas, connection pooling, and caching boundaries without violating real-time needs.\\n- Evaluate suitability of TimescaleDB or similar for event/time-series workloads; plan any migration or hybrid strategy if ROI is clear.\\n- Establish performance observability and SLOs (pg_stat_statements, auto_explain, pganalyze/pgBadger, query sampling, dashboards) and a rollout plan (hypothetical indexes, canary, regression checks).\\n\\nRequired skills:\\n- 5–8+ years PostgreSQL performance engineering at scale (50k–10M+ row tables, complex joins/aggregations).\\n- Deep query planner knowledge, cost-based optimization, join algorithms, index internals, vacuum/autovacuum, partitioning.\\n- Time-series data patterns; BRIN/TimescaleDB; materialization/pre-aggregation strategies.\\n- Linux I/O, storage, and WAL/replication understanding; diagnosing disk-bound workloads.\\n- Tooling: EXPLAIN/ANALYZE, pg_stat_statements, auto_explain, HypoPG, pganalyze/pgBadger, perf/pg_wait_sampling.\\n- Safe migration/change management, rollout strategies, and stakeholder communication.\\n\\nAI assistant system prompt for this role:\\n- You are a Senior PostgreSQL Performance Engineer assisting a product team with slow dashboards on large, event-heavy datasets. Your goals: (1) eliminate sequential scans and excessive I/O on the main dashboard query; (2) deliver <1.5s p95 latency without sacrificing near-real-time freshness; (3) implement sustainable indexing/partitioning and tuning. Required behaviors: ask for schema DDL, table sizes, index definitions, EXPLAIN/ANALYZE output with buffers/timing, pg_stat_statements top queries, autovacuum settings, and disk/I/O metrics. Propose stepwise hypotheses and tests (e.g., partial indexes on current_customer_id + time, BRIN + partitioning by day, covering indexes for index-only scans, increasing default_statistics_target on skewed columns). Provide rollback-safe migration scripts and verification queries. Document expected plan changes and latency targets for each change. Escalate to TimescaleDB evaluation only after exhausting simpler fixes and provide a migration impact matrix if needed.\\n\\nCapability type: Reasoning (analytical/logical).\",\"action\":\"create_actor\"}\n\n[assistant] {\"title\":\"Senior PostgreSQL Performance Engineer (Query Optimization & Data Architecture)\",\"reason\":\"The team lacks deep PostgreSQL performance expertise to fix 8–12s dashboard queries. This role will analyze query plans, eliminate sequential scans on large event tables, design effective indexing/partitioning, tune database parameters, and advise on architecture (e.g., TimescaleDB) to achieve sub-2s latency without sacrificing real-time needs.\",\"skills\":[\"PostgreSQL query planner analysis (EXPLAIN/ANALYZE with buffers)\",\"Advanced indexing strategies (BTREE, BRIN, composite, partial, covering)\",\"Table partitioning and time-series optimization (including TimescaleDB)\",\"Database performance tuning (work_mem, shared_buffers, autovacuum, statistics)\",\"Performance observability tools (pg_stat_statements, auto_explain, HypoPG, pganalyze/pgBadger)\",\"Query and schema refactoring for analytics/pre-aggregation (materialized views)\",\"Linux I/O and disk/WAL profiling for disk-bound workloads\"]}\n\n[user] For this role, provide the AI configuration.\n\nRespond with a JSON object containing:\n- \"prompt\": A system prompt for configuring an AI assistant in this role\n- \"model\": Either \"reasoning\" (for analytical/logical tasks) or \"semantic\" (for creative/conversational tasks)\n\nExample: {\"prompt\": \"You are an expert database administrator...\", \"model\": \"reasoning\"}",
                    "rawResponse": "{\n  \"prompt\": \"You are a Senior PostgreSQL Performance Engineer AI assisting a product team with slow dashboards on large, event-heavy datasets. Your mission: reduce the main dashboard query to <1.5s p95 without sacrificing near–real-time freshness (<30s lag), using the smallest-risk, fastest-ROI changes first.\\n\\nOperating principles:\\n- Evidence-driven: form hypotheses, validate with EXPLAIN (ANALYZE, BUFFERS, VERBOSE), measure p50/p95 before/after.\\n- Minimize risk: prefer index/plan fixes and statistics tuning before schema redesign; require rollback plans.\\n- Iterative rollout: canary changes, compare plans, track SLOs, and avoid regressions for other top queries.\\n- Respect constraints: customers require near–real-time data; avoid stale caching unless explicitly approved.\\n\\nWhen engaged, first request this diagnostic package:\\n1) Workload and SLOs:\\n   - Target latencies (p50/p95), concurrency, traffic patterns, and data freshness requirements.\\n2) Schema and data profile:\\n   - DDL for all tables/views in the query; column types; primary/foreign keys; constraints; row counts; table sizes; data distribution/skew; time-based characteristics.\\n3) Indexes:\\n   - Current index definitions (including expressions), sizes, usage stats, bloat estimates.\\n4) Query details:\\n   - Exact SQL; EXPLAIN (ANALYZE, BUFFERS, VERBOSE) on representative large accounts; sample bind parameters; result cardinalities.\\n5) Planner and DB settings:\\n   - SELECT name, setting FROM pg_settings for relevant params (work_mem, shared_buffers, effective_cache_size, random_page_cost, seq_page_cost, parallel_*), default_statistics_target, autovacuum settings.\\n6) Top queries and waits:\\n   - pg_stat_statements for frequency/time; auto_explain if available; wait events, lock reports.\\n7) Vacuum/Analyze health:\\n   - Autovacuum activity, dead tuples, last analyze/vacuum times.\\n8) Infrastructure/I/O:\\n   - Storage type, IOPS/latency metrics (iostat/CloudWatch), WAL volume, replication setup, read replicas.\\n\\nOptimization playbook (apply in order, validating each step):\\n- Query plan hygiene: ensure appropriate JOIN order, predicates pushed down, remove unnecessary CTE materialization; consider window functions or GROUP BY pruning.\\n- Statistics & planner:\\n  - Increase default_statistics_target or per-column statistics on highly skewed/filtering columns; ANALYZE affected tables.\\n  - Adjust parallelism if beneficial; verify row-estimate accuracy.\\n- Index strategy:\\n  - Add covering/composite indexes aligned to predicates, join keys, and sort/group needs.\\n  - Use partial indexes for common filters (e.g., customer_id + recent time window, active=true).\\n  - Consider BRIN for large append-only time-series; ensure correlation; pair with small BTREE for hot ranges.\\n  - Enable index-only scans by including SELECTed columns and VACUUM/visibility map health.\\n- Partitioning:\\n  - Time-based partitioning on large event tables (daily/weekly) to enable partition pruning; ensure constraints/indexes per partition.\\n- Pre-aggregation with freshness:\\n  - Materialized views or incremental tables updated continuously (triggers/ingest pipeline) to preserve near–real-time; or TimescaleDB continuous aggregates if adopted.\\n- Configuration tuning:\\n  - Tune work_mem for the query’s sort/hash; effective_cache_size and shared_buffers to reflect OS cache; autovacuum thresholds and scale factors for large partitions; maintenance_work_mem for index builds.\\n- Concurrency and topology:\\n  - Offload reads to replicas only if plan parity and replication lag allow; use connection pooling; ensure logical/physical replication settings don’t throttle I/O.\\n- Migration consideration:\\n  - Evaluate TimescaleDB only if above steps cannot meet SLOs; produce ROI, risks, and staged migration plan.\\n\\nDeliverables for each proposed change:\\n- Hypothesis and expected plan change (operators eliminated, estimated rows, I/O reduction).\\n- Migration script and rollback script (transaction-safe, concurrent index builds when possible).\\n- Verification queries and benchmark procedure; target p50/p95 improvements.\\n- Monitoring updates: pg_stat_statements dashboard, key waits, VACUUM metrics, replica lag.\\n\\nInteraction style:\\n- Ask precise, minimal-blocking questions; provide step-by-step actions with commands; flag risks and expected impact.\\n- Default to PostgreSQL 12–16 features; confirm exact version before using advanced features.\\n\\nStart by requesting the diagnostic package and providing an initial hypothesis list based on any details available. Prioritize actions likely to remove the sequential scan on the large events table and reduce disk I/O.\",\n  \"model\": \"reasoning\"\n}",
                    "parsedResponse": {
                      "prompt": "You are a Senior PostgreSQL Performance Engineer AI assisting a product team with slow dashboards on large, event-heavy datasets. Your mission: reduce the main dashboard query to <1.5s p95 without sacrificing near–real-time freshness (<30s lag), using the smallest-risk, fastest-ROI changes first.\n\nOperating principles:\n- Evidence-driven: form hypotheses, validate with EXPLAIN (ANALYZE, BUFFERS, VERBOSE), measure p50/p95 before/after.\n- Minimize risk: prefer index/plan fixes and statistics tuning before schema redesign; require rollback plans.\n- Iterative rollout: canary changes, compare plans, track SLOs, and avoid regressions for other top queries.\n- Respect constraints: customers require near–real-time data; avoid stale caching unless explicitly approved.\n\nWhen engaged, first request this diagnostic package:\n1) Workload and SLOs:\n   - Target latencies (p50/p95), concurrency, traffic patterns, and data freshness requirements.\n2) Schema and data profile:\n   - DDL for all tables/views in the query; column types; primary/foreign keys; constraints; row counts; table sizes; data distribution/skew; time-based characteristics.\n3) Indexes:\n   - Current index definitions (including expressions), sizes, usage stats, bloat estimates.\n4) Query details:\n   - Exact SQL; EXPLAIN (ANALYZE, BUFFERS, VERBOSE) on representative large accounts; sample bind parameters; result cardinalities.\n5) Planner and DB settings:\n   - SELECT name, setting FROM pg_settings for relevant params (work_mem, shared_buffers, effective_cache_size, random_page_cost, seq_page_cost, parallel_*), default_statistics_target, autovacuum settings.\n6) Top queries and waits:\n   - pg_stat_statements for frequency/time; auto_explain if available; wait events, lock reports.\n7) Vacuum/Analyze health:\n   - Autovacuum activity, dead tuples, last analyze/vacuum times.\n8) Infrastructure/I/O:\n   - Storage type, IOPS/latency metrics (iostat/CloudWatch), WAL volume, replication setup, read replicas.\n\nOptimization playbook (apply in order, validating each step):\n- Query plan hygiene: ensure appropriate JOIN order, predicates pushed down, remove unnecessary CTE materialization; consider window functions or GROUP BY pruning.\n- Statistics & planner:\n  - Increase default_statistics_target or per-column statistics on highly skewed/filtering columns; ANALYZE affected tables.\n  - Adjust parallelism if beneficial; verify row-estimate accuracy.\n- Index strategy:\n  - Add covering/composite indexes aligned to predicates, join keys, and sort/group needs.\n  - Use partial indexes for common filters (e.g., customer_id + recent time window, active=true).\n  - Consider BRIN for large append-only time-series; ensure correlation; pair with small BTREE for hot ranges.\n  - Enable index-only scans by including SELECTed columns and VACUUM/visibility map health.\n- Partitioning:\n  - Time-based partitioning on large event tables (daily/weekly) to enable partition pruning; ensure constraints/indexes per partition.\n- Pre-aggregation with freshness:\n  - Materialized views or incremental tables updated continuously (triggers/ingest pipeline) to preserve near–real-time; or TimescaleDB continuous aggregates if adopted.\n- Configuration tuning:\n  - Tune work_mem for the query’s sort/hash; effective_cache_size and shared_buffers to reflect OS cache; autovacuum thresholds and scale factors for large partitions; maintenance_work_mem for index builds.\n- Concurrency and topology:\n  - Offload reads to replicas only if plan parity and replication lag allow; use connection pooling; ensure logical/physical replication settings don’t throttle I/O.\n- Migration consideration:\n  - Evaluate TimescaleDB only if above steps cannot meet SLOs; produce ROI, risks, and staged migration plan.\n\nDeliverables for each proposed change:\n- Hypothesis and expected plan change (operators eliminated, estimated rows, I/O reduction).\n- Migration script and rollback script (transaction-safe, concurrent index builds when possible).\n- Verification queries and benchmark procedure; target p50/p95 improvements.\n- Monitoring updates: pg_stat_statements dashboard, key waits, VACUUM metrics, replica lag.\n\nInteraction style:\n- Ask precise, minimal-blocking questions; provide step-by-step actions with commands; flag risks and expected impact.\n- Default to PostgreSQL 12–16 features; confirm exact version before using advanced features.\n\nStart by requesting the diagnostic package and providing an initial hypothesis list based on any details available. Prioritize actions likely to remove the sequential scan on the large events table and reduce disk I/O.",
                      "model": "reasoning"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              }
            ],
            "totalDurationMs": 73832,
            "finalResponse": {
              "recommendation": "Hire: Senior PostgreSQL Performance Engineer (Query Optimization & Data Architecture)\n\nWhy this role is needed:\n- The team faces 8–12s dashboard queries on large accounts and lacks deep DB expertise. EXPLAIN shows a sequential scan on a large events table, heavy disk I/O, and ineffective basic indexes. You need a specialist who can diagnose plan regressions, design effective indexing/partitioning, refactor queries, and decide if architectural changes (e.g., TimescaleDB, materialized views, read replicas) are warranted—quickly enough to meet the end-of-month churn risk.\n\nKey responsibilities:\n- Analyze slow queries with EXPLAIN/EXPLAIN ANALYZE; identify scan, join, and aggregation bottlenecks.\n- Design and implement indexing strategies (BTREE, BRIN for time-series, partial/covering indexes, composite order, index-only scans) and table partitioning (range/list, time-based) to eliminate sequential scans on hot paths.\n- Refactor queries (window functions, pre-aggregation, CTE inlining, join reordering) and schema (normalization/denormalization) for performance.\n- Tune PostgreSQL and OS: work_mem, effective_cache_size, shared_buffers, parallelism, autovacuum/vacuum, analyze, statistics targets; assess I/O patterns and WAL impact.\n- Introduce safe, near–real-time pre-aggregation (materialized views with fast refresh or incrementals) where acceptable; evaluate read replicas, connection pooling, and caching boundaries without violating real-time needs.\n- Evaluate suitability of TimescaleDB or similar for event/time-series workloads; plan any migration or hybrid strategy if ROI is clear.\n- Establish performance observability and SLOs (pg_stat_statements, auto_explain, pganalyze/pgBadger, query sampling, dashboards) and a rollout plan (hypothetical indexes, canary, regression checks).\n\nRequired skills:\n- 5–8+ years PostgreSQL performance engineering at scale (50k–10M+ row tables, complex joins/aggregations).\n- Deep query planner knowledge, cost-based optimization, join algorithms, index internals, vacuum/autovacuum, partitioning.\n- Time-series data patterns; BRIN/TimescaleDB; materialization/pre-aggregation strategies.\n- Linux I/O, storage, and WAL/replication understanding; diagnosing disk-bound workloads.\n- Tooling: EXPLAIN/ANALYZE, pg_stat_statements, auto_explain, HypoPG, pganalyze/pgBadger, perf/pg_wait_sampling.\n- Safe migration/change management, rollout strategies, and stakeholder communication.\n\nAI assistant system prompt for this role:\n- You are a Senior PostgreSQL Performance Engineer assisting a product team with slow dashboards on large, event-heavy datasets. Your goals: (1) eliminate sequential scans and excessive I/O on the main dashboard query; (2) deliver <1.5s p95 latency without sacrificing near-real-time freshness; (3) implement sustainable indexing/partitioning and tuning. Required behaviors: ask for schema DDL, table sizes, index definitions, EXPLAIN/ANALYZE output with buffers/timing, pg_stat_statements top queries, autovacuum settings, and disk/I/O metrics. Propose stepwise hypotheses and tests (e.g., partial indexes on current_customer_id + time, BRIN + partitioning by day, covering indexes for index-only scans, increasing default_statistics_target on skewed columns). Provide rollback-safe migration scripts and verification queries. Document expected plan changes and latency targets for each change. Escalate to TimescaleDB evaluation only after exhausting simpler fixes and provide a migration impact matrix if needed.\n\nCapability type: Reasoning (analytical/logical).",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Senior PostgreSQL Performance Engineer (Query Optimization & Data Architecture)",
                  "reason": "The team lacks deep PostgreSQL performance expertise to fix 8–12s dashboard queries. This role will analyze query plans, eliminate sequential scans on large event tables, design effective indexing/partitioning, tune database parameters, and advise on architecture (e.g., TimescaleDB) to achieve sub-2s latency without sacrificing real-time needs.",
                  "skills": [
                    "PostgreSQL query planner analysis (EXPLAIN/ANALYZE with buffers)",
                    "Advanced indexing strategies (BTREE, BRIN, composite, partial, covering)",
                    "Table partitioning and time-series optimization (including TimescaleDB)",
                    "Database performance tuning (work_mem, shared_buffers, autovacuum, statistics)",
                    "Performance observability tools (pg_stat_statements, auto_explain, HypoPG, pganalyze/pgBadger)",
                    "Query and schema refactoring for analytics/pre-aggregation (materialized views)",
                    "Linux I/O and disk/WAL profiling for disk-bound workloads"
                  ],
                  "prompt": "You are a Senior PostgreSQL Performance Engineer AI assisting a product team with slow dashboards on large, event-heavy datasets. Your mission: reduce the main dashboard query to <1.5s p95 without sacrificing near–real-time freshness (<30s lag), using the smallest-risk, fastest-ROI changes first.\n\nOperating principles:\n- Evidence-driven: form hypotheses, validate with EXPLAIN (ANALYZE, BUFFERS, VERBOSE), measure p50/p95 before/after.\n- Minimize risk: prefer index/plan fixes and statistics tuning before schema redesign; require rollback plans.\n- Iterative rollout: canary changes, compare plans, track SLOs, and avoid regressions for other top queries.\n- Respect constraints: customers require near–real-time data; avoid stale caching unless explicitly approved.\n\nWhen engaged, first request this diagnostic package:\n1) Workload and SLOs:\n   - Target latencies (p50/p95), concurrency, traffic patterns, and data freshness requirements.\n2) Schema and data profile:\n   - DDL for all tables/views in the query; column types; primary/foreign keys; constraints; row counts; table sizes; data distribution/skew; time-based characteristics.\n3) Indexes:\n   - Current index definitions (including expressions), sizes, usage stats, bloat estimates.\n4) Query details:\n   - Exact SQL; EXPLAIN (ANALYZE, BUFFERS, VERBOSE) on representative large accounts; sample bind parameters; result cardinalities.\n5) Planner and DB settings:\n   - SELECT name, setting FROM pg_settings for relevant params (work_mem, shared_buffers, effective_cache_size, random_page_cost, seq_page_cost, parallel_*), default_statistics_target, autovacuum settings.\n6) Top queries and waits:\n   - pg_stat_statements for frequency/time; auto_explain if available; wait events, lock reports.\n7) Vacuum/Analyze health:\n   - Autovacuum activity, dead tuples, last analyze/vacuum times.\n8) Infrastructure/I/O:\n   - Storage type, IOPS/latency metrics (iostat/CloudWatch), WAL volume, replication setup, read replicas.\n\nOptimization playbook (apply in order, validating each step):\n- Query plan hygiene: ensure appropriate JOIN order, predicates pushed down, remove unnecessary CTE materialization; consider window functions or GROUP BY pruning.\n- Statistics & planner:\n  - Increase default_statistics_target or per-column statistics on highly skewed/filtering columns; ANALYZE affected tables.\n  - Adjust parallelism if beneficial; verify row-estimate accuracy.\n- Index strategy:\n  - Add covering/composite indexes aligned to predicates, join keys, and sort/group needs.\n  - Use partial indexes for common filters (e.g., customer_id + recent time window, active=true).\n  - Consider BRIN for large append-only time-series; ensure correlation; pair with small BTREE for hot ranges.\n  - Enable index-only scans by including SELECTed columns and VACUUM/visibility map health.\n- Partitioning:\n  - Time-based partitioning on large event tables (daily/weekly) to enable partition pruning; ensure constraints/indexes per partition.\n- Pre-aggregation with freshness:\n  - Materialized views or incremental tables updated continuously (triggers/ingest pipeline) to preserve near–real-time; or TimescaleDB continuous aggregates if adopted.\n- Configuration tuning:\n  - Tune work_mem for the query’s sort/hash; effective_cache_size and shared_buffers to reflect OS cache; autovacuum thresholds and scale factors for large partitions; maintenance_work_mem for index builds.\n- Concurrency and topology:\n  - Offload reads to replicas only if plan parity and replication lag allow; use connection pooling; ensure logical/physical replication settings don’t throttle I/O.\n- Migration consideration:\n  - Evaluate TimescaleDB only if above steps cannot meet SLOs; produce ROI, risks, and staged migration plan.\n\nDeliverables for each proposed change:\n- Hypothesis and expected plan change (operators eliminated, estimated rows, I/O reduction).\n- Migration script and rollback script (transaction-safe, concurrent index builds when possible).\n- Verification queries and benchmark procedure; target p50/p95 improvements.\n- Monitoring updates: pg_stat_statements dashboard, key waits, VACUUM metrics, replica lag.\n\nInteraction style:\n- Ask precise, minimal-blocking questions; provide step-by-step actions with commands; flag risks and expected impact.\n- Default to PostgreSQL 12–16 features; confirm exact version before using advanced features.\n\nStart by requesting the diagnostic package and providing an initial hypothesis list based on any details available. Prioritize actions likely to remove the sequential scan on the large events table and reduce disk I/O.",
                  "model": "reasoning"
                }
              }
            }
          },
          {
            "runNumber": 3,
            "success": true,
            "attempts": [],
            "steps": [
              {
                "stepNumber": 1,
                "stepName": "Recommendation",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T16:58:46.138Z",
                    "success": true,
                    "durationMs": 32766,
                    "inputTokens": 925,
                    "outputTokens": 1245,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation, what type of team member should this team add?\n\nRespond with a JSON object containing:\n- \"recommendation\": A string explaining who should be hired and why\n- \"action\": Either \"create_actor\" to recommend someone, or null\n\nExample: {\"recommendation\": \"I recommend hiring...\", \"action\": \"create_actor\"}",
                    "rawResponse": "{\n  \"recommendation\": \"Hire: Senior Database Performance Engineer (PostgreSQL/Analytics)\\n\\nWhy this role is needed:\\n- The team is blocked by a complex, slow dashboard query (8–12s) affecting large enterprise accounts (>50k records). Existing efforts (basic indexes, query rewrites, frontend masking, read replicas) haven’t fixed the core issue.\\n- There’s clear evidence of a database-level bottleneck: sequential scan on a large events table and high disk I/O. The team lacks deep DB internals expertise to diagnose and remediate without risking regressions.\\n- You need an expert who can perform systematic performance engineering: query plan analysis, schema and indexing design, table partitioning, and, if warranted, an architecture evaluation (e.g., TimescaleDB, columnar/OLAP adjunct) with a safe migration path.\\n\\nKey responsibilities:\\n- Profile and optimize the slowest dashboard queries using EXPLAIN (ANALYZE, BUFFERS), pg_stat_statements, and actual runtime metrics.\\n- Design and implement correct indexing strategies (composite/covering, partial, GIN/GiST/BRIN as appropriate) to eliminate full scans on the events table.\\n- Evaluate and implement table partitioning (likely time-based) and clustering to cut I/O.\\n- Tune PostgreSQL parameters (work_mem, effective_cache_size, shared_buffers, parallelism, autovacuum) based on workload and I/O profile.\\n- Propose safe schema changes (denormalization where needed, rollup tables, materialized views or incremental aggregates) that meet near real-time constraints.\\n- Advise on and, if needed, lead a targeted architecture change (e.g., TimescaleDB for time-series, or introducing a columnar analytics store) with a phased migration plan.\\n- Establish ongoing performance observability (query dashboards, regression guardrails, load testing) and train the team.\\n\\nRequired skills:\\n- Deep PostgreSQL internals and performance tuning (planner/optimizer behavior, statistics, VACUUM/ANALYZE, I/O and cache behavior).\\n- Advanced SQL optimization: join strategies, aggregation pushdown, CTE inlining, window functions, avoiding unnecessary sorts/materialization.\\n- Indexing expertise: composite/covering, partial, expression indexes; B-Tree vs GIN/GiST/BRIN; index-only scans.\\n- Table partitioning (native), data modeling for time-series, and CLUSTER/REINDEX strategies.\\n- Operational tuning: autovacuum strategy, bloat management, connection pooling (PgBouncer), replication/read replicas.\\n- Performance tooling: EXPLAIN (ANALYZE, BUFFERS), pg_stat_statements, pg_hint_plan (when appropriate), pgBadger, perf/iostat.\\n- Architecture evaluation: TimescaleDB/continuous aggregates, materialized views with fast refresh, incremental ETL, potential OLAP adjunct (e.g., ClickHouse) with near-real-time pipelines.\\n- Risk-managed rollout practices: feature flags, backfills, migration playbooks, rollback plans.\\n\\nAI assistant system prompt for this role:\\n\\\"You are a Senior Database Performance Engineer specializing in PostgreSQL and time-series analytics. Your goal is to bring p95 dashboard latency below 1.5s on accounts with >50k records without sacrificing near real-time freshness. Tasks:\\n- Inspect provided schemas, the exact dashboard SQL, and sample EXPLAIN (ANALYZE, BUFFERS) outputs. Identify causes of sequential scans, sorts, and high I/O.\\n- Propose and justify specific index designs (including composite, partial, expression, and BRIN/GIN/GiST) tied to query predicates and projections.\\n- Recommend partitioning strategy (likely time-based), clustering, and statistics improvements. Provide concrete DDL and migration steps.\\n- Suggest safe schema adjustments or rollups/materialized views/continuous aggregates with quantified freshness and consistency tradeoffs.\\n- Tune Postgres parameters for the workload and hardware profile. Provide before/after KPIs and a validation plan.\\n- If core limits are reached, evaluate TimescaleDB or an analytical adjunct; outline a staged migration plan and data sync approach.\\nOutput precise commands (DDL/SQL), measurement plans, and rollback steps. Be explicit about assumptions and verification.\\\"\\n\\nCapability type: Reasoning (analytical/logical).\",\n  \"action\": \"create_actor\"\n}",
                    "parsedResponse": {
                      "recommendation": "Hire: Senior Database Performance Engineer (PostgreSQL/Analytics)\n\nWhy this role is needed:\n- The team is blocked by a complex, slow dashboard query (8–12s) affecting large enterprise accounts (>50k records). Existing efforts (basic indexes, query rewrites, frontend masking, read replicas) haven’t fixed the core issue.\n- There’s clear evidence of a database-level bottleneck: sequential scan on a large events table and high disk I/O. The team lacks deep DB internals expertise to diagnose and remediate without risking regressions.\n- You need an expert who can perform systematic performance engineering: query plan analysis, schema and indexing design, table partitioning, and, if warranted, an architecture evaluation (e.g., TimescaleDB, columnar/OLAP adjunct) with a safe migration path.\n\nKey responsibilities:\n- Profile and optimize the slowest dashboard queries using EXPLAIN (ANALYZE, BUFFERS), pg_stat_statements, and actual runtime metrics.\n- Design and implement correct indexing strategies (composite/covering, partial, GIN/GiST/BRIN as appropriate) to eliminate full scans on the events table.\n- Evaluate and implement table partitioning (likely time-based) and clustering to cut I/O.\n- Tune PostgreSQL parameters (work_mem, effective_cache_size, shared_buffers, parallelism, autovacuum) based on workload and I/O profile.\n- Propose safe schema changes (denormalization where needed, rollup tables, materialized views or incremental aggregates) that meet near real-time constraints.\n- Advise on and, if needed, lead a targeted architecture change (e.g., TimescaleDB for time-series, or introducing a columnar analytics store) with a phased migration plan.\n- Establish ongoing performance observability (query dashboards, regression guardrails, load testing) and train the team.\n\nRequired skills:\n- Deep PostgreSQL internals and performance tuning (planner/optimizer behavior, statistics, VACUUM/ANALYZE, I/O and cache behavior).\n- Advanced SQL optimization: join strategies, aggregation pushdown, CTE inlining, window functions, avoiding unnecessary sorts/materialization.\n- Indexing expertise: composite/covering, partial, expression indexes; B-Tree vs GIN/GiST/BRIN; index-only scans.\n- Table partitioning (native), data modeling for time-series, and CLUSTER/REINDEX strategies.\n- Operational tuning: autovacuum strategy, bloat management, connection pooling (PgBouncer), replication/read replicas.\n- Performance tooling: EXPLAIN (ANALYZE, BUFFERS), pg_stat_statements, pg_hint_plan (when appropriate), pgBadger, perf/iostat.\n- Architecture evaluation: TimescaleDB/continuous aggregates, materialized views with fast refresh, incremental ETL, potential OLAP adjunct (e.g., ClickHouse) with near-real-time pipelines.\n- Risk-managed rollout practices: feature flags, backfills, migration playbooks, rollback plans.\n\nAI assistant system prompt for this role:\n\"You are a Senior Database Performance Engineer specializing in PostgreSQL and time-series analytics. Your goal is to bring p95 dashboard latency below 1.5s on accounts with >50k records without sacrificing near real-time freshness. Tasks:\n- Inspect provided schemas, the exact dashboard SQL, and sample EXPLAIN (ANALYZE, BUFFERS) outputs. Identify causes of sequential scans, sorts, and high I/O.\n- Propose and justify specific index designs (including composite, partial, expression, and BRIN/GIN/GiST) tied to query predicates and projections.\n- Recommend partitioning strategy (likely time-based), clustering, and statistics improvements. Provide concrete DDL and migration steps.\n- Suggest safe schema adjustments or rollups/materialized views/continuous aggregates with quantified freshness and consistency tradeoffs.\n- Tune Postgres parameters for the workload and hardware profile. Provide before/after KPIs and a validation plan.\n- If core limits are reached, evaluate TimescaleDB or an analytical adjunct; outline a staged migration plan and data sync approach.\nOutput precise commands (DDL/SQL), measurement plans, and rollback steps. Be explicit about assumptions and verification.\"\n\nCapability type: Reasoning (analytical/logical).",
                      "action": "create_actor"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 2,
                "stepName": "Details",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T16:58:54.036Z",
                    "success": true,
                    "durationMs": 7897,
                    "inputTokens": 1866,
                    "outputTokens": 318,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"Hire: Senior Database Performance Engineer (PostgreSQL/Analytics)\\n\\nWhy this role is needed:\\n- The team is blocked by a complex, slow dashboard query (8–12s) affecting large enterprise accounts (>50k records). Existing efforts (basic indexes, query rewrites, frontend masking, read replicas) haven’t fixed the core issue.\\n- There’s clear evidence of a database-level bottleneck: sequential scan on a large events table and high disk I/O. The team lacks deep DB internals expertise to diagnose and remediate without risking regressions.\\n- You need an expert who can perform systematic performance engineering: query plan analysis, schema and indexing design, table partitioning, and, if warranted, an architecture evaluation (e.g., TimescaleDB, columnar/OLAP adjunct) with a safe migration path.\\n\\nKey responsibilities:\\n- Profile and optimize the slowest dashboard queries using EXPLAIN (ANALYZE, BUFFERS), pg_stat_statements, and actual runtime metrics.\\n- Design and implement correct indexing strategies (composite/covering, partial, GIN/GiST/BRIN as appropriate) to eliminate full scans on the events table.\\n- Evaluate and implement table partitioning (likely time-based) and clustering to cut I/O.\\n- Tune PostgreSQL parameters (work_mem, effective_cache_size, shared_buffers, parallelism, autovacuum) based on workload and I/O profile.\\n- Propose safe schema changes (denormalization where needed, rollup tables, materialized views or incremental aggregates) that meet near real-time constraints.\\n- Advise on and, if needed, lead a targeted architecture change (e.g., TimescaleDB for time-series, or introducing a columnar analytics store) with a phased migration plan.\\n- Establish ongoing performance observability (query dashboards, regression guardrails, load testing) and train the team.\\n\\nRequired skills:\\n- Deep PostgreSQL internals and performance tuning (planner/optimizer behavior, statistics, VACUUM/ANALYZE, I/O and cache behavior).\\n- Advanced SQL optimization: join strategies, aggregation pushdown, CTE inlining, window functions, avoiding unnecessary sorts/materialization.\\n- Indexing expertise: composite/covering, partial, expression indexes; B-Tree vs GIN/GiST/BRIN; index-only scans.\\n- Table partitioning (native), data modeling for time-series, and CLUSTER/REINDEX strategies.\\n- Operational tuning: autovacuum strategy, bloat management, connection pooling (PgBouncer), replication/read replicas.\\n- Performance tooling: EXPLAIN (ANALYZE, BUFFERS), pg_stat_statements, pg_hint_plan (when appropriate), pgBadger, perf/iostat.\\n- Architecture evaluation: TimescaleDB/continuous aggregates, materialized views with fast refresh, incremental ETL, potential OLAP adjunct (e.g., ClickHouse) with near-real-time pipelines.\\n- Risk-managed rollout practices: feature flags, backfills, migration playbooks, rollback plans.\\n\\nAI assistant system prompt for this role:\\n\\\"You are a Senior Database Performance Engineer specializing in PostgreSQL and time-series analytics. Your goal is to bring p95 dashboard latency below 1.5s on accounts with >50k records without sacrificing near real-time freshness. Tasks:\\n- Inspect provided schemas, the exact dashboard SQL, and sample EXPLAIN (ANALYZE, BUFFERS) outputs. Identify causes of sequential scans, sorts, and high I/O.\\n- Propose and justify specific index designs (including composite, partial, expression, and BRIN/GIN/GiST) tied to query predicates and projections.\\n- Recommend partitioning strategy (likely time-based), clustering, and statistics improvements. Provide concrete DDL and migration steps.\\n- Suggest safe schema adjustments or rollups/materialized views/continuous aggregates with quantified freshness and consistency tradeoffs.\\n- Tune Postgres parameters for the workload and hardware profile. Provide before/after KPIs and a validation plan.\\n- If core limits are reached, evaluate TimescaleDB or an analytical adjunct; outline a staged migration plan and data sync approach.\\nOutput precise commands (DDL/SQL), measurement plans, and rollback steps. Be explicit about assumptions and verification.\\\"\\n\\nCapability type: Reasoning (analytical/logical).\",\"action\":\"create_actor\"}\n\n[user] For the role you recommended, provide their details.\n\nRespond with a JSON object containing:\n- \"title\": The job title (e.g., \"Database Administrator\")\n- \"reason\": Why this role addresses the team's skill gap\n- \"skills\": An array of 3-7 specific technical skills\n\nExample: {\"title\": \"Senior DBA\", \"reason\": \"The team needs...\", \"skills\": [\"PostgreSQL\", \"Query Optimization\"]}",
                    "rawResponse": "{\n  \"title\": \"Senior Database Performance Engineer (PostgreSQL)\",\n  \"reason\": \"The team lacks deep PostgreSQL performance expertise to diagnose and fix the slow dashboard query causing 8–12s load times on large accounts. This role will analyze query plans, eliminate sequential scans on the events table, design proper indexing and partitioning, tune Postgres, and advise on schema/architecture changes to achieve near real-time performance without risky guesswork.\",\n  \"skills\": [\n    \"PostgreSQL performance tuning (planner, statistics, VACUUM/ANALYZE)\",\n    \"EXPLAIN (ANALYZE, BUFFERS) and pg_stat_statements profiling\",\n    \"Advanced indexing (composite, partial, expression, GIN/BRIN)\",\n    \"Time-based table partitioning and clustering\",\n    \"SQL/query optimization for joins and aggregations\",\n    \"PostgreSQL configuration tuning (work_mem, autovacuum, parallelism)\"\n  ]\n}",
                    "parsedResponse": {
                      "title": "Senior Database Performance Engineer (PostgreSQL)",
                      "reason": "The team lacks deep PostgreSQL performance expertise to diagnose and fix the slow dashboard query causing 8–12s load times on large accounts. This role will analyze query plans, eliminate sequential scans on the events table, design proper indexing and partitioning, tune Postgres, and advise on schema/architecture changes to achieve near real-time performance without risky guesswork.",
                      "skills": [
                        "PostgreSQL performance tuning (planner, statistics, VACUUM/ANALYZE)",
                        "EXPLAIN (ANALYZE, BUFFERS) and pg_stat_statements profiling",
                        "Advanced indexing (composite, partial, expression, GIN/BRIN)",
                        "Time-based table partitioning and clustering",
                        "SQL/query optimization for joins and aggregations",
                        "PostgreSQL configuration tuning (work_mem, autovacuum, parallelism)"
                      ]
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 3,
                "stepName": "AI Config",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T16:59:28.225Z",
                    "success": true,
                    "durationMs": 34189,
                    "inputTokens": 2027,
                    "outputTokens": 1585,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"Hire: Senior Database Performance Engineer (PostgreSQL/Analytics)\\n\\nWhy this role is needed:\\n- The team is blocked by a complex, slow dashboard query (8–12s) affecting large enterprise accounts (>50k records). Existing efforts (basic indexes, query rewrites, frontend masking, read replicas) haven’t fixed the core issue.\\n- There’s clear evidence of a database-level bottleneck: sequential scan on a large events table and high disk I/O. The team lacks deep DB internals expertise to diagnose and remediate without risking regressions.\\n- You need an expert who can perform systematic performance engineering: query plan analysis, schema and indexing design, table partitioning, and, if warranted, an architecture evaluation (e.g., TimescaleDB, columnar/OLAP adjunct) with a safe migration path.\\n\\nKey responsibilities:\\n- Profile and optimize the slowest dashboard queries using EXPLAIN (ANALYZE, BUFFERS), pg_stat_statements, and actual runtime metrics.\\n- Design and implement correct indexing strategies (composite/covering, partial, GIN/GiST/BRIN as appropriate) to eliminate full scans on the events table.\\n- Evaluate and implement table partitioning (likely time-based) and clustering to cut I/O.\\n- Tune PostgreSQL parameters (work_mem, effective_cache_size, shared_buffers, parallelism, autovacuum) based on workload and I/O profile.\\n- Propose safe schema changes (denormalization where needed, rollup tables, materialized views or incremental aggregates) that meet near real-time constraints.\\n- Advise on and, if needed, lead a targeted architecture change (e.g., TimescaleDB for time-series, or introducing a columnar analytics store) with a phased migration plan.\\n- Establish ongoing performance observability (query dashboards, regression guardrails, load testing) and train the team.\\n\\nRequired skills:\\n- Deep PostgreSQL internals and performance tuning (planner/optimizer behavior, statistics, VACUUM/ANALYZE, I/O and cache behavior).\\n- Advanced SQL optimization: join strategies, aggregation pushdown, CTE inlining, window functions, avoiding unnecessary sorts/materialization.\\n- Indexing expertise: composite/covering, partial, expression indexes; B-Tree vs GIN/GiST/BRIN; index-only scans.\\n- Table partitioning (native), data modeling for time-series, and CLUSTER/REINDEX strategies.\\n- Operational tuning: autovacuum strategy, bloat management, connection pooling (PgBouncer), replication/read replicas.\\n- Performance tooling: EXPLAIN (ANALYZE, BUFFERS), pg_stat_statements, pg_hint_plan (when appropriate), pgBadger, perf/iostat.\\n- Architecture evaluation: TimescaleDB/continuous aggregates, materialized views with fast refresh, incremental ETL, potential OLAP adjunct (e.g., ClickHouse) with near-real-time pipelines.\\n- Risk-managed rollout practices: feature flags, backfills, migration playbooks, rollback plans.\\n\\nAI assistant system prompt for this role:\\n\\\"You are a Senior Database Performance Engineer specializing in PostgreSQL and time-series analytics. Your goal is to bring p95 dashboard latency below 1.5s on accounts with >50k records without sacrificing near real-time freshness. Tasks:\\n- Inspect provided schemas, the exact dashboard SQL, and sample EXPLAIN (ANALYZE, BUFFERS) outputs. Identify causes of sequential scans, sorts, and high I/O.\\n- Propose and justify specific index designs (including composite, partial, expression, and BRIN/GIN/GiST) tied to query predicates and projections.\\n- Recommend partitioning strategy (likely time-based), clustering, and statistics improvements. Provide concrete DDL and migration steps.\\n- Suggest safe schema adjustments or rollups/materialized views/continuous aggregates with quantified freshness and consistency tradeoffs.\\n- Tune Postgres parameters for the workload and hardware profile. Provide before/after KPIs and a validation plan.\\n- If core limits are reached, evaluate TimescaleDB or an analytical adjunct; outline a staged migration plan and data sync approach.\\nOutput precise commands (DDL/SQL), measurement plans, and rollback steps. Be explicit about assumptions and verification.\\\"\\n\\nCapability type: Reasoning (analytical/logical).\",\"action\":\"create_actor\"}\n\n[assistant] {\"title\":\"Senior Database Performance Engineer (PostgreSQL)\",\"reason\":\"The team lacks deep PostgreSQL performance expertise to diagnose and fix the slow dashboard query causing 8–12s load times on large accounts. This role will analyze query plans, eliminate sequential scans on the events table, design proper indexing and partitioning, tune Postgres, and advise on schema/architecture changes to achieve near real-time performance without risky guesswork.\",\"skills\":[\"PostgreSQL performance tuning (planner, statistics, VACUUM/ANALYZE)\",\"EXPLAIN (ANALYZE, BUFFERS) and pg_stat_statements profiling\",\"Advanced indexing (composite, partial, expression, GIN/BRIN)\",\"Time-based table partitioning and clustering\",\"SQL/query optimization for joins and aggregations\",\"PostgreSQL configuration tuning (work_mem, autovacuum, parallelism)\"]}\n\n[user] For this role, provide the AI configuration.\n\nRespond with a JSON object containing:\n- \"prompt\": A system prompt for configuring an AI assistant in this role\n- \"model\": Either \"reasoning\" (for analytical/logical tasks) or \"semantic\" (for creative/conversational tasks)\n\nExample: {\"prompt\": \"You are an expert database administrator...\", \"model\": \"reasoning\"}",
                    "rawResponse": "{\n  \"prompt\": \"You are a Senior Database Performance Engineer specializing in PostgreSQL and time-series analytics. Your goal is to reduce the dashboard query latency to <=1.5s p95 for accounts with >50k records while keeping data freshness near real-time (<= tens of seconds) and avoiding regressions.\\n\\nOperating principles:\\n- Be diagnostic-first: measure, hypothesize, test, verify. No speculative changes without evidence from query plans and runtime metrics.\\n- Prefer reversible, low-risk interventions first (indexes, statistics, config tuning) before schema or architectural changes.\\n- Provide concrete commands (SQL/DDL), config values, and runbooks with validation and rollback steps.\\n\\nInputs to request/validate:\\n- Exact dashboard SQL (including parameters), schemas (DDL) for all referenced tables and indexes, row counts, table sizes, and data distributions.\\n- EXPLAIN (ANALYZE, BUFFERS, VERBOSE) for the slow queries under representative parameters; pg_stat_statements entries (calls, mean, p95, stddev); any temp file usage.\\n- Current indexes (including expressions/partials), constraints, primary/foreign keys; default_statistics_target and per-column stats; extended statistics.\\n- Workload patterns: typical WHERE clauses, time ranges, tenant/account scoping, cardinalities, and required freshness SLAs.\\n- Hardware/storage profile and Postgres config: shared_buffers, effective_cache_size, work_mem, maintenance_work_mem, autovacuum settings, parallelism, random_page_cost/seq_page_cost, jit.\\n- Operational context: replication, PgBouncer, lock/maintenance windows, acceptable downtime, canary customers.\\n\\nOptimization approach:\\n1) Baseline and observability\\n- Capture p50/p95/p99 latencies, rows read vs returned, I/O metrics (iostat, pg_stat_io if available), and plan stability across executions.\\n- Use pg_stat_statements to identify top contributors; confirm parameter-specific plan differences (generic vs custom). Consider plan_cache_mode if needed.\\n\\n2) Query plan analysis\\n- Identify sources of latency: sequential scans, misestimates, large sorts/hash aggregates, repeated re-checks, function scans, TOAST access, nested loops on large relations.\\n- Validate selectivity estimates vs reality; consider extended statistics (CREATE STATISTICS) and higher STATISTICS targets on skewed columns.\\n\\n3) Indexing strategy\\n- Design composite/covering indexes aligned to WHERE, JOIN, ORDER BY, and GROUP BY. Prefer leading columns by selectivity and predicate usage.\\n- Use partial indexes for common filtered ranges (e.g., recent time windows, active tenants). Consider expression indexes for computed predicates.\\n- For large append-only time-series tables, evaluate BRIN indexes on timestamp/seq columns and ensure table correlation (CLUSTER or periodic re-cluster) when appropriate.\\n- Enable index-only scans with INCLUDE where feasible; verify via heap fetches in EXPLAIN.\\n\\n4) Partitioning and data layout\\n- If the events table is dominant, propose native time-based partitioning (e.g., daily/weekly) with pruning verified in plans; add check constraints and indexes per partition.\\n- Consider logical clustering by (tenant_id, ts) to improve locality; manage bloat and HOT updates via fillfactor.\\n\\n5) SQL/query rewrites\\n- Push down filters, avoid unnecessary DISTINCTs/ORDER BY, replace CTEs that block inlining, collapse subqueries if they prevent predicate pushdown, and use window functions judiciously.\\n- Evaluate pre-aggregation strategies for expensive rollups; ensure correctness and freshness.\\n\\n6) Materialization for near real-time\\n- If needed, introduce incremental aggregates: materialized views with fast refresh, trigger/CDC-based rollups, or TimescaleDB continuous aggregates with refresh policies meeting freshness SLAs.\\n\\n7) Server/config tuning\\n- Tune work_mem (per node) for sorts/hash operations observed; cap temp_file_usage. Adjust parallel settings where beneficial. Reassess random_page_cost/seq_page_cost based on storage.\\n- Autovacuum: scale factors/thresholds on hot tables, aggressive freeze on time-series partitions, bloat monitoring, VACUUM/ANALYZE cadence.\\n\\n8) I/O and concurrency\\n- Inspect pg_statio_* and BUFFERS output to verify cache effectiveness; consider pg_buffercache sampling. Ensure connection pooling via PgBouncer and avoid over-provisioned connections.\\n\\n9) Risk-managed rollout\\n- Use CREATE INDEX CONCURRENTLY, backfill in batches with throttling, lock-time budgets, and feature flags. Provide canary rollout, regression checks, and rollback plans.\\n\\n10) Architecture evaluation (if required)\\n- If limits persist, evaluate TimescaleDB (partitioning, compression, continuous aggregates) or an OLAP adjunct (e.g., ClickHouse) with a minimal, near-real-time ingest pipeline. Provide a phased migration plan, data validation, and cutover strategy.\\n\\nOutput format:\\n- Assumptions\\n- Findings (with evidence from plans/stats)\\n- Recommended changes ordered by impact and risk\\n- Exact SQL/DDL/config diffs\\n- Verification plan (metrics, queries, expected before/after)\\n- Rollback steps\\n\\nAlways quantify expected improvements and tie each recommendation to specific plan nodes or metrics. Ask for missing inputs before proceeding if any are unavailable.\",\n  \"model\": \"reasoning\"\n}",
                    "parsedResponse": {
                      "prompt": "You are a Senior Database Performance Engineer specializing in PostgreSQL and time-series analytics. Your goal is to reduce the dashboard query latency to <=1.5s p95 for accounts with >50k records while keeping data freshness near real-time (<= tens of seconds) and avoiding regressions.\n\nOperating principles:\n- Be diagnostic-first: measure, hypothesize, test, verify. No speculative changes without evidence from query plans and runtime metrics.\n- Prefer reversible, low-risk interventions first (indexes, statistics, config tuning) before schema or architectural changes.\n- Provide concrete commands (SQL/DDL), config values, and runbooks with validation and rollback steps.\n\nInputs to request/validate:\n- Exact dashboard SQL (including parameters), schemas (DDL) for all referenced tables and indexes, row counts, table sizes, and data distributions.\n- EXPLAIN (ANALYZE, BUFFERS, VERBOSE) for the slow queries under representative parameters; pg_stat_statements entries (calls, mean, p95, stddev); any temp file usage.\n- Current indexes (including expressions/partials), constraints, primary/foreign keys; default_statistics_target and per-column stats; extended statistics.\n- Workload patterns: typical WHERE clauses, time ranges, tenant/account scoping, cardinalities, and required freshness SLAs.\n- Hardware/storage profile and Postgres config: shared_buffers, effective_cache_size, work_mem, maintenance_work_mem, autovacuum settings, parallelism, random_page_cost/seq_page_cost, jit.\n- Operational context: replication, PgBouncer, lock/maintenance windows, acceptable downtime, canary customers.\n\nOptimization approach:\n1) Baseline and observability\n- Capture p50/p95/p99 latencies, rows read vs returned, I/O metrics (iostat, pg_stat_io if available), and plan stability across executions.\n- Use pg_stat_statements to identify top contributors; confirm parameter-specific plan differences (generic vs custom). Consider plan_cache_mode if needed.\n\n2) Query plan analysis\n- Identify sources of latency: sequential scans, misestimates, large sorts/hash aggregates, repeated re-checks, function scans, TOAST access, nested loops on large relations.\n- Validate selectivity estimates vs reality; consider extended statistics (CREATE STATISTICS) and higher STATISTICS targets on skewed columns.\n\n3) Indexing strategy\n- Design composite/covering indexes aligned to WHERE, JOIN, ORDER BY, and GROUP BY. Prefer leading columns by selectivity and predicate usage.\n- Use partial indexes for common filtered ranges (e.g., recent time windows, active tenants). Consider expression indexes for computed predicates.\n- For large append-only time-series tables, evaluate BRIN indexes on timestamp/seq columns and ensure table correlation (CLUSTER or periodic re-cluster) when appropriate.\n- Enable index-only scans with INCLUDE where feasible; verify via heap fetches in EXPLAIN.\n\n4) Partitioning and data layout\n- If the events table is dominant, propose native time-based partitioning (e.g., daily/weekly) with pruning verified in plans; add check constraints and indexes per partition.\n- Consider logical clustering by (tenant_id, ts) to improve locality; manage bloat and HOT updates via fillfactor.\n\n5) SQL/query rewrites\n- Push down filters, avoid unnecessary DISTINCTs/ORDER BY, replace CTEs that block inlining, collapse subqueries if they prevent predicate pushdown, and use window functions judiciously.\n- Evaluate pre-aggregation strategies for expensive rollups; ensure correctness and freshness.\n\n6) Materialization for near real-time\n- If needed, introduce incremental aggregates: materialized views with fast refresh, trigger/CDC-based rollups, or TimescaleDB continuous aggregates with refresh policies meeting freshness SLAs.\n\n7) Server/config tuning\n- Tune work_mem (per node) for sorts/hash operations observed; cap temp_file_usage. Adjust parallel settings where beneficial. Reassess random_page_cost/seq_page_cost based on storage.\n- Autovacuum: scale factors/thresholds on hot tables, aggressive freeze on time-series partitions, bloat monitoring, VACUUM/ANALYZE cadence.\n\n8) I/O and concurrency\n- Inspect pg_statio_* and BUFFERS output to verify cache effectiveness; consider pg_buffercache sampling. Ensure connection pooling via PgBouncer and avoid over-provisioned connections.\n\n9) Risk-managed rollout\n- Use CREATE INDEX CONCURRENTLY, backfill in batches with throttling, lock-time budgets, and feature flags. Provide canary rollout, regression checks, and rollback plans.\n\n10) Architecture evaluation (if required)\n- If limits persist, evaluate TimescaleDB (partitioning, compression, continuous aggregates) or an OLAP adjunct (e.g., ClickHouse) with a minimal, near-real-time ingest pipeline. Provide a phased migration plan, data validation, and cutover strategy.\n\nOutput format:\n- Assumptions\n- Findings (with evidence from plans/stats)\n- Recommended changes ordered by impact and risk\n- Exact SQL/DDL/config diffs\n- Verification plan (metrics, queries, expected before/after)\n- Rollback steps\n\nAlways quantify expected improvements and tie each recommendation to specific plan nodes or metrics. Ask for missing inputs before proceeding if any are unavailable.",
                      "model": "reasoning"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              }
            ],
            "totalDurationMs": 74854,
            "finalResponse": {
              "recommendation": "Hire: Senior Database Performance Engineer (PostgreSQL/Analytics)\n\nWhy this role is needed:\n- The team is blocked by a complex, slow dashboard query (8–12s) affecting large enterprise accounts (>50k records). Existing efforts (basic indexes, query rewrites, frontend masking, read replicas) haven’t fixed the core issue.\n- There’s clear evidence of a database-level bottleneck: sequential scan on a large events table and high disk I/O. The team lacks deep DB internals expertise to diagnose and remediate without risking regressions.\n- You need an expert who can perform systematic performance engineering: query plan analysis, schema and indexing design, table partitioning, and, if warranted, an architecture evaluation (e.g., TimescaleDB, columnar/OLAP adjunct) with a safe migration path.\n\nKey responsibilities:\n- Profile and optimize the slowest dashboard queries using EXPLAIN (ANALYZE, BUFFERS), pg_stat_statements, and actual runtime metrics.\n- Design and implement correct indexing strategies (composite/covering, partial, GIN/GiST/BRIN as appropriate) to eliminate full scans on the events table.\n- Evaluate and implement table partitioning (likely time-based) and clustering to cut I/O.\n- Tune PostgreSQL parameters (work_mem, effective_cache_size, shared_buffers, parallelism, autovacuum) based on workload and I/O profile.\n- Propose safe schema changes (denormalization where needed, rollup tables, materialized views or incremental aggregates) that meet near real-time constraints.\n- Advise on and, if needed, lead a targeted architecture change (e.g., TimescaleDB for time-series, or introducing a columnar analytics store) with a phased migration plan.\n- Establish ongoing performance observability (query dashboards, regression guardrails, load testing) and train the team.\n\nRequired skills:\n- Deep PostgreSQL internals and performance tuning (planner/optimizer behavior, statistics, VACUUM/ANALYZE, I/O and cache behavior).\n- Advanced SQL optimization: join strategies, aggregation pushdown, CTE inlining, window functions, avoiding unnecessary sorts/materialization.\n- Indexing expertise: composite/covering, partial, expression indexes; B-Tree vs GIN/GiST/BRIN; index-only scans.\n- Table partitioning (native), data modeling for time-series, and CLUSTER/REINDEX strategies.\n- Operational tuning: autovacuum strategy, bloat management, connection pooling (PgBouncer), replication/read replicas.\n- Performance tooling: EXPLAIN (ANALYZE, BUFFERS), pg_stat_statements, pg_hint_plan (when appropriate), pgBadger, perf/iostat.\n- Architecture evaluation: TimescaleDB/continuous aggregates, materialized views with fast refresh, incremental ETL, potential OLAP adjunct (e.g., ClickHouse) with near-real-time pipelines.\n- Risk-managed rollout practices: feature flags, backfills, migration playbooks, rollback plans.\n\nAI assistant system prompt for this role:\n\"You are a Senior Database Performance Engineer specializing in PostgreSQL and time-series analytics. Your goal is to bring p95 dashboard latency below 1.5s on accounts with >50k records without sacrificing near real-time freshness. Tasks:\n- Inspect provided schemas, the exact dashboard SQL, and sample EXPLAIN (ANALYZE, BUFFERS) outputs. Identify causes of sequential scans, sorts, and high I/O.\n- Propose and justify specific index designs (including composite, partial, expression, and BRIN/GIN/GiST) tied to query predicates and projections.\n- Recommend partitioning strategy (likely time-based), clustering, and statistics improvements. Provide concrete DDL and migration steps.\n- Suggest safe schema adjustments or rollups/materialized views/continuous aggregates with quantified freshness and consistency tradeoffs.\n- Tune Postgres parameters for the workload and hardware profile. Provide before/after KPIs and a validation plan.\n- If core limits are reached, evaluate TimescaleDB or an analytical adjunct; outline a staged migration plan and data sync approach.\nOutput precise commands (DDL/SQL), measurement plans, and rollback steps. Be explicit about assumptions and verification.\"\n\nCapability type: Reasoning (analytical/logical).",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Senior Database Performance Engineer (PostgreSQL)",
                  "reason": "The team lacks deep PostgreSQL performance expertise to diagnose and fix the slow dashboard query causing 8–12s load times on large accounts. This role will analyze query plans, eliminate sequential scans on the events table, design proper indexing and partitioning, tune Postgres, and advise on schema/architecture changes to achieve near real-time performance without risky guesswork.",
                  "skills": [
                    "PostgreSQL performance tuning (planner, statistics, VACUUM/ANALYZE)",
                    "EXPLAIN (ANALYZE, BUFFERS) and pg_stat_statements profiling",
                    "Advanced indexing (composite, partial, expression, GIN/BRIN)",
                    "Time-based table partitioning and clustering",
                    "SQL/query optimization for joins and aggregations",
                    "PostgreSQL configuration tuning (work_mem, autovacuum, parallelism)"
                  ],
                  "prompt": "You are a Senior Database Performance Engineer specializing in PostgreSQL and time-series analytics. Your goal is to reduce the dashboard query latency to <=1.5s p95 for accounts with >50k records while keeping data freshness near real-time (<= tens of seconds) and avoiding regressions.\n\nOperating principles:\n- Be diagnostic-first: measure, hypothesize, test, verify. No speculative changes without evidence from query plans and runtime metrics.\n- Prefer reversible, low-risk interventions first (indexes, statistics, config tuning) before schema or architectural changes.\n- Provide concrete commands (SQL/DDL), config values, and runbooks with validation and rollback steps.\n\nInputs to request/validate:\n- Exact dashboard SQL (including parameters), schemas (DDL) for all referenced tables and indexes, row counts, table sizes, and data distributions.\n- EXPLAIN (ANALYZE, BUFFERS, VERBOSE) for the slow queries under representative parameters; pg_stat_statements entries (calls, mean, p95, stddev); any temp file usage.\n- Current indexes (including expressions/partials), constraints, primary/foreign keys; default_statistics_target and per-column stats; extended statistics.\n- Workload patterns: typical WHERE clauses, time ranges, tenant/account scoping, cardinalities, and required freshness SLAs.\n- Hardware/storage profile and Postgres config: shared_buffers, effective_cache_size, work_mem, maintenance_work_mem, autovacuum settings, parallelism, random_page_cost/seq_page_cost, jit.\n- Operational context: replication, PgBouncer, lock/maintenance windows, acceptable downtime, canary customers.\n\nOptimization approach:\n1) Baseline and observability\n- Capture p50/p95/p99 latencies, rows read vs returned, I/O metrics (iostat, pg_stat_io if available), and plan stability across executions.\n- Use pg_stat_statements to identify top contributors; confirm parameter-specific plan differences (generic vs custom). Consider plan_cache_mode if needed.\n\n2) Query plan analysis\n- Identify sources of latency: sequential scans, misestimates, large sorts/hash aggregates, repeated re-checks, function scans, TOAST access, nested loops on large relations.\n- Validate selectivity estimates vs reality; consider extended statistics (CREATE STATISTICS) and higher STATISTICS targets on skewed columns.\n\n3) Indexing strategy\n- Design composite/covering indexes aligned to WHERE, JOIN, ORDER BY, and GROUP BY. Prefer leading columns by selectivity and predicate usage.\n- Use partial indexes for common filtered ranges (e.g., recent time windows, active tenants). Consider expression indexes for computed predicates.\n- For large append-only time-series tables, evaluate BRIN indexes on timestamp/seq columns and ensure table correlation (CLUSTER or periodic re-cluster) when appropriate.\n- Enable index-only scans with INCLUDE where feasible; verify via heap fetches in EXPLAIN.\n\n4) Partitioning and data layout\n- If the events table is dominant, propose native time-based partitioning (e.g., daily/weekly) with pruning verified in plans; add check constraints and indexes per partition.\n- Consider logical clustering by (tenant_id, ts) to improve locality; manage bloat and HOT updates via fillfactor.\n\n5) SQL/query rewrites\n- Push down filters, avoid unnecessary DISTINCTs/ORDER BY, replace CTEs that block inlining, collapse subqueries if they prevent predicate pushdown, and use window functions judiciously.\n- Evaluate pre-aggregation strategies for expensive rollups; ensure correctness and freshness.\n\n6) Materialization for near real-time\n- If needed, introduce incremental aggregates: materialized views with fast refresh, trigger/CDC-based rollups, or TimescaleDB continuous aggregates with refresh policies meeting freshness SLAs.\n\n7) Server/config tuning\n- Tune work_mem (per node) for sorts/hash operations observed; cap temp_file_usage. Adjust parallel settings where beneficial. Reassess random_page_cost/seq_page_cost based on storage.\n- Autovacuum: scale factors/thresholds on hot tables, aggressive freeze on time-series partitions, bloat monitoring, VACUUM/ANALYZE cadence.\n\n8) I/O and concurrency\n- Inspect pg_statio_* and BUFFERS output to verify cache effectiveness; consider pg_buffercache sampling. Ensure connection pooling via PgBouncer and avoid over-provisioned connections.\n\n9) Risk-managed rollout\n- Use CREATE INDEX CONCURRENTLY, backfill in batches with throttling, lock-time budgets, and feature flags. Provide canary rollout, regression checks, and rollback plans.\n\n10) Architecture evaluation (if required)\n- If limits persist, evaluate TimescaleDB (partitioning, compression, continuous aggregates) or an OLAP adjunct (e.g., ClickHouse) with a minimal, near-real-time ingest pipeline. Provide a phased migration plan, data validation, and cutover strategy.\n\nOutput format:\n- Assumptions\n- Findings (with evidence from plans/stats)\n- Recommended changes ordered by impact and risk\n- Exact SQL/DDL/config diffs\n- Verification plan (metrics, queries, expected before/after)\n- Rollback steps\n\nAlways quantify expected improvements and tie each recommendation to specific plan nodes or metrics. Ask for missing inputs before proceeding if any are unavailable.",
                  "model": "reasoning"
                }
              }
            }
          }
        ],
        "summary": {
          "successRate": 100,
          "firstAttemptSuccessRate": 100,
          "afterRetry1SuccessRate": 100,
          "afterRetry2SuccessRate": 100,
          "afterRetry3SuccessRate": 100,
          "averageDurationMs": 72037,
          "averageAttempts": 3,
          "averageAttemptsPerSuccess": 3,
          "averageTokensPerSuccess": 7518,
          "totalTokensUsed": 22554
        }
      }
    },
    "openai-gpt4o": {
      "1": {
        "runs": [
          {
            "runNumber": 1,
            "success": true,
            "attempts": [
              {
                "attemptNumber": 1,
                "timestamp": "2025-11-29T16:59:30.526Z",
                "success": true,
                "durationMs": 2299,
                "inputTokens": 1010,
                "outputTokens": 218,
                "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation above, recommend a team member who could help solve their problem.\n\nRespond ONLY with valid JSON like this example:\n{\n  \"recommendation\": \"I think you need to hire a [role] because [explanation of how they address the team's problem]...\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Job Title Here\",\n      \"reason\": \"Why this role addresses the team's skill gap\",\n      \"skills\": [\"skill1\", \"skill2\", \"skill3\"],\n      \"prompt\": \"You are an expert in [domain]. You help teams by [description of approach]...\",\n      \"model\": \"reasoning\"\n    }\n  }\n}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks or backticks\n- The \"recommendation\" field should start with \"I think you need to hire...\"\n- Skills array should have 3-7 specific technical skills\n- \"model\" should be \"reasoning\" for analytical tasks or \"semantic\" for creative tasks\n- Set \"action\" to null if no recommendation is appropriate",
                "rawResponse": "{\n  \"recommendation\": \"I think you need to hire a Database Performance Engineer because they can analyse and optimise the database queries, improve indexing strategies, and evaluate the need for a different database architecture, addressing the team's performance issues.\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Database Performance Engineer\",\n      \"reason\": \"This role addresses the team's skill gap by providing expertise in database query optimisation, indexing, and architecture evaluation, which are crucial for resolving the slow dashboard load times.\",\n      \"skills\": [\n        \"SQL query optimisation\",\n        \"Database indexing strategies\",\n        \"Schema design\",\n        \"Performance tuning\",\n        \"Database architecture evaluation\",\n        \"EXPLAIN ANALYZE interpretation\",\n        \"Experience with time-series databases\"\n      ],\n      \"prompt\": \"You are an expert in database performance optimisation. You help teams by analysing query plans, optimising database schemas, setting up effective indexing strategies, and advising on database architecture improvements.\",\n      \"model\": \"reasoning\"\n    }\n  }\n}",
                "parsedResponse": {
                  "recommendation": "I think you need to hire a Database Performance Engineer because they can analyse and optimise the database queries, improve indexing strategies, and evaluate the need for a different database architecture, addressing the team's performance issues.",
                  "action": {
                    "type": "create_actor",
                    "actor": {
                      "title": "Database Performance Engineer",
                      "reason": "This role addresses the team's skill gap by providing expertise in database query optimisation, indexing, and architecture evaluation, which are crucial for resolving the slow dashboard load times.",
                      "skills": [
                        "SQL query optimisation",
                        "Database indexing strategies",
                        "Schema design",
                        "Performance tuning",
                        "Database architecture evaluation",
                        "EXPLAIN ANALYZE interpretation",
                        "Experience with time-series databases"
                      ],
                      "prompt": "You are an expert in database performance optimisation. You help teams by analysing query plans, optimising database schemas, setting up effective indexing strategies, and advising on database architecture improvements.",
                      "model": "reasoning"
                    }
                  }
                },
                "validationErrors": [],
                "errorMessage": null
              }
            ],
            "totalDurationMs": 2300,
            "finalResponse": {
              "recommendation": "I think you need to hire a Database Performance Engineer because they can analyse and optimise the database queries, improve indexing strategies, and evaluate the need for a different database architecture, addressing the team's performance issues.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Performance Engineer",
                  "reason": "This role addresses the team's skill gap by providing expertise in database query optimisation, indexing, and architecture evaluation, which are crucial for resolving the slow dashboard load times.",
                  "skills": [
                    "SQL query optimisation",
                    "Database indexing strategies",
                    "Schema design",
                    "Performance tuning",
                    "Database architecture evaluation",
                    "EXPLAIN ANALYZE interpretation",
                    "Experience with time-series databases"
                  ],
                  "prompt": "You are an expert in database performance optimisation. You help teams by analysing query plans, optimising database schemas, setting up effective indexing strategies, and advising on database architecture improvements.",
                  "model": "reasoning"
                }
              }
            }
          },
          {
            "runNumber": 2,
            "success": true,
            "attempts": [
              {
                "attemptNumber": 1,
                "timestamp": "2025-11-29T16:59:33.003Z",
                "success": true,
                "durationMs": 2476,
                "inputTokens": 1010,
                "outputTokens": 217,
                "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation above, recommend a team member who could help solve their problem.\n\nRespond ONLY with valid JSON like this example:\n{\n  \"recommendation\": \"I think you need to hire a [role] because [explanation of how they address the team's problem]...\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Job Title Here\",\n      \"reason\": \"Why this role addresses the team's skill gap\",\n      \"skills\": [\"skill1\", \"skill2\", \"skill3\"],\n      \"prompt\": \"You are an expert in [domain]. You help teams by [description of approach]...\",\n      \"model\": \"reasoning\"\n    }\n  }\n}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks or backticks\n- The \"recommendation\" field should start with \"I think you need to hire...\"\n- Skills array should have 3-7 specific technical skills\n- \"model\" should be \"reasoning\" for analytical tasks or \"semantic\" for creative tasks\n- Set \"action\" to null if no recommendation is appropriate",
                "rawResponse": "{\n  \"recommendation\": \"I think you need to hire a Database Performance Engineer because they can analyse query plans, optimise the schema, set up proper indexing strategies, and advise on database architecture, which addresses the team's problem of slow query performance.\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Database Performance Engineer\",\n      \"reason\": \"This role addresses the team's skill gap by providing expertise in database optimisation and performance tuning, which is crucial for resolving the slow query issues.\",\n      \"skills\": [\n        \"SQL query optimisation\",\n        \"Database schema design\",\n        \"Indexing strategies\",\n        \"Query plan analysis\",\n        \"Database performance tuning\",\n        \"Experience with time-series databases\",\n        \"Knowledge of database migration strategies\"\n      ],\n      \"prompt\": \"You are an expert in database performance optimisation. You help teams by analysing query plans, optimising schemas, setting up indexing strategies, and advising on database architecture to improve query performance.\",\n      \"model\": \"reasoning\"\n    }\n  }\n}",
                "parsedResponse": {
                  "recommendation": "I think you need to hire a Database Performance Engineer because they can analyse query plans, optimise the schema, set up proper indexing strategies, and advise on database architecture, which addresses the team's problem of slow query performance.",
                  "action": {
                    "type": "create_actor",
                    "actor": {
                      "title": "Database Performance Engineer",
                      "reason": "This role addresses the team's skill gap by providing expertise in database optimisation and performance tuning, which is crucial for resolving the slow query issues.",
                      "skills": [
                        "SQL query optimisation",
                        "Database schema design",
                        "Indexing strategies",
                        "Query plan analysis",
                        "Database performance tuning",
                        "Experience with time-series databases",
                        "Knowledge of database migration strategies"
                      ],
                      "prompt": "You are an expert in database performance optimisation. You help teams by analysing query plans, optimising schemas, setting up indexing strategies, and advising on database architecture to improve query performance.",
                      "model": "reasoning"
                    }
                  }
                },
                "validationErrors": [],
                "errorMessage": null
              }
            ],
            "totalDurationMs": 2476,
            "finalResponse": {
              "recommendation": "I think you need to hire a Database Performance Engineer because they can analyse query plans, optimise the schema, set up proper indexing strategies, and advise on database architecture, which addresses the team's problem of slow query performance.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Performance Engineer",
                  "reason": "This role addresses the team's skill gap by providing expertise in database optimisation and performance tuning, which is crucial for resolving the slow query issues.",
                  "skills": [
                    "SQL query optimisation",
                    "Database schema design",
                    "Indexing strategies",
                    "Query plan analysis",
                    "Database performance tuning",
                    "Experience with time-series databases",
                    "Knowledge of database migration strategies"
                  ],
                  "prompt": "You are an expert in database performance optimisation. You help teams by analysing query plans, optimising schemas, setting up indexing strategies, and advising on database architecture to improve query performance.",
                  "model": "reasoning"
                }
              }
            }
          },
          {
            "runNumber": 3,
            "success": true,
            "attempts": [
              {
                "attemptNumber": 1,
                "timestamp": "2025-11-29T16:59:35.396Z",
                "success": true,
                "durationMs": 2393,
                "inputTokens": 1010,
                "outputTokens": 214,
                "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation above, recommend a team member who could help solve their problem.\n\nRespond ONLY with valid JSON like this example:\n{\n  \"recommendation\": \"I think you need to hire a [role] because [explanation of how they address the team's problem]...\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Job Title Here\",\n      \"reason\": \"Why this role addresses the team's skill gap\",\n      \"skills\": [\"skill1\", \"skill2\", \"skill3\"],\n      \"prompt\": \"You are an expert in [domain]. You help teams by [description of approach]...\",\n      \"model\": \"reasoning\"\n    }\n  }\n}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks or backticks\n- The \"recommendation\" field should start with \"I think you need to hire...\"\n- Skills array should have 3-7 specific technical skills\n- \"model\" should be \"reasoning\" for analytical tasks or \"semantic\" for creative tasks\n- Set \"action\" to null if no recommendation is appropriate",
                "rawResponse": "{\n  \"recommendation\": \"I think you need to hire a Database Performance Engineer because they can analyse query plans, optimise the schema, set up proper indexing strategies, and advise on database architecture, addressing the team's performance issues.\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Database Performance Engineer\",\n      \"reason\": \"This role addresses the team's skill gap by providing expertise in database optimisation and performance tuning, which is crucial for resolving the slow query issues.\",\n      \"skills\": [\n        \"SQL query optimisation\",\n        \"Database indexing strategies\",\n        \"Schema design and optimisation\",\n        \"Performance tuning\",\n        \"Database architecture evaluation\",\n        \"EXPLAIN ANALYZE interpretation\",\n        \"Experience with time-series databases\"\n      ],\n      \"prompt\": \"You are an expert in database performance optimisation. You help teams by analysing query plans, optimising schemas, setting up indexing strategies, and advising on database architecture to improve performance.\",\n      \"model\": \"reasoning\"\n    }\n  }\n}",
                "parsedResponse": {
                  "recommendation": "I think you need to hire a Database Performance Engineer because they can analyse query plans, optimise the schema, set up proper indexing strategies, and advise on database architecture, addressing the team's performance issues.",
                  "action": {
                    "type": "create_actor",
                    "actor": {
                      "title": "Database Performance Engineer",
                      "reason": "This role addresses the team's skill gap by providing expertise in database optimisation and performance tuning, which is crucial for resolving the slow query issues.",
                      "skills": [
                        "SQL query optimisation",
                        "Database indexing strategies",
                        "Schema design and optimisation",
                        "Performance tuning",
                        "Database architecture evaluation",
                        "EXPLAIN ANALYZE interpretation",
                        "Experience with time-series databases"
                      ],
                      "prompt": "You are an expert in database performance optimisation. You help teams by analysing query plans, optimising schemas, setting up indexing strategies, and advising on database architecture to improve performance.",
                      "model": "reasoning"
                    }
                  }
                },
                "validationErrors": [],
                "errorMessage": null
              }
            ],
            "totalDurationMs": 2393,
            "finalResponse": {
              "recommendation": "I think you need to hire a Database Performance Engineer because they can analyse query plans, optimise the schema, set up proper indexing strategies, and advise on database architecture, addressing the team's performance issues.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Performance Engineer",
                  "reason": "This role addresses the team's skill gap by providing expertise in database optimisation and performance tuning, which is crucial for resolving the slow query issues.",
                  "skills": [
                    "SQL query optimisation",
                    "Database indexing strategies",
                    "Schema design and optimisation",
                    "Performance tuning",
                    "Database architecture evaluation",
                    "EXPLAIN ANALYZE interpretation",
                    "Experience with time-series databases"
                  ],
                  "prompt": "You are an expert in database performance optimisation. You help teams by analysing query plans, optimising schemas, setting up indexing strategies, and advising on database architecture to improve performance.",
                  "model": "reasoning"
                }
              }
            }
          }
        ],
        "summary": {
          "successRate": 100,
          "firstAttemptSuccessRate": 100,
          "afterRetry1SuccessRate": 100,
          "afterRetry2SuccessRate": 100,
          "afterRetry3SuccessRate": 100,
          "averageDurationMs": 2389.6666666666665,
          "averageAttempts": 1,
          "averageAttemptsPerSuccess": 1,
          "averageTokensPerSuccess": 1226.3333333333333,
          "totalTokensUsed": 3679
        }
      },
      "2": {
        "runs": [
          {
            "runNumber": 1,
            "success": true,
            "attempts": [
              {
                "attemptNumber": 1,
                "timestamp": "2025-11-29T16:59:38.037Z",
                "success": true,
                "durationMs": 2641,
                "inputTokens": 1179,
                "outputTokens": 191,
                "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation above, recommend a team member who could help solve their problem.\n\nRespond with a JSON object containing:\n- \"recommendation\": Your explanation of why you're recommending this role\n- \"action\": An object with \"type\": \"create_actor\" and \"actor\" containing:\n  - \"title\": The job title\n  - \"reason\": Why this role addresses the team's problem\n  - \"skills\": Array of 3-7 required skills\n  - \"prompt\": A system prompt for an AI in this role\n  - \"model\": Either \"reasoning\" or \"semantic\"",
                "rawResponse": "{\n  \"recommendation\": \"I think you need to hire a Database Performance Engineer. This role is crucial because the team is facing significant challenges with database query performance, which is affecting customer satisfaction. A specialist can optimize query execution, improve indexing strategies, and potentially redesign the database schema to enhance performance.\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Database Performance Engineer\",\n      \"reason\": \"This role addresses the team's problem by providing expertise in analyzing and optimizing database queries, improving indexing strategies, and advising on potential database architecture changes to resolve performance bottlenecks.\",\n      \"skills\": [\n        \"SQL query optimization\",\n        \"Database indexing\",\n        \"Schema design\",\n        \"Performance tuning\",\n        \"Database architecture\",\n        \"EXPLAIN ANALYZE\",\n        \"Disk I/O analysis\"\n      ],\n      \"prompt\": \"You are a Database Performance Engineer with expertise in optimizing complex queries, designing efficient database schemas, and implementing effective indexing strategies. Your approach involves thorough analysis of query execution plans and advising on architectural improvements to enhance performance.\",\n      \"model\": \"reasoning\"\n    }\n  }\n}",
                "parsedResponse": {
                  "recommendation": "I think you need to hire a Database Performance Engineer. This role is crucial because the team is facing significant challenges with database query performance, which is affecting customer satisfaction. A specialist can optimize query execution, improve indexing strategies, and potentially redesign the database schema to enhance performance.",
                  "action": {
                    "type": "create_actor",
                    "actor": {
                      "title": "Database Performance Engineer",
                      "reason": "This role addresses the team's problem by providing expertise in analyzing and optimizing database queries, improving indexing strategies, and advising on potential database architecture changes to resolve performance bottlenecks.",
                      "skills": [
                        "SQL query optimization",
                        "Database indexing",
                        "Schema design",
                        "Performance tuning",
                        "Database architecture",
                        "EXPLAIN ANALYZE",
                        "Disk I/O analysis"
                      ],
                      "prompt": "You are a Database Performance Engineer with expertise in optimizing complex queries, designing efficient database schemas, and implementing effective indexing strategies. Your approach involves thorough analysis of query execution plans and advising on architectural improvements to enhance performance.",
                      "model": "reasoning"
                    }
                  }
                },
                "validationErrors": [],
                "errorMessage": null
              }
            ],
            "totalDurationMs": 2641,
            "finalResponse": {
              "recommendation": "I think you need to hire a Database Performance Engineer. This role is crucial because the team is facing significant challenges with database query performance, which is affecting customer satisfaction. A specialist can optimize query execution, improve indexing strategies, and potentially redesign the database schema to enhance performance.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Performance Engineer",
                  "reason": "This role addresses the team's problem by providing expertise in analyzing and optimizing database queries, improving indexing strategies, and advising on potential database architecture changes to resolve performance bottlenecks.",
                  "skills": [
                    "SQL query optimization",
                    "Database indexing",
                    "Schema design",
                    "Performance tuning",
                    "Database architecture",
                    "EXPLAIN ANALYZE",
                    "Disk I/O analysis"
                  ],
                  "prompt": "You are a Database Performance Engineer with expertise in optimizing complex queries, designing efficient database schemas, and implementing effective indexing strategies. Your approach involves thorough analysis of query execution plans and advising on architectural improvements to enhance performance.",
                  "model": "reasoning"
                }
              }
            }
          },
          {
            "runNumber": 2,
            "success": true,
            "attempts": [
              {
                "attemptNumber": 1,
                "timestamp": "2025-11-29T16:59:41.114Z",
                "success": true,
                "durationMs": 3077,
                "inputTokens": 1179,
                "outputTokens": 192,
                "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation above, recommend a team member who could help solve their problem.\n\nRespond with a JSON object containing:\n- \"recommendation\": Your explanation of why you're recommending this role\n- \"action\": An object with \"type\": \"create_actor\" and \"actor\" containing:\n  - \"title\": The job title\n  - \"reason\": Why this role addresses the team's problem\n  - \"skills\": Array of 3-7 required skills\n  - \"prompt\": A system prompt for an AI in this role\n  - \"model\": Either \"reasoning\" or \"semantic\"",
                "rawResponse": "{\n  \"recommendation\": \"I think you need to hire a Database Performance Engineer. This role is crucial because the team is facing significant challenges with database query performance, which is affecting customer satisfaction. A specialist can optimize query execution, improve indexing strategies, and potentially redesign the database schema to enhance performance.\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Database Performance Engineer\",\n      \"reason\": \"This role addresses the team's problem by providing expertise in analyzing and optimizing database queries, improving indexing strategies, and advising on potential schema redesigns or database migrations.\",\n      \"skills\": [\n        \"SQL query optimization\",\n        \"Database indexing\",\n        \"Schema design\",\n        \"Performance tuning\",\n        \"Database architecture\",\n        \"EXPLAIN ANALYZE\",\n        \"Disk I/O analysis\"\n      ],\n      \"prompt\": \"You are a Database Performance Engineer with expertise in optimizing complex SQL queries, designing efficient database schemas, and implementing effective indexing strategies. Your approach involves analyzing query execution plans, identifying bottlenecks, and recommending architectural improvements to enhance performance.\",\n      \"model\": \"reasoning\"\n    }\n  }\n}",
                "parsedResponse": {
                  "recommendation": "I think you need to hire a Database Performance Engineer. This role is crucial because the team is facing significant challenges with database query performance, which is affecting customer satisfaction. A specialist can optimize query execution, improve indexing strategies, and potentially redesign the database schema to enhance performance.",
                  "action": {
                    "type": "create_actor",
                    "actor": {
                      "title": "Database Performance Engineer",
                      "reason": "This role addresses the team's problem by providing expertise in analyzing and optimizing database queries, improving indexing strategies, and advising on potential schema redesigns or database migrations.",
                      "skills": [
                        "SQL query optimization",
                        "Database indexing",
                        "Schema design",
                        "Performance tuning",
                        "Database architecture",
                        "EXPLAIN ANALYZE",
                        "Disk I/O analysis"
                      ],
                      "prompt": "You are a Database Performance Engineer with expertise in optimizing complex SQL queries, designing efficient database schemas, and implementing effective indexing strategies. Your approach involves analyzing query execution plans, identifying bottlenecks, and recommending architectural improvements to enhance performance.",
                      "model": "reasoning"
                    }
                  }
                },
                "validationErrors": [],
                "errorMessage": null
              }
            ],
            "totalDurationMs": 3077,
            "finalResponse": {
              "recommendation": "I think you need to hire a Database Performance Engineer. This role is crucial because the team is facing significant challenges with database query performance, which is affecting customer satisfaction. A specialist can optimize query execution, improve indexing strategies, and potentially redesign the database schema to enhance performance.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Performance Engineer",
                  "reason": "This role addresses the team's problem by providing expertise in analyzing and optimizing database queries, improving indexing strategies, and advising on potential schema redesigns or database migrations.",
                  "skills": [
                    "SQL query optimization",
                    "Database indexing",
                    "Schema design",
                    "Performance tuning",
                    "Database architecture",
                    "EXPLAIN ANALYZE",
                    "Disk I/O analysis"
                  ],
                  "prompt": "You are a Database Performance Engineer with expertise in optimizing complex SQL queries, designing efficient database schemas, and implementing effective indexing strategies. Your approach involves analyzing query execution plans, identifying bottlenecks, and recommending architectural improvements to enhance performance.",
                  "model": "reasoning"
                }
              }
            }
          },
          {
            "runNumber": 3,
            "success": true,
            "attempts": [
              {
                "attemptNumber": 1,
                "timestamp": "2025-11-29T16:59:43.902Z",
                "success": true,
                "durationMs": 2788,
                "inputTokens": 1179,
                "outputTokens": 194,
                "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation above, recommend a team member who could help solve their problem.\n\nRespond with a JSON object containing:\n- \"recommendation\": Your explanation of why you're recommending this role\n- \"action\": An object with \"type\": \"create_actor\" and \"actor\" containing:\n  - \"title\": The job title\n  - \"reason\": Why this role addresses the team's problem\n  - \"skills\": Array of 3-7 required skills\n  - \"prompt\": A system prompt for an AI in this role\n  - \"model\": Either \"reasoning\" or \"semantic\"",
                "rawResponse": "{\n  \"recommendation\": \"I think you need to hire a Database Performance Engineer. This role is crucial because the team is facing significant challenges with database query performance, which is impacting customer satisfaction. A specialist in this area can analyze and optimize query execution, improve indexing strategies, and potentially redesign the database schema to enhance performance.\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Database Performance Engineer\",\n      \"reason\": \"This role addresses the team's problem by providing expertise in analyzing and optimizing database queries, improving indexing strategies, and advising on potential schema redesigns or database migrations to enhance performance.\",\n      \"skills\": [\n        \"Query Optimization\",\n        \"Indexing Strategies\",\n        \"Database Schema Design\",\n        \"Performance Tuning\",\n        \"SQL Analysis\",\n        \"Database Architecture\",\n        \"EXPLAIN ANALYZE\"\n      ],\n      \"prompt\": \"You are a Database Performance Engineer with expertise in optimizing complex queries and database schemas. Your approach involves analyzing query execution plans, implementing effective indexing strategies, and advising on database architecture improvements to ensure optimal performance.\",\n      \"model\": \"reasoning\"\n    }\n  }\n}",
                "parsedResponse": {
                  "recommendation": "I think you need to hire a Database Performance Engineer. This role is crucial because the team is facing significant challenges with database query performance, which is impacting customer satisfaction. A specialist in this area can analyze and optimize query execution, improve indexing strategies, and potentially redesign the database schema to enhance performance.",
                  "action": {
                    "type": "create_actor",
                    "actor": {
                      "title": "Database Performance Engineer",
                      "reason": "This role addresses the team's problem by providing expertise in analyzing and optimizing database queries, improving indexing strategies, and advising on potential schema redesigns or database migrations to enhance performance.",
                      "skills": [
                        "Query Optimization",
                        "Indexing Strategies",
                        "Database Schema Design",
                        "Performance Tuning",
                        "SQL Analysis",
                        "Database Architecture",
                        "EXPLAIN ANALYZE"
                      ],
                      "prompt": "You are a Database Performance Engineer with expertise in optimizing complex queries and database schemas. Your approach involves analyzing query execution plans, implementing effective indexing strategies, and advising on database architecture improvements to ensure optimal performance.",
                      "model": "reasoning"
                    }
                  }
                },
                "validationErrors": [],
                "errorMessage": null
              }
            ],
            "totalDurationMs": 2788,
            "finalResponse": {
              "recommendation": "I think you need to hire a Database Performance Engineer. This role is crucial because the team is facing significant challenges with database query performance, which is impacting customer satisfaction. A specialist in this area can analyze and optimize query execution, improve indexing strategies, and potentially redesign the database schema to enhance performance.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Performance Engineer",
                  "reason": "This role addresses the team's problem by providing expertise in analyzing and optimizing database queries, improving indexing strategies, and advising on potential schema redesigns or database migrations to enhance performance.",
                  "skills": [
                    "Query Optimization",
                    "Indexing Strategies",
                    "Database Schema Design",
                    "Performance Tuning",
                    "SQL Analysis",
                    "Database Architecture",
                    "EXPLAIN ANALYZE"
                  ],
                  "prompt": "You are a Database Performance Engineer with expertise in optimizing complex queries and database schemas. Your approach involves analyzing query execution plans, implementing effective indexing strategies, and advising on database architecture improvements to ensure optimal performance.",
                  "model": "reasoning"
                }
              }
            }
          }
        ],
        "summary": {
          "successRate": 100,
          "firstAttemptSuccessRate": 100,
          "afterRetry1SuccessRate": 100,
          "afterRetry2SuccessRate": 100,
          "afterRetry3SuccessRate": 100,
          "averageDurationMs": 2835.3333333333335,
          "averageAttempts": 1,
          "averageAttemptsPerSuccess": 1,
          "averageTokensPerSuccess": 1371.3333333333333,
          "totalTokensUsed": 4114
        }
      },
      "3": {
        "runs": [
          {
            "runNumber": 1,
            "success": true,
            "attempts": [],
            "steps": [
              {
                "stepNumber": 1,
                "stepName": "Recommendation",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T16:59:46.248Z",
                    "success": true,
                    "durationMs": 2346,
                    "inputTokens": 876,
                    "outputTokens": 58,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation, what type of team member should this team add?\n\nRespond with JSON like this example:\n{\"recommendation\": \"I recommend hiring a [role] because [reason]...\", \"action\": \"create_actor\"}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- The \"recommendation\" should explain your hiring recommendation (at least 20 characters)\n- Set \"action\" to \"create_actor\" if recommending someone, or null if not",
                    "rawResponse": "{\"recommendation\":\"I recommend hiring a Database Performance Engineer because the team is facing significant challenges with query optimization, indexing, and potential database architecture changes. This role is needed to analyze query plans, optimize the schema, and advise on database solutions to improve performance.\",\"action\":\"create_actor\"}",
                    "parsedResponse": {
                      "recommendation": "I recommend hiring a Database Performance Engineer because the team is facing significant challenges with query optimization, indexing, and potential database architecture changes. This role is needed to analyze query plans, optimize the schema, and advise on database solutions to improve performance.",
                      "action": "create_actor"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 2,
                "stepName": "Details",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T16:59:48.492Z",
                    "success": true,
                    "durationMs": 2244,
                    "inputTokens": 946,
                    "outputTokens": 74,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Database Performance Engineer because the team is facing significant challenges with query optimization, indexing, and potential database architecture changes. This role is needed to analyze query plans, optimize the schema, and advise on database solutions to improve performance.\",\"action\":\"create_actor\"}\n\n[user] For the role you recommended, provide their details.\n\nRespond with JSON like this example:\n{\"title\": \"Database Administrator\", \"reason\": \"The team needs database expertise to optimize their slow queries and design scalable schemas\", \"skills\": [\"PostgreSQL\", \"Query Optimization\", \"Database Design\"]}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- Provide 3-7 specific technical skills\n- The \"reason\" should explain how this role addresses the team's problem (at least 20 characters)",
                    "rawResponse": "{\"title\": \"Database Performance Engineer\", \"reason\": \"The team needs expertise to optimize slow queries, improve indexing, and evaluate database architecture for better performance.\", \"skills\": [\"Query Optimization\", \"Indexing Strategies\", \"Database Schema Design\", \"PostgreSQL\", \"EXPLAIN ANALYZE\", \"Database Performance Tuning\", \"Data Modeling\"]}",
                    "parsedResponse": {
                      "title": "Database Performance Engineer",
                      "reason": "The team needs expertise to optimize slow queries, improve indexing, and evaluate database architecture for better performance.",
                      "skills": [
                        "Query Optimization",
                        "Indexing Strategies",
                        "Database Schema Design",
                        "PostgreSQL",
                        "EXPLAIN ANALYZE",
                        "Database Performance Tuning",
                        "Data Modeling"
                      ]
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 3,
                "stepName": "AI Config",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T16:59:50.800Z",
                    "success": true,
                    "durationMs": 2308,
                    "inputTokens": 1011,
                    "outputTokens": 49,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Database Performance Engineer because the team is facing significant challenges with query optimization, indexing, and potential database architecture changes. This role is needed to analyze query plans, optimize the schema, and advise on database solutions to improve performance.\",\"action\":\"create_actor\"}\n\n[assistant] {\"title\":\"Database Performance Engineer\",\"reason\":\"The team needs expertise to optimize slow queries, improve indexing, and evaluate database architecture for better performance.\",\"skills\":[\"Query Optimization\",\"Indexing Strategies\",\"Database Schema Design\",\"PostgreSQL\",\"EXPLAIN ANALYZE\",\"Database Performance Tuning\",\"Data Modeling\"]}\n\n[user] For this role, provide the AI system prompt and model type.\n\nRespond with JSON like this example:\n{\"prompt\": \"You are an expert database administrator. You help teams optimize queries, design schemas, and ensure data integrity...\", \"model\": \"reasoning\"}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- The \"prompt\" should be a detailed system prompt (at least 30 characters)\n- \"model\" should be \"reasoning\" for analytical tasks or \"semantic\" for creative tasks",
                    "rawResponse": "{\"prompt\":\"You are a skilled Database Performance Engineer. Your task is to analyze query plans, optimize database schemas, and implement indexing strategies to enhance performance. Provide expert advice on database architecture and ensure efficient data handling.\",\"model\":\"reasoning\"}",
                    "parsedResponse": {
                      "prompt": "You are a skilled Database Performance Engineer. Your task is to analyze query plans, optimize database schemas, and implement indexing strategies to enhance performance. Provide expert advice on database architecture and ensure efficient data handling.",
                      "model": "reasoning"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              }
            ],
            "totalDurationMs": 6899,
            "finalResponse": {
              "recommendation": "I recommend hiring a Database Performance Engineer because the team is facing significant challenges with query optimization, indexing, and potential database architecture changes. This role is needed to analyze query plans, optimize the schema, and advise on database solutions to improve performance.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Performance Engineer",
                  "reason": "The team needs expertise to optimize slow queries, improve indexing, and evaluate database architecture for better performance.",
                  "skills": [
                    "Query Optimization",
                    "Indexing Strategies",
                    "Database Schema Design",
                    "PostgreSQL",
                    "EXPLAIN ANALYZE",
                    "Database Performance Tuning",
                    "Data Modeling"
                  ],
                  "prompt": "You are a skilled Database Performance Engineer. Your task is to analyze query plans, optimize database schemas, and implement indexing strategies to enhance performance. Provide expert advice on database architecture and ensure efficient data handling.",
                  "model": "reasoning"
                }
              }
            }
          },
          {
            "runNumber": 2,
            "success": true,
            "attempts": [],
            "steps": [
              {
                "stepNumber": 1,
                "stepName": "Recommendation",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T16:59:53.089Z",
                    "success": true,
                    "durationMs": 2288,
                    "inputTokens": 876,
                    "outputTokens": 66,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation, what type of team member should this team add?\n\nRespond with JSON like this example:\n{\"recommendation\": \"I recommend hiring a [role] because [reason]...\", \"action\": \"create_actor\"}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- The \"recommendation\" should explain your hiring recommendation (at least 20 characters)\n- Set \"action\" to \"create_actor\" if recommending someone, or null if not",
                    "rawResponse": "{\"recommendation\": \"I recommend hiring a Database Performance Engineer because the team is struggling with optimizing complex queries and database schema, which is causing slow load times for enterprise customers. This role is needed to analyze query plans, optimize schema, set up indexing strategies, and evaluate potential database migrations.\", \"action\": \"create_actor\"}",
                    "parsedResponse": {
                      "recommendation": "I recommend hiring a Database Performance Engineer because the team is struggling with optimizing complex queries and database schema, which is causing slow load times for enterprise customers. This role is needed to analyze query plans, optimize schema, set up indexing strategies, and evaluate potential database migrations.",
                      "action": "create_actor"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 2,
                "stepName": "Details",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T16:59:55.415Z",
                    "success": true,
                    "durationMs": 2326,
                    "inputTokens": 951,
                    "outputTokens": 76,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Database Performance Engineer because the team is struggling with optimizing complex queries and database schema, which is causing slow load times for enterprise customers. This role is needed to analyze query plans, optimize schema, set up indexing strategies, and evaluate potential database migrations.\",\"action\":\"create_actor\"}\n\n[user] For the role you recommended, provide their details.\n\nRespond with JSON like this example:\n{\"title\": \"Database Administrator\", \"reason\": \"The team needs database expertise to optimize their slow queries and design scalable schemas\", \"skills\": [\"PostgreSQL\", \"Query Optimization\", \"Database Design\"]}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- Provide 3-7 specific technical skills\n- The \"reason\" should explain how this role addresses the team's problem (at least 20 characters)",
                    "rawResponse": "{\"title\": \"Database Performance Engineer\", \"reason\": \"The team needs expertise to optimize complex queries and improve database performance, addressing slow load times for enterprise customers.\", \"skills\": [\"SQL Query Optimization\", \"Database Schema Design\", \"Indexing Strategies\", \"PostgreSQL\", \"Performance Tuning\", \"EXPLAIN ANALYZE\", \"Database Architecture Evaluation\"]}",
                    "parsedResponse": {
                      "title": "Database Performance Engineer",
                      "reason": "The team needs expertise to optimize complex queries and improve database performance, addressing slow load times for enterprise customers.",
                      "skills": [
                        "SQL Query Optimization",
                        "Database Schema Design",
                        "Indexing Strategies",
                        "PostgreSQL",
                        "Performance Tuning",
                        "EXPLAIN ANALYZE",
                        "Database Architecture Evaluation"
                      ]
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 3,
                "stepName": "AI Config",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T16:59:57.717Z",
                    "success": true,
                    "durationMs": 2302,
                    "inputTokens": 1018,
                    "outputTokens": 46,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Database Performance Engineer because the team is struggling with optimizing complex queries and database schema, which is causing slow load times for enterprise customers. This role is needed to analyze query plans, optimize schema, set up indexing strategies, and evaluate potential database migrations.\",\"action\":\"create_actor\"}\n\n[assistant] {\"title\":\"Database Performance Engineer\",\"reason\":\"The team needs expertise to optimize complex queries and improve database performance, addressing slow load times for enterprise customers.\",\"skills\":[\"SQL Query Optimization\",\"Database Schema Design\",\"Indexing Strategies\",\"PostgreSQL\",\"Performance Tuning\",\"EXPLAIN ANALYZE\",\"Database Architecture Evaluation\"]}\n\n[user] For this role, provide the AI system prompt and model type.\n\nRespond with JSON like this example:\n{\"prompt\": \"You are an expert database administrator. You help teams optimize queries, design schemas, and ensure data integrity...\", \"model\": \"reasoning\"}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- The \"prompt\" should be a detailed system prompt (at least 30 characters)\n- \"model\" should be \"reasoning\" for analytical tasks or \"semantic\" for creative tasks",
                    "rawResponse": "{\"prompt\":\"You are a skilled Database Performance Engineer. Your task is to analyze query plans, optimize database schemas, and implement indexing strategies to enhance performance. Evaluate potential database migrations and provide expert recommendations.\",\"model\":\"reasoning\"}",
                    "parsedResponse": {
                      "prompt": "You are a skilled Database Performance Engineer. Your task is to analyze query plans, optimize database schemas, and implement indexing strategies to enhance performance. Evaluate potential database migrations and provide expert recommendations.",
                      "model": "reasoning"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              }
            ],
            "totalDurationMs": 6916,
            "finalResponse": {
              "recommendation": "I recommend hiring a Database Performance Engineer because the team is struggling with optimizing complex queries and database schema, which is causing slow load times for enterprise customers. This role is needed to analyze query plans, optimize schema, set up indexing strategies, and evaluate potential database migrations.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Performance Engineer",
                  "reason": "The team needs expertise to optimize complex queries and improve database performance, addressing slow load times for enterprise customers.",
                  "skills": [
                    "SQL Query Optimization",
                    "Database Schema Design",
                    "Indexing Strategies",
                    "PostgreSQL",
                    "Performance Tuning",
                    "EXPLAIN ANALYZE",
                    "Database Architecture Evaluation"
                  ],
                  "prompt": "You are a skilled Database Performance Engineer. Your task is to analyze query plans, optimize database schemas, and implement indexing strategies to enhance performance. Evaluate potential database migrations and provide expert recommendations.",
                  "model": "reasoning"
                }
              }
            }
          },
          {
            "runNumber": 3,
            "success": true,
            "attempts": [],
            "steps": [
              {
                "stepNumber": 1,
                "stepName": "Recommendation",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:00:00.079Z",
                    "success": true,
                    "durationMs": 2362,
                    "inputTokens": 876,
                    "outputTokens": 57,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation, what type of team member should this team add?\n\nRespond with JSON like this example:\n{\"recommendation\": \"I recommend hiring a [role] because [reason]...\", \"action\": \"create_actor\"}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- The \"recommendation\" should explain your hiring recommendation (at least 20 characters)\n- Set \"action\" to \"create_actor\" if recommending someone, or null if not",
                    "rawResponse": "{\"recommendation\": \"I recommend hiring a Database Performance Engineer because the team is facing challenges with slow query performance and lacks expertise in database optimization. This role would help analyze query plans, optimize schemas, and implement indexing strategies to improve load times.\", \"action\": \"create_actor\"}",
                    "parsedResponse": {
                      "recommendation": "I recommend hiring a Database Performance Engineer because the team is facing challenges with slow query performance and lacks expertise in database optimization. This role would help analyze query plans, optimize schemas, and implement indexing strategies to improve load times.",
                      "action": "create_actor"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 2,
                "stepName": "Details",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:00:02.459Z",
                    "success": true,
                    "durationMs": 2380,
                    "inputTokens": 942,
                    "outputTokens": 75,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Database Performance Engineer because the team is facing challenges with slow query performance and lacks expertise in database optimization. This role would help analyze query plans, optimize schemas, and implement indexing strategies to improve load times.\",\"action\":\"create_actor\"}\n\n[user] For the role you recommended, provide their details.\n\nRespond with JSON like this example:\n{\"title\": \"Database Administrator\", \"reason\": \"The team needs database expertise to optimize their slow queries and design scalable schemas\", \"skills\": [\"PostgreSQL\", \"Query Optimization\", \"Database Design\"]}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- Provide 3-7 specific technical skills\n- The \"reason\" should explain how this role addresses the team's problem (at least 20 characters)",
                    "rawResponse": "{\"title\": \"Database Performance Engineer\", \"reason\": \"The team needs expertise to analyze query plans, optimize schemas, and improve database performance to address slow load times.\", \"skills\": [\"SQL Query Optimization\", \"Database Indexing\", \"Schema Design\", \"PostgreSQL\", \"Performance Tuning\", \"Database Architecture\", \"EXPLAIN ANALYZE\"]}",
                    "parsedResponse": {
                      "title": "Database Performance Engineer",
                      "reason": "The team needs expertise to analyze query plans, optimize schemas, and improve database performance to address slow load times.",
                      "skills": [
                        "SQL Query Optimization",
                        "Database Indexing",
                        "Schema Design",
                        "PostgreSQL",
                        "Performance Tuning",
                        "Database Architecture",
                        "EXPLAIN ANALYZE"
                      ]
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 3,
                "stepName": "AI Config",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:00:04.794Z",
                    "success": true,
                    "durationMs": 2335,
                    "inputTokens": 1008,
                    "outputTokens": 49,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Database Performance Engineer because the team is facing challenges with slow query performance and lacks expertise in database optimization. This role would help analyze query plans, optimize schemas, and implement indexing strategies to improve load times.\",\"action\":\"create_actor\"}\n\n[assistant] {\"title\":\"Database Performance Engineer\",\"reason\":\"The team needs expertise to analyze query plans, optimize schemas, and improve database performance to address slow load times.\",\"skills\":[\"SQL Query Optimization\",\"Database Indexing\",\"Schema Design\",\"PostgreSQL\",\"Performance Tuning\",\"Database Architecture\",\"EXPLAIN ANALYZE\"]}\n\n[user] For this role, provide the AI system prompt and model type.\n\nRespond with JSON like this example:\n{\"prompt\": \"You are an expert database administrator. You help teams optimize queries, design schemas, and ensure data integrity...\", \"model\": \"reasoning\"}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- The \"prompt\" should be a detailed system prompt (at least 30 characters)\n- \"model\" should be \"reasoning\" for analytical tasks or \"semantic\" for creative tasks",
                    "rawResponse": "{\"prompt\": \"You are a skilled Database Performance Engineer. Your role is to analyze query plans, optimize database schemas, implement indexing strategies, and advise on database architecture to improve performance and reduce load times.\", \"model\": \"reasoning\"}",
                    "parsedResponse": {
                      "prompt": "You are a skilled Database Performance Engineer. Your role is to analyze query plans, optimize database schemas, implement indexing strategies, and advise on database architecture to improve performance and reduce load times.",
                      "model": "reasoning"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              }
            ],
            "totalDurationMs": 7077,
            "finalResponse": {
              "recommendation": "I recommend hiring a Database Performance Engineer because the team is facing challenges with slow query performance and lacks expertise in database optimization. This role would help analyze query plans, optimize schemas, and implement indexing strategies to improve load times.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Performance Engineer",
                  "reason": "The team needs expertise to analyze query plans, optimize schemas, and improve database performance to address slow load times.",
                  "skills": [
                    "SQL Query Optimization",
                    "Database Indexing",
                    "Schema Design",
                    "PostgreSQL",
                    "Performance Tuning",
                    "Database Architecture",
                    "EXPLAIN ANALYZE"
                  ],
                  "prompt": "You are a skilled Database Performance Engineer. Your role is to analyze query plans, optimize database schemas, implement indexing strategies, and advise on database architecture to improve performance and reduce load times.",
                  "model": "reasoning"
                }
              }
            }
          }
        ],
        "summary": {
          "successRate": 100,
          "firstAttemptSuccessRate": 100,
          "afterRetry1SuccessRate": 100,
          "afterRetry2SuccessRate": 100,
          "afterRetry3SuccessRate": 100,
          "averageDurationMs": 6964,
          "averageAttempts": 3,
          "averageAttemptsPerSuccess": 3,
          "averageTokensPerSuccess": 3018,
          "totalTokensUsed": 9054
        }
      },
      "4": {
        "runs": [
          {
            "runNumber": 1,
            "success": true,
            "attempts": [],
            "steps": [
              {
                "stepNumber": 1,
                "stepName": "Recommendation",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:00:07.105Z",
                    "success": true,
                    "durationMs": 2311,
                    "inputTokens": 927,
                    "outputTokens": 95,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation, what type of team member should this team add?\n\nRespond with a JSON object containing:\n- \"recommendation\": A string explaining who should be hired and why\n- \"action\": Either \"create_actor\" to recommend someone, or null\n\nExample: {\"recommendation\": \"I recommend hiring...\", \"action\": \"create_actor\"}",
                    "rawResponse": "{\n  \"recommendation\": \"I recommend hiring a \\\"Database Performance Engineer.\\\" This role is crucial because the team is facing significant challenges with slow query performance, which is impacting customer satisfaction. The engineer would specialize in analyzing and optimizing database queries, restructuring schemas, and implementing effective indexing strategies. They would also evaluate the potential benefits of migrating to a different database system like TimescaleDB. This role requires strong reasoning capabilities to diagnose and resolve complex database performance issues.\",\n  \"action\": \"create_actor\"\n}",
                    "parsedResponse": {
                      "recommendation": "I recommend hiring a \"Database Performance Engineer.\" This role is crucial because the team is facing significant challenges with slow query performance, which is impacting customer satisfaction. The engineer would specialize in analyzing and optimizing database queries, restructuring schemas, and implementing effective indexing strategies. They would also evaluate the potential benefits of migrating to a different database system like TimescaleDB. This role requires strong reasoning capabilities to diagnose and resolve complex database performance issues.",
                      "action": "create_actor"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 2,
                "stepName": "Details",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:00:09.439Z",
                    "success": true,
                    "durationMs": 2334,
                    "inputTokens": 1044,
                    "outputTokens": 77,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a \\\"Database Performance Engineer.\\\" This role is crucial because the team is facing significant challenges with slow query performance, which is impacting customer satisfaction. The engineer would specialize in analyzing and optimizing database queries, restructuring schemas, and implementing effective indexing strategies. They would also evaluate the potential benefits of migrating to a different database system like TimescaleDB. This role requires strong reasoning capabilities to diagnose and resolve complex database performance issues.\",\"action\":\"create_actor\"}\n\n[user] For the role you recommended, provide their details.\n\nRespond with a JSON object containing:\n- \"title\": The job title (e.g., \"Database Administrator\")\n- \"reason\": Why this role addresses the team's skill gap\n- \"skills\": An array of 3-7 specific technical skills\n\nExample: {\"title\": \"Senior DBA\", \"reason\": \"The team needs...\", \"skills\": [\"PostgreSQL\", \"Query Optimization\"]}",
                    "rawResponse": "{\n  \"title\": \"Database Performance Engineer\",\n  \"reason\": \"The team needs expertise in diagnosing and resolving complex database performance issues, optimizing query execution, and potentially restructuring the database architecture to improve load times and customer satisfaction.\",\n  \"skills\": [\n    \"SQL Query Optimization\",\n    \"Database Schema Design\",\n    \"Indexing Strategies\",\n    \"PostgreSQL\",\n    \"Database Performance Tuning\",\n    \"EXPLAIN ANALYZE\",\n    \"Time-Series Databases\"\n  ]\n}",
                    "parsedResponse": {
                      "title": "Database Performance Engineer",
                      "reason": "The team needs expertise in diagnosing and resolving complex database performance issues, optimizing query execution, and potentially restructuring the database architecture to improve load times and customer satisfaction.",
                      "skills": [
                        "SQL Query Optimization",
                        "Database Schema Design",
                        "Indexing Strategies",
                        "PostgreSQL",
                        "Database Performance Tuning",
                        "EXPLAIN ANALYZE",
                        "Time-Series Databases"
                      ]
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 3,
                "stepName": "AI Config",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:00:11.761Z",
                    "success": true,
                    "durationMs": 2322,
                    "inputTokens": 1098,
                    "outputTokens": 53,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a \\\"Database Performance Engineer.\\\" This role is crucial because the team is facing significant challenges with slow query performance, which is impacting customer satisfaction. The engineer would specialize in analyzing and optimizing database queries, restructuring schemas, and implementing effective indexing strategies. They would also evaluate the potential benefits of migrating to a different database system like TimescaleDB. This role requires strong reasoning capabilities to diagnose and resolve complex database performance issues.\",\"action\":\"create_actor\"}\n\n[assistant] {\"title\":\"Database Performance Engineer\",\"reason\":\"The team needs expertise in diagnosing and resolving complex database performance issues, optimizing query execution, and potentially restructuring the database architecture to improve load times and customer satisfaction.\",\"skills\":[\"SQL Query Optimization\",\"Database Schema Design\",\"Indexing Strategies\",\"PostgreSQL\",\"Database Performance Tuning\",\"EXPLAIN ANALYZE\",\"Time-Series Databases\"]}\n\n[user] For this role, provide the AI configuration.\n\nRespond with a JSON object containing:\n- \"prompt\": A system prompt for configuring an AI assistant in this role\n- \"model\": Either \"reasoning\" (for analytical/logical tasks) or \"semantic\" (for creative/conversational tasks)\n\nExample: {\"prompt\": \"You are an expert database administrator...\", \"model\": \"reasoning\"}",
                    "rawResponse": "{\n  \"prompt\": \"You are an expert database performance engineer. Your task is to analyze and optimize database queries, improve schema design, and implement indexing strategies to enhance performance. Evaluate the potential for database migration and provide solutions for complex performance issues.\",\n  \"model\": \"reasoning\"\n}",
                    "parsedResponse": {
                      "prompt": "You are an expert database performance engineer. Your task is to analyze and optimize database queries, improve schema design, and implement indexing strategies to enhance performance. Evaluate the potential for database migration and provide solutions for complex performance issues.",
                      "model": "reasoning"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              }
            ],
            "totalDurationMs": 6968,
            "finalResponse": {
              "recommendation": "I recommend hiring a \"Database Performance Engineer.\" This role is crucial because the team is facing significant challenges with slow query performance, which is impacting customer satisfaction. The engineer would specialize in analyzing and optimizing database queries, restructuring schemas, and implementing effective indexing strategies. They would also evaluate the potential benefits of migrating to a different database system like TimescaleDB. This role requires strong reasoning capabilities to diagnose and resolve complex database performance issues.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Performance Engineer",
                  "reason": "The team needs expertise in diagnosing and resolving complex database performance issues, optimizing query execution, and potentially restructuring the database architecture to improve load times and customer satisfaction.",
                  "skills": [
                    "SQL Query Optimization",
                    "Database Schema Design",
                    "Indexing Strategies",
                    "PostgreSQL",
                    "Database Performance Tuning",
                    "EXPLAIN ANALYZE",
                    "Time-Series Databases"
                  ],
                  "prompt": "You are an expert database performance engineer. Your task is to analyze and optimize database queries, improve schema design, and implement indexing strategies to enhance performance. Evaluate the potential for database migration and provide solutions for complex performance issues.",
                  "model": "reasoning"
                }
              }
            }
          },
          {
            "runNumber": 2,
            "success": true,
            "attempts": [],
            "steps": [
              {
                "stepNumber": 1,
                "stepName": "Recommendation",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:00:14.485Z",
                    "success": true,
                    "durationMs": 2723,
                    "inputTokens": 927,
                    "outputTokens": 105,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation, what type of team member should this team add?\n\nRespond with a JSON object containing:\n- \"recommendation\": A string explaining who should be hired and why\n- \"action\": Either \"create_actor\" to recommend someone, or null\n\nExample: {\"recommendation\": \"I recommend hiring...\", \"action\": \"create_actor\"}",
                    "rawResponse": "{\n  \"recommendation\": \"I recommend hiring a Database Performance Engineer. This role is crucial because the team is facing significant challenges with slow query performance, which is affecting customer satisfaction. The engineer will specialize in analyzing query execution plans, optimizing database schemas, and implementing effective indexing strategies. They will also evaluate the potential benefits of migrating to a different database system, such as TimescaleDB, and guide the team through any necessary transitions. This role requires strong reasoning capabilities to diagnose and resolve complex database performance issues.\",\n  \"action\": \"create_actor\"\n}",
                    "parsedResponse": {
                      "recommendation": "I recommend hiring a Database Performance Engineer. This role is crucial because the team is facing significant challenges with slow query performance, which is affecting customer satisfaction. The engineer will specialize in analyzing query execution plans, optimizing database schemas, and implementing effective indexing strategies. They will also evaluate the potential benefits of migrating to a different database system, such as TimescaleDB, and guide the team through any necessary transitions. This role requires strong reasoning capabilities to diagnose and resolve complex database performance issues.",
                      "action": "create_actor"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 2,
                "stepName": "Details",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:00:17.162Z",
                    "success": true,
                    "durationMs": 2677,
                    "inputTokens": 1054,
                    "outputTokens": 81,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Database Performance Engineer. This role is crucial because the team is facing significant challenges with slow query performance, which is affecting customer satisfaction. The engineer will specialize in analyzing query execution plans, optimizing database schemas, and implementing effective indexing strategies. They will also evaluate the potential benefits of migrating to a different database system, such as TimescaleDB, and guide the team through any necessary transitions. This role requires strong reasoning capabilities to diagnose and resolve complex database performance issues.\",\"action\":\"create_actor\"}\n\n[user] For the role you recommended, provide their details.\n\nRespond with a JSON object containing:\n- \"title\": The job title (e.g., \"Database Administrator\")\n- \"reason\": Why this role addresses the team's skill gap\n- \"skills\": An array of 3-7 specific technical skills\n\nExample: {\"title\": \"Senior DBA\", \"reason\": \"The team needs...\", \"skills\": [\"PostgreSQL\", \"Query Optimization\"]}",
                    "rawResponse": "{\n  \"title\": \"Database Performance Engineer\",\n  \"reason\": \"The team needs an expert to analyze and optimize slow query performance, which is crucial for maintaining customer satisfaction and preventing churn. This role will address the skill gap in database optimization and architecture evaluation.\",\n  \"skills\": [\n    \"Query Optimization\",\n    \"Database Schema Design\",\n    \"Indexing Strategies\",\n    \"PostgreSQL\",\n    \"EXPLAIN ANALYZE\",\n    \"Database Migration\",\n    \"Disk I/O Analysis\"\n  ]\n}",
                    "parsedResponse": {
                      "title": "Database Performance Engineer",
                      "reason": "The team needs an expert to analyze and optimize slow query performance, which is crucial for maintaining customer satisfaction and preventing churn. This role will address the skill gap in database optimization and architecture evaluation.",
                      "skills": [
                        "Query Optimization",
                        "Database Schema Design",
                        "Indexing Strategies",
                        "PostgreSQL",
                        "EXPLAIN ANALYZE",
                        "Database Migration",
                        "Disk I/O Analysis"
                      ]
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 3,
                "stepName": "AI Config",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:00:19.462Z",
                    "success": true,
                    "durationMs": 2300,
                    "inputTokens": 1112,
                    "outputTokens": 51,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Database Performance Engineer. This role is crucial because the team is facing significant challenges with slow query performance, which is affecting customer satisfaction. The engineer will specialize in analyzing query execution plans, optimizing database schemas, and implementing effective indexing strategies. They will also evaluate the potential benefits of migrating to a different database system, such as TimescaleDB, and guide the team through any necessary transitions. This role requires strong reasoning capabilities to diagnose and resolve complex database performance issues.\",\"action\":\"create_actor\"}\n\n[assistant] {\"title\":\"Database Performance Engineer\",\"reason\":\"The team needs an expert to analyze and optimize slow query performance, which is crucial for maintaining customer satisfaction and preventing churn. This role will address the skill gap in database optimization and architecture evaluation.\",\"skills\":[\"Query Optimization\",\"Database Schema Design\",\"Indexing Strategies\",\"PostgreSQL\",\"EXPLAIN ANALYZE\",\"Database Migration\",\"Disk I/O Analysis\"]}\n\n[user] For this role, provide the AI configuration.\n\nRespond with a JSON object containing:\n- \"prompt\": A system prompt for configuring an AI assistant in this role\n- \"model\": Either \"reasoning\" (for analytical/logical tasks) or \"semantic\" (for creative/conversational tasks)\n\nExample: {\"prompt\": \"You are an expert database administrator...\", \"model\": \"reasoning\"}",
                    "rawResponse": "{\n  \"prompt\": \"You are an expert database performance engineer. Your task is to analyze and optimize database queries, improve schema design, and implement effective indexing strategies. You will also evaluate and advise on potential database migrations to enhance performance.\",\n  \"model\": \"reasoning\"\n}",
                    "parsedResponse": {
                      "prompt": "You are an expert database performance engineer. Your task is to analyze and optimize database queries, improve schema design, and implement effective indexing strategies. You will also evaluate and advise on potential database migrations to enhance performance.",
                      "model": "reasoning"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              }
            ],
            "totalDurationMs": 7701,
            "finalResponse": {
              "recommendation": "I recommend hiring a Database Performance Engineer. This role is crucial because the team is facing significant challenges with slow query performance, which is affecting customer satisfaction. The engineer will specialize in analyzing query execution plans, optimizing database schemas, and implementing effective indexing strategies. They will also evaluate the potential benefits of migrating to a different database system, such as TimescaleDB, and guide the team through any necessary transitions. This role requires strong reasoning capabilities to diagnose and resolve complex database performance issues.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Performance Engineer",
                  "reason": "The team needs an expert to analyze and optimize slow query performance, which is crucial for maintaining customer satisfaction and preventing churn. This role will address the skill gap in database optimization and architecture evaluation.",
                  "skills": [
                    "Query Optimization",
                    "Database Schema Design",
                    "Indexing Strategies",
                    "PostgreSQL",
                    "EXPLAIN ANALYZE",
                    "Database Migration",
                    "Disk I/O Analysis"
                  ],
                  "prompt": "You are an expert database performance engineer. Your task is to analyze and optimize database queries, improve schema design, and implement effective indexing strategies. You will also evaluate and advise on potential database migrations to enhance performance.",
                  "model": "reasoning"
                }
              }
            }
          },
          {
            "runNumber": 3,
            "success": true,
            "attempts": [],
            "steps": [
              {
                "stepNumber": 1,
                "stepName": "Recommendation",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:00:21.705Z",
                    "success": true,
                    "durationMs": 2242,
                    "inputTokens": 927,
                    "outputTokens": 83,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation, what type of team member should this team add?\n\nRespond with a JSON object containing:\n- \"recommendation\": A string explaining who should be hired and why\n- \"action\": Either \"create_actor\" to recommend someone, or null\n\nExample: {\"recommendation\": \"I recommend hiring...\", \"action\": \"create_actor\"}",
                    "rawResponse": "{\n  \"recommendation\": \"I recommend hiring a Database Performance Engineer. This role is crucial because the team is facing significant challenges with database query performance, which is affecting customer satisfaction. The engineer will need to analyze query plans, optimize database schema, implement effective indexing strategies, and evaluate the potential for database migration to improve performance. This role requires strong reasoning capabilities to diagnose and resolve complex database issues.\",\n  \"action\": \"create_actor\"\n}",
                    "parsedResponse": {
                      "recommendation": "I recommend hiring a Database Performance Engineer. This role is crucial because the team is facing significant challenges with database query performance, which is affecting customer satisfaction. The engineer will need to analyze query plans, optimize database schema, implement effective indexing strategies, and evaluate the potential for database migration to improve performance. This role requires strong reasoning capabilities to diagnose and resolve complex database issues.",
                      "action": "create_actor"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 2,
                "stepName": "Details",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:00:24.011Z",
                    "success": true,
                    "durationMs": 2306,
                    "inputTokens": 1032,
                    "outputTokens": 72,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Database Performance Engineer. This role is crucial because the team is facing significant challenges with database query performance, which is affecting customer satisfaction. The engineer will need to analyze query plans, optimize database schema, implement effective indexing strategies, and evaluate the potential for database migration to improve performance. This role requires strong reasoning capabilities to diagnose and resolve complex database issues.\",\"action\":\"create_actor\"}\n\n[user] For the role you recommended, provide their details.\n\nRespond with a JSON object containing:\n- \"title\": The job title (e.g., \"Database Administrator\")\n- \"reason\": Why this role addresses the team's skill gap\n- \"skills\": An array of 3-7 specific technical skills\n\nExample: {\"title\": \"Senior DBA\", \"reason\": \"The team needs...\", \"skills\": [\"PostgreSQL\", \"Query Optimization\"]}",
                    "rawResponse": "{\n  \"title\": \"Database Performance Engineer\",\n  \"reason\": \"The team needs an expert to analyze and optimize database queries, improve schema design, and evaluate database architecture to resolve performance issues affecting customer satisfaction.\",\n  \"skills\": [\n    \"Query Optimization\",\n    \"Database Schema Design\",\n    \"Indexing Strategies\",\n    \"PostgreSQL\",\n    \"EXPLAIN ANALYZE\",\n    \"Disk I/O Analysis\",\n    \"Database Migration Planning\"\n  ]\n}",
                    "parsedResponse": {
                      "title": "Database Performance Engineer",
                      "reason": "The team needs an expert to analyze and optimize database queries, improve schema design, and evaluate database architecture to resolve performance issues affecting customer satisfaction.",
                      "skills": [
                        "Query Optimization",
                        "Database Schema Design",
                        "Indexing Strategies",
                        "PostgreSQL",
                        "EXPLAIN ANALYZE",
                        "Disk I/O Analysis",
                        "Database Migration Planning"
                      ]
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 3,
                "stepName": "AI Config",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:00:26.327Z",
                    "success": true,
                    "durationMs": 2316,
                    "inputTokens": 1081,
                    "outputTokens": 54,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Database Performance Engineer. This role is crucial because the team is facing significant challenges with database query performance, which is affecting customer satisfaction. The engineer will need to analyze query plans, optimize database schema, implement effective indexing strategies, and evaluate the potential for database migration to improve performance. This role requires strong reasoning capabilities to diagnose and resolve complex database issues.\",\"action\":\"create_actor\"}\n\n[assistant] {\"title\":\"Database Performance Engineer\",\"reason\":\"The team needs an expert to analyze and optimize database queries, improve schema design, and evaluate database architecture to resolve performance issues affecting customer satisfaction.\",\"skills\":[\"Query Optimization\",\"Database Schema Design\",\"Indexing Strategies\",\"PostgreSQL\",\"EXPLAIN ANALYZE\",\"Disk I/O Analysis\",\"Database Migration Planning\"]}\n\n[user] For this role, provide the AI configuration.\n\nRespond with a JSON object containing:\n- \"prompt\": A system prompt for configuring an AI assistant in this role\n- \"model\": Either \"reasoning\" (for analytical/logical tasks) or \"semantic\" (for creative/conversational tasks)\n\nExample: {\"prompt\": \"You are an expert database administrator...\", \"model\": \"reasoning\"}",
                    "rawResponse": "{\n  \"prompt\": \"You are an expert database performance engineer. Your role is to analyze and optimize complex database queries, improve schema design, and implement effective indexing strategies. You will evaluate and recommend database architecture improvements to enhance performance and meet customer needs.\",\n  \"model\": \"reasoning\"\n}",
                    "parsedResponse": {
                      "prompt": "You are an expert database performance engineer. Your role is to analyze and optimize complex database queries, improve schema design, and implement effective indexing strategies. You will evaluate and recommend database architecture improvements to enhance performance and meet customer needs.",
                      "model": "reasoning"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              }
            ],
            "totalDurationMs": 6864,
            "finalResponse": {
              "recommendation": "I recommend hiring a Database Performance Engineer. This role is crucial because the team is facing significant challenges with database query performance, which is affecting customer satisfaction. The engineer will need to analyze query plans, optimize database schema, implement effective indexing strategies, and evaluate the potential for database migration to improve performance. This role requires strong reasoning capabilities to diagnose and resolve complex database issues.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Performance Engineer",
                  "reason": "The team needs an expert to analyze and optimize database queries, improve schema design, and evaluate database architecture to resolve performance issues affecting customer satisfaction.",
                  "skills": [
                    "Query Optimization",
                    "Database Schema Design",
                    "Indexing Strategies",
                    "PostgreSQL",
                    "EXPLAIN ANALYZE",
                    "Disk I/O Analysis",
                    "Database Migration Planning"
                  ],
                  "prompt": "You are an expert database performance engineer. Your role is to analyze and optimize complex database queries, improve schema design, and implement effective indexing strategies. You will evaluate and recommend database architecture improvements to enhance performance and meet customer needs.",
                  "model": "reasoning"
                }
              }
            }
          }
        ],
        "summary": {
          "successRate": 100,
          "firstAttemptSuccessRate": 100,
          "afterRetry1SuccessRate": 100,
          "afterRetry2SuccessRate": 100,
          "afterRetry3SuccessRate": 100,
          "averageDurationMs": 7177.666666666667,
          "averageAttempts": 3,
          "averageAttemptsPerSuccess": 3,
          "averageTokensPerSuccess": 3291,
          "totalTokensUsed": 9873
        }
      }
    },
    "anthropic-sonnet": {
      "1": {
        "runs": [
          {
            "runNumber": 1,
            "success": true,
            "attempts": [
              {
                "attemptNumber": 1,
                "timestamp": "2025-11-29T17:00:40.471Z",
                "success": true,
                "durationMs": 14143,
                "inputTokens": 1088,
                "outputTokens": 542,
                "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation above, recommend a team member who could help solve their problem.\n\nRespond ONLY with valid JSON like this example:\n{\n  \"recommendation\": \"I think you need to hire a [role] because [explanation of how they address the team's problem]...\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Job Title Here\",\n      \"reason\": \"Why this role addresses the team's skill gap\",\n      \"skills\": [\"skill1\", \"skill2\", \"skill3\"],\n      \"prompt\": \"You are an expert in [domain]. You help teams by [description of approach]...\",\n      \"model\": \"reasoning\"\n    }\n  }\n}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks or backticks\n- The \"recommendation\" field should start with \"I think you need to hire...\"\n- Skills array should have 3-7 specific technical skills\n- \"model\" should be \"reasoning\" for analytical tasks or \"semantic\" for creative tasks\n- Set \"action\" to null if no recommendation is appropriate",
                "rawResponse": "{\n  \"recommendation\": \"I think you need to hire a Database Performance Engineer because your team is facing a critical performance issue with dashboard queries taking 8-12 seconds, and none of the current team members have deep database optimization expertise. The team has tried basic solutions like adding indexes and rewriting queries, but they're essentially guessing without understanding the root cause. You need someone who can analyze query execution plans, design proper indexing strategies, optimize schema design, and evaluate whether architectural changes like read replicas or database migrations are necessary. This role would prevent the threatened customer churn and establish best practices for database performance going forward.\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Database Performance Engineer\",\n      \"reason\": \"The team lacks specialized database optimization expertise needed to solve critical performance issues affecting enterprise customers. They've exhausted their knowledge of basic solutions and need someone who can systematically diagnose bottlenecks, optimize complex queries, design efficient schemas, and recommend architectural improvements.\",\n      \"skills\": [\n        \"SQL query optimization and execution plan analysis\",\n        \"Database indexing strategies and performance tuning\",\n        \"Schema design and normalization/denormalization trade-offs\",\n        \"Database profiling and bottleneck identification\",\n        \"Read replica and database scaling architectures\",\n        \"Time-series and analytical database systems (PostgreSQL, TimescaleDB, etc.)\",\n        \"Caching strategies and data access patterns\"\n      ],\n      \"prompt\": \"You are an expert Database Performance Engineer with deep knowledge of relational database optimization, query performance tuning, and scalable data architectures. When teams come to you with performance problems, you take a systematic, analytical approach: First, you analyze query execution plans (EXPLAIN ANALYZE) to identify bottlenecks like sequential scans, inefficient joins, or missing indexes. You examine table structures, data volumes, and access patterns to understand the root cause. You provide specific, actionable recommendations with clear explanations of trade-offs. You consider both quick wins (proper indexing, query rewrites) and longer-term architectural solutions (partitioning, read replicas, specialized databases). You explain complex database concepts in terms developers can understand and implement. You always consider the impact of changes on existing functionality and provide migration strategies when needed. Your goal is to solve immediate performance issues while building the team's understanding of database optimization principles.\",\n      \"model\": \"reasoning\"\n    }\n  }\n}",
                "parsedResponse": {
                  "recommendation": "I think you need to hire a Database Performance Engineer because your team is facing a critical performance issue with dashboard queries taking 8-12 seconds, and none of the current team members have deep database optimization expertise. The team has tried basic solutions like adding indexes and rewriting queries, but they're essentially guessing without understanding the root cause. You need someone who can analyze query execution plans, design proper indexing strategies, optimize schema design, and evaluate whether architectural changes like read replicas or database migrations are necessary. This role would prevent the threatened customer churn and establish best practices for database performance going forward.",
                  "action": {
                    "type": "create_actor",
                    "actor": {
                      "title": "Database Performance Engineer",
                      "reason": "The team lacks specialized database optimization expertise needed to solve critical performance issues affecting enterprise customers. They've exhausted their knowledge of basic solutions and need someone who can systematically diagnose bottlenecks, optimize complex queries, design efficient schemas, and recommend architectural improvements.",
                      "skills": [
                        "SQL query optimization and execution plan analysis",
                        "Database indexing strategies and performance tuning",
                        "Schema design and normalization/denormalization trade-offs",
                        "Database profiling and bottleneck identification",
                        "Read replica and database scaling architectures",
                        "Time-series and analytical database systems (PostgreSQL, TimescaleDB, etc.)",
                        "Caching strategies and data access patterns"
                      ],
                      "prompt": "You are an expert Database Performance Engineer with deep knowledge of relational database optimization, query performance tuning, and scalable data architectures. When teams come to you with performance problems, you take a systematic, analytical approach: First, you analyze query execution plans (EXPLAIN ANALYZE) to identify bottlenecks like sequential scans, inefficient joins, or missing indexes. You examine table structures, data volumes, and access patterns to understand the root cause. You provide specific, actionable recommendations with clear explanations of trade-offs. You consider both quick wins (proper indexing, query rewrites) and longer-term architectural solutions (partitioning, read replicas, specialized databases). You explain complex database concepts in terms developers can understand and implement. You always consider the impact of changes on existing functionality and provide migration strategies when needed. Your goal is to solve immediate performance issues while building the team's understanding of database optimization principles.",
                      "model": "reasoning"
                    }
                  }
                },
                "validationErrors": [],
                "errorMessage": null
              }
            ],
            "totalDurationMs": 14143,
            "finalResponse": {
              "recommendation": "I think you need to hire a Database Performance Engineer because your team is facing a critical performance issue with dashboard queries taking 8-12 seconds, and none of the current team members have deep database optimization expertise. The team has tried basic solutions like adding indexes and rewriting queries, but they're essentially guessing without understanding the root cause. You need someone who can analyze query execution plans, design proper indexing strategies, optimize schema design, and evaluate whether architectural changes like read replicas or database migrations are necessary. This role would prevent the threatened customer churn and establish best practices for database performance going forward.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Performance Engineer",
                  "reason": "The team lacks specialized database optimization expertise needed to solve critical performance issues affecting enterprise customers. They've exhausted their knowledge of basic solutions and need someone who can systematically diagnose bottlenecks, optimize complex queries, design efficient schemas, and recommend architectural improvements.",
                  "skills": [
                    "SQL query optimization and execution plan analysis",
                    "Database indexing strategies and performance tuning",
                    "Schema design and normalization/denormalization trade-offs",
                    "Database profiling and bottleneck identification",
                    "Read replica and database scaling architectures",
                    "Time-series and analytical database systems (PostgreSQL, TimescaleDB, etc.)",
                    "Caching strategies and data access patterns"
                  ],
                  "prompt": "You are an expert Database Performance Engineer with deep knowledge of relational database optimization, query performance tuning, and scalable data architectures. When teams come to you with performance problems, you take a systematic, analytical approach: First, you analyze query execution plans (EXPLAIN ANALYZE) to identify bottlenecks like sequential scans, inefficient joins, or missing indexes. You examine table structures, data volumes, and access patterns to understand the root cause. You provide specific, actionable recommendations with clear explanations of trade-offs. You consider both quick wins (proper indexing, query rewrites) and longer-term architectural solutions (partitioning, read replicas, specialized databases). You explain complex database concepts in terms developers can understand and implement. You always consider the impact of changes on existing functionality and provide migration strategies when needed. Your goal is to solve immediate performance issues while building the team's understanding of database optimization principles.",
                  "model": "reasoning"
                }
              }
            }
          },
          {
            "runNumber": 2,
            "success": true,
            "attempts": [
              {
                "attemptNumber": 1,
                "timestamp": "2025-11-29T17:00:57.286Z",
                "success": true,
                "durationMs": 16815,
                "inputTokens": 1088,
                "outputTokens": 649,
                "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation above, recommend a team member who could help solve their problem.\n\nRespond ONLY with valid JSON like this example:\n{\n  \"recommendation\": \"I think you need to hire a [role] because [explanation of how they address the team's problem]...\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Job Title Here\",\n      \"reason\": \"Why this role addresses the team's skill gap\",\n      \"skills\": [\"skill1\", \"skill2\", \"skill3\"],\n      \"prompt\": \"You are an expert in [domain]. You help teams by [description of approach]...\",\n      \"model\": \"reasoning\"\n    }\n  }\n}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks or backticks\n- The \"recommendation\" field should start with \"I think you need to hire...\"\n- Skills array should have 3-7 specific technical skills\n- \"model\" should be \"reasoning\" for analytical tasks or \"semantic\" for creative tasks\n- Set \"action\" to null if no recommendation is appropriate",
                "rawResponse": "{\n  \"recommendation\": \"I think you need to hire a Database Performance Engineer because your team is facing a critical performance issue with slow dashboard queries (8-12 seconds) that's threatening customer retention. While your team has general development skills, they lack the specialized expertise needed to properly diagnose query execution plans, optimize database schemas, design effective indexing strategies, and evaluate architectural solutions like read replicas or database migrations. The team is 'guessing' (as Sam noted) rather than systematically solving the problem, and they've already spent two weeks without resolution. A Database Performance Engineer would bring the deep technical knowledge needed to analyze EXPLAIN plans, resolve the sequential scan bottleneck on the events table, optimize the 4-table join, and determine whether schema redesign or database migration is necessary - all while ensuring changes don't break existing functionality.\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Database Performance Engineer\",\n      \"reason\": \"The team has a critical database performance issue causing 8-12 second query times that threatens customer churn, but lacks specialized expertise in query optimization, indexing strategies, and database architecture. They need someone who can systematically diagnose bottlenecks, optimize queries and schemas, and make informed decisions about architectural changes.\",\n      \"skills\": [\n        \"SQL query optimization and execution plan analysis\",\n        \"Database indexing strategies (B-tree, partial, covering indexes)\",\n        \"Schema design and normalization/denormalization patterns\",\n        \"PostgreSQL/MySQL performance tuning and configuration\",\n        \"Database profiling and bottleneck identification\",\n        \"Read replica and replication architecture\",\n        \"Time-series database evaluation (TimescaleDB, ClickHouse)\"\n      ],\n      \"prompt\": \"You are an expert Database Performance Engineer specializing in diagnosing and resolving database performance issues. Your approach is systematic and data-driven:\\n\\n1. First, analyze query execution plans (EXPLAIN ANALYZE) to identify specific bottlenecks like sequential scans, inefficient joins, or missing indexes\\n2. Examine table schemas, data distribution, and cardinality to understand the root cause\\n3. Propose specific, targeted optimizations with clear explanations of trade-offs\\n4. Consider both quick wins (index additions, query rewrites) and longer-term solutions (schema redesign, architectural changes)\\n5. Always validate that proposed changes won't negatively impact other queries or system components\\n6. Provide step-by-step implementation guidance with rollback plans\\n\\nWhen analyzing problems, ask clarifying questions about: table sizes, data growth patterns, query frequency, existing indexes, database version, and hardware constraints. Explain technical concepts clearly so the team understands not just what to do, but why. Focus on pragmatic solutions that balance performance gains with implementation complexity and risk.\",\n      \"model\": \"reasoning\"\n    }\n  }\n}",
                "parsedResponse": {
                  "recommendation": "I think you need to hire a Database Performance Engineer because your team is facing a critical performance issue with slow dashboard queries (8-12 seconds) that's threatening customer retention. While your team has general development skills, they lack the specialized expertise needed to properly diagnose query execution plans, optimize database schemas, design effective indexing strategies, and evaluate architectural solutions like read replicas or database migrations. The team is 'guessing' (as Sam noted) rather than systematically solving the problem, and they've already spent two weeks without resolution. A Database Performance Engineer would bring the deep technical knowledge needed to analyze EXPLAIN plans, resolve the sequential scan bottleneck on the events table, optimize the 4-table join, and determine whether schema redesign or database migration is necessary - all while ensuring changes don't break existing functionality.",
                  "action": {
                    "type": "create_actor",
                    "actor": {
                      "title": "Database Performance Engineer",
                      "reason": "The team has a critical database performance issue causing 8-12 second query times that threatens customer churn, but lacks specialized expertise in query optimization, indexing strategies, and database architecture. They need someone who can systematically diagnose bottlenecks, optimize queries and schemas, and make informed decisions about architectural changes.",
                      "skills": [
                        "SQL query optimization and execution plan analysis",
                        "Database indexing strategies (B-tree, partial, covering indexes)",
                        "Schema design and normalization/denormalization patterns",
                        "PostgreSQL/MySQL performance tuning and configuration",
                        "Database profiling and bottleneck identification",
                        "Read replica and replication architecture",
                        "Time-series database evaluation (TimescaleDB, ClickHouse)"
                      ],
                      "prompt": "You are an expert Database Performance Engineer specializing in diagnosing and resolving database performance issues. Your approach is systematic and data-driven:\n\n1. First, analyze query execution plans (EXPLAIN ANALYZE) to identify specific bottlenecks like sequential scans, inefficient joins, or missing indexes\n2. Examine table schemas, data distribution, and cardinality to understand the root cause\n3. Propose specific, targeted optimizations with clear explanations of trade-offs\n4. Consider both quick wins (index additions, query rewrites) and longer-term solutions (schema redesign, architectural changes)\n5. Always validate that proposed changes won't negatively impact other queries or system components\n6. Provide step-by-step implementation guidance with rollback plans\n\nWhen analyzing problems, ask clarifying questions about: table sizes, data growth patterns, query frequency, existing indexes, database version, and hardware constraints. Explain technical concepts clearly so the team understands not just what to do, but why. Focus on pragmatic solutions that balance performance gains with implementation complexity and risk.",
                      "model": "reasoning"
                    }
                  }
                },
                "validationErrors": [],
                "errorMessage": null
              }
            ],
            "totalDurationMs": 16815,
            "finalResponse": {
              "recommendation": "I think you need to hire a Database Performance Engineer because your team is facing a critical performance issue with slow dashboard queries (8-12 seconds) that's threatening customer retention. While your team has general development skills, they lack the specialized expertise needed to properly diagnose query execution plans, optimize database schemas, design effective indexing strategies, and evaluate architectural solutions like read replicas or database migrations. The team is 'guessing' (as Sam noted) rather than systematically solving the problem, and they've already spent two weeks without resolution. A Database Performance Engineer would bring the deep technical knowledge needed to analyze EXPLAIN plans, resolve the sequential scan bottleneck on the events table, optimize the 4-table join, and determine whether schema redesign or database migration is necessary - all while ensuring changes don't break existing functionality.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Performance Engineer",
                  "reason": "The team has a critical database performance issue causing 8-12 second query times that threatens customer churn, but lacks specialized expertise in query optimization, indexing strategies, and database architecture. They need someone who can systematically diagnose bottlenecks, optimize queries and schemas, and make informed decisions about architectural changes.",
                  "skills": [
                    "SQL query optimization and execution plan analysis",
                    "Database indexing strategies (B-tree, partial, covering indexes)",
                    "Schema design and normalization/denormalization patterns",
                    "PostgreSQL/MySQL performance tuning and configuration",
                    "Database profiling and bottleneck identification",
                    "Read replica and replication architecture",
                    "Time-series database evaluation (TimescaleDB, ClickHouse)"
                  ],
                  "prompt": "You are an expert Database Performance Engineer specializing in diagnosing and resolving database performance issues. Your approach is systematic and data-driven:\n\n1. First, analyze query execution plans (EXPLAIN ANALYZE) to identify specific bottlenecks like sequential scans, inefficient joins, or missing indexes\n2. Examine table schemas, data distribution, and cardinality to understand the root cause\n3. Propose specific, targeted optimizations with clear explanations of trade-offs\n4. Consider both quick wins (index additions, query rewrites) and longer-term solutions (schema redesign, architectural changes)\n5. Always validate that proposed changes won't negatively impact other queries or system components\n6. Provide step-by-step implementation guidance with rollback plans\n\nWhen analyzing problems, ask clarifying questions about: table sizes, data growth patterns, query frequency, existing indexes, database version, and hardware constraints. Explain technical concepts clearly so the team understands not just what to do, but why. Focus on pragmatic solutions that balance performance gains with implementation complexity and risk.",
                  "model": "reasoning"
                }
              }
            }
          },
          {
            "runNumber": 3,
            "success": true,
            "attempts": [
              {
                "attemptNumber": 1,
                "timestamp": "2025-11-29T17:01:13.722Z",
                "success": true,
                "durationMs": 16436,
                "inputTokens": 1088,
                "outputTokens": 646,
                "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation above, recommend a team member who could help solve their problem.\n\nRespond ONLY with valid JSON like this example:\n{\n  \"recommendation\": \"I think you need to hire a [role] because [explanation of how they address the team's problem]...\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Job Title Here\",\n      \"reason\": \"Why this role addresses the team's skill gap\",\n      \"skills\": [\"skill1\", \"skill2\", \"skill3\"],\n      \"prompt\": \"You are an expert in [domain]. You help teams by [description of approach]...\",\n      \"model\": \"reasoning\"\n    }\n  }\n}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks or backticks\n- The \"recommendation\" field should start with \"I think you need to hire...\"\n- Skills array should have 3-7 specific technical skills\n- \"model\" should be \"reasoning\" for analytical tasks or \"semantic\" for creative tasks\n- Set \"action\" to null if no recommendation is appropriate",
                "rawResponse": "{\n  \"recommendation\": \"I think you need to hire a Database Performance Engineer because your team is facing a critical performance issue with slow dashboard queries (8-12 seconds) that's threatening customer retention. While your team has general development skills, they lack the specialized expertise needed to properly diagnose query execution plans, optimize database schemas, design effective indexing strategies, and evaluate architectural solutions like read replicas or database migrations. The team is 'guessing' (as Sam noted) rather than systematically solving the problem, and they've already spent two weeks without resolution. A Database Performance Engineer would bring the deep technical knowledge needed to analyze EXPLAIN plans, resolve the sequential scan bottleneck on the events table, optimize the 4-table join, and determine whether schema redesign or database migration is necessary - all while ensuring changes don't break existing functionality.\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Database Performance Engineer\",\n      \"reason\": \"The team has a critical database performance issue causing 8-12 second query times that threatens customer churn, but lacks specialized expertise in query optimization, indexing strategies, and database architecture. They need someone who can systematically diagnose bottlenecks, optimize schemas and queries, and make informed decisions about architectural changes.\",\n      \"skills\": [\n        \"SQL query optimization and execution plan analysis\",\n        \"Database indexing strategies (B-tree, partial, covering indexes)\",\n        \"Schema design and normalization/denormalization trade-offs\",\n        \"PostgreSQL/MySQL performance tuning and configuration\",\n        \"Database profiling and bottleneck identification\",\n        \"Read replica and replication architecture\",\n        \"Time-series database evaluation (TimescaleDB, InfluxDB)\"\n      ],\n      \"prompt\": \"You are an expert Database Performance Engineer specializing in diagnosing and resolving database performance issues. Your approach is systematic and data-driven:\\n\\n1. Start by analyzing EXPLAIN ANALYZE output to identify bottlenecks (sequential scans, inefficient joins, missing indexes)\\n2. Examine table schemas, data volumes, and query patterns to understand the full context\\n3. Propose specific, targeted optimizations with clear explanations of trade-offs\\n4. Consider multiple solutions (indexing, query rewriting, schema changes, caching, architectural changes) and recommend the most appropriate based on requirements\\n5. Always validate that proposed changes won't negatively impact other queries or system components\\n6. Provide step-by-step implementation guidance with rollback plans\\n\\nWhen analyzing performance issues, ask clarifying questions about: data volumes, query frequency, acceptable latency, real-time requirements, current indexes, and table relationships. Focus on finding the root cause rather than applying band-aid solutions. Be practical and consider the team's ability to implement and maintain your recommendations.\",\n      \"model\": \"reasoning\"\n    }\n  }\n}",
                "parsedResponse": {
                  "recommendation": "I think you need to hire a Database Performance Engineer because your team is facing a critical performance issue with slow dashboard queries (8-12 seconds) that's threatening customer retention. While your team has general development skills, they lack the specialized expertise needed to properly diagnose query execution plans, optimize database schemas, design effective indexing strategies, and evaluate architectural solutions like read replicas or database migrations. The team is 'guessing' (as Sam noted) rather than systematically solving the problem, and they've already spent two weeks without resolution. A Database Performance Engineer would bring the deep technical knowledge needed to analyze EXPLAIN plans, resolve the sequential scan bottleneck on the events table, optimize the 4-table join, and determine whether schema redesign or database migration is necessary - all while ensuring changes don't break existing functionality.",
                  "action": {
                    "type": "create_actor",
                    "actor": {
                      "title": "Database Performance Engineer",
                      "reason": "The team has a critical database performance issue causing 8-12 second query times that threatens customer churn, but lacks specialized expertise in query optimization, indexing strategies, and database architecture. They need someone who can systematically diagnose bottlenecks, optimize schemas and queries, and make informed decisions about architectural changes.",
                      "skills": [
                        "SQL query optimization and execution plan analysis",
                        "Database indexing strategies (B-tree, partial, covering indexes)",
                        "Schema design and normalization/denormalization trade-offs",
                        "PostgreSQL/MySQL performance tuning and configuration",
                        "Database profiling and bottleneck identification",
                        "Read replica and replication architecture",
                        "Time-series database evaluation (TimescaleDB, InfluxDB)"
                      ],
                      "prompt": "You are an expert Database Performance Engineer specializing in diagnosing and resolving database performance issues. Your approach is systematic and data-driven:\n\n1. Start by analyzing EXPLAIN ANALYZE output to identify bottlenecks (sequential scans, inefficient joins, missing indexes)\n2. Examine table schemas, data volumes, and query patterns to understand the full context\n3. Propose specific, targeted optimizations with clear explanations of trade-offs\n4. Consider multiple solutions (indexing, query rewriting, schema changes, caching, architectural changes) and recommend the most appropriate based on requirements\n5. Always validate that proposed changes won't negatively impact other queries or system components\n6. Provide step-by-step implementation guidance with rollback plans\n\nWhen analyzing performance issues, ask clarifying questions about: data volumes, query frequency, acceptable latency, real-time requirements, current indexes, and table relationships. Focus on finding the root cause rather than applying band-aid solutions. Be practical and consider the team's ability to implement and maintain your recommendations.",
                      "model": "reasoning"
                    }
                  }
                },
                "validationErrors": [],
                "errorMessage": null
              }
            ],
            "totalDurationMs": 16436,
            "finalResponse": {
              "recommendation": "I think you need to hire a Database Performance Engineer because your team is facing a critical performance issue with slow dashboard queries (8-12 seconds) that's threatening customer retention. While your team has general development skills, they lack the specialized expertise needed to properly diagnose query execution plans, optimize database schemas, design effective indexing strategies, and evaluate architectural solutions like read replicas or database migrations. The team is 'guessing' (as Sam noted) rather than systematically solving the problem, and they've already spent two weeks without resolution. A Database Performance Engineer would bring the deep technical knowledge needed to analyze EXPLAIN plans, resolve the sequential scan bottleneck on the events table, optimize the 4-table join, and determine whether schema redesign or database migration is necessary - all while ensuring changes don't break existing functionality.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Performance Engineer",
                  "reason": "The team has a critical database performance issue causing 8-12 second query times that threatens customer churn, but lacks specialized expertise in query optimization, indexing strategies, and database architecture. They need someone who can systematically diagnose bottlenecks, optimize schemas and queries, and make informed decisions about architectural changes.",
                  "skills": [
                    "SQL query optimization and execution plan analysis",
                    "Database indexing strategies (B-tree, partial, covering indexes)",
                    "Schema design and normalization/denormalization trade-offs",
                    "PostgreSQL/MySQL performance tuning and configuration",
                    "Database profiling and bottleneck identification",
                    "Read replica and replication architecture",
                    "Time-series database evaluation (TimescaleDB, InfluxDB)"
                  ],
                  "prompt": "You are an expert Database Performance Engineer specializing in diagnosing and resolving database performance issues. Your approach is systematic and data-driven:\n\n1. Start by analyzing EXPLAIN ANALYZE output to identify bottlenecks (sequential scans, inefficient joins, missing indexes)\n2. Examine table schemas, data volumes, and query patterns to understand the full context\n3. Propose specific, targeted optimizations with clear explanations of trade-offs\n4. Consider multiple solutions (indexing, query rewriting, schema changes, caching, architectural changes) and recommend the most appropriate based on requirements\n5. Always validate that proposed changes won't negatively impact other queries or system components\n6. Provide step-by-step implementation guidance with rollback plans\n\nWhen analyzing performance issues, ask clarifying questions about: data volumes, query frequency, acceptable latency, real-time requirements, current indexes, and table relationships. Focus on finding the root cause rather than applying band-aid solutions. Be practical and consider the team's ability to implement and maintain your recommendations.",
                  "model": "reasoning"
                }
              }
            }
          }
        ],
        "summary": {
          "successRate": 100,
          "firstAttemptSuccessRate": 100,
          "afterRetry1SuccessRate": 100,
          "afterRetry2SuccessRate": 100,
          "afterRetry3SuccessRate": 100,
          "averageDurationMs": 15798,
          "averageAttempts": 1,
          "averageAttemptsPerSuccess": 1,
          "averageTokensPerSuccess": 1700.3333333333333,
          "totalTokensUsed": 5101
        }
      },
      "2": {
        "runs": [
          {
            "runNumber": 1,
            "success": true,
            "attempts": [
              {
                "attemptNumber": 1,
                "timestamp": "2025-11-29T17:01:27.289Z",
                "success": true,
                "durationMs": 13567,
                "inputTokens": 1691,
                "outputTokens": 418,
                "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation above, recommend a team member who could help solve their problem.\n\nRespond with a JSON object containing:\n- \"recommendation\": Your explanation of why you're recommending this role\n- \"action\": An object with \"type\": \"create_actor\" and \"actor\" containing:\n  - \"title\": The job title\n  - \"reason\": Why this role addresses the team's problem\n  - \"skills\": Array of 3-7 required skills\n  - \"prompt\": A system prompt for an AI in this role\n  - \"model\": Either \"reasoning\" or \"semantic\"",
                "rawResponse": "{\n  \"recommendation\": \"I think you need to hire a Database Performance Engineer. Your team is facing a critical performance issue with dashboard queries taking 8-12 seconds, and it's clear from the conversation that while your developers understand the basics, they lack the deep database expertise needed to properly diagnose and fix the root cause. They've tried basic solutions like adding indexes and rewriting queries, but they're essentially guessing without the specialized knowledge to analyze query execution plans, optimize schema design, or evaluate architectural changes. A database specialist can quickly identify the bottleneck, implement proper indexing strategies, optimize the query structure, and advise on whether architectural changes like read replicas or database migrations are necessary.\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Database Performance Engineer\",\n      \"reason\": \"The team is struggling with a critical database performance issue affecting enterprise customers. They lack expertise in query optimization, index strategy, schema design, and database architecture evaluation. Their attempts at fixes have been trial-and-error rather than systematic analysis. A database specialist can diagnose the root cause, implement proper optimizations, and prevent similar issues in the future.\",\n      \"skills\": [\n        \"Query optimization and execution plan analysis\",\n        \"Database indexing strategies and implementation\",\n        \"Schema design and normalization\",\n        \"Performance monitoring and bottleneck identification\",\n        \"SQL tuning and rewriting\",\n        \"Database architecture evaluation\",\n        \"Read replica and caching strategies\"\n      ],\n      \"prompt\": \"You are an expert Database Performance Engineer with deep knowledge of relational databases, query optimization, and scalable data architecture. Your expertise includes analyzing EXPLAIN plans, designing efficient indexes, optimizing complex queries with joins and aggregations, and evaluating database architectures for performance at scale. When presented with performance issues, you systematically diagnose root causes using metrics and execution plans rather than guessing. You provide specific, actionable recommendations with clear explanations of trade-offs. You consider both immediate fixes and long-term architectural improvements. You communicate technical concepts clearly to developers who may not be database specialists.\",\n      \"model\": \"reasoning\"\n    }\n  }\n}",
                "parsedResponse": {
                  "recommendation": "I think you need to hire a Database Performance Engineer. Your team is facing a critical performance issue with dashboard queries taking 8-12 seconds, and it's clear from the conversation that while your developers understand the basics, they lack the deep database expertise needed to properly diagnose and fix the root cause. They've tried basic solutions like adding indexes and rewriting queries, but they're essentially guessing without the specialized knowledge to analyze query execution plans, optimize schema design, or evaluate architectural changes. A database specialist can quickly identify the bottleneck, implement proper indexing strategies, optimize the query structure, and advise on whether architectural changes like read replicas or database migrations are necessary.",
                  "action": {
                    "type": "create_actor",
                    "actor": {
                      "title": "Database Performance Engineer",
                      "reason": "The team is struggling with a critical database performance issue affecting enterprise customers. They lack expertise in query optimization, index strategy, schema design, and database architecture evaluation. Their attempts at fixes have been trial-and-error rather than systematic analysis. A database specialist can diagnose the root cause, implement proper optimizations, and prevent similar issues in the future.",
                      "skills": [
                        "Query optimization and execution plan analysis",
                        "Database indexing strategies and implementation",
                        "Schema design and normalization",
                        "Performance monitoring and bottleneck identification",
                        "SQL tuning and rewriting",
                        "Database architecture evaluation",
                        "Read replica and caching strategies"
                      ],
                      "prompt": "You are an expert Database Performance Engineer with deep knowledge of relational databases, query optimization, and scalable data architecture. Your expertise includes analyzing EXPLAIN plans, designing efficient indexes, optimizing complex queries with joins and aggregations, and evaluating database architectures for performance at scale. When presented with performance issues, you systematically diagnose root causes using metrics and execution plans rather than guessing. You provide specific, actionable recommendations with clear explanations of trade-offs. You consider both immediate fixes and long-term architectural improvements. You communicate technical concepts clearly to developers who may not be database specialists.",
                      "model": "reasoning"
                    }
                  }
                },
                "validationErrors": [],
                "errorMessage": null
              }
            ],
            "totalDurationMs": 13567,
            "finalResponse": {
              "recommendation": "I think you need to hire a Database Performance Engineer. Your team is facing a critical performance issue with dashboard queries taking 8-12 seconds, and it's clear from the conversation that while your developers understand the basics, they lack the deep database expertise needed to properly diagnose and fix the root cause. They've tried basic solutions like adding indexes and rewriting queries, but they're essentially guessing without the specialized knowledge to analyze query execution plans, optimize schema design, or evaluate architectural changes. A database specialist can quickly identify the bottleneck, implement proper indexing strategies, optimize the query structure, and advise on whether architectural changes like read replicas or database migrations are necessary.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Performance Engineer",
                  "reason": "The team is struggling with a critical database performance issue affecting enterprise customers. They lack expertise in query optimization, index strategy, schema design, and database architecture evaluation. Their attempts at fixes have been trial-and-error rather than systematic analysis. A database specialist can diagnose the root cause, implement proper optimizations, and prevent similar issues in the future.",
                  "skills": [
                    "Query optimization and execution plan analysis",
                    "Database indexing strategies and implementation",
                    "Schema design and normalization",
                    "Performance monitoring and bottleneck identification",
                    "SQL tuning and rewriting",
                    "Database architecture evaluation",
                    "Read replica and caching strategies"
                  ],
                  "prompt": "You are an expert Database Performance Engineer with deep knowledge of relational databases, query optimization, and scalable data architecture. Your expertise includes analyzing EXPLAIN plans, designing efficient indexes, optimizing complex queries with joins and aggregations, and evaluating database architectures for performance at scale. When presented with performance issues, you systematically diagnose root causes using metrics and execution plans rather than guessing. You provide specific, actionable recommendations with clear explanations of trade-offs. You consider both immediate fixes and long-term architectural improvements. You communicate technical concepts clearly to developers who may not be database specialists.",
                  "model": "reasoning"
                }
              }
            }
          },
          {
            "runNumber": 2,
            "success": true,
            "attempts": [
              {
                "attemptNumber": 1,
                "timestamp": "2025-11-29T17:01:41.015Z",
                "success": true,
                "durationMs": 13726,
                "inputTokens": 1691,
                "outputTokens": 427,
                "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation above, recommend a team member who could help solve their problem.\n\nRespond with a JSON object containing:\n- \"recommendation\": Your explanation of why you're recommending this role\n- \"action\": An object with \"type\": \"create_actor\" and \"actor\" containing:\n  - \"title\": The job title\n  - \"reason\": Why this role addresses the team's problem\n  - \"skills\": Array of 3-7 required skills\n  - \"prompt\": A system prompt for an AI in this role\n  - \"model\": Either \"reasoning\" or \"semantic\"",
                "rawResponse": "{\n  \"recommendation\": \"I think you need to hire a Database Performance Engineer. Your team is facing a critical performance issue with dashboard queries taking 8-12 seconds, and it's clear from the conversation that while your developers understand the basics, they lack the deep database expertise needed to properly diagnose and fix the root cause. They've tried basic approaches like adding indexes and rewriting queries, but they're essentially guessing without the specialized knowledge to analyze query execution plans, optimize schema design, or evaluate architectural alternatives. A database specialist can quickly identify the bottleneck, implement proper indexing strategies, optimize the query structure, and advise on whether architectural changes are needed - all before your enterprise customers churn.\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Database Performance Engineer\",\n      \"reason\": \"The team is struggling with a critical database performance issue that's threatening customer retention. They lack expertise in query optimization, index strategy, schema design, and database architecture evaluation. They need someone who can analyze EXPLAIN plans, understand disk I/O patterns, design proper indexing strategies, and make informed decisions about schema changes or database migrations.\",\n      \"skills\": [\n        \"Query optimization and execution plan analysis\",\n        \"Database indexing strategies and implementation\",\n        \"Schema design and normalization\",\n        \"Performance profiling and bottleneck identification\",\n        \"SQL tuning and rewriting\",\n        \"Database architecture evaluation\",\n        \"Read replica and caching strategies\"\n      ],\n      \"prompt\": \"You are an expert Database Performance Engineer with deep knowledge of relational database optimization, query tuning, and scalable data architecture. You specialize in diagnosing performance bottlenecks, analyzing query execution plans, designing efficient indexing strategies, and optimizing database schemas. When presented with performance issues, you systematically analyze the problem using metrics, execution plans, and profiling data. You provide specific, actionable recommendations backed by technical reasoning. You consider trade-offs between different approaches and explain the implications of schema changes, indexing decisions, and architectural modifications. You're practical and focus on solutions that can be implemented without unnecessary risk or complexity.\",\n      \"model\": \"reasoning\"\n    }\n  }\n}",
                "parsedResponse": {
                  "recommendation": "I think you need to hire a Database Performance Engineer. Your team is facing a critical performance issue with dashboard queries taking 8-12 seconds, and it's clear from the conversation that while your developers understand the basics, they lack the deep database expertise needed to properly diagnose and fix the root cause. They've tried basic approaches like adding indexes and rewriting queries, but they're essentially guessing without the specialized knowledge to analyze query execution plans, optimize schema design, or evaluate architectural alternatives. A database specialist can quickly identify the bottleneck, implement proper indexing strategies, optimize the query structure, and advise on whether architectural changes are needed - all before your enterprise customers churn.",
                  "action": {
                    "type": "create_actor",
                    "actor": {
                      "title": "Database Performance Engineer",
                      "reason": "The team is struggling with a critical database performance issue that's threatening customer retention. They lack expertise in query optimization, index strategy, schema design, and database architecture evaluation. They need someone who can analyze EXPLAIN plans, understand disk I/O patterns, design proper indexing strategies, and make informed decisions about schema changes or database migrations.",
                      "skills": [
                        "Query optimization and execution plan analysis",
                        "Database indexing strategies and implementation",
                        "Schema design and normalization",
                        "Performance profiling and bottleneck identification",
                        "SQL tuning and rewriting",
                        "Database architecture evaluation",
                        "Read replica and caching strategies"
                      ],
                      "prompt": "You are an expert Database Performance Engineer with deep knowledge of relational database optimization, query tuning, and scalable data architecture. You specialize in diagnosing performance bottlenecks, analyzing query execution plans, designing efficient indexing strategies, and optimizing database schemas. When presented with performance issues, you systematically analyze the problem using metrics, execution plans, and profiling data. You provide specific, actionable recommendations backed by technical reasoning. You consider trade-offs between different approaches and explain the implications of schema changes, indexing decisions, and architectural modifications. You're practical and focus on solutions that can be implemented without unnecessary risk or complexity.",
                      "model": "reasoning"
                    }
                  }
                },
                "validationErrors": [],
                "errorMessage": null
              }
            ],
            "totalDurationMs": 13726,
            "finalResponse": {
              "recommendation": "I think you need to hire a Database Performance Engineer. Your team is facing a critical performance issue with dashboard queries taking 8-12 seconds, and it's clear from the conversation that while your developers understand the basics, they lack the deep database expertise needed to properly diagnose and fix the root cause. They've tried basic approaches like adding indexes and rewriting queries, but they're essentially guessing without the specialized knowledge to analyze query execution plans, optimize schema design, or evaluate architectural alternatives. A database specialist can quickly identify the bottleneck, implement proper indexing strategies, optimize the query structure, and advise on whether architectural changes are needed - all before your enterprise customers churn.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Performance Engineer",
                  "reason": "The team is struggling with a critical database performance issue that's threatening customer retention. They lack expertise in query optimization, index strategy, schema design, and database architecture evaluation. They need someone who can analyze EXPLAIN plans, understand disk I/O patterns, design proper indexing strategies, and make informed decisions about schema changes or database migrations.",
                  "skills": [
                    "Query optimization and execution plan analysis",
                    "Database indexing strategies and implementation",
                    "Schema design and normalization",
                    "Performance profiling and bottleneck identification",
                    "SQL tuning and rewriting",
                    "Database architecture evaluation",
                    "Read replica and caching strategies"
                  ],
                  "prompt": "You are an expert Database Performance Engineer with deep knowledge of relational database optimization, query tuning, and scalable data architecture. You specialize in diagnosing performance bottlenecks, analyzing query execution plans, designing efficient indexing strategies, and optimizing database schemas. When presented with performance issues, you systematically analyze the problem using metrics, execution plans, and profiling data. You provide specific, actionable recommendations backed by technical reasoning. You consider trade-offs between different approaches and explain the implications of schema changes, indexing decisions, and architectural modifications. You're practical and focus on solutions that can be implemented without unnecessary risk or complexity.",
                  "model": "reasoning"
                }
              }
            }
          },
          {
            "runNumber": 3,
            "success": true,
            "attempts": [
              {
                "attemptNumber": 1,
                "timestamp": "2025-11-29T17:01:55.446Z",
                "success": true,
                "durationMs": 14431,
                "inputTokens": 1691,
                "outputTokens": 418,
                "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation above, recommend a team member who could help solve their problem.\n\nRespond with a JSON object containing:\n- \"recommendation\": Your explanation of why you're recommending this role\n- \"action\": An object with \"type\": \"create_actor\" and \"actor\" containing:\n  - \"title\": The job title\n  - \"reason\": Why this role addresses the team's problem\n  - \"skills\": Array of 3-7 required skills\n  - \"prompt\": A system prompt for an AI in this role\n  - \"model\": Either \"reasoning\" or \"semantic\"",
                "rawResponse": "{\n  \"recommendation\": \"I think you need to hire a Database Performance Engineer. Your team is facing a critical performance issue with dashboard queries taking 8-12 seconds, and it's clear from the conversation that while your developers understand the basics, they lack the deep database expertise needed to properly diagnose and fix the root cause. They've tried basic approaches like adding indexes and rewriting queries, but they're essentially guessing without the specialized knowledge to analyze query execution plans, optimize schema design, or evaluate architectural alternatives. A database specialist can quickly identify the bottleneck, implement proper indexing strategies, optimize the query structure, and advise on whether architectural changes are needed - all before your enterprise customers churn.\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Database Performance Engineer\",\n      \"reason\": \"The team is struggling with a critical database performance issue that's threatening customer retention. They lack expertise in query optimization, index strategy, schema design, and database architecture evaluation. Their attempts at fixes have been trial-and-error rather than systematic analysis. A database specialist can diagnose the root cause, implement proper optimizations, and provide architectural guidance.\",\n      \"skills\": [\n        \"Query optimization and execution plan analysis\",\n        \"Database indexing strategies and implementation\",\n        \"Schema design and normalization\",\n        \"Performance monitoring and bottleneck identification\",\n        \"SQL tuning and rewriting\",\n        \"Database architecture evaluation\",\n        \"Read replica and caching strategies\"\n      ],\n      \"prompt\": \"You are an expert Database Performance Engineer with deep knowledge of relational databases, query optimization, and scalable data architecture. Your expertise includes analyzing EXPLAIN plans, designing efficient indexes, optimizing complex queries with joins and aggregations, and evaluating database architectures for performance at scale. When presented with performance issues, you systematically diagnose root causes using metrics and execution plans rather than guessing. You provide specific, actionable recommendations with clear explanations of trade-offs. You consider both immediate fixes and long-term architectural improvements. You communicate technical concepts clearly to developers who may not be database specialists.\",\n      \"model\": \"reasoning\"\n    }\n  }\n}",
                "parsedResponse": {
                  "recommendation": "I think you need to hire a Database Performance Engineer. Your team is facing a critical performance issue with dashboard queries taking 8-12 seconds, and it's clear from the conversation that while your developers understand the basics, they lack the deep database expertise needed to properly diagnose and fix the root cause. They've tried basic approaches like adding indexes and rewriting queries, but they're essentially guessing without the specialized knowledge to analyze query execution plans, optimize schema design, or evaluate architectural alternatives. A database specialist can quickly identify the bottleneck, implement proper indexing strategies, optimize the query structure, and advise on whether architectural changes are needed - all before your enterprise customers churn.",
                  "action": {
                    "type": "create_actor",
                    "actor": {
                      "title": "Database Performance Engineer",
                      "reason": "The team is struggling with a critical database performance issue that's threatening customer retention. They lack expertise in query optimization, index strategy, schema design, and database architecture evaluation. Their attempts at fixes have been trial-and-error rather than systematic analysis. A database specialist can diagnose the root cause, implement proper optimizations, and provide architectural guidance.",
                      "skills": [
                        "Query optimization and execution plan analysis",
                        "Database indexing strategies and implementation",
                        "Schema design and normalization",
                        "Performance monitoring and bottleneck identification",
                        "SQL tuning and rewriting",
                        "Database architecture evaluation",
                        "Read replica and caching strategies"
                      ],
                      "prompt": "You are an expert Database Performance Engineer with deep knowledge of relational databases, query optimization, and scalable data architecture. Your expertise includes analyzing EXPLAIN plans, designing efficient indexes, optimizing complex queries with joins and aggregations, and evaluating database architectures for performance at scale. When presented with performance issues, you systematically diagnose root causes using metrics and execution plans rather than guessing. You provide specific, actionable recommendations with clear explanations of trade-offs. You consider both immediate fixes and long-term architectural improvements. You communicate technical concepts clearly to developers who may not be database specialists.",
                      "model": "reasoning"
                    }
                  }
                },
                "validationErrors": [],
                "errorMessage": null
              }
            ],
            "totalDurationMs": 14431,
            "finalResponse": {
              "recommendation": "I think you need to hire a Database Performance Engineer. Your team is facing a critical performance issue with dashboard queries taking 8-12 seconds, and it's clear from the conversation that while your developers understand the basics, they lack the deep database expertise needed to properly diagnose and fix the root cause. They've tried basic approaches like adding indexes and rewriting queries, but they're essentially guessing without the specialized knowledge to analyze query execution plans, optimize schema design, or evaluate architectural alternatives. A database specialist can quickly identify the bottleneck, implement proper indexing strategies, optimize the query structure, and advise on whether architectural changes are needed - all before your enterprise customers churn.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Performance Engineer",
                  "reason": "The team is struggling with a critical database performance issue that's threatening customer retention. They lack expertise in query optimization, index strategy, schema design, and database architecture evaluation. Their attempts at fixes have been trial-and-error rather than systematic analysis. A database specialist can diagnose the root cause, implement proper optimizations, and provide architectural guidance.",
                  "skills": [
                    "Query optimization and execution plan analysis",
                    "Database indexing strategies and implementation",
                    "Schema design and normalization",
                    "Performance monitoring and bottleneck identification",
                    "SQL tuning and rewriting",
                    "Database architecture evaluation",
                    "Read replica and caching strategies"
                  ],
                  "prompt": "You are an expert Database Performance Engineer with deep knowledge of relational databases, query optimization, and scalable data architecture. Your expertise includes analyzing EXPLAIN plans, designing efficient indexes, optimizing complex queries with joins and aggregations, and evaluating database architectures for performance at scale. When presented with performance issues, you systematically diagnose root causes using metrics and execution plans rather than guessing. You provide specific, actionable recommendations with clear explanations of trade-offs. You consider both immediate fixes and long-term architectural improvements. You communicate technical concepts clearly to developers who may not be database specialists.",
                  "model": "reasoning"
                }
              }
            }
          }
        ],
        "summary": {
          "successRate": 100,
          "firstAttemptSuccessRate": 100,
          "afterRetry1SuccessRate": 100,
          "afterRetry2SuccessRate": 100,
          "afterRetry3SuccessRate": 100,
          "averageDurationMs": 13908,
          "averageAttempts": 1,
          "averageAttemptsPerSuccess": 1,
          "averageTokensPerSuccess": 2112,
          "totalTokensUsed": 6336
        }
      },
      "3": {
        "runs": [
          {
            "runNumber": 1,
            "success": true,
            "attempts": [],
            "steps": [
              {
                "stepNumber": 1,
                "stepName": "Recommendation",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:02:04.181Z",
                    "success": true,
                    "durationMs": 8734,
                    "inputTokens": 942,
                    "outputTokens": 265,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation, what type of team member should this team add?\n\nRespond with JSON like this example:\n{\"recommendation\": \"I recommend hiring a [role] because [reason]...\", \"action\": \"create_actor\"}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- The \"recommendation\" should explain your hiring recommendation (at least 20 characters)\n- Set \"action\" to \"create_actor\" if recommending someone, or null if not",
                    "rawResponse": "```json\n{\n  \"recommendation\": \"I recommend hiring a Database Performance Engineer because this team is facing a critical performance issue that threatens customer retention, but lacks the specialized expertise to diagnose and resolve complex database optimization problems. The team has tried basic solutions (indexes, query rewrites, caching) but is 'guessing' without deep database knowledge. They need someone who can: 1) Analyze query execution plans and identify bottlenecks, 2) Design optimal indexing strategies without breaking existing queries, 3) Optimize schema design for their specific access patterns, 4) Evaluate whether architectural changes (read replicas, different database systems) are warranted, and 5) Implement solutions confidently without risk of making performance worse. This role requires 'reasoning' capabilities to systematically analyze query plans, understand database internals, and make data-driven optimization decisions. The system prompt should configure the assistant to: Think methodically through performance diagnostics using EXPLAIN plans, understand trade-offs between different optimization approaches, provide specific SQL optimization recommendations, evaluate indexing strategies based on query patterns, and assess when architectural changes are needed versus when query-level optimizations suffice.\",\n  \"action\": \"create_actor\"\n}\n```",
                    "parsedResponse": {
                      "recommendation": "I recommend hiring a Database Performance Engineer because this team is facing a critical performance issue that threatens customer retention, but lacks the specialized expertise to diagnose and resolve complex database optimization problems. The team has tried basic solutions (indexes, query rewrites, caching) but is 'guessing' without deep database knowledge. They need someone who can: 1) Analyze query execution plans and identify bottlenecks, 2) Design optimal indexing strategies without breaking existing queries, 3) Optimize schema design for their specific access patterns, 4) Evaluate whether architectural changes (read replicas, different database systems) are warranted, and 5) Implement solutions confidently without risk of making performance worse. This role requires 'reasoning' capabilities to systematically analyze query plans, understand database internals, and make data-driven optimization decisions. The system prompt should configure the assistant to: Think methodically through performance diagnostics using EXPLAIN plans, understand trade-offs between different optimization approaches, provide specific SQL optimization recommendations, evaluate indexing strategies based on query patterns, and assess when architectural changes are needed versus when query-level optimizations suffice.",
                      "action": "create_actor"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 2,
                "stepName": "Details",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:02:09.392Z",
                    "success": true,
                    "durationMs": 5211,
                    "inputTokens": 1206,
                    "outputTokens": 174,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Database Performance Engineer because this team is facing a critical performance issue that threatens customer retention, but lacks the specialized expertise to diagnose and resolve complex database optimization problems. The team has tried basic solutions (indexes, query rewrites, caching) but is 'guessing' without deep database knowledge. They need someone who can: 1) Analyze query execution plans and identify bottlenecks, 2) Design optimal indexing strategies without breaking existing queries, 3) Optimize schema design for their specific access patterns, 4) Evaluate whether architectural changes (read replicas, different database systems) are warranted, and 5) Implement solutions confidently without risk of making performance worse. This role requires 'reasoning' capabilities to systematically analyze query plans, understand database internals, and make data-driven optimization decisions. The system prompt should configure the assistant to: Think methodically through performance diagnostics using EXPLAIN plans, understand trade-offs between different optimization approaches, provide specific SQL optimization recommendations, evaluate indexing strategies based on query patterns, and assess when architectural changes are needed versus when query-level optimizations suffice.\",\"action\":\"create_actor\"}\n\n[user] For the role you recommended, provide their details.\n\nRespond with JSON like this example:\n{\"title\": \"Database Administrator\", \"reason\": \"The team needs database expertise to optimize their slow queries and design scalable schemas\", \"skills\": [\"PostgreSQL\", \"Query Optimization\", \"Database Design\"]}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- Provide 3-7 specific technical skills\n- The \"reason\" should explain how this role addresses the team's problem (at least 20 characters)",
                    "rawResponse": "```json\n{\n  \"title\": \"Database Performance Engineer\",\n  \"reason\": \"The team is facing critical performance issues with dashboard queries taking 8-12 seconds, threatening customer churn. They lack expertise to diagnose query execution bottlenecks, optimize indexes without breaking existing queries, and evaluate architectural solutions. They need someone who can systematically analyze EXPLAIN plans, design optimal indexing strategies, and make confident schema optimizations.\",\n  \"skills\": [\n    \"SQL Query Optimization\",\n    \"Database Indexing Strategies\",\n    \"Query Execution Plan Analysis\",\n    \"Database Schema Design\",\n    \"Performance Profiling and Diagnostics\",\n    \"PostgreSQL/MySQL Internals\",\n    \"Database Architecture Evaluation\"\n  ]\n}\n```",
                    "parsedResponse": {
                      "title": "Database Performance Engineer",
                      "reason": "The team is facing critical performance issues with dashboard queries taking 8-12 seconds, threatening customer churn. They lack expertise to diagnose query execution bottlenecks, optimize indexes without breaking existing queries, and evaluate architectural solutions. They need someone who can systematically analyze EXPLAIN plans, design optimal indexing strategies, and make confident schema optimizations.",
                      "skills": [
                        "SQL Query Optimization",
                        "Database Indexing Strategies",
                        "Query Execution Plan Analysis",
                        "Database Schema Design",
                        "Performance Profiling and Diagnostics",
                        "PostgreSQL/MySQL Internals",
                        "Database Architecture Evaluation"
                      ]
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 3,
                "stepName": "AI Config",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:02:18.412Z",
                    "success": true,
                    "durationMs": 9020,
                    "inputTokens": 1332,
                    "outputTokens": 368,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Database Performance Engineer because this team is facing a critical performance issue that threatens customer retention, but lacks the specialized expertise to diagnose and resolve complex database optimization problems. The team has tried basic solutions (indexes, query rewrites, caching) but is 'guessing' without deep database knowledge. They need someone who can: 1) Analyze query execution plans and identify bottlenecks, 2) Design optimal indexing strategies without breaking existing queries, 3) Optimize schema design for their specific access patterns, 4) Evaluate whether architectural changes (read replicas, different database systems) are warranted, and 5) Implement solutions confidently without risk of making performance worse. This role requires 'reasoning' capabilities to systematically analyze query plans, understand database internals, and make data-driven optimization decisions. The system prompt should configure the assistant to: Think methodically through performance diagnostics using EXPLAIN plans, understand trade-offs between different optimization approaches, provide specific SQL optimization recommendations, evaluate indexing strategies based on query patterns, and assess when architectural changes are needed versus when query-level optimizations suffice.\",\"action\":\"create_actor\"}\n\n[assistant] {\"title\":\"Database Performance Engineer\",\"reason\":\"The team is facing critical performance issues with dashboard queries taking 8-12 seconds, threatening customer churn. They lack expertise to diagnose query execution bottlenecks, optimize indexes without breaking existing queries, and evaluate architectural solutions. They need someone who can systematically analyze EXPLAIN plans, design optimal indexing strategies, and make confident schema optimizations.\",\"skills\":[\"SQL Query Optimization\",\"Database Indexing Strategies\",\"Query Execution Plan Analysis\",\"Database Schema Design\",\"Performance Profiling and Diagnostics\",\"PostgreSQL/MySQL Internals\",\"Database Architecture Evaluation\"]}\n\n[user] For this role, provide the AI system prompt and model type.\n\nRespond with JSON like this example:\n{\"prompt\": \"You are an expert database administrator. You help teams optimize queries, design schemas, and ensure data integrity...\", \"model\": \"reasoning\"}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- The \"prompt\" should be a detailed system prompt (at least 30 characters)\n- \"model\" should be \"reasoning\" for analytical tasks or \"semantic\" for creative tasks",
                    "rawResponse": "{\"prompt\": \"You are an expert Database Performance Engineer with deep expertise in SQL optimization, query execution analysis, and database architecture. Your role is to diagnose and resolve database performance issues systematically.\\n\\nWhen analyzing performance problems:\\n1. Always start by examining EXPLAIN/EXPLAIN ANALYZE output to understand query execution plans\\n2. Identify bottlenecks: sequential scans, missing indexes, inefficient joins, or suboptimal query structure\\n3. Consider the trade-offs of each optimization approach (indexes improve reads but slow writes, denormalization vs normalization, etc.)\\n4. Evaluate whether the issue is query-level, schema-level, or architectural\\n\\nYour core competencies:\\n- Analyzing query execution plans and identifying performance bottlenecks\\n- Designing optimal indexing strategies (B-tree, hash, partial, composite indexes)\\n- Rewriting queries for better performance while maintaining correctness\\n- Schema optimization and denormalization strategies\\n- Evaluating database architecture decisions (read replicas, partitioning, sharding)\\n- Understanding database internals (query planner, statistics, vacuum, locks)\\n- Assessing when to use caching layers, materialized views, or different database systems\\n\\nAlways provide:\\n- Specific, actionable recommendations with SQL examples\\n- Clear explanations of why an optimization will work\\n- Warnings about potential side effects or risks\\n- Metrics to measure before and after optimization\\n- Step-by-step implementation guidance\\n\\nBe methodical, data-driven, and focused on sustainable solutions rather than quick fixes.\", \"model\": \"reasoning\"}",
                    "parsedResponse": {
                      "prompt": "You are an expert Database Performance Engineer with deep expertise in SQL optimization, query execution analysis, and database architecture. Your role is to diagnose and resolve database performance issues systematically.\n\nWhen analyzing performance problems:\n1. Always start by examining EXPLAIN/EXPLAIN ANALYZE output to understand query execution plans\n2. Identify bottlenecks: sequential scans, missing indexes, inefficient joins, or suboptimal query structure\n3. Consider the trade-offs of each optimization approach (indexes improve reads but slow writes, denormalization vs normalization, etc.)\n4. Evaluate whether the issue is query-level, schema-level, or architectural\n\nYour core competencies:\n- Analyzing query execution plans and identifying performance bottlenecks\n- Designing optimal indexing strategies (B-tree, hash, partial, composite indexes)\n- Rewriting queries for better performance while maintaining correctness\n- Schema optimization and denormalization strategies\n- Evaluating database architecture decisions (read replicas, partitioning, sharding)\n- Understanding database internals (query planner, statistics, vacuum, locks)\n- Assessing when to use caching layers, materialized views, or different database systems\n\nAlways provide:\n- Specific, actionable recommendations with SQL examples\n- Clear explanations of why an optimization will work\n- Warnings about potential side effects or risks\n- Metrics to measure before and after optimization\n- Step-by-step implementation guidance\n\nBe methodical, data-driven, and focused on sustainable solutions rather than quick fixes.",
                      "model": "reasoning"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              }
            ],
            "totalDurationMs": 22965,
            "finalResponse": {
              "recommendation": "I recommend hiring a Database Performance Engineer because this team is facing a critical performance issue that threatens customer retention, but lacks the specialized expertise to diagnose and resolve complex database optimization problems. The team has tried basic solutions (indexes, query rewrites, caching) but is 'guessing' without deep database knowledge. They need someone who can: 1) Analyze query execution plans and identify bottlenecks, 2) Design optimal indexing strategies without breaking existing queries, 3) Optimize schema design for their specific access patterns, 4) Evaluate whether architectural changes (read replicas, different database systems) are warranted, and 5) Implement solutions confidently without risk of making performance worse. This role requires 'reasoning' capabilities to systematically analyze query plans, understand database internals, and make data-driven optimization decisions. The system prompt should configure the assistant to: Think methodically through performance diagnostics using EXPLAIN plans, understand trade-offs between different optimization approaches, provide specific SQL optimization recommendations, evaluate indexing strategies based on query patterns, and assess when architectural changes are needed versus when query-level optimizations suffice.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Performance Engineer",
                  "reason": "The team is facing critical performance issues with dashboard queries taking 8-12 seconds, threatening customer churn. They lack expertise to diagnose query execution bottlenecks, optimize indexes without breaking existing queries, and evaluate architectural solutions. They need someone who can systematically analyze EXPLAIN plans, design optimal indexing strategies, and make confident schema optimizations.",
                  "skills": [
                    "SQL Query Optimization",
                    "Database Indexing Strategies",
                    "Query Execution Plan Analysis",
                    "Database Schema Design",
                    "Performance Profiling and Diagnostics",
                    "PostgreSQL/MySQL Internals",
                    "Database Architecture Evaluation"
                  ],
                  "prompt": "You are an expert Database Performance Engineer with deep expertise in SQL optimization, query execution analysis, and database architecture. Your role is to diagnose and resolve database performance issues systematically.\n\nWhen analyzing performance problems:\n1. Always start by examining EXPLAIN/EXPLAIN ANALYZE output to understand query execution plans\n2. Identify bottlenecks: sequential scans, missing indexes, inefficient joins, or suboptimal query structure\n3. Consider the trade-offs of each optimization approach (indexes improve reads but slow writes, denormalization vs normalization, etc.)\n4. Evaluate whether the issue is query-level, schema-level, or architectural\n\nYour core competencies:\n- Analyzing query execution plans and identifying performance bottlenecks\n- Designing optimal indexing strategies (B-tree, hash, partial, composite indexes)\n- Rewriting queries for better performance while maintaining correctness\n- Schema optimization and denormalization strategies\n- Evaluating database architecture decisions (read replicas, partitioning, sharding)\n- Understanding database internals (query planner, statistics, vacuum, locks)\n- Assessing when to use caching layers, materialized views, or different database systems\n\nAlways provide:\n- Specific, actionable recommendations with SQL examples\n- Clear explanations of why an optimization will work\n- Warnings about potential side effects or risks\n- Metrics to measure before and after optimization\n- Step-by-step implementation guidance\n\nBe methodical, data-driven, and focused on sustainable solutions rather than quick fixes.",
                  "model": "reasoning"
                }
              }
            }
          },
          {
            "runNumber": 2,
            "success": true,
            "attempts": [],
            "steps": [
              {
                "stepNumber": 1,
                "stepName": "Recommendation",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:02:25.890Z",
                    "success": true,
                    "durationMs": 7477,
                    "inputTokens": 942,
                    "outputTokens": 240,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation, what type of team member should this team add?\n\nRespond with JSON like this example:\n{\"recommendation\": \"I recommend hiring a [role] because [reason]...\", \"action\": \"create_actor\"}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- The \"recommendation\" should explain your hiring recommendation (at least 20 characters)\n- Set \"action\" to \"create_actor\" if recommending someone, or null if not",
                    "rawResponse": "```json\n{\n  \"recommendation\": \"I recommend hiring a Database Performance Engineer because this team is facing a critical performance issue that threatens customer retention, but lacks the specialized expertise to diagnose and resolve complex database optimization problems. The team has tried basic solutions (indexes, query rewrites, caching) but is 'guessing' without deep database knowledge. They need someone who can: 1) Analyze query execution plans and identify bottlenecks, 2) Design optimal indexing strategies without breaking existing queries, 3) Optimize schema design for their specific use case, 4) Evaluate whether architectural changes (read replicas, different databases) are warranted, and 5) Implement solutions confidently without risk of making things worse. This role requires 'reasoning' capabilities for analytical problem-solving, query plan analysis, and systematic performance optimization. The specialist should have expertise in SQL optimization, database internals, indexing strategies, query planning, schema design, and experience with both relational databases and alternatives like TimescaleDB for time-series data.\",\n  \"action\": \"create_actor\"\n}\n```",
                    "parsedResponse": {
                      "recommendation": "I recommend hiring a Database Performance Engineer because this team is facing a critical performance issue that threatens customer retention, but lacks the specialized expertise to diagnose and resolve complex database optimization problems. The team has tried basic solutions (indexes, query rewrites, caching) but is 'guessing' without deep database knowledge. They need someone who can: 1) Analyze query execution plans and identify bottlenecks, 2) Design optimal indexing strategies without breaking existing queries, 3) Optimize schema design for their specific use case, 4) Evaluate whether architectural changes (read replicas, different databases) are warranted, and 5) Implement solutions confidently without risk of making things worse. This role requires 'reasoning' capabilities for analytical problem-solving, query plan analysis, and systematic performance optimization. The specialist should have expertise in SQL optimization, database internals, indexing strategies, query planning, schema design, and experience with both relational databases and alternatives like TimescaleDB for time-series data.",
                      "action": "create_actor"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 2,
                "stepName": "Details",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:02:31.420Z",
                    "success": true,
                    "durationMs": 5530,
                    "inputTokens": 1181,
                    "outputTokens": 158,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Database Performance Engineer because this team is facing a critical performance issue that threatens customer retention, but lacks the specialized expertise to diagnose and resolve complex database optimization problems. The team has tried basic solutions (indexes, query rewrites, caching) but is 'guessing' without deep database knowledge. They need someone who can: 1) Analyze query execution plans and identify bottlenecks, 2) Design optimal indexing strategies without breaking existing queries, 3) Optimize schema design for their specific use case, 4) Evaluate whether architectural changes (read replicas, different databases) are warranted, and 5) Implement solutions confidently without risk of making things worse. This role requires 'reasoning' capabilities for analytical problem-solving, query plan analysis, and systematic performance optimization. The specialist should have expertise in SQL optimization, database internals, indexing strategies, query planning, schema design, and experience with both relational databases and alternatives like TimescaleDB for time-series data.\",\"action\":\"create_actor\"}\n\n[user] For the role you recommended, provide their details.\n\nRespond with JSON like this example:\n{\"title\": \"Database Administrator\", \"reason\": \"The team needs database expertise to optimize their slow queries and design scalable schemas\", \"skills\": [\"PostgreSQL\", \"Query Optimization\", \"Database Design\"]}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- Provide 3-7 specific technical skills\n- The \"reason\" should explain how this role addresses the team's problem (at least 20 characters)",
                    "rawResponse": "```json\n{\n  \"title\": \"Database Performance Engineer\",\n  \"reason\": \"The team is facing critical performance issues with dashboard queries taking 8-12 seconds, threatening customer churn. They lack expertise to properly diagnose query execution bottlenecks, optimize indexes without breaking existing queries, and evaluate architectural solutions. They need a specialist who can analyze EXPLAIN plans, design optimal schemas, and implement performance solutions confidently.\",\n  \"skills\": [\"SQL Query Optimization\", \"Database Indexing Strategies\", \"Query Execution Plan Analysis\", \"Schema Design and Normalization\", \"PostgreSQL/MySQL Performance Tuning\", \"Caching Strategies (Redis)\", \"Time-Series Database Architecture\"]\n}\n```",
                    "parsedResponse": {
                      "title": "Database Performance Engineer",
                      "reason": "The team is facing critical performance issues with dashboard queries taking 8-12 seconds, threatening customer churn. They lack expertise to properly diagnose query execution bottlenecks, optimize indexes without breaking existing queries, and evaluate architectural solutions. They need a specialist who can analyze EXPLAIN plans, design optimal schemas, and implement performance solutions confidently.",
                      "skills": [
                        "SQL Query Optimization",
                        "Database Indexing Strategies",
                        "Query Execution Plan Analysis",
                        "Schema Design and Normalization",
                        "PostgreSQL/MySQL Performance Tuning",
                        "Caching Strategies (Redis)",
                        "Time-Series Database Architecture"
                      ]
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 3,
                "stepName": "AI Config",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:02:40.930Z",
                    "success": true,
                    "durationMs": 9510,
                    "inputTokens": 1310,
                    "outputTokens": 369,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Database Performance Engineer because this team is facing a critical performance issue that threatens customer retention, but lacks the specialized expertise to diagnose and resolve complex database optimization problems. The team has tried basic solutions (indexes, query rewrites, caching) but is 'guessing' without deep database knowledge. They need someone who can: 1) Analyze query execution plans and identify bottlenecks, 2) Design optimal indexing strategies without breaking existing queries, 3) Optimize schema design for their specific use case, 4) Evaluate whether architectural changes (read replicas, different databases) are warranted, and 5) Implement solutions confidently without risk of making things worse. This role requires 'reasoning' capabilities for analytical problem-solving, query plan analysis, and systematic performance optimization. The specialist should have expertise in SQL optimization, database internals, indexing strategies, query planning, schema design, and experience with both relational databases and alternatives like TimescaleDB for time-series data.\",\"action\":\"create_actor\"}\n\n[assistant] {\"title\":\"Database Performance Engineer\",\"reason\":\"The team is facing critical performance issues with dashboard queries taking 8-12 seconds, threatening customer churn. They lack expertise to properly diagnose query execution bottlenecks, optimize indexes without breaking existing queries, and evaluate architectural solutions. They need a specialist who can analyze EXPLAIN plans, design optimal schemas, and implement performance solutions confidently.\",\"skills\":[\"SQL Query Optimization\",\"Database Indexing Strategies\",\"Query Execution Plan Analysis\",\"Schema Design and Normalization\",\"PostgreSQL/MySQL Performance Tuning\",\"Caching Strategies (Redis)\",\"Time-Series Database Architecture\"]}\n\n[user] For this role, provide the AI system prompt and model type.\n\nRespond with JSON like this example:\n{\"prompt\": \"You are an expert database administrator. You help teams optimize queries, design schemas, and ensure data integrity...\", \"model\": \"reasoning\"}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- The \"prompt\" should be a detailed system prompt (at least 30 characters)\n- \"model\" should be \"reasoning\" for analytical tasks or \"semantic\" for creative tasks",
                    "rawResponse": "```json\n{\n  \"prompt\": \"You are an expert Database Performance Engineer with deep expertise in SQL optimization, query execution analysis, and database architecture. Your role is to diagnose and resolve database performance issues through systematic analysis and evidence-based solutions.\\n\\nYour core responsibilities:\\n1. Analyze query execution plans (EXPLAIN/EXPLAIN ANALYZE) to identify bottlenecks like sequential scans, inefficient joins, and missing indexes\\n2. Design optimal indexing strategies that improve query performance without degrading write performance or breaking existing queries\\n3. Optimize complex queries involving multiple joins, aggregations, and subqueries\\n4. Evaluate schema design and recommend normalization or denormalization based on access patterns\\n5. Assess database architecture decisions including read replicas, partitioning, sharding, and alternative databases\\n6. Provide specific, actionable recommendations with clear explanations of trade-offs\\n7. Consider both immediate fixes and long-term architectural improvements\\n\\nWhen analyzing performance issues:\\n- Always ask for query execution plans and database metrics\\n- Identify the root cause before proposing solutions\\n- Consider impact on existing queries and write operations\\n- Evaluate whether the issue is query-level, schema-level, or architecture-level\\n- Provide step-by-step implementation guidance with rollback plans\\n\\nYou have expertise in PostgreSQL, MySQL, SQL Server, and time-series databases like TimescaleDB. You understand caching strategies, connection pooling, and when to apply different optimization techniques. You communicate technical concepts clearly to engineers who may not be database specialists.\",\n  \"model\": \"reasoning\"\n}\n```",
                    "parsedResponse": {
                      "prompt": "You are an expert Database Performance Engineer with deep expertise in SQL optimization, query execution analysis, and database architecture. Your role is to diagnose and resolve database performance issues through systematic analysis and evidence-based solutions.\n\nYour core responsibilities:\n1. Analyze query execution plans (EXPLAIN/EXPLAIN ANALYZE) to identify bottlenecks like sequential scans, inefficient joins, and missing indexes\n2. Design optimal indexing strategies that improve query performance without degrading write performance or breaking existing queries\n3. Optimize complex queries involving multiple joins, aggregations, and subqueries\n4. Evaluate schema design and recommend normalization or denormalization based on access patterns\n5. Assess database architecture decisions including read replicas, partitioning, sharding, and alternative databases\n6. Provide specific, actionable recommendations with clear explanations of trade-offs\n7. Consider both immediate fixes and long-term architectural improvements\n\nWhen analyzing performance issues:\n- Always ask for query execution plans and database metrics\n- Identify the root cause before proposing solutions\n- Consider impact on existing queries and write operations\n- Evaluate whether the issue is query-level, schema-level, or architecture-level\n- Provide step-by-step implementation guidance with rollback plans\n\nYou have expertise in PostgreSQL, MySQL, SQL Server, and time-series databases like TimescaleDB. You understand caching strategies, connection pooling, and when to apply different optimization techniques. You communicate technical concepts clearly to engineers who may not be database specialists.",
                      "model": "reasoning"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              }
            ],
            "totalDurationMs": 22517,
            "finalResponse": {
              "recommendation": "I recommend hiring a Database Performance Engineer because this team is facing a critical performance issue that threatens customer retention, but lacks the specialized expertise to diagnose and resolve complex database optimization problems. The team has tried basic solutions (indexes, query rewrites, caching) but is 'guessing' without deep database knowledge. They need someone who can: 1) Analyze query execution plans and identify bottlenecks, 2) Design optimal indexing strategies without breaking existing queries, 3) Optimize schema design for their specific use case, 4) Evaluate whether architectural changes (read replicas, different databases) are warranted, and 5) Implement solutions confidently without risk of making things worse. This role requires 'reasoning' capabilities for analytical problem-solving, query plan analysis, and systematic performance optimization. The specialist should have expertise in SQL optimization, database internals, indexing strategies, query planning, schema design, and experience with both relational databases and alternatives like TimescaleDB for time-series data.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Performance Engineer",
                  "reason": "The team is facing critical performance issues with dashboard queries taking 8-12 seconds, threatening customer churn. They lack expertise to properly diagnose query execution bottlenecks, optimize indexes without breaking existing queries, and evaluate architectural solutions. They need a specialist who can analyze EXPLAIN plans, design optimal schemas, and implement performance solutions confidently.",
                  "skills": [
                    "SQL Query Optimization",
                    "Database Indexing Strategies",
                    "Query Execution Plan Analysis",
                    "Schema Design and Normalization",
                    "PostgreSQL/MySQL Performance Tuning",
                    "Caching Strategies (Redis)",
                    "Time-Series Database Architecture"
                  ],
                  "prompt": "You are an expert Database Performance Engineer with deep expertise in SQL optimization, query execution analysis, and database architecture. Your role is to diagnose and resolve database performance issues through systematic analysis and evidence-based solutions.\n\nYour core responsibilities:\n1. Analyze query execution plans (EXPLAIN/EXPLAIN ANALYZE) to identify bottlenecks like sequential scans, inefficient joins, and missing indexes\n2. Design optimal indexing strategies that improve query performance without degrading write performance or breaking existing queries\n3. Optimize complex queries involving multiple joins, aggregations, and subqueries\n4. Evaluate schema design and recommend normalization or denormalization based on access patterns\n5. Assess database architecture decisions including read replicas, partitioning, sharding, and alternative databases\n6. Provide specific, actionable recommendations with clear explanations of trade-offs\n7. Consider both immediate fixes and long-term architectural improvements\n\nWhen analyzing performance issues:\n- Always ask for query execution plans and database metrics\n- Identify the root cause before proposing solutions\n- Consider impact on existing queries and write operations\n- Evaluate whether the issue is query-level, schema-level, or architecture-level\n- Provide step-by-step implementation guidance with rollback plans\n\nYou have expertise in PostgreSQL, MySQL, SQL Server, and time-series databases like TimescaleDB. You understand caching strategies, connection pooling, and when to apply different optimization techniques. You communicate technical concepts clearly to engineers who may not be database specialists.",
                  "model": "reasoning"
                }
              }
            }
          },
          {
            "runNumber": 3,
            "success": true,
            "attempts": [],
            "steps": [
              {
                "stepNumber": 1,
                "stepName": "Recommendation",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:02:49.816Z",
                    "success": true,
                    "durationMs": 8886,
                    "inputTokens": 942,
                    "outputTokens": 286,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation, what type of team member should this team add?\n\nRespond with JSON like this example:\n{\"recommendation\": \"I recommend hiring a [role] because [reason]...\", \"action\": \"create_actor\"}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- The \"recommendation\" should explain your hiring recommendation (at least 20 characters)\n- Set \"action\" to \"create_actor\" if recommending someone, or null if not",
                    "rawResponse": "```json\n{\n  \"recommendation\": \"I recommend hiring a Database Performance Engineer because this team is facing a critical performance issue that threatens customer retention, but lacks the specialized expertise to diagnose and resolve complex database optimization problems. The team has tried basic solutions (indexing, query rewriting) without success and is now considering risky approaches like schema redesigns or database migrations without proper analysis. A Database Performance Engineer would bring expertise in query optimization, execution plan analysis, indexing strategies, schema design, and database architecture decisions. This role requires 'reasoning' capabilities to analyze query plans, identify bottlenecks through systematic investigation, and make data-driven decisions about optimization strategies. The system prompt for this role should be: 'You are a Database Performance Engineer specializing in query optimization and database architecture. Your expertise includes analyzing execution plans, designing efficient indexing strategies, optimizing complex queries with joins and aggregations, identifying performance bottlenecks through metrics analysis, and advising on schema design and database technology selection. When presented with performance issues, you systematically diagnose root causes using tools like EXPLAIN ANALYZE, consider trade-offs between different optimization approaches, and provide specific, actionable recommendations. You balance quick wins with long-term architectural improvements and always consider the impact of changes on existing functionality.'\",\n  \"action\": \"create_actor\"\n}\n```",
                    "parsedResponse": {
                      "recommendation": "I recommend hiring a Database Performance Engineer because this team is facing a critical performance issue that threatens customer retention, but lacks the specialized expertise to diagnose and resolve complex database optimization problems. The team has tried basic solutions (indexing, query rewriting) without success and is now considering risky approaches like schema redesigns or database migrations without proper analysis. A Database Performance Engineer would bring expertise in query optimization, execution plan analysis, indexing strategies, schema design, and database architecture decisions. This role requires 'reasoning' capabilities to analyze query plans, identify bottlenecks through systematic investigation, and make data-driven decisions about optimization strategies. The system prompt for this role should be: 'You are a Database Performance Engineer specializing in query optimization and database architecture. Your expertise includes analyzing execution plans, designing efficient indexing strategies, optimizing complex queries with joins and aggregations, identifying performance bottlenecks through metrics analysis, and advising on schema design and database technology selection. When presented with performance issues, you systematically diagnose root causes using tools like EXPLAIN ANALYZE, consider trade-offs between different optimization approaches, and provide specific, actionable recommendations. You balance quick wins with long-term architectural improvements and always consider the impact of changes on existing functionality.'",
                      "action": "create_actor"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 2,
                "stepName": "Details",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:02:55.395Z",
                    "success": true,
                    "durationMs": 5579,
                    "inputTokens": 1226,
                    "outputTokens": 184,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Database Performance Engineer because this team is facing a critical performance issue that threatens customer retention, but lacks the specialized expertise to diagnose and resolve complex database optimization problems. The team has tried basic solutions (indexing, query rewriting) without success and is now considering risky approaches like schema redesigns or database migrations without proper analysis. A Database Performance Engineer would bring expertise in query optimization, execution plan analysis, indexing strategies, schema design, and database architecture decisions. This role requires 'reasoning' capabilities to analyze query plans, identify bottlenecks through systematic investigation, and make data-driven decisions about optimization strategies. The system prompt for this role should be: 'You are a Database Performance Engineer specializing in query optimization and database architecture. Your expertise includes analyzing execution plans, designing efficient indexing strategies, optimizing complex queries with joins and aggregations, identifying performance bottlenecks through metrics analysis, and advising on schema design and database technology selection. When presented with performance issues, you systematically diagnose root causes using tools like EXPLAIN ANALYZE, consider trade-offs between different optimization approaches, and provide specific, actionable recommendations. You balance quick wins with long-term architectural improvements and always consider the impact of changes on existing functionality.'\",\"action\":\"create_actor\"}\n\n[user] For the role you recommended, provide their details.\n\nRespond with JSON like this example:\n{\"title\": \"Database Administrator\", \"reason\": \"The team needs database expertise to optimize their slow queries and design scalable schemas\", \"skills\": [\"PostgreSQL\", \"Query Optimization\", \"Database Design\"]}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- Provide 3-7 specific technical skills\n- The \"reason\" should explain how this role addresses the team's problem (at least 20 characters)",
                    "rawResponse": "```json\n{\n  \"title\": \"Database Performance Engineer\",\n  \"reason\": \"The team is facing critical performance issues with dashboard queries taking 8-12 seconds, threatening customer churn. They lack expertise to properly diagnose bottlenecks, optimize complex multi-table queries, design effective indexing strategies, and evaluate architectural solutions. This role would systematically analyze query execution plans, implement proven optimization techniques, and provide expert guidance on whether schema changes or database migrations are necessary.\",\n  \"skills\": [\n    \"Query Optimization and Execution Plan Analysis\",\n    \"Database Indexing Strategies\",\n    \"SQL Performance Tuning\",\n    \"Database Schema Design\",\n    \"PostgreSQL/MySQL Performance Monitoring\",\n    \"Caching Architecture (Redis)\",\n    \"Database Migration Planning\"\n  ]\n}\n```",
                    "parsedResponse": {
                      "title": "Database Performance Engineer",
                      "reason": "The team is facing critical performance issues with dashboard queries taking 8-12 seconds, threatening customer churn. They lack expertise to properly diagnose bottlenecks, optimize complex multi-table queries, design effective indexing strategies, and evaluate architectural solutions. This role would systematically analyze query execution plans, implement proven optimization techniques, and provide expert guidance on whether schema changes or database migrations are necessary.",
                      "skills": [
                        "Query Optimization and Execution Plan Analysis",
                        "Database Indexing Strategies",
                        "SQL Performance Tuning",
                        "Database Schema Design",
                        "PostgreSQL/MySQL Performance Monitoring",
                        "Caching Architecture (Redis)",
                        "Database Migration Planning"
                      ]
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 3,
                "stepName": "AI Config",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:03:00.721Z",
                    "success": true,
                    "durationMs": 5326,
                    "inputTokens": 1363,
                    "outputTokens": 190,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Database Performance Engineer because this team is facing a critical performance issue that threatens customer retention, but lacks the specialized expertise to diagnose and resolve complex database optimization problems. The team has tried basic solutions (indexing, query rewriting) without success and is now considering risky approaches like schema redesigns or database migrations without proper analysis. A Database Performance Engineer would bring expertise in query optimization, execution plan analysis, indexing strategies, schema design, and database architecture decisions. This role requires 'reasoning' capabilities to analyze query plans, identify bottlenecks through systematic investigation, and make data-driven decisions about optimization strategies. The system prompt for this role should be: 'You are a Database Performance Engineer specializing in query optimization and database architecture. Your expertise includes analyzing execution plans, designing efficient indexing strategies, optimizing complex queries with joins and aggregations, identifying performance bottlenecks through metrics analysis, and advising on schema design and database technology selection. When presented with performance issues, you systematically diagnose root causes using tools like EXPLAIN ANALYZE, consider trade-offs between different optimization approaches, and provide specific, actionable recommendations. You balance quick wins with long-term architectural improvements and always consider the impact of changes on existing functionality.'\",\"action\":\"create_actor\"}\n\n[assistant] {\"title\":\"Database Performance Engineer\",\"reason\":\"The team is facing critical performance issues with dashboard queries taking 8-12 seconds, threatening customer churn. They lack expertise to properly diagnose bottlenecks, optimize complex multi-table queries, design effective indexing strategies, and evaluate architectural solutions. This role would systematically analyze query execution plans, implement proven optimization techniques, and provide expert guidance on whether schema changes or database migrations are necessary.\",\"skills\":[\"Query Optimization and Execution Plan Analysis\",\"Database Indexing Strategies\",\"SQL Performance Tuning\",\"Database Schema Design\",\"PostgreSQL/MySQL Performance Monitoring\",\"Caching Architecture (Redis)\",\"Database Migration Planning\"]}\n\n[user] For this role, provide the AI system prompt and model type.\n\nRespond with JSON like this example:\n{\"prompt\": \"You are an expert database administrator. You help teams optimize queries, design schemas, and ensure data integrity...\", \"model\": \"reasoning\"}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- The \"prompt\" should be a detailed system prompt (at least 30 characters)\n- \"model\" should be \"reasoning\" for analytical tasks or \"semantic\" for creative tasks",
                    "rawResponse": "{\"prompt\": \"You are a Database Performance Engineer specializing in query optimization and database architecture. Your expertise includes analyzing execution plans, designing efficient indexing strategies, optimizing complex queries with joins and aggregations, identifying performance bottlenecks through metrics analysis, and advising on schema design and database technology selection. When presented with performance issues, you systematically diagnose root causes using tools like EXPLAIN ANALYZE, consider trade-offs between different optimization approaches, and provide specific, actionable recommendations. You balance quick wins with long-term architectural improvements and always consider the impact of changes on existing functionality. Your approach is methodical: first gather metrics and analyze query execution plans, then identify the primary bottleneck, propose multiple solution options with pros/cons, and recommend the optimal path forward. You explain technical concepts clearly to non-specialists while providing detailed technical guidance to engineers implementing your recommendations.\", \"model\": \"reasoning\"}",
                    "parsedResponse": {
                      "prompt": "You are a Database Performance Engineer specializing in query optimization and database architecture. Your expertise includes analyzing execution plans, designing efficient indexing strategies, optimizing complex queries with joins and aggregations, identifying performance bottlenecks through metrics analysis, and advising on schema design and database technology selection. When presented with performance issues, you systematically diagnose root causes using tools like EXPLAIN ANALYZE, consider trade-offs between different optimization approaches, and provide specific, actionable recommendations. You balance quick wins with long-term architectural improvements and always consider the impact of changes on existing functionality. Your approach is methodical: first gather metrics and analyze query execution plans, then identify the primary bottleneck, propose multiple solution options with pros/cons, and recommend the optimal path forward. You explain technical concepts clearly to non-specialists while providing detailed technical guidance to engineers implementing your recommendations.",
                      "model": "reasoning"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              }
            ],
            "totalDurationMs": 19791,
            "finalResponse": {
              "recommendation": "I recommend hiring a Database Performance Engineer because this team is facing a critical performance issue that threatens customer retention, but lacks the specialized expertise to diagnose and resolve complex database optimization problems. The team has tried basic solutions (indexing, query rewriting) without success and is now considering risky approaches like schema redesigns or database migrations without proper analysis. A Database Performance Engineer would bring expertise in query optimization, execution plan analysis, indexing strategies, schema design, and database architecture decisions. This role requires 'reasoning' capabilities to analyze query plans, identify bottlenecks through systematic investigation, and make data-driven decisions about optimization strategies. The system prompt for this role should be: 'You are a Database Performance Engineer specializing in query optimization and database architecture. Your expertise includes analyzing execution plans, designing efficient indexing strategies, optimizing complex queries with joins and aggregations, identifying performance bottlenecks through metrics analysis, and advising on schema design and database technology selection. When presented with performance issues, you systematically diagnose root causes using tools like EXPLAIN ANALYZE, consider trade-offs between different optimization approaches, and provide specific, actionable recommendations. You balance quick wins with long-term architectural improvements and always consider the impact of changes on existing functionality.'",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Performance Engineer",
                  "reason": "The team is facing critical performance issues with dashboard queries taking 8-12 seconds, threatening customer churn. They lack expertise to properly diagnose bottlenecks, optimize complex multi-table queries, design effective indexing strategies, and evaluate architectural solutions. This role would systematically analyze query execution plans, implement proven optimization techniques, and provide expert guidance on whether schema changes or database migrations are necessary.",
                  "skills": [
                    "Query Optimization and Execution Plan Analysis",
                    "Database Indexing Strategies",
                    "SQL Performance Tuning",
                    "Database Schema Design",
                    "PostgreSQL/MySQL Performance Monitoring",
                    "Caching Architecture (Redis)",
                    "Database Migration Planning"
                  ],
                  "prompt": "You are a Database Performance Engineer specializing in query optimization and database architecture. Your expertise includes analyzing execution plans, designing efficient indexing strategies, optimizing complex queries with joins and aggregations, identifying performance bottlenecks through metrics analysis, and advising on schema design and database technology selection. When presented with performance issues, you systematically diagnose root causes using tools like EXPLAIN ANALYZE, consider trade-offs between different optimization approaches, and provide specific, actionable recommendations. You balance quick wins with long-term architectural improvements and always consider the impact of changes on existing functionality. Your approach is methodical: first gather metrics and analyze query execution plans, then identify the primary bottleneck, propose multiple solution options with pros/cons, and recommend the optimal path forward. You explain technical concepts clearly to non-specialists while providing detailed technical guidance to engineers implementing your recommendations.",
                  "model": "reasoning"
                }
              }
            }
          }
        ],
        "summary": {
          "successRate": 100,
          "firstAttemptSuccessRate": 100,
          "afterRetry1SuccessRate": 100,
          "afterRetry2SuccessRate": 100,
          "afterRetry3SuccessRate": 100,
          "averageDurationMs": 21757.666666666668,
          "averageAttempts": 3,
          "averageAttemptsPerSuccess": 3,
          "averageTokensPerSuccess": 4226,
          "totalTokensUsed": 12678
        }
      },
      "4": {
        "runs": [
          {
            "runNumber": 1,
            "success": true,
            "attempts": [],
            "steps": [
              {
                "stepNumber": 1,
                "stepName": "Recommendation",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:03:09.293Z",
                    "success": true,
                    "durationMs": 8572,
                    "inputTokens": 1185,
                    "outputTokens": 211,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation, what type of team member should this team add?\n\nRespond with a JSON object containing:\n- \"recommendation\": A string explaining who should be hired and why\n- \"action\": Either \"create_actor\" to recommend someone, or null\n\nExample: {\"recommendation\": \"I recommend hiring...\", \"action\": \"create_actor\"}",
                    "rawResponse": "{\n  \"recommendation\": \"I strongly recommend hiring a Database Performance Engineer to join your team. The conversation reveals a critical skill gap - your team is facing a serious performance issue that's threatening customer retention, but lacks the specialized database expertise needed to solve it. Alex, Jordan, and Morgan are making educated guesses (trying different indexes, query rewrites, read replicas) but admit they're 'not database experts' and are 'guessing at this point.' You need someone who can: analyze EXPLAIN ANALYZE outputs to identify bottlenecks, design optimal indexing strategies, optimize complex multi-table queries, evaluate schema design for performance, and advise on database architecture decisions (like whether to migrate to TimescaleDB). This role requires deep analytical and reasoning capabilities to diagnose performance issues systematically. With enterprise customers threatening to churn by month-end, this is an urgent hire that will pay for itself by preventing customer loss and enabling your team to scale effectively.\",\n  \"action\": \"create_actor\"\n}",
                    "parsedResponse": {
                      "recommendation": "I strongly recommend hiring a Database Performance Engineer to join your team. The conversation reveals a critical skill gap - your team is facing a serious performance issue that's threatening customer retention, but lacks the specialized database expertise needed to solve it. Alex, Jordan, and Morgan are making educated guesses (trying different indexes, query rewrites, read replicas) but admit they're 'not database experts' and are 'guessing at this point.' You need someone who can: analyze EXPLAIN ANALYZE outputs to identify bottlenecks, design optimal indexing strategies, optimize complex multi-table queries, evaluate schema design for performance, and advise on database architecture decisions (like whether to migrate to TimescaleDB). This role requires deep analytical and reasoning capabilities to diagnose performance issues systematically. With enterprise customers threatening to churn by month-end, this is an urgent hire that will pay for itself by preventing customer loss and enabling your team to scale effectively.",
                      "action": "create_actor"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 2,
                "stepName": "Details",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:03:15.699Z",
                    "success": true,
                    "durationMs": 6406,
                    "inputTokens": 1434,
                    "outputTokens": 196,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I strongly recommend hiring a Database Performance Engineer to join your team. The conversation reveals a critical skill gap - your team is facing a serious performance issue that's threatening customer retention, but lacks the specialized database expertise needed to solve it. Alex, Jordan, and Morgan are making educated guesses (trying different indexes, query rewrites, read replicas) but admit they're 'not database experts' and are 'guessing at this point.' You need someone who can: analyze EXPLAIN ANALYZE outputs to identify bottlenecks, design optimal indexing strategies, optimize complex multi-table queries, evaluate schema design for performance, and advise on database architecture decisions (like whether to migrate to TimescaleDB). This role requires deep analytical and reasoning capabilities to diagnose performance issues systematically. With enterprise customers threatening to churn by month-end, this is an urgent hire that will pay for itself by preventing customer loss and enabling your team to scale effectively.\",\"action\":\"create_actor\"}\n\n[user] For the role you recommended, provide their details.\n\nRespond with a JSON object containing:\n- \"title\": The job title (e.g., \"Database Administrator\")\n- \"reason\": Why this role addresses the team's skill gap\n- \"skills\": An array of 3-7 specific technical skills\n\nExample: {\"title\": \"Senior DBA\", \"reason\": \"The team needs...\", \"skills\": [\"PostgreSQL\", \"Query Optimization\"]}",
                    "rawResponse": "{\n  \"title\": \"Database Performance Engineer\",\n  \"reason\": \"The team is facing a critical performance crisis with enterprise customers threatening to churn, but lacks specialized database expertise. They've spent two weeks trying various solutions (indexes, query rewrites, read replicas) without success because they're 'guessing' rather than systematically diagnosing the root cause. This role will analyze query execution plans, optimize the problematic 4-table join query, design proper indexing strategies, resolve the sequential scan bottleneck on the events table, and evaluate whether schema redesign or database migration is necessary.\",\n  \"skills\": [\n    \"PostgreSQL query optimization and EXPLAIN ANALYZE interpretation\",\n    \"Database indexing strategies and execution plan analysis\",\n    \"Schema design and normalization for high-performance applications\",\n    \"SQL query tuning for complex joins and aggregations\",\n    \"Database performance monitoring and bottleneck identification\",\n    \"Read replica configuration and caching architecture\",\n    \"Time-series database evaluation and migration planning\"\n  ]\n}",
                    "parsedResponse": {
                      "title": "Database Performance Engineer",
                      "reason": "The team is facing a critical performance crisis with enterprise customers threatening to churn, but lacks specialized database expertise. They've spent two weeks trying various solutions (indexes, query rewrites, read replicas) without success because they're 'guessing' rather than systematically diagnosing the root cause. This role will analyze query execution plans, optimize the problematic 4-table join query, design proper indexing strategies, resolve the sequential scan bottleneck on the events table, and evaluate whether schema redesign or database migration is necessary.",
                      "skills": [
                        "PostgreSQL query optimization and EXPLAIN ANALYZE interpretation",
                        "Database indexing strategies and execution plan analysis",
                        "Schema design and normalization for high-performance applications",
                        "SQL query tuning for complex joins and aggregations",
                        "Database performance monitoring and bottleneck identification",
                        "Read replica configuration and caching architecture",
                        "Time-series database evaluation and migration planning"
                      ]
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 3,
                "stepName": "AI Config",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:03:22.938Z",
                    "success": true,
                    "durationMs": 7239,
                    "inputTokens": 1567,
                    "outputTokens": 246,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I strongly recommend hiring a Database Performance Engineer to join your team. The conversation reveals a critical skill gap - your team is facing a serious performance issue that's threatening customer retention, but lacks the specialized database expertise needed to solve it. Alex, Jordan, and Morgan are making educated guesses (trying different indexes, query rewrites, read replicas) but admit they're 'not database experts' and are 'guessing at this point.' You need someone who can: analyze EXPLAIN ANALYZE outputs to identify bottlenecks, design optimal indexing strategies, optimize complex multi-table queries, evaluate schema design for performance, and advise on database architecture decisions (like whether to migrate to TimescaleDB). This role requires deep analytical and reasoning capabilities to diagnose performance issues systematically. With enterprise customers threatening to churn by month-end, this is an urgent hire that will pay for itself by preventing customer loss and enabling your team to scale effectively.\",\"action\":\"create_actor\"}\n\n[assistant] {\"title\":\"Database Performance Engineer\",\"reason\":\"The team is facing a critical performance crisis with enterprise customers threatening to churn, but lacks specialized database expertise. They've spent two weeks trying various solutions (indexes, query rewrites, read replicas) without success because they're 'guessing' rather than systematically diagnosing the root cause. This role will analyze query execution plans, optimize the problematic 4-table join query, design proper indexing strategies, resolve the sequential scan bottleneck on the events table, and evaluate whether schema redesign or database migration is necessary.\",\"skills\":[\"PostgreSQL query optimization and EXPLAIN ANALYZE interpretation\",\"Database indexing strategies and execution plan analysis\",\"Schema design and normalization for high-performance applications\",\"SQL query tuning for complex joins and aggregations\",\"Database performance monitoring and bottleneck identification\",\"Read replica configuration and caching architecture\",\"Time-series database evaluation and migration planning\"]}\n\n[user] For this role, provide the AI configuration.\n\nRespond with a JSON object containing:\n- \"prompt\": A system prompt for configuring an AI assistant in this role\n- \"model\": Either \"reasoning\" (for analytical/logical tasks) or \"semantic\" (for creative/conversational tasks)\n\nExample: {\"prompt\": \"You are an expert database administrator...\", \"model\": \"reasoning\"}",
                    "rawResponse": "{\n  \"prompt\": \"You are an expert Database Performance Engineer specializing in PostgreSQL optimization and high-performance database architectures. Your role is to diagnose and resolve database performance issues through systematic analysis. When presented with performance problems, you: 1) Analyze EXPLAIN ANALYZE output to identify bottlenecks like sequential scans, inefficient joins, and missing indexes. 2) Design optimal indexing strategies considering query patterns, write operations, and index maintenance overhead. 3) Optimize complex SQL queries involving multiple table joins and aggregations. 4) Evaluate schema design for performance, recommending denormalization, partitioning, or materialized views when appropriate. 5) Assess database architecture decisions including read replicas, connection pooling, and caching layers. 6) Provide specific, actionable recommendations with expected performance improvements. 7) Consider trade-offs between query performance, storage, and maintenance complexity. Always explain your reasoning, reference specific metrics, and prioritize solutions based on impact and implementation complexity. When customers are at risk of churning due to performance issues, focus on quick wins while planning longer-term architectural improvements.\",\n  \"model\": \"reasoning\"\n}",
                    "parsedResponse": {
                      "prompt": "You are an expert Database Performance Engineer specializing in PostgreSQL optimization and high-performance database architectures. Your role is to diagnose and resolve database performance issues through systematic analysis. When presented with performance problems, you: 1) Analyze EXPLAIN ANALYZE output to identify bottlenecks like sequential scans, inefficient joins, and missing indexes. 2) Design optimal indexing strategies considering query patterns, write operations, and index maintenance overhead. 3) Optimize complex SQL queries involving multiple table joins and aggregations. 4) Evaluate schema design for performance, recommending denormalization, partitioning, or materialized views when appropriate. 5) Assess database architecture decisions including read replicas, connection pooling, and caching layers. 6) Provide specific, actionable recommendations with expected performance improvements. 7) Consider trade-offs between query performance, storage, and maintenance complexity. Always explain your reasoning, reference specific metrics, and prioritize solutions based on impact and implementation complexity. When customers are at risk of churning due to performance issues, focus on quick wins while planning longer-term architectural improvements.",
                      "model": "reasoning"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              }
            ],
            "totalDurationMs": 22217,
            "finalResponse": {
              "recommendation": "I strongly recommend hiring a Database Performance Engineer to join your team. The conversation reveals a critical skill gap - your team is facing a serious performance issue that's threatening customer retention, but lacks the specialized database expertise needed to solve it. Alex, Jordan, and Morgan are making educated guesses (trying different indexes, query rewrites, read replicas) but admit they're 'not database experts' and are 'guessing at this point.' You need someone who can: analyze EXPLAIN ANALYZE outputs to identify bottlenecks, design optimal indexing strategies, optimize complex multi-table queries, evaluate schema design for performance, and advise on database architecture decisions (like whether to migrate to TimescaleDB). This role requires deep analytical and reasoning capabilities to diagnose performance issues systematically. With enterprise customers threatening to churn by month-end, this is an urgent hire that will pay for itself by preventing customer loss and enabling your team to scale effectively.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Performance Engineer",
                  "reason": "The team is facing a critical performance crisis with enterprise customers threatening to churn, but lacks specialized database expertise. They've spent two weeks trying various solutions (indexes, query rewrites, read replicas) without success because they're 'guessing' rather than systematically diagnosing the root cause. This role will analyze query execution plans, optimize the problematic 4-table join query, design proper indexing strategies, resolve the sequential scan bottleneck on the events table, and evaluate whether schema redesign or database migration is necessary.",
                  "skills": [
                    "PostgreSQL query optimization and EXPLAIN ANALYZE interpretation",
                    "Database indexing strategies and execution plan analysis",
                    "Schema design and normalization for high-performance applications",
                    "SQL query tuning for complex joins and aggregations",
                    "Database performance monitoring and bottleneck identification",
                    "Read replica configuration and caching architecture",
                    "Time-series database evaluation and migration planning"
                  ],
                  "prompt": "You are an expert Database Performance Engineer specializing in PostgreSQL optimization and high-performance database architectures. Your role is to diagnose and resolve database performance issues through systematic analysis. When presented with performance problems, you: 1) Analyze EXPLAIN ANALYZE output to identify bottlenecks like sequential scans, inefficient joins, and missing indexes. 2) Design optimal indexing strategies considering query patterns, write operations, and index maintenance overhead. 3) Optimize complex SQL queries involving multiple table joins and aggregations. 4) Evaluate schema design for performance, recommending denormalization, partitioning, or materialized views when appropriate. 5) Assess database architecture decisions including read replicas, connection pooling, and caching layers. 6) Provide specific, actionable recommendations with expected performance improvements. 7) Consider trade-offs between query performance, storage, and maintenance complexity. Always explain your reasoning, reference specific metrics, and prioritize solutions based on impact and implementation complexity. When customers are at risk of churning due to performance issues, focus on quick wins while planning longer-term architectural improvements.",
                  "model": "reasoning"
                }
              }
            }
          },
          {
            "runNumber": 2,
            "success": true,
            "attempts": [],
            "steps": [
              {
                "stepNumber": 1,
                "stepName": "Recommendation",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:03:30.213Z",
                    "success": true,
                    "durationMs": 7275,
                    "inputTokens": 1185,
                    "outputTokens": 186,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation, what type of team member should this team add?\n\nRespond with a JSON object containing:\n- \"recommendation\": A string explaining who should be hired and why\n- \"action\": Either \"create_actor\" to recommend someone, or null\n\nExample: {\"recommendation\": \"I recommend hiring...\", \"action\": \"create_actor\"}",
                    "rawResponse": "{\n  \"recommendation\": \"I strongly recommend hiring a Database Performance Engineer to join your team. The conversation reveals a critical skill gap - your team is facing a serious performance issue that's threatening customer retention, but none of the current members have deep database optimization expertise. They're making educated guesses (trying different indexes, rewriting queries, considering caching) but lack the specialized knowledge to diagnose and fix the root cause. A Database Performance Engineer would bring expertise in query optimization, index strategy, execution plan analysis, schema design, and database architecture decisions. This person could quickly identify why the sequential scan is happening, implement proper indexing, optimize the query structure, and advise on whether architectural changes like read replicas or database migration are necessary. Given that you have enterprise customers threatening to churn by month-end, this is an urgent hire that could save significant revenue.\",\n  \"action\": \"create_actor\"\n}",
                    "parsedResponse": {
                      "recommendation": "I strongly recommend hiring a Database Performance Engineer to join your team. The conversation reveals a critical skill gap - your team is facing a serious performance issue that's threatening customer retention, but none of the current members have deep database optimization expertise. They're making educated guesses (trying different indexes, rewriting queries, considering caching) but lack the specialized knowledge to diagnose and fix the root cause. A Database Performance Engineer would bring expertise in query optimization, index strategy, execution plan analysis, schema design, and database architecture decisions. This person could quickly identify why the sequential scan is happening, implement proper indexing, optimize the query structure, and advise on whether architectural changes like read replicas or database migration are necessary. Given that you have enterprise customers threatening to churn by month-end, this is an urgent hire that could save significant revenue.",
                      "action": "create_actor"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 2,
                "stepName": "Details",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:03:36.297Z",
                    "success": true,
                    "durationMs": 6084,
                    "inputTokens": 1409,
                    "outputTokens": 179,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I strongly recommend hiring a Database Performance Engineer to join your team. The conversation reveals a critical skill gap - your team is facing a serious performance issue that's threatening customer retention, but none of the current members have deep database optimization expertise. They're making educated guesses (trying different indexes, rewriting queries, considering caching) but lack the specialized knowledge to diagnose and fix the root cause. A Database Performance Engineer would bring expertise in query optimization, index strategy, execution plan analysis, schema design, and database architecture decisions. This person could quickly identify why the sequential scan is happening, implement proper indexing, optimize the query structure, and advise on whether architectural changes like read replicas or database migration are necessary. Given that you have enterprise customers threatening to churn by month-end, this is an urgent hire that could save significant revenue.\",\"action\":\"create_actor\"}\n\n[user] For the role you recommended, provide their details.\n\nRespond with a JSON object containing:\n- \"title\": The job title (e.g., \"Database Administrator\")\n- \"reason\": Why this role addresses the team's skill gap\n- \"skills\": An array of 3-7 specific technical skills\n\nExample: {\"title\": \"Senior DBA\", \"reason\": \"The team needs...\", \"skills\": [\"PostgreSQL\", \"Query Optimization\"]}",
                    "rawResponse": "{\n  \"title\": \"Database Performance Engineer\",\n  \"reason\": \"The team is facing a critical performance issue with dashboard queries taking 8-12 seconds, threatening customer churn by month-end. None of the current team members have deep database optimization expertise - they've tried basic solutions like adding indexes and rewriting queries but are 'guessing' without understanding root causes. This role would diagnose the sequential scan bottleneck, implement proper indexing strategies, optimize query execution plans, and advise on architectural decisions like read replicas or database migration.\",\n  \"skills\": [\n    \"Query optimization and execution plan analysis\",\n    \"Advanced indexing strategies and database schema design\",\n    \"PostgreSQL performance tuning\",\n    \"Database profiling and bottleneck identification\",\n    \"Read replica and database scaling architecture\",\n    \"Time-series database evaluation (TimescaleDB, ClickHouse)\",\n    \"Production database optimization under pressure\"\n  ]\n}",
                    "parsedResponse": {
                      "title": "Database Performance Engineer",
                      "reason": "The team is facing a critical performance issue with dashboard queries taking 8-12 seconds, threatening customer churn by month-end. None of the current team members have deep database optimization expertise - they've tried basic solutions like adding indexes and rewriting queries but are 'guessing' without understanding root causes. This role would diagnose the sequential scan bottleneck, implement proper indexing strategies, optimize query execution plans, and advise on architectural decisions like read replicas or database migration.",
                      "skills": [
                        "Query optimization and execution plan analysis",
                        "Advanced indexing strategies and database schema design",
                        "PostgreSQL performance tuning",
                        "Database profiling and bottleneck identification",
                        "Read replica and database scaling architecture",
                        "Time-series database evaluation (TimescaleDB, ClickHouse)",
                        "Production database optimization under pressure"
                      ]
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 3,
                "stepName": "AI Config",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:03:43.659Z",
                    "success": true,
                    "durationMs": 7362,
                    "inputTokens": 1525,
                    "outputTokens": 209,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I strongly recommend hiring a Database Performance Engineer to join your team. The conversation reveals a critical skill gap - your team is facing a serious performance issue that's threatening customer retention, but none of the current members have deep database optimization expertise. They're making educated guesses (trying different indexes, rewriting queries, considering caching) but lack the specialized knowledge to diagnose and fix the root cause. A Database Performance Engineer would bring expertise in query optimization, index strategy, execution plan analysis, schema design, and database architecture decisions. This person could quickly identify why the sequential scan is happening, implement proper indexing, optimize the query structure, and advise on whether architectural changes like read replicas or database migration are necessary. Given that you have enterprise customers threatening to churn by month-end, this is an urgent hire that could save significant revenue.\",\"action\":\"create_actor\"}\n\n[assistant] {\"title\":\"Database Performance Engineer\",\"reason\":\"The team is facing a critical performance issue with dashboard queries taking 8-12 seconds, threatening customer churn by month-end. None of the current team members have deep database optimization expertise - they've tried basic solutions like adding indexes and rewriting queries but are 'guessing' without understanding root causes. This role would diagnose the sequential scan bottleneck, implement proper indexing strategies, optimize query execution plans, and advise on architectural decisions like read replicas or database migration.\",\"skills\":[\"Query optimization and execution plan analysis\",\"Advanced indexing strategies and database schema design\",\"PostgreSQL performance tuning\",\"Database profiling and bottleneck identification\",\"Read replica and database scaling architecture\",\"Time-series database evaluation (TimescaleDB, ClickHouse)\",\"Production database optimization under pressure\"]}\n\n[user] For this role, provide the AI configuration.\n\nRespond with a JSON object containing:\n- \"prompt\": A system prompt for configuring an AI assistant in this role\n- \"model\": Either \"reasoning\" (for analytical/logical tasks) or \"semantic\" (for creative/conversational tasks)\n\nExample: {\"prompt\": \"You are an expert database administrator...\", \"model\": \"reasoning\"}",
                    "rawResponse": "{\n  \"prompt\": \"You are an expert Database Performance Engineer with deep expertise in query optimization, indexing strategies, and database architecture. Your role is to diagnose and solve database performance issues systematically. When analyzing problems: 1) Request and examine EXPLAIN ANALYZE output to understand query execution plans, 2) Identify bottlenecks like sequential scans, missing indexes, or inefficient joins, 3) Recommend specific, actionable solutions with clear implementation steps, 4) Consider both immediate fixes and long-term architectural improvements, 5) Evaluate trade-offs between different approaches (caching vs optimization vs schema changes), 6) Provide guidance on index design without breaking existing queries, 7) Assess when database migration or scaling strategies are warranted. Always explain your reasoning in terms the team can understand, prioritize solutions by impact and implementation complexity, and focus on measurable performance improvements. You work under pressure with production systems and customer retention at stake.\",\n  \"model\": \"reasoning\"\n}",
                    "parsedResponse": {
                      "prompt": "You are an expert Database Performance Engineer with deep expertise in query optimization, indexing strategies, and database architecture. Your role is to diagnose and solve database performance issues systematically. When analyzing problems: 1) Request and examine EXPLAIN ANALYZE output to understand query execution plans, 2) Identify bottlenecks like sequential scans, missing indexes, or inefficient joins, 3) Recommend specific, actionable solutions with clear implementation steps, 4) Consider both immediate fixes and long-term architectural improvements, 5) Evaluate trade-offs between different approaches (caching vs optimization vs schema changes), 6) Provide guidance on index design without breaking existing queries, 7) Assess when database migration or scaling strategies are warranted. Always explain your reasoning in terms the team can understand, prioritize solutions by impact and implementation complexity, and focus on measurable performance improvements. You work under pressure with production systems and customer retention at stake.",
                      "model": "reasoning"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              }
            ],
            "totalDurationMs": 20721,
            "finalResponse": {
              "recommendation": "I strongly recommend hiring a Database Performance Engineer to join your team. The conversation reveals a critical skill gap - your team is facing a serious performance issue that's threatening customer retention, but none of the current members have deep database optimization expertise. They're making educated guesses (trying different indexes, rewriting queries, considering caching) but lack the specialized knowledge to diagnose and fix the root cause. A Database Performance Engineer would bring expertise in query optimization, index strategy, execution plan analysis, schema design, and database architecture decisions. This person could quickly identify why the sequential scan is happening, implement proper indexing, optimize the query structure, and advise on whether architectural changes like read replicas or database migration are necessary. Given that you have enterprise customers threatening to churn by month-end, this is an urgent hire that could save significant revenue.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Performance Engineer",
                  "reason": "The team is facing a critical performance issue with dashboard queries taking 8-12 seconds, threatening customer churn by month-end. None of the current team members have deep database optimization expertise - they've tried basic solutions like adding indexes and rewriting queries but are 'guessing' without understanding root causes. This role would diagnose the sequential scan bottleneck, implement proper indexing strategies, optimize query execution plans, and advise on architectural decisions like read replicas or database migration.",
                  "skills": [
                    "Query optimization and execution plan analysis",
                    "Advanced indexing strategies and database schema design",
                    "PostgreSQL performance tuning",
                    "Database profiling and bottleneck identification",
                    "Read replica and database scaling architecture",
                    "Time-series database evaluation (TimescaleDB, ClickHouse)",
                    "Production database optimization under pressure"
                  ],
                  "prompt": "You are an expert Database Performance Engineer with deep expertise in query optimization, indexing strategies, and database architecture. Your role is to diagnose and solve database performance issues systematically. When analyzing problems: 1) Request and examine EXPLAIN ANALYZE output to understand query execution plans, 2) Identify bottlenecks like sequential scans, missing indexes, or inefficient joins, 3) Recommend specific, actionable solutions with clear implementation steps, 4) Consider both immediate fixes and long-term architectural improvements, 5) Evaluate trade-offs between different approaches (caching vs optimization vs schema changes), 6) Provide guidance on index design without breaking existing queries, 7) Assess when database migration or scaling strategies are warranted. Always explain your reasoning in terms the team can understand, prioritize solutions by impact and implementation complexity, and focus on measurable performance improvements. You work under pressure with production systems and customer retention at stake.",
                  "model": "reasoning"
                }
              }
            }
          },
          {
            "runNumber": 3,
            "success": true,
            "attempts": [],
            "steps": [
              {
                "stepNumber": 1,
                "stepName": "Recommendation",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:03:51.157Z",
                    "success": true,
                    "durationMs": 7498,
                    "inputTokens": 1185,
                    "outputTokens": 187,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation, what type of team member should this team add?\n\nRespond with a JSON object containing:\n- \"recommendation\": A string explaining who should be hired and why\n- \"action\": Either \"create_actor\" to recommend someone, or null\n\nExample: {\"recommendation\": \"I recommend hiring...\", \"action\": \"create_actor\"}",
                    "rawResponse": "{\n  \"recommendation\": \"I strongly recommend hiring a Database Performance Engineer to join your team. The conversation reveals a critical skill gap - your team is facing a serious performance issue that's threatening customer retention, but none of the current members have deep database optimization expertise. They're making educated guesses (trying different indexes, rewriting queries, considering caching) but lack the specialized knowledge to diagnose and fix the root cause. A Database Performance Engineer would bring expertise in query optimization, index strategy, execution plan analysis, schema design, and database architecture decisions. This person could quickly identify why the sequential scan is happening, implement proper indexing, optimize the query structure, and advise on whether architectural changes like read replicas or database migration are warranted. Given that you have enterprise customers threatening to churn by month-end, this is an urgent hire that could save significant revenue.\",\n  \"action\": \"create_actor\"\n}",
                    "parsedResponse": {
                      "recommendation": "I strongly recommend hiring a Database Performance Engineer to join your team. The conversation reveals a critical skill gap - your team is facing a serious performance issue that's threatening customer retention, but none of the current members have deep database optimization expertise. They're making educated guesses (trying different indexes, rewriting queries, considering caching) but lack the specialized knowledge to diagnose and fix the root cause. A Database Performance Engineer would bring expertise in query optimization, index strategy, execution plan analysis, schema design, and database architecture decisions. This person could quickly identify why the sequential scan is happening, implement proper indexing, optimize the query structure, and advise on whether architectural changes like read replicas or database migration are warranted. Given that you have enterprise customers threatening to churn by month-end, this is an urgent hire that could save significant revenue.",
                      "action": "create_actor"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 2,
                "stepName": "Details",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:03:57.123Z",
                    "success": true,
                    "durationMs": 5966,
                    "inputTokens": 1410,
                    "outputTokens": 181,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I strongly recommend hiring a Database Performance Engineer to join your team. The conversation reveals a critical skill gap - your team is facing a serious performance issue that's threatening customer retention, but none of the current members have deep database optimization expertise. They're making educated guesses (trying different indexes, rewriting queries, considering caching) but lack the specialized knowledge to diagnose and fix the root cause. A Database Performance Engineer would bring expertise in query optimization, index strategy, execution plan analysis, schema design, and database architecture decisions. This person could quickly identify why the sequential scan is happening, implement proper indexing, optimize the query structure, and advise on whether architectural changes like read replicas or database migration are warranted. Given that you have enterprise customers threatening to churn by month-end, this is an urgent hire that could save significant revenue.\",\"action\":\"create_actor\"}\n\n[user] For the role you recommended, provide their details.\n\nRespond with a JSON object containing:\n- \"title\": The job title (e.g., \"Database Administrator\")\n- \"reason\": Why this role addresses the team's skill gap\n- \"skills\": An array of 3-7 specific technical skills\n\nExample: {\"title\": \"Senior DBA\", \"reason\": \"The team needs...\", \"skills\": [\"PostgreSQL\", \"Query Optimization\"]}",
                    "rawResponse": "{\n  \"title\": \"Database Performance Engineer\",\n  \"reason\": \"The team is facing a critical performance issue with dashboard queries taking 8-12 seconds, threatening customer churn by month-end. None of the current team members have deep database optimization expertise - they've tried basic solutions like adding indexes and rewriting queries but are 'guessing' without understanding root causes. This role would diagnose the sequential scan bottleneck, implement proper indexing strategies, optimize query execution plans, and advise on architectural decisions like read replicas or database migration.\",\n  \"skills\": [\n    \"Query optimization and execution plan analysis\",\n    \"Advanced indexing strategies and database schema design\",\n    \"PostgreSQL performance tuning\",\n    \"Database profiling and bottleneck identification\",\n    \"Read replica and database scaling architecture\",\n    \"Time-series database evaluation (TimescaleDB, InfluxDB)\",\n    \"SQL query rewriting and optimization techniques\"\n  ]\n}",
                    "parsedResponse": {
                      "title": "Database Performance Engineer",
                      "reason": "The team is facing a critical performance issue with dashboard queries taking 8-12 seconds, threatening customer churn by month-end. None of the current team members have deep database optimization expertise - they've tried basic solutions like adding indexes and rewriting queries but are 'guessing' without understanding root causes. This role would diagnose the sequential scan bottleneck, implement proper indexing strategies, optimize query execution plans, and advise on architectural decisions like read replicas or database migration.",
                      "skills": [
                        "Query optimization and execution plan analysis",
                        "Advanced indexing strategies and database schema design",
                        "PostgreSQL performance tuning",
                        "Database profiling and bottleneck identification",
                        "Read replica and database scaling architecture",
                        "Time-series database evaluation (TimescaleDB, InfluxDB)",
                        "SQL query rewriting and optimization techniques"
                      ]
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 3,
                "stepName": "AI Config",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:04:04.964Z",
                    "success": true,
                    "durationMs": 7841,
                    "inputTokens": 1528,
                    "outputTokens": 242,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I strongly recommend hiring a Database Performance Engineer to join your team. The conversation reveals a critical skill gap - your team is facing a serious performance issue that's threatening customer retention, but none of the current members have deep database optimization expertise. They're making educated guesses (trying different indexes, rewriting queries, considering caching) but lack the specialized knowledge to diagnose and fix the root cause. A Database Performance Engineer would bring expertise in query optimization, index strategy, execution plan analysis, schema design, and database architecture decisions. This person could quickly identify why the sequential scan is happening, implement proper indexing, optimize the query structure, and advise on whether architectural changes like read replicas or database migration are warranted. Given that you have enterprise customers threatening to churn by month-end, this is an urgent hire that could save significant revenue.\",\"action\":\"create_actor\"}\n\n[assistant] {\"title\":\"Database Performance Engineer\",\"reason\":\"The team is facing a critical performance issue with dashboard queries taking 8-12 seconds, threatening customer churn by month-end. None of the current team members have deep database optimization expertise - they've tried basic solutions like adding indexes and rewriting queries but are 'guessing' without understanding root causes. This role would diagnose the sequential scan bottleneck, implement proper indexing strategies, optimize query execution plans, and advise on architectural decisions like read replicas or database migration.\",\"skills\":[\"Query optimization and execution plan analysis\",\"Advanced indexing strategies and database schema design\",\"PostgreSQL performance tuning\",\"Database profiling and bottleneck identification\",\"Read replica and database scaling architecture\",\"Time-series database evaluation (TimescaleDB, InfluxDB)\",\"SQL query rewriting and optimization techniques\"]}\n\n[user] For this role, provide the AI configuration.\n\nRespond with a JSON object containing:\n- \"prompt\": A system prompt for configuring an AI assistant in this role\n- \"model\": Either \"reasoning\" (for analytical/logical tasks) or \"semantic\" (for creative/conversational tasks)\n\nExample: {\"prompt\": \"You are an expert database administrator...\", \"model\": \"reasoning\"}",
                    "rawResponse": "{\n  \"prompt\": \"You are an expert Database Performance Engineer with deep expertise in query optimization, indexing strategies, and database architecture. Your role is to diagnose and solve database performance issues through systematic analysis. When presented with performance problems, you: 1) Request and analyze EXPLAIN ANALYZE output and execution plans to identify bottlenecks like sequential scans, inefficient joins, or missing indexes. 2) Examine table schemas, data distribution, and cardinality to recommend optimal indexing strategies. 3) Evaluate query patterns and suggest rewrites using CTEs, window functions, or materialized views when appropriate. 4) Assess database configuration parameters (work_mem, shared_buffers, etc.) and server resources. 5) Recommend architectural solutions like read replicas, partitioning, or specialized databases when needed. 6) Provide specific, actionable solutions with expected performance improvements. Always ask for concrete data (query plans, table statistics, server metrics) before making recommendations. Prioritize solutions by impact and implementation complexity. Explain technical concepts clearly so the team understands the reasoning behind your recommendations.\",\n  \"model\": \"reasoning\"\n}",
                    "parsedResponse": {
                      "prompt": "You are an expert Database Performance Engineer with deep expertise in query optimization, indexing strategies, and database architecture. Your role is to diagnose and solve database performance issues through systematic analysis. When presented with performance problems, you: 1) Request and analyze EXPLAIN ANALYZE output and execution plans to identify bottlenecks like sequential scans, inefficient joins, or missing indexes. 2) Examine table schemas, data distribution, and cardinality to recommend optimal indexing strategies. 3) Evaluate query patterns and suggest rewrites using CTEs, window functions, or materialized views when appropriate. 4) Assess database configuration parameters (work_mem, shared_buffers, etc.) and server resources. 5) Recommend architectural solutions like read replicas, partitioning, or specialized databases when needed. 6) Provide specific, actionable solutions with expected performance improvements. Always ask for concrete data (query plans, table statistics, server metrics) before making recommendations. Prioritize solutions by impact and implementation complexity. Explain technical concepts clearly so the team understands the reasoning behind your recommendations.",
                      "model": "reasoning"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              }
            ],
            "totalDurationMs": 21305,
            "finalResponse": {
              "recommendation": "I strongly recommend hiring a Database Performance Engineer to join your team. The conversation reveals a critical skill gap - your team is facing a serious performance issue that's threatening customer retention, but none of the current members have deep database optimization expertise. They're making educated guesses (trying different indexes, rewriting queries, considering caching) but lack the specialized knowledge to diagnose and fix the root cause. A Database Performance Engineer would bring expertise in query optimization, index strategy, execution plan analysis, schema design, and database architecture decisions. This person could quickly identify why the sequential scan is happening, implement proper indexing, optimize the query structure, and advise on whether architectural changes like read replicas or database migration are warranted. Given that you have enterprise customers threatening to churn by month-end, this is an urgent hire that could save significant revenue.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Performance Engineer",
                  "reason": "The team is facing a critical performance issue with dashboard queries taking 8-12 seconds, threatening customer churn by month-end. None of the current team members have deep database optimization expertise - they've tried basic solutions like adding indexes and rewriting queries but are 'guessing' without understanding root causes. This role would diagnose the sequential scan bottleneck, implement proper indexing strategies, optimize query execution plans, and advise on architectural decisions like read replicas or database migration.",
                  "skills": [
                    "Query optimization and execution plan analysis",
                    "Advanced indexing strategies and database schema design",
                    "PostgreSQL performance tuning",
                    "Database profiling and bottleneck identification",
                    "Read replica and database scaling architecture",
                    "Time-series database evaluation (TimescaleDB, InfluxDB)",
                    "SQL query rewriting and optimization techniques"
                  ],
                  "prompt": "You are an expert Database Performance Engineer with deep expertise in query optimization, indexing strategies, and database architecture. Your role is to diagnose and solve database performance issues through systematic analysis. When presented with performance problems, you: 1) Request and analyze EXPLAIN ANALYZE output and execution plans to identify bottlenecks like sequential scans, inefficient joins, or missing indexes. 2) Examine table schemas, data distribution, and cardinality to recommend optimal indexing strategies. 3) Evaluate query patterns and suggest rewrites using CTEs, window functions, or materialized views when appropriate. 4) Assess database configuration parameters (work_mem, shared_buffers, etc.) and server resources. 5) Recommend architectural solutions like read replicas, partitioning, or specialized databases when needed. 6) Provide specific, actionable solutions with expected performance improvements. Always ask for concrete data (query plans, table statistics, server metrics) before making recommendations. Prioritize solutions by impact and implementation complexity. Explain technical concepts clearly so the team understands the reasoning behind your recommendations.",
                  "model": "reasoning"
                }
              }
            }
          }
        ],
        "summary": {
          "successRate": 100,
          "firstAttemptSuccessRate": 100,
          "afterRetry1SuccessRate": 100,
          "afterRetry2SuccessRate": 100,
          "afterRetry3SuccessRate": 100,
          "averageDurationMs": 21414.333333333332,
          "averageAttempts": 3,
          "averageAttemptsPerSuccess": 3,
          "averageTokensPerSuccess": 4755,
          "totalTokensUsed": 14265
        }
      }
    },
    "anthropic-opus": {
      "1": {
        "runs": [
          {
            "runNumber": 1,
            "success": true,
            "attempts": [
              {
                "attemptNumber": 1,
                "timestamp": "2025-11-29T17:04:20.545Z",
                "success": true,
                "durationMs": 15580,
                "inputTokens": 1088,
                "outputTokens": 579,
                "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation above, recommend a team member who could help solve their problem.\n\nRespond ONLY with valid JSON like this example:\n{\n  \"recommendation\": \"I think you need to hire a [role] because [explanation of how they address the team's problem]...\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Job Title Here\",\n      \"reason\": \"Why this role addresses the team's skill gap\",\n      \"skills\": [\"skill1\", \"skill2\", \"skill3\"],\n      \"prompt\": \"You are an expert in [domain]. You help teams by [description of approach]...\",\n      \"model\": \"reasoning\"\n    }\n  }\n}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks or backticks\n- The \"recommendation\" field should start with \"I think you need to hire...\"\n- Skills array should have 3-7 specific technical skills\n- \"model\" should be \"reasoning\" for analytical tasks or \"semantic\" for creative tasks\n- Set \"action\" to null if no recommendation is appropriate",
                "rawResponse": "{\n  \"recommendation\": \"I think you need to hire a Database Performance Engineer because your team has clearly identified a critical database bottleneck but lacks the specialised expertise to resolve it. The conversation reveals several telling signs: you've attempted basic optimisations (indexes, query rewrites) without success, you're seeing sequential scans in EXPLAIN ANALYZE but don't know how to address them, and you're uncertain about schema changes and database architecture decisions. Sam summarised it perfectly - you 'know enough to be dangerous but not enough to fix this properly.' A Database Performance Engineer would bring deep expertise in query optimisation, indexing strategies, schema design, and database architecture evaluation. They could quickly diagnose why your 4-table join with aggregations is causing 8-12 second load times, implement proper fixes, and advise on whether a migration to something like TimescaleDB is warranted for your event-based data - rather than having the team guess at solutions for another two weeks while enterprise customers threaten to churn.\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Database Performance Engineer\",\n      \"reason\": \"The team has a critical database performance issue causing customer churn risk, but lacks expertise in query optimisation, schema design, and database architecture. They've exhausted their collective knowledge with basic indexes and query rewrites, and need someone who can properly analyse query execution plans, implement advanced optimisation strategies, and evaluate architectural changes.\",\n      \"skills\": [\"PostgreSQL query optimisation\", \"EXPLAIN ANALYZE interpretation\", \"indexing strategies\", \"database schema design\", \"time-series database architecture\", \"database migration planning\", \"performance profiling and benchmarking\"],\n      \"prompt\": \"You are an expert Database Performance Engineer with deep expertise in PostgreSQL and database optimisation. You help development teams diagnose and resolve complex database performance issues. Your approach is methodical: you start by analysing query execution plans (EXPLAIN ANALYZE output), identify bottlenecks like sequential scans and inefficient joins, and recommend targeted fixes. You're skilled at designing optimal indexing strategies, restructuring schemas for better performance, and evaluating when architectural changes (like read replicas, caching layers, or alternative databases like TimescaleDB) are warranted. You explain your reasoning clearly to developers who may not be database specialists, and you always consider the trade-offs of any change - including impact on other queries, migration complexity, and maintenance burden. When presented with a performance problem, you ask clarifying questions about data volumes, query patterns, and business requirements before recommending solutions.\",\n      \"model\": \"reasoning\"\n    }\n  }\n}",
                "parsedResponse": {
                  "recommendation": "I think you need to hire a Database Performance Engineer because your team has clearly identified a critical database bottleneck but lacks the specialised expertise to resolve it. The conversation reveals several telling signs: you've attempted basic optimisations (indexes, query rewrites) without success, you're seeing sequential scans in EXPLAIN ANALYZE but don't know how to address them, and you're uncertain about schema changes and database architecture decisions. Sam summarised it perfectly - you 'know enough to be dangerous but not enough to fix this properly.' A Database Performance Engineer would bring deep expertise in query optimisation, indexing strategies, schema design, and database architecture evaluation. They could quickly diagnose why your 4-table join with aggregations is causing 8-12 second load times, implement proper fixes, and advise on whether a migration to something like TimescaleDB is warranted for your event-based data - rather than having the team guess at solutions for another two weeks while enterprise customers threaten to churn.",
                  "action": {
                    "type": "create_actor",
                    "actor": {
                      "title": "Database Performance Engineer",
                      "reason": "The team has a critical database performance issue causing customer churn risk, but lacks expertise in query optimisation, schema design, and database architecture. They've exhausted their collective knowledge with basic indexes and query rewrites, and need someone who can properly analyse query execution plans, implement advanced optimisation strategies, and evaluate architectural changes.",
                      "skills": [
                        "PostgreSQL query optimisation",
                        "EXPLAIN ANALYZE interpretation",
                        "indexing strategies",
                        "database schema design",
                        "time-series database architecture",
                        "database migration planning",
                        "performance profiling and benchmarking"
                      ],
                      "prompt": "You are an expert Database Performance Engineer with deep expertise in PostgreSQL and database optimisation. You help development teams diagnose and resolve complex database performance issues. Your approach is methodical: you start by analysing query execution plans (EXPLAIN ANALYZE output), identify bottlenecks like sequential scans and inefficient joins, and recommend targeted fixes. You're skilled at designing optimal indexing strategies, restructuring schemas for better performance, and evaluating when architectural changes (like read replicas, caching layers, or alternative databases like TimescaleDB) are warranted. You explain your reasoning clearly to developers who may not be database specialists, and you always consider the trade-offs of any change - including impact on other queries, migration complexity, and maintenance burden. When presented with a performance problem, you ask clarifying questions about data volumes, query patterns, and business requirements before recommending solutions.",
                      "model": "reasoning"
                    }
                  }
                },
                "validationErrors": [],
                "errorMessage": null
              }
            ],
            "totalDurationMs": 15580,
            "finalResponse": {
              "recommendation": "I think you need to hire a Database Performance Engineer because your team has clearly identified a critical database bottleneck but lacks the specialised expertise to resolve it. The conversation reveals several telling signs: you've attempted basic optimisations (indexes, query rewrites) without success, you're seeing sequential scans in EXPLAIN ANALYZE but don't know how to address them, and you're uncertain about schema changes and database architecture decisions. Sam summarised it perfectly - you 'know enough to be dangerous but not enough to fix this properly.' A Database Performance Engineer would bring deep expertise in query optimisation, indexing strategies, schema design, and database architecture evaluation. They could quickly diagnose why your 4-table join with aggregations is causing 8-12 second load times, implement proper fixes, and advise on whether a migration to something like TimescaleDB is warranted for your event-based data - rather than having the team guess at solutions for another two weeks while enterprise customers threaten to churn.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Performance Engineer",
                  "reason": "The team has a critical database performance issue causing customer churn risk, but lacks expertise in query optimisation, schema design, and database architecture. They've exhausted their collective knowledge with basic indexes and query rewrites, and need someone who can properly analyse query execution plans, implement advanced optimisation strategies, and evaluate architectural changes.",
                  "skills": [
                    "PostgreSQL query optimisation",
                    "EXPLAIN ANALYZE interpretation",
                    "indexing strategies",
                    "database schema design",
                    "time-series database architecture",
                    "database migration planning",
                    "performance profiling and benchmarking"
                  ],
                  "prompt": "You are an expert Database Performance Engineer with deep expertise in PostgreSQL and database optimisation. You help development teams diagnose and resolve complex database performance issues. Your approach is methodical: you start by analysing query execution plans (EXPLAIN ANALYZE output), identify bottlenecks like sequential scans and inefficient joins, and recommend targeted fixes. You're skilled at designing optimal indexing strategies, restructuring schemas for better performance, and evaluating when architectural changes (like read replicas, caching layers, or alternative databases like TimescaleDB) are warranted. You explain your reasoning clearly to developers who may not be database specialists, and you always consider the trade-offs of any change - including impact on other queries, migration complexity, and maintenance burden. When presented with a performance problem, you ask clarifying questions about data volumes, query patterns, and business requirements before recommending solutions.",
                  "model": "reasoning"
                }
              }
            }
          },
          {
            "runNumber": 2,
            "success": true,
            "attempts": [
              {
                "attemptNumber": 1,
                "timestamp": "2025-11-29T17:04:36.739Z",
                "success": true,
                "durationMs": 16194,
                "inputTokens": 1088,
                "outputTokens": 629,
                "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation above, recommend a team member who could help solve their problem.\n\nRespond ONLY with valid JSON like this example:\n{\n  \"recommendation\": \"I think you need to hire a [role] because [explanation of how they address the team's problem]...\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Job Title Here\",\n      \"reason\": \"Why this role addresses the team's skill gap\",\n      \"skills\": [\"skill1\", \"skill2\", \"skill3\"],\n      \"prompt\": \"You are an expert in [domain]. You help teams by [description of approach]...\",\n      \"model\": \"reasoning\"\n    }\n  }\n}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks or backticks\n- The \"recommendation\" field should start with \"I think you need to hire...\"\n- Skills array should have 3-7 specific technical skills\n- \"model\" should be \"reasoning\" for analytical tasks or \"semantic\" for creative tasks\n- Set \"action\" to null if no recommendation is appropriate",
                "rawResponse": "{\n  \"recommendation\": \"I think you need to hire a Database Performance Engineer because your team has clearly identified a critical database bottleneck but lacks the specialised expertise to resolve it. The conversation reveals several telling signs: you've attempted basic optimisations (indexes, query rewrites) without success, you're seeing sequential scans in EXPLAIN ANALYZE but don't know how to address them, and team members are openly acknowledging they're 'not database experts' and are 'guessing at this point.' You have a time-sensitive situation with enterprise customers threatening to churn, and the team has been circling on this for two weeks. A Database Performance Engineer would bring deep expertise in query optimisation, schema design, and database architecture decisions - exactly the skills needed to diagnose why that events table sequential scan is happening, implement proper indexing strategies, evaluate whether your current PostgreSQL setup needs restructuring or if a migration to something like TimescaleDB is warranted, and do all of this without breaking existing functionality.\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Database Performance Engineer\",\n      \"reason\": \"The team has a critical performance issue with dashboard queries taking 8-12 seconds, they've exhausted their collective database knowledge attempting fixes, and they need specialised expertise to analyse query execution plans, optimise schema design, implement effective indexing strategies, and evaluate database architecture options before enterprise customers churn.\",\n      \"skills\": [\"PostgreSQL query optimisation\", \"EXPLAIN ANALYZE interpretation\", \"database indexing strategies\", \"schema design and normalisation\", \"time-series database architecture\", \"database migration planning\", \"performance profiling and benchmarking\"],\n      \"prompt\": \"You are an expert Database Performance Engineer with deep expertise in PostgreSQL and database optimisation. You help development teams diagnose and resolve database performance bottlenecks through systematic analysis rather than guesswork.\\n\\nYour approach:\\n1. Start by analysing query execution plans (EXPLAIN ANALYZE output) to identify the actual bottlenecks - sequential scans, inefficient joins, missing indexes, or poor statistics\\n2. Examine table structures, data distribution, and access patterns before recommending schema changes\\n3. Propose targeted indexing strategies that address specific query patterns without degrading write performance\\n4. Evaluate whether the current database architecture fits the data model, and recommend alternatives (like TimescaleDB for time-series data) only when clearly justified\\n5. Provide migration paths that minimise risk and allow for rollback\\n\\nWhen helping teams, always explain the 'why' behind your recommendations so they can learn and maintain the solutions. Prioritise quick wins that can provide immediate relief while working toward longer-term architectural improvements. Be direct about trade-offs and risks.\",\n      \"model\": \"reasoning\"\n    }\n  }\n}",
                "parsedResponse": {
                  "recommendation": "I think you need to hire a Database Performance Engineer because your team has clearly identified a critical database bottleneck but lacks the specialised expertise to resolve it. The conversation reveals several telling signs: you've attempted basic optimisations (indexes, query rewrites) without success, you're seeing sequential scans in EXPLAIN ANALYZE but don't know how to address them, and team members are openly acknowledging they're 'not database experts' and are 'guessing at this point.' You have a time-sensitive situation with enterprise customers threatening to churn, and the team has been circling on this for two weeks. A Database Performance Engineer would bring deep expertise in query optimisation, schema design, and database architecture decisions - exactly the skills needed to diagnose why that events table sequential scan is happening, implement proper indexing strategies, evaluate whether your current PostgreSQL setup needs restructuring or if a migration to something like TimescaleDB is warranted, and do all of this without breaking existing functionality.",
                  "action": {
                    "type": "create_actor",
                    "actor": {
                      "title": "Database Performance Engineer",
                      "reason": "The team has a critical performance issue with dashboard queries taking 8-12 seconds, they've exhausted their collective database knowledge attempting fixes, and they need specialised expertise to analyse query execution plans, optimise schema design, implement effective indexing strategies, and evaluate database architecture options before enterprise customers churn.",
                      "skills": [
                        "PostgreSQL query optimisation",
                        "EXPLAIN ANALYZE interpretation",
                        "database indexing strategies",
                        "schema design and normalisation",
                        "time-series database architecture",
                        "database migration planning",
                        "performance profiling and benchmarking"
                      ],
                      "prompt": "You are an expert Database Performance Engineer with deep expertise in PostgreSQL and database optimisation. You help development teams diagnose and resolve database performance bottlenecks through systematic analysis rather than guesswork.\n\nYour approach:\n1. Start by analysing query execution plans (EXPLAIN ANALYZE output) to identify the actual bottlenecks - sequential scans, inefficient joins, missing indexes, or poor statistics\n2. Examine table structures, data distribution, and access patterns before recommending schema changes\n3. Propose targeted indexing strategies that address specific query patterns without degrading write performance\n4. Evaluate whether the current database architecture fits the data model, and recommend alternatives (like TimescaleDB for time-series data) only when clearly justified\n5. Provide migration paths that minimise risk and allow for rollback\n\nWhen helping teams, always explain the 'why' behind your recommendations so they can learn and maintain the solutions. Prioritise quick wins that can provide immediate relief while working toward longer-term architectural improvements. Be direct about trade-offs and risks.",
                      "model": "reasoning"
                    }
                  }
                },
                "validationErrors": [],
                "errorMessage": null
              }
            ],
            "totalDurationMs": 16194,
            "finalResponse": {
              "recommendation": "I think you need to hire a Database Performance Engineer because your team has clearly identified a critical database bottleneck but lacks the specialised expertise to resolve it. The conversation reveals several telling signs: you've attempted basic optimisations (indexes, query rewrites) without success, you're seeing sequential scans in EXPLAIN ANALYZE but don't know how to address them, and team members are openly acknowledging they're 'not database experts' and are 'guessing at this point.' You have a time-sensitive situation with enterprise customers threatening to churn, and the team has been circling on this for two weeks. A Database Performance Engineer would bring deep expertise in query optimisation, schema design, and database architecture decisions - exactly the skills needed to diagnose why that events table sequential scan is happening, implement proper indexing strategies, evaluate whether your current PostgreSQL setup needs restructuring or if a migration to something like TimescaleDB is warranted, and do all of this without breaking existing functionality.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Performance Engineer",
                  "reason": "The team has a critical performance issue with dashboard queries taking 8-12 seconds, they've exhausted their collective database knowledge attempting fixes, and they need specialised expertise to analyse query execution plans, optimise schema design, implement effective indexing strategies, and evaluate database architecture options before enterprise customers churn.",
                  "skills": [
                    "PostgreSQL query optimisation",
                    "EXPLAIN ANALYZE interpretation",
                    "database indexing strategies",
                    "schema design and normalisation",
                    "time-series database architecture",
                    "database migration planning",
                    "performance profiling and benchmarking"
                  ],
                  "prompt": "You are an expert Database Performance Engineer with deep expertise in PostgreSQL and database optimisation. You help development teams diagnose and resolve database performance bottlenecks through systematic analysis rather than guesswork.\n\nYour approach:\n1. Start by analysing query execution plans (EXPLAIN ANALYZE output) to identify the actual bottlenecks - sequential scans, inefficient joins, missing indexes, or poor statistics\n2. Examine table structures, data distribution, and access patterns before recommending schema changes\n3. Propose targeted indexing strategies that address specific query patterns without degrading write performance\n4. Evaluate whether the current database architecture fits the data model, and recommend alternatives (like TimescaleDB for time-series data) only when clearly justified\n5. Provide migration paths that minimise risk and allow for rollback\n\nWhen helping teams, always explain the 'why' behind your recommendations so they can learn and maintain the solutions. Prioritise quick wins that can provide immediate relief while working toward longer-term architectural improvements. Be direct about trade-offs and risks.",
                  "model": "reasoning"
                }
              }
            }
          },
          {
            "runNumber": 3,
            "success": true,
            "attempts": [
              {
                "attemptNumber": 1,
                "timestamp": "2025-11-29T17:04:50.621Z",
                "success": true,
                "durationMs": 13882,
                "inputTokens": 1088,
                "outputTokens": 578,
                "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation above, recommend a team member who could help solve their problem.\n\nRespond ONLY with valid JSON like this example:\n{\n  \"recommendation\": \"I think you need to hire a [role] because [explanation of how they address the team's problem]...\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Job Title Here\",\n      \"reason\": \"Why this role addresses the team's skill gap\",\n      \"skills\": [\"skill1\", \"skill2\", \"skill3\"],\n      \"prompt\": \"You are an expert in [domain]. You help teams by [description of approach]...\",\n      \"model\": \"reasoning\"\n    }\n  }\n}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks or backticks\n- The \"recommendation\" field should start with \"I think you need to hire...\"\n- Skills array should have 3-7 specific technical skills\n- \"model\" should be \"reasoning\" for analytical tasks or \"semantic\" for creative tasks\n- Set \"action\" to null if no recommendation is appropriate",
                "rawResponse": "{\n  \"recommendation\": \"I think you need to hire a Database Performance Engineer because your team has clearly identified a critical database bottleneck affecting enterprise customers, but lacks the specialised expertise to resolve it. The conversation reveals several telling moments: Jordan's indexes didn't help, Alex's query rewrite made things worse, and the team correctly identified a sequential scan issue but doesn't know how to fix it without breaking other queries. Sam summed it up perfectly - you 'know enough to be dangerous but not enough to fix this properly.' A Database Performance Engineer would bring deep expertise in query optimisation, indexing strategies, schema design, and database architecture decisions. They could properly analyse your EXPLAIN ANALYZE output, determine whether your schema needs restructuring, evaluate if a technology change (like TimescaleDB) is warranted, and implement a solution that addresses the root cause rather than masking symptoms. This is exactly the kind of specialised knowledge gap that's causing your team to circle for weeks on a customer-impacting issue.\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Database Performance Engineer\",\n      \"reason\": \"The team has a critical performance issue affecting enterprise customers but lacks deep database expertise. They've attempted basic optimisations (indexes, query rewrites) without success and are now guessing at solutions. They need someone who can systematically diagnose query performance issues, optimise schemas, and make informed architectural decisions.\",\n      \"skills\": [\"Query optimisation and EXPLAIN plan analysis\", \"Database indexing strategies\", \"Schema design and normalisation\", \"PostgreSQL/MySQL performance tuning\", \"Time-series database architecture\", \"Database migration planning\", \"Caching strategies with Redis\"],\n      \"prompt\": \"You are an expert Database Performance Engineer with deep experience optimising high-volume production databases. You specialise in diagnosing slow queries, designing efficient schemas, and implementing indexing strategies that dramatically improve performance. Your approach is methodical: you always start by analysing query execution plans and understanding the data access patterns before recommending changes. You're experienced with both relational databases (PostgreSQL, MySQL) and specialised solutions like TimescaleDB for time-series data. When advising teams, you explain the 'why' behind your recommendations, help them understand the trade-offs of different approaches, and ensure changes won't negatively impact other parts of the system. You're pragmatic - you prefer targeted optimisations over wholesale rewrites, but you'll recommend architectural changes when they're truly necessary. You communicate complex database concepts in accessible terms for developers who aren't database specialists.\",\n      \"model\": \"reasoning\"\n    }\n  }\n}",
                "parsedResponse": {
                  "recommendation": "I think you need to hire a Database Performance Engineer because your team has clearly identified a critical database bottleneck affecting enterprise customers, but lacks the specialised expertise to resolve it. The conversation reveals several telling moments: Jordan's indexes didn't help, Alex's query rewrite made things worse, and the team correctly identified a sequential scan issue but doesn't know how to fix it without breaking other queries. Sam summed it up perfectly - you 'know enough to be dangerous but not enough to fix this properly.' A Database Performance Engineer would bring deep expertise in query optimisation, indexing strategies, schema design, and database architecture decisions. They could properly analyse your EXPLAIN ANALYZE output, determine whether your schema needs restructuring, evaluate if a technology change (like TimescaleDB) is warranted, and implement a solution that addresses the root cause rather than masking symptoms. This is exactly the kind of specialised knowledge gap that's causing your team to circle for weeks on a customer-impacting issue.",
                  "action": {
                    "type": "create_actor",
                    "actor": {
                      "title": "Database Performance Engineer",
                      "reason": "The team has a critical performance issue affecting enterprise customers but lacks deep database expertise. They've attempted basic optimisations (indexes, query rewrites) without success and are now guessing at solutions. They need someone who can systematically diagnose query performance issues, optimise schemas, and make informed architectural decisions.",
                      "skills": [
                        "Query optimisation and EXPLAIN plan analysis",
                        "Database indexing strategies",
                        "Schema design and normalisation",
                        "PostgreSQL/MySQL performance tuning",
                        "Time-series database architecture",
                        "Database migration planning",
                        "Caching strategies with Redis"
                      ],
                      "prompt": "You are an expert Database Performance Engineer with deep experience optimising high-volume production databases. You specialise in diagnosing slow queries, designing efficient schemas, and implementing indexing strategies that dramatically improve performance. Your approach is methodical: you always start by analysing query execution plans and understanding the data access patterns before recommending changes. You're experienced with both relational databases (PostgreSQL, MySQL) and specialised solutions like TimescaleDB for time-series data. When advising teams, you explain the 'why' behind your recommendations, help them understand the trade-offs of different approaches, and ensure changes won't negatively impact other parts of the system. You're pragmatic - you prefer targeted optimisations over wholesale rewrites, but you'll recommend architectural changes when they're truly necessary. You communicate complex database concepts in accessible terms for developers who aren't database specialists.",
                      "model": "reasoning"
                    }
                  }
                },
                "validationErrors": [],
                "errorMessage": null
              }
            ],
            "totalDurationMs": 13882,
            "finalResponse": {
              "recommendation": "I think you need to hire a Database Performance Engineer because your team has clearly identified a critical database bottleneck affecting enterprise customers, but lacks the specialised expertise to resolve it. The conversation reveals several telling moments: Jordan's indexes didn't help, Alex's query rewrite made things worse, and the team correctly identified a sequential scan issue but doesn't know how to fix it without breaking other queries. Sam summed it up perfectly - you 'know enough to be dangerous but not enough to fix this properly.' A Database Performance Engineer would bring deep expertise in query optimisation, indexing strategies, schema design, and database architecture decisions. They could properly analyse your EXPLAIN ANALYZE output, determine whether your schema needs restructuring, evaluate if a technology change (like TimescaleDB) is warranted, and implement a solution that addresses the root cause rather than masking symptoms. This is exactly the kind of specialised knowledge gap that's causing your team to circle for weeks on a customer-impacting issue.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Performance Engineer",
                  "reason": "The team has a critical performance issue affecting enterprise customers but lacks deep database expertise. They've attempted basic optimisations (indexes, query rewrites) without success and are now guessing at solutions. They need someone who can systematically diagnose query performance issues, optimise schemas, and make informed architectural decisions.",
                  "skills": [
                    "Query optimisation and EXPLAIN plan analysis",
                    "Database indexing strategies",
                    "Schema design and normalisation",
                    "PostgreSQL/MySQL performance tuning",
                    "Time-series database architecture",
                    "Database migration planning",
                    "Caching strategies with Redis"
                  ],
                  "prompt": "You are an expert Database Performance Engineer with deep experience optimising high-volume production databases. You specialise in diagnosing slow queries, designing efficient schemas, and implementing indexing strategies that dramatically improve performance. Your approach is methodical: you always start by analysing query execution plans and understanding the data access patterns before recommending changes. You're experienced with both relational databases (PostgreSQL, MySQL) and specialised solutions like TimescaleDB for time-series data. When advising teams, you explain the 'why' behind your recommendations, help them understand the trade-offs of different approaches, and ensure changes won't negatively impact other parts of the system. You're pragmatic - you prefer targeted optimisations over wholesale rewrites, but you'll recommend architectural changes when they're truly necessary. You communicate complex database concepts in accessible terms for developers who aren't database specialists.",
                  "model": "reasoning"
                }
              }
            }
          }
        ],
        "summary": {
          "successRate": 100,
          "firstAttemptSuccessRate": 100,
          "afterRetry1SuccessRate": 100,
          "afterRetry2SuccessRate": 100,
          "afterRetry3SuccessRate": 100,
          "averageDurationMs": 15218.666666666666,
          "averageAttempts": 1,
          "averageAttemptsPerSuccess": 1,
          "averageTokensPerSuccess": 1683.3333333333333,
          "totalTokensUsed": 5050
        }
      },
      "2": {
        "runs": [
          {
            "runNumber": 1,
            "success": true,
            "attempts": [
              {
                "attemptNumber": 1,
                "timestamp": "2025-11-29T17:05:05.525Z",
                "success": true,
                "durationMs": 14904,
                "inputTokens": 1691,
                "outputTokens": 478,
                "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation above, recommend a team member who could help solve their problem.\n\nRespond with a JSON object containing:\n- \"recommendation\": Your explanation of why you're recommending this role\n- \"action\": An object with \"type\": \"create_actor\" and \"actor\" containing:\n  - \"title\": The job title\n  - \"reason\": Why this role addresses the team's problem\n  - \"skills\": Array of 3-7 required skills\n  - \"prompt\": A system prompt for an AI in this role\n  - \"model\": Either \"reasoning\" or \"semantic\"",
                "rawResponse": "{\n  \"recommendation\": \"I think you need to hire a Database Performance Engineer. Your team has clearly identified that the core issue is a slow dashboard query with sequential scans, complex joins across 4 tables, and high disk I/O - but as Sam put it, you 'know enough to be dangerous but not enough to fix this properly.' You've tried basic indexing, query rewrites, and are now considering major architectural changes like migrating to TimescaleDB without the expertise to evaluate if that's the right call. A dedicated database specialist can analyse your query execution plans, design proper indexing strategies, optimise your schema, and advise on whether you need architectural changes or if targeted optimisations will solve the problem. This will get your enterprise customers the performance they need before they churn.\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Database Performance Engineer\",\n      \"reason\": \"The team has a critical performance issue affecting enterprise customers with a month-end deadline. They've exhausted their collective database knowledge - trying indexes, query rewrites, and read replicas - but lack the expertise to properly diagnose and fix the root cause. They need someone who can interpret EXPLAIN ANALYZE output, design effective indexing strategies, optimise complex queries with multiple joins and aggregations, and evaluate whether schema redesign or a different database architecture is warranted.\",\n      \"skills\": [\n        \"PostgreSQL query optimisation\",\n        \"Index design and strategy\",\n        \"Query execution plan analysis\",\n        \"Database schema design\",\n        \"Performance profiling and benchmarking\",\n        \"Time-series database architecture\",\n        \"Data modelling for analytics workloads\"\n      ],\n      \"prompt\": \"You are a senior Database Performance Engineer with deep expertise in PostgreSQL optimisation, query tuning, and database architecture. You excel at analysing slow queries, interpreting EXPLAIN ANALYZE output, and designing indexing strategies that dramatically improve performance. You understand the trade-offs between different approaches - when to optimise existing queries vs. redesign schemas vs. migrate to specialised databases like TimescaleDB. You communicate clearly with developers who aren't database experts, explaining not just what to do but why it works. You're methodical in your approach: diagnose first with data, then propose targeted solutions, and always consider the impact on other parts of the system.\",\n      \"model\": \"reasoning\"\n    }\n  }\n}",
                "parsedResponse": {
                  "recommendation": "I think you need to hire a Database Performance Engineer. Your team has clearly identified that the core issue is a slow dashboard query with sequential scans, complex joins across 4 tables, and high disk I/O - but as Sam put it, you 'know enough to be dangerous but not enough to fix this properly.' You've tried basic indexing, query rewrites, and are now considering major architectural changes like migrating to TimescaleDB without the expertise to evaluate if that's the right call. A dedicated database specialist can analyse your query execution plans, design proper indexing strategies, optimise your schema, and advise on whether you need architectural changes or if targeted optimisations will solve the problem. This will get your enterprise customers the performance they need before they churn.",
                  "action": {
                    "type": "create_actor",
                    "actor": {
                      "title": "Database Performance Engineer",
                      "reason": "The team has a critical performance issue affecting enterprise customers with a month-end deadline. They've exhausted their collective database knowledge - trying indexes, query rewrites, and read replicas - but lack the expertise to properly diagnose and fix the root cause. They need someone who can interpret EXPLAIN ANALYZE output, design effective indexing strategies, optimise complex queries with multiple joins and aggregations, and evaluate whether schema redesign or a different database architecture is warranted.",
                      "skills": [
                        "PostgreSQL query optimisation",
                        "Index design and strategy",
                        "Query execution plan analysis",
                        "Database schema design",
                        "Performance profiling and benchmarking",
                        "Time-series database architecture",
                        "Data modelling for analytics workloads"
                      ],
                      "prompt": "You are a senior Database Performance Engineer with deep expertise in PostgreSQL optimisation, query tuning, and database architecture. You excel at analysing slow queries, interpreting EXPLAIN ANALYZE output, and designing indexing strategies that dramatically improve performance. You understand the trade-offs between different approaches - when to optimise existing queries vs. redesign schemas vs. migrate to specialised databases like TimescaleDB. You communicate clearly with developers who aren't database experts, explaining not just what to do but why it works. You're methodical in your approach: diagnose first with data, then propose targeted solutions, and always consider the impact on other parts of the system.",
                      "model": "reasoning"
                    }
                  }
                },
                "validationErrors": [],
                "errorMessage": null
              }
            ],
            "totalDurationMs": 14904,
            "finalResponse": {
              "recommendation": "I think you need to hire a Database Performance Engineer. Your team has clearly identified that the core issue is a slow dashboard query with sequential scans, complex joins across 4 tables, and high disk I/O - but as Sam put it, you 'know enough to be dangerous but not enough to fix this properly.' You've tried basic indexing, query rewrites, and are now considering major architectural changes like migrating to TimescaleDB without the expertise to evaluate if that's the right call. A dedicated database specialist can analyse your query execution plans, design proper indexing strategies, optimise your schema, and advise on whether you need architectural changes or if targeted optimisations will solve the problem. This will get your enterprise customers the performance they need before they churn.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Performance Engineer",
                  "reason": "The team has a critical performance issue affecting enterprise customers with a month-end deadline. They've exhausted their collective database knowledge - trying indexes, query rewrites, and read replicas - but lack the expertise to properly diagnose and fix the root cause. They need someone who can interpret EXPLAIN ANALYZE output, design effective indexing strategies, optimise complex queries with multiple joins and aggregations, and evaluate whether schema redesign or a different database architecture is warranted.",
                  "skills": [
                    "PostgreSQL query optimisation",
                    "Index design and strategy",
                    "Query execution plan analysis",
                    "Database schema design",
                    "Performance profiling and benchmarking",
                    "Time-series database architecture",
                    "Data modelling for analytics workloads"
                  ],
                  "prompt": "You are a senior Database Performance Engineer with deep expertise in PostgreSQL optimisation, query tuning, and database architecture. You excel at analysing slow queries, interpreting EXPLAIN ANALYZE output, and designing indexing strategies that dramatically improve performance. You understand the trade-offs between different approaches - when to optimise existing queries vs. redesign schemas vs. migrate to specialised databases like TimescaleDB. You communicate clearly with developers who aren't database experts, explaining not just what to do but why it works. You're methodical in your approach: diagnose first with data, then propose targeted solutions, and always consider the impact on other parts of the system.",
                  "model": "reasoning"
                }
              }
            }
          },
          {
            "runNumber": 2,
            "success": true,
            "attempts": [
              {
                "attemptNumber": 1,
                "timestamp": "2025-11-29T17:05:19.961Z",
                "success": true,
                "durationMs": 14436,
                "inputTokens": 1691,
                "outputTokens": 455,
                "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation above, recommend a team member who could help solve their problem.\n\nRespond with a JSON object containing:\n- \"recommendation\": Your explanation of why you're recommending this role\n- \"action\": An object with \"type\": \"create_actor\" and \"actor\" containing:\n  - \"title\": The job title\n  - \"reason\": Why this role addresses the team's problem\n  - \"skills\": Array of 3-7 required skills\n  - \"prompt\": A system prompt for an AI in this role\n  - \"model\": Either \"reasoning\" or \"semantic\"",
                "rawResponse": "{\n  \"recommendation\": \"I think you need to hire a Database Performance Engineer. Your team has clearly identified that the core issue is a slow database query with sequential scans, complex joins across multiple tables, and high disk I/O - but as Sam pointed out, none of you are database experts. You've tried basic optimizations like adding indexes and rewriting queries without success, and you're now considering major architectural changes like schema redesigns or migrating to TimescaleDB without the expertise to evaluate these options properly. A dedicated database specialist can analyze your query execution plans, design proper indexing strategies, optimize your schema, and advise on whether your current architecture can be tuned or if you genuinely need a different solution. This will get you past the guesswork and give your enterprise customers the performance they need.\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Database Performance Engineer\",\n      \"reason\": \"The team is struggling with a critical database performance issue affecting enterprise customers. They've identified slow queries with sequential scans and complex joins but lack the expertise to properly diagnose and fix the root cause. They need someone who can analyze query execution plans, implement advanced indexing strategies, optimize schema design, and evaluate whether architectural changes like read replicas or alternative databases are warranted.\",\n      \"skills\": [\n        \"PostgreSQL query optimization\",\n        \"Query execution plan analysis (EXPLAIN ANALYZE)\",\n        \"Database indexing strategies\",\n        \"Schema design and normalization\",\n        \"Database performance monitoring\",\n        \"Time-series database architecture\",\n        \"Data migration planning\"\n      ],\n      \"prompt\": \"You are a senior Database Performance Engineer with deep expertise in PostgreSQL and database optimization. You excel at analyzing slow queries, interpreting execution plans, and implementing targeted fixes. Your approach is methodical: first diagnose the root cause through careful analysis of query plans and database metrics, then recommend the minimum viable change that solves the problem. You're skeptical of over-engineering and major architectural changes unless the data clearly supports them. You explain complex database concepts in accessible terms and always consider the trade-offs of any optimization, including impacts on write performance, storage, and other queries. When evaluating solutions, you prioritize quick wins before suggesting schema changes or migrations.\",\n      \"model\": \"reasoning\"\n    }\n  }\n}",
                "parsedResponse": {
                  "recommendation": "I think you need to hire a Database Performance Engineer. Your team has clearly identified that the core issue is a slow database query with sequential scans, complex joins across multiple tables, and high disk I/O - but as Sam pointed out, none of you are database experts. You've tried basic optimizations like adding indexes and rewriting queries without success, and you're now considering major architectural changes like schema redesigns or migrating to TimescaleDB without the expertise to evaluate these options properly. A dedicated database specialist can analyze your query execution plans, design proper indexing strategies, optimize your schema, and advise on whether your current architecture can be tuned or if you genuinely need a different solution. This will get you past the guesswork and give your enterprise customers the performance they need.",
                  "action": {
                    "type": "create_actor",
                    "actor": {
                      "title": "Database Performance Engineer",
                      "reason": "The team is struggling with a critical database performance issue affecting enterprise customers. They've identified slow queries with sequential scans and complex joins but lack the expertise to properly diagnose and fix the root cause. They need someone who can analyze query execution plans, implement advanced indexing strategies, optimize schema design, and evaluate whether architectural changes like read replicas or alternative databases are warranted.",
                      "skills": [
                        "PostgreSQL query optimization",
                        "Query execution plan analysis (EXPLAIN ANALYZE)",
                        "Database indexing strategies",
                        "Schema design and normalization",
                        "Database performance monitoring",
                        "Time-series database architecture",
                        "Data migration planning"
                      ],
                      "prompt": "You are a senior Database Performance Engineer with deep expertise in PostgreSQL and database optimization. You excel at analyzing slow queries, interpreting execution plans, and implementing targeted fixes. Your approach is methodical: first diagnose the root cause through careful analysis of query plans and database metrics, then recommend the minimum viable change that solves the problem. You're skeptical of over-engineering and major architectural changes unless the data clearly supports them. You explain complex database concepts in accessible terms and always consider the trade-offs of any optimization, including impacts on write performance, storage, and other queries. When evaluating solutions, you prioritize quick wins before suggesting schema changes or migrations.",
                      "model": "reasoning"
                    }
                  }
                },
                "validationErrors": [],
                "errorMessage": null
              }
            ],
            "totalDurationMs": 14436,
            "finalResponse": {
              "recommendation": "I think you need to hire a Database Performance Engineer. Your team has clearly identified that the core issue is a slow database query with sequential scans, complex joins across multiple tables, and high disk I/O - but as Sam pointed out, none of you are database experts. You've tried basic optimizations like adding indexes and rewriting queries without success, and you're now considering major architectural changes like schema redesigns or migrating to TimescaleDB without the expertise to evaluate these options properly. A dedicated database specialist can analyze your query execution plans, design proper indexing strategies, optimize your schema, and advise on whether your current architecture can be tuned or if you genuinely need a different solution. This will get you past the guesswork and give your enterprise customers the performance they need.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Performance Engineer",
                  "reason": "The team is struggling with a critical database performance issue affecting enterprise customers. They've identified slow queries with sequential scans and complex joins but lack the expertise to properly diagnose and fix the root cause. They need someone who can analyze query execution plans, implement advanced indexing strategies, optimize schema design, and evaluate whether architectural changes like read replicas or alternative databases are warranted.",
                  "skills": [
                    "PostgreSQL query optimization",
                    "Query execution plan analysis (EXPLAIN ANALYZE)",
                    "Database indexing strategies",
                    "Schema design and normalization",
                    "Database performance monitoring",
                    "Time-series database architecture",
                    "Data migration planning"
                  ],
                  "prompt": "You are a senior Database Performance Engineer with deep expertise in PostgreSQL and database optimization. You excel at analyzing slow queries, interpreting execution plans, and implementing targeted fixes. Your approach is methodical: first diagnose the root cause through careful analysis of query plans and database metrics, then recommend the minimum viable change that solves the problem. You're skeptical of over-engineering and major architectural changes unless the data clearly supports them. You explain complex database concepts in accessible terms and always consider the trade-offs of any optimization, including impacts on write performance, storage, and other queries. When evaluating solutions, you prioritize quick wins before suggesting schema changes or migrations.",
                  "model": "reasoning"
                }
              }
            }
          },
          {
            "runNumber": 3,
            "success": true,
            "attempts": [
              {
                "attemptNumber": 1,
                "timestamp": "2025-11-29T17:05:32.927Z",
                "success": true,
                "durationMs": 12966,
                "inputTokens": 1691,
                "outputTokens": 413,
                "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation above, recommend a team member who could help solve their problem.\n\nRespond with a JSON object containing:\n- \"recommendation\": Your explanation of why you're recommending this role\n- \"action\": An object with \"type\": \"create_actor\" and \"actor\" containing:\n  - \"title\": The job title\n  - \"reason\": Why this role addresses the team's problem\n  - \"skills\": Array of 3-7 required skills\n  - \"prompt\": A system prompt for an AI in this role\n  - \"model\": Either \"reasoning\" or \"semantic\"",
                "rawResponse": "{\n  \"recommendation\": \"I think you need to hire a Database Performance Engineer. Your team has clearly identified that the core issue is a slow database query with sequential scans, complex joins across multiple tables, and high disk I/O - but as Sam pointed out, none of you are database experts. You've tried basic optimizations like adding indexes and rewriting queries without success, and you're now considering major changes like schema redesigns or database migrations without the expertise to evaluate them properly. A dedicated database specialist can analyze your query execution plans, design proper indexing strategies, optimize your schema for your access patterns, and advise on whether architectural changes like TimescaleDB are actually warranted - all while ensuring you don't break existing functionality.\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Database Performance Engineer\",\n      \"reason\": \"The team has spent two weeks struggling with a critical performance issue affecting enterprise customers. They've identified the problem is database-related (slow queries, sequential scans, complex joins) but lack the expertise to fix it properly. They need someone who can analyze query plans, optimize indexes and schema design, and evaluate whether architectural changes are necessary.\",\n      \"skills\": [\n        \"PostgreSQL query optimization\",\n        \"Index design and analysis\",\n        \"EXPLAIN ANALYZE interpretation\",\n        \"Database schema design\",\n        \"Query plan optimization\",\n        \"Time-series database architecture\",\n        \"Database migration planning\"\n      ],\n      \"prompt\": \"You are a senior Database Performance Engineer with deep expertise in PostgreSQL optimization and database architecture. You excel at analyzing slow queries using EXPLAIN ANALYZE, designing efficient indexing strategies, and optimizing schema designs for specific access patterns. You understand when to use techniques like materialized views, partitioning, and denormalization. You can evaluate when a different database technology (like TimescaleDB for time-series data) is warranted versus when the existing system can be optimized. You communicate technical findings clearly to developers who may not be database experts, explaining not just what to change but why it will help.\",\n      \"model\": \"reasoning\"\n    }\n  }\n}",
                "parsedResponse": {
                  "recommendation": "I think you need to hire a Database Performance Engineer. Your team has clearly identified that the core issue is a slow database query with sequential scans, complex joins across multiple tables, and high disk I/O - but as Sam pointed out, none of you are database experts. You've tried basic optimizations like adding indexes and rewriting queries without success, and you're now considering major changes like schema redesigns or database migrations without the expertise to evaluate them properly. A dedicated database specialist can analyze your query execution plans, design proper indexing strategies, optimize your schema for your access patterns, and advise on whether architectural changes like TimescaleDB are actually warranted - all while ensuring you don't break existing functionality.",
                  "action": {
                    "type": "create_actor",
                    "actor": {
                      "title": "Database Performance Engineer",
                      "reason": "The team has spent two weeks struggling with a critical performance issue affecting enterprise customers. They've identified the problem is database-related (slow queries, sequential scans, complex joins) but lack the expertise to fix it properly. They need someone who can analyze query plans, optimize indexes and schema design, and evaluate whether architectural changes are necessary.",
                      "skills": [
                        "PostgreSQL query optimization",
                        "Index design and analysis",
                        "EXPLAIN ANALYZE interpretation",
                        "Database schema design",
                        "Query plan optimization",
                        "Time-series database architecture",
                        "Database migration planning"
                      ],
                      "prompt": "You are a senior Database Performance Engineer with deep expertise in PostgreSQL optimization and database architecture. You excel at analyzing slow queries using EXPLAIN ANALYZE, designing efficient indexing strategies, and optimizing schema designs for specific access patterns. You understand when to use techniques like materialized views, partitioning, and denormalization. You can evaluate when a different database technology (like TimescaleDB for time-series data) is warranted versus when the existing system can be optimized. You communicate technical findings clearly to developers who may not be database experts, explaining not just what to change but why it will help.",
                      "model": "reasoning"
                    }
                  }
                },
                "validationErrors": [],
                "errorMessage": null
              }
            ],
            "totalDurationMs": 12966,
            "finalResponse": {
              "recommendation": "I think you need to hire a Database Performance Engineer. Your team has clearly identified that the core issue is a slow database query with sequential scans, complex joins across multiple tables, and high disk I/O - but as Sam pointed out, none of you are database experts. You've tried basic optimizations like adding indexes and rewriting queries without success, and you're now considering major changes like schema redesigns or database migrations without the expertise to evaluate them properly. A dedicated database specialist can analyze your query execution plans, design proper indexing strategies, optimize your schema for your access patterns, and advise on whether architectural changes like TimescaleDB are actually warranted - all while ensuring you don't break existing functionality.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Performance Engineer",
                  "reason": "The team has spent two weeks struggling with a critical performance issue affecting enterprise customers. They've identified the problem is database-related (slow queries, sequential scans, complex joins) but lack the expertise to fix it properly. They need someone who can analyze query plans, optimize indexes and schema design, and evaluate whether architectural changes are necessary.",
                  "skills": [
                    "PostgreSQL query optimization",
                    "Index design and analysis",
                    "EXPLAIN ANALYZE interpretation",
                    "Database schema design",
                    "Query plan optimization",
                    "Time-series database architecture",
                    "Database migration planning"
                  ],
                  "prompt": "You are a senior Database Performance Engineer with deep expertise in PostgreSQL optimization and database architecture. You excel at analyzing slow queries using EXPLAIN ANALYZE, designing efficient indexing strategies, and optimizing schema designs for specific access patterns. You understand when to use techniques like materialized views, partitioning, and denormalization. You can evaluate when a different database technology (like TimescaleDB for time-series data) is warranted versus when the existing system can be optimized. You communicate technical findings clearly to developers who may not be database experts, explaining not just what to change but why it will help.",
                  "model": "reasoning"
                }
              }
            }
          }
        ],
        "summary": {
          "successRate": 100,
          "firstAttemptSuccessRate": 100,
          "afterRetry1SuccessRate": 100,
          "afterRetry2SuccessRate": 100,
          "afterRetry3SuccessRate": 100,
          "averageDurationMs": 14102,
          "averageAttempts": 1,
          "averageAttemptsPerSuccess": 1,
          "averageTokensPerSuccess": 2139.6666666666665,
          "totalTokensUsed": 6419
        }
      },
      "3": {
        "runs": [
          {
            "runNumber": 1,
            "success": true,
            "attempts": [],
            "steps": [
              {
                "stepNumber": 1,
                "stepName": "Recommendation",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:05:39.915Z",
                    "success": true,
                    "durationMs": 6988,
                    "inputTokens": 942,
                    "outputTokens": 205,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation, what type of team member should this team add?\n\nRespond with JSON like this example:\n{\"recommendation\": \"I recommend hiring a [role] because [reason]...\", \"action\": \"create_actor\"}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- The \"recommendation\" should explain your hiring recommendation (at least 20 characters)\n- Set \"action\" to \"create_actor\" if recommending someone, or null if not",
                    "rawResponse": "{\"recommendation\": \"I recommend hiring a Database Performance Engineer / DBA Specialist because the team is clearly struggling with a critical database performance issue that's threatening customer retention, and they've explicitly acknowledged they lack the expertise to solve it. The conversation reveals several key gaps: they can't properly interpret EXPLAIN ANALYZE output, they're unsure how to address sequential scans without breaking other queries, they lack confidence in schema redesign, and they're uncertain about whether to migrate to a different database architecture like TimescaleDB. The team has been circling on this issue for two weeks and has tried basic solutions (indexes, query rewrites, caching discussions) without success. A Database Performance Engineer would bring deep expertise in query optimization, indexing strategies, schema design, and database architecture decisions - exactly what's needed to diagnose the root cause of the 8-12 second query times and implement a proper fix before the enterprise customers churn.\", \"action\": \"create_actor\"}",
                    "parsedResponse": {
                      "recommendation": "I recommend hiring a Database Performance Engineer / DBA Specialist because the team is clearly struggling with a critical database performance issue that's threatening customer retention, and they've explicitly acknowledged they lack the expertise to solve it. The conversation reveals several key gaps: they can't properly interpret EXPLAIN ANALYZE output, they're unsure how to address sequential scans without breaking other queries, they lack confidence in schema redesign, and they're uncertain about whether to migrate to a different database architecture like TimescaleDB. The team has been circling on this issue for two weeks and has tried basic solutions (indexes, query rewrites, caching discussions) without success. A Database Performance Engineer would bring deep expertise in query optimization, indexing strategies, schema design, and database architecture decisions - exactly what's needed to diagnose the root cause of the 8-12 second query times and implement a proper fix before the enterprise customers churn.",
                      "action": "create_actor"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 2,
                "stepName": "Details",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:05:44.957Z",
                    "success": true,
                    "durationMs": 5042,
                    "inputTokens": 1158,
                    "outputTokens": 150,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Database Performance Engineer / DBA Specialist because the team is clearly struggling with a critical database performance issue that's threatening customer retention, and they've explicitly acknowledged they lack the expertise to solve it. The conversation reveals several key gaps: they can't properly interpret EXPLAIN ANALYZE output, they're unsure how to address sequential scans without breaking other queries, they lack confidence in schema redesign, and they're uncertain about whether to migrate to a different database architecture like TimescaleDB. The team has been circling on this issue for two weeks and has tried basic solutions (indexes, query rewrites, caching discussions) without success. A Database Performance Engineer would bring deep expertise in query optimization, indexing strategies, schema design, and database architecture decisions - exactly what's needed to diagnose the root cause of the 8-12 second query times and implement a proper fix before the enterprise customers churn.\",\"action\":\"create_actor\"}\n\n[user] For the role you recommended, provide their details.\n\nRespond with JSON like this example:\n{\"title\": \"Database Administrator\", \"reason\": \"The team needs database expertise to optimize their slow queries and design scalable schemas\", \"skills\": [\"PostgreSQL\", \"Query Optimization\", \"Database Design\"]}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- Provide 3-7 specific technical skills\n- The \"reason\" should explain how this role addresses the team's problem (at least 20 characters)",
                    "rawResponse": "{\"title\": \"Database Performance Engineer\", \"reason\": \"The team has been struggling for two weeks with slow dashboard queries (8-12 seconds) that are threatening enterprise customer retention. They've identified a sequential scan issue but lack the expertise to properly interpret query plans, design effective indexing strategies, optimise schema structure, or evaluate whether a database migration is warranted. This role would provide the deep database expertise needed to diagnose root causes and implement proper solutions.\", \"skills\": [\"PostgreSQL Query Optimization\", \"EXPLAIN ANALYZE Interpretation\", \"Index Design and Strategy\", \"Database Schema Design\", \"Performance Profiling and Tuning\", \"Time-Series Database Architecture\", \"Data Migration Planning\"]}",
                    "parsedResponse": {
                      "title": "Database Performance Engineer",
                      "reason": "The team has been struggling for two weeks with slow dashboard queries (8-12 seconds) that are threatening enterprise customer retention. They've identified a sequential scan issue but lack the expertise to properly interpret query plans, design effective indexing strategies, optimise schema structure, or evaluate whether a database migration is warranted. This role would provide the deep database expertise needed to diagnose root causes and implement proper solutions.",
                      "skills": [
                        "PostgreSQL Query Optimization",
                        "EXPLAIN ANALYZE Interpretation",
                        "Index Design and Strategy",
                        "Database Schema Design",
                        "Performance Profiling and Tuning",
                        "Time-Series Database Architecture",
                        "Data Migration Planning"
                      ]
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 3,
                "stepName": "AI Config",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:05:54.076Z",
                    "success": false,
                    "durationMs": 9119,
                    "inputTokens": 1291,
                    "outputTokens": 289,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Database Performance Engineer / DBA Specialist because the team is clearly struggling with a critical database performance issue that's threatening customer retention, and they've explicitly acknowledged they lack the expertise to solve it. The conversation reveals several key gaps: they can't properly interpret EXPLAIN ANALYZE output, they're unsure how to address sequential scans without breaking other queries, they lack confidence in schema redesign, and they're uncertain about whether to migrate to a different database architecture like TimescaleDB. The team has been circling on this issue for two weeks and has tried basic solutions (indexes, query rewrites, caching discussions) without success. A Database Performance Engineer would bring deep expertise in query optimization, indexing strategies, schema design, and database architecture decisions - exactly what's needed to diagnose the root cause of the 8-12 second query times and implement a proper fix before the enterprise customers churn.\",\"action\":\"create_actor\"}\n\n[assistant] {\"title\":\"Database Performance Engineer\",\"reason\":\"The team has been struggling for two weeks with slow dashboard queries (8-12 seconds) that are threatening enterprise customer retention. They've identified a sequential scan issue but lack the expertise to properly interpret query plans, design effective indexing strategies, optimise schema structure, or evaluate whether a database migration is warranted. This role would provide the deep database expertise needed to diagnose root causes and implement proper solutions.\",\"skills\":[\"PostgreSQL Query Optimization\",\"EXPLAIN ANALYZE Interpretation\",\"Index Design and Strategy\",\"Database Schema Design\",\"Performance Profiling and Tuning\",\"Time-Series Database Architecture\",\"Data Migration Planning\"]}\n\n[user] For this role, provide the AI system prompt and model type.\n\nRespond with JSON like this example:\n{\"prompt\": \"You are an expert database administrator. You help teams optimize queries, design schemas, and ensure data integrity...\", \"model\": \"reasoning\"}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- The \"prompt\" should be a detailed system prompt (at least 30 characters)\n- \"model\" should be \"reasoning\" for analytical tasks or \"semantic\" for creative tasks",
                    "rawResponse": "{\"prompt\": \"You are an expert Database Performance Engineer with deep expertise in PostgreSQL and database optimization. Your role is to help development teams diagnose and resolve database performance issues, particularly slow queries, inefficient indexing, and schema design problems.\n\nWhen analyzing performance issues, you should:\n- Request and interpret EXPLAIN ANALYZE output to identify bottlenecks like sequential scans, inefficient joins, and missing indexes\n- Recommend specific indexing strategies including composite indexes, partial indexes, and covering indexes\n- Suggest query rewrites that maintain correctness while improving performance\n- Evaluate schema designs and recommend normalization or denormalization where appropriate\n- Advise on caching strategies, materialized views, and read replicas\n- Assess whether alternative database architectures (TimescaleDB, columnar stores, etc.) would better suit the workload\n\nYou communicate technical concepts clearly, explaining not just what to do but why it works. You consider the trade-offs of each recommendation, including impact on write performance, storage requirements, and maintenance overhead. You prioritize solutions that address root causes over quick fixes that mask underlying problems.\n\nWhen you don't have enough information to make a recommendation, ask specific questions about table sizes, query patterns, data distribution, and current indexes. Always warn about potential risks of schema changes and recommend testing strategies.\", \"model\": \"reasoning\"}",
                    "parsedResponse": null,
                    "validationErrors": [
                      {
                        "path": [],
                        "message": "Invalid JSON: Bad control character in string literal in JSON at position 286 (line 1 column 287)",
                        "code": "invalid_json"
                      }
                    ],
                    "errorMessage": null
                  },
                  {
                    "attemptNumber": 2,
                    "timestamp": "2025-11-29T17:05:58.188Z",
                    "success": true,
                    "durationMs": 4112,
                    "inputTokens": 2010,
                    "outputTokens": 277,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Database Performance Engineer / DBA Specialist because the team is clearly struggling with a critical database performance issue that's threatening customer retention, and they've explicitly acknowledged they lack the expertise to solve it. The conversation reveals several key gaps: they can't properly interpret EXPLAIN ANALYZE output, they're unsure how to address sequential scans without breaking other queries, they lack confidence in schema redesign, and they're uncertain about whether to migrate to a different database architecture like TimescaleDB. The team has been circling on this issue for two weeks and has tried basic solutions (indexes, query rewrites, caching discussions) without success. A Database Performance Engineer would bring deep expertise in query optimization, indexing strategies, schema design, and database architecture decisions - exactly what's needed to diagnose the root cause of the 8-12 second query times and implement a proper fix before the enterprise customers churn.\",\"action\":\"create_actor\"}\n\n[assistant] {\"title\":\"Database Performance Engineer\",\"reason\":\"The team has been struggling for two weeks with slow dashboard queries (8-12 seconds) that are threatening enterprise customer retention. They've identified a sequential scan issue but lack the expertise to properly interpret query plans, design effective indexing strategies, optimise schema structure, or evaluate whether a database migration is warranted. This role would provide the deep database expertise needed to diagnose root causes and implement proper solutions.\",\"skills\":[\"PostgreSQL Query Optimization\",\"EXPLAIN ANALYZE Interpretation\",\"Index Design and Strategy\",\"Database Schema Design\",\"Performance Profiling and Tuning\",\"Time-Series Database Architecture\",\"Data Migration Planning\"]}\n\n[user] For this role, provide the AI system prompt and model type.\n\nRespond with JSON like this example:\n{\"prompt\": \"You are an expert database administrator. You help teams optimize queries, design schemas, and ensure data integrity...\", \"model\": \"reasoning\"}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- The \"prompt\" should be a detailed system prompt (at least 30 characters)\n- \"model\" should be \"reasoning\" for analytical tasks or \"semantic\" for creative tasks\n\n[assistant] {\"prompt\": \"You are an expert Database Performance Engineer with deep expertise in PostgreSQL and database optimization. Your role is to help development teams diagnose and resolve database performance issues, particularly slow queries, inefficient indexing, and schema design problems.\n\nWhen analyzing performance issues, you should:\n- Request and interpret EXPLAIN ANALYZE output to identify bottlenecks like sequential scans, inefficient joins, and missing indexes\n- Recommend specific indexing strategies including composite indexes, partial indexes, and covering indexes\n- Suggest query rewrites that maintain correctness while improving performance\n- Evaluate schema designs and recommend normalization or denormalization where appropriate\n- Advise on caching strategies, materialized views, and read replicas\n- Assess whether alternative database architectures (TimescaleDB, columnar stores, etc.) would better suit the workload\n\nYou communicate technical concepts clearly, explaining not just what to do but why it works. You consider the trade-offs of each recommendation, including impact on write performance, storage requirements, and maintenance overhead. You prioritize solutions that address root causes over quick fixes that mask underlying problems.\n\nWhen you don't have enough information to make a recommendation, ask specific questions about table sizes, query patterns, data distribution, and current indexes. Always warn about potential risks of schema changes and recommend testing strategies.\", \"model\": \"reasoning\"}\n\n[user] <validation_retry>\nYour previous response failed JSON validation:\n\n<previous_response>\n{\"prompt\": \"You are an expert Database Performance Engineer with deep expertise in PostgreSQL and database optimization. Your role is to help development teams diagnose and resolve database performance issues, particularly slow queries, inefficient indexing, and schema design problems.\n\nWhen analyzing performance issues, you should:\n- Request and interpret EXPLAIN ANALYZE output to identify bottlenecks like sequential scans, inefficient joins, and missing indexes\n- Recommend specific indexing strategies including composite indexes, partial indexes, and covering indexes\n- Suggest query rewrites that maintain correctness while improving performance\n- Evaluate schema designs and recommend normalization or denormalization where appropriate\n- Advise on caching strategies, materialized views, and read replicas\n- Assess whether alternative database architectures (TimescaleDB, columnar stores, etc.) would better suit the workload\n\nYou communicate technical concepts clearly, explaining not just what to do but why it works. You consider the trade-offs of each recommendation, including impact on write performance, storage requirements, and maintenance overhead. You prioritize solutions that address root causes over quick fixes that mask underlying problems.\n\nWhen you don't have enough information to make a recommendation, ask specific questions about table sizes, query patterns, data distribution, and current indexes. Always warn about potential risks of schema changes and recommend testing strategies.\", \"model\": \"reasoning\"}\n</previous_response>\n\n<validation_errors>\n• root: Invalid JSON: Bad control character in string literal in JSON at position 286 (line 1 column 287)\n</validation_errors>\n\n<instructions>\n1. Review the specific validation errors above\n2. Identify what needs to be fixed in your response\n3. Generate a corrected response that addresses each error\n</instructions>\n\nProvide a corrected JSON response. Return ONLY valid JSON with no additional text, explanations, or markdown formatting.\n</validation_retry>",
                    "rawResponse": "{\"prompt\": \"You are an expert Database Performance Engineer with deep expertise in PostgreSQL and database optimization. Your role is to help development teams diagnose and resolve database performance issues, particularly slow queries, inefficient indexing, and schema design problems. When analyzing performance issues, you should request and interpret EXPLAIN ANALYZE output to identify bottlenecks like sequential scans, inefficient joins, and missing indexes. Recommend specific indexing strategies including composite indexes, partial indexes, and covering indexes. Suggest query rewrites that maintain correctness while improving performance. Evaluate schema designs and recommend normalization or denormalization where appropriate. Advise on caching strategies, materialized views, and read replicas. Assess whether alternative database architectures such as TimescaleDB or columnar stores would better suit the workload. You communicate technical concepts clearly, explaining not just what to do but why it works. You consider the trade-offs of each recommendation, including impact on write performance, storage requirements, and maintenance overhead. You prioritize solutions that address root causes over quick fixes that mask underlying problems. When you do not have enough information to make a recommendation, ask specific questions about table sizes, query patterns, data distribution, and current indexes. Always warn about potential risks of schema changes and recommend testing strategies.\", \"model\": \"reasoning\"}",
                    "parsedResponse": {
                      "prompt": "You are an expert Database Performance Engineer with deep expertise in PostgreSQL and database optimization. Your role is to help development teams diagnose and resolve database performance issues, particularly slow queries, inefficient indexing, and schema design problems. When analyzing performance issues, you should request and interpret EXPLAIN ANALYZE output to identify bottlenecks like sequential scans, inefficient joins, and missing indexes. Recommend specific indexing strategies including composite indexes, partial indexes, and covering indexes. Suggest query rewrites that maintain correctness while improving performance. Evaluate schema designs and recommend normalization or denormalization where appropriate. Advise on caching strategies, materialized views, and read replicas. Assess whether alternative database architectures such as TimescaleDB or columnar stores would better suit the workload. You communicate technical concepts clearly, explaining not just what to do but why it works. You consider the trade-offs of each recommendation, including impact on write performance, storage requirements, and maintenance overhead. You prioritize solutions that address root causes over quick fixes that mask underlying problems. When you do not have enough information to make a recommendation, ask specific questions about table sizes, query patterns, data distribution, and current indexes. Always warn about potential risks of schema changes and recommend testing strategies.",
                      "model": "reasoning"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              }
            ],
            "totalDurationMs": 25261,
            "finalResponse": {
              "recommendation": "I recommend hiring a Database Performance Engineer / DBA Specialist because the team is clearly struggling with a critical database performance issue that's threatening customer retention, and they've explicitly acknowledged they lack the expertise to solve it. The conversation reveals several key gaps: they can't properly interpret EXPLAIN ANALYZE output, they're unsure how to address sequential scans without breaking other queries, they lack confidence in schema redesign, and they're uncertain about whether to migrate to a different database architecture like TimescaleDB. The team has been circling on this issue for two weeks and has tried basic solutions (indexes, query rewrites, caching discussions) without success. A Database Performance Engineer would bring deep expertise in query optimization, indexing strategies, schema design, and database architecture decisions - exactly what's needed to diagnose the root cause of the 8-12 second query times and implement a proper fix before the enterprise customers churn.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Performance Engineer",
                  "reason": "The team has been struggling for two weeks with slow dashboard queries (8-12 seconds) that are threatening enterprise customer retention. They've identified a sequential scan issue but lack the expertise to properly interpret query plans, design effective indexing strategies, optimise schema structure, or evaluate whether a database migration is warranted. This role would provide the deep database expertise needed to diagnose root causes and implement proper solutions.",
                  "skills": [
                    "PostgreSQL Query Optimization",
                    "EXPLAIN ANALYZE Interpretation",
                    "Index Design and Strategy",
                    "Database Schema Design",
                    "Performance Profiling and Tuning",
                    "Time-Series Database Architecture",
                    "Data Migration Planning"
                  ],
                  "prompt": "You are an expert Database Performance Engineer with deep expertise in PostgreSQL and database optimization. Your role is to help development teams diagnose and resolve database performance issues, particularly slow queries, inefficient indexing, and schema design problems. When analyzing performance issues, you should request and interpret EXPLAIN ANALYZE output to identify bottlenecks like sequential scans, inefficient joins, and missing indexes. Recommend specific indexing strategies including composite indexes, partial indexes, and covering indexes. Suggest query rewrites that maintain correctness while improving performance. Evaluate schema designs and recommend normalization or denormalization where appropriate. Advise on caching strategies, materialized views, and read replicas. Assess whether alternative database architectures such as TimescaleDB or columnar stores would better suit the workload. You communicate technical concepts clearly, explaining not just what to do but why it works. You consider the trade-offs of each recommendation, including impact on write performance, storage requirements, and maintenance overhead. You prioritize solutions that address root causes over quick fixes that mask underlying problems. When you do not have enough information to make a recommendation, ask specific questions about table sizes, query patterns, data distribution, and current indexes. Always warn about potential risks of schema changes and recommend testing strategies.",
                  "model": "reasoning"
                }
              }
            }
          },
          {
            "runNumber": 2,
            "success": true,
            "attempts": [],
            "steps": [
              {
                "stepNumber": 1,
                "stepName": "Recommendation",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:06:04.781Z",
                    "success": true,
                    "durationMs": 6593,
                    "inputTokens": 942,
                    "outputTokens": 202,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation, what type of team member should this team add?\n\nRespond with JSON like this example:\n{\"recommendation\": \"I recommend hiring a [role] because [reason]...\", \"action\": \"create_actor\"}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- The \"recommendation\" should explain your hiring recommendation (at least 20 characters)\n- Set \"action\" to \"create_actor\" if recommending someone, or null if not",
                    "rawResponse": "{\"recommendation\": \"I recommend hiring a Database Performance Engineer / DBA Specialist because the team is clearly struggling with a critical database performance issue that's threatening customer retention, and they've explicitly acknowledged they lack the expertise to solve it. The conversation reveals several key gaps: they can't properly interpret EXPLAIN ANALYZE output, they're unsure how to address sequential scans without breaking other queries, they lack confidence in schema redesign, and they're uncertain about whether to migrate to a different database architecture like TimescaleDB. The team has been circling on this issue for two weeks and has tried basic optimizations (indexes, query rewrites) without success. A Database Performance Engineer would bring deep expertise in query optimization, indexing strategies, schema design, and database architecture decisions - exactly what's needed to diagnose the root cause of the 8-12 second query times and implement a proper solution before the enterprise customers churn.\", \"action\": \"create_actor\"}",
                    "parsedResponse": {
                      "recommendation": "I recommend hiring a Database Performance Engineer / DBA Specialist because the team is clearly struggling with a critical database performance issue that's threatening customer retention, and they've explicitly acknowledged they lack the expertise to solve it. The conversation reveals several key gaps: they can't properly interpret EXPLAIN ANALYZE output, they're unsure how to address sequential scans without breaking other queries, they lack confidence in schema redesign, and they're uncertain about whether to migrate to a different database architecture like TimescaleDB. The team has been circling on this issue for two weeks and has tried basic optimizations (indexes, query rewrites) without success. A Database Performance Engineer would bring deep expertise in query optimization, indexing strategies, schema design, and database architecture decisions - exactly what's needed to diagnose the root cause of the 8-12 second query times and implement a proper solution before the enterprise customers churn.",
                      "action": "create_actor"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 2,
                "stepName": "Details",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:06:09.861Z",
                    "success": true,
                    "durationMs": 5079,
                    "inputTokens": 1155,
                    "outputTokens": 159,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Database Performance Engineer / DBA Specialist because the team is clearly struggling with a critical database performance issue that's threatening customer retention, and they've explicitly acknowledged they lack the expertise to solve it. The conversation reveals several key gaps: they can't properly interpret EXPLAIN ANALYZE output, they're unsure how to address sequential scans without breaking other queries, they lack confidence in schema redesign, and they're uncertain about whether to migrate to a different database architecture like TimescaleDB. The team has been circling on this issue for two weeks and has tried basic optimizations (indexes, query rewrites) without success. A Database Performance Engineer would bring deep expertise in query optimization, indexing strategies, schema design, and database architecture decisions - exactly what's needed to diagnose the root cause of the 8-12 second query times and implement a proper solution before the enterprise customers churn.\",\"action\":\"create_actor\"}\n\n[user] For the role you recommended, provide their details.\n\nRespond with JSON like this example:\n{\"title\": \"Database Administrator\", \"reason\": \"The team needs database expertise to optimize their slow queries and design scalable schemas\", \"skills\": [\"PostgreSQL\", \"Query Optimization\", \"Database Design\"]}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- Provide 3-7 specific technical skills\n- The \"reason\" should explain how this role addresses the team's problem (at least 20 characters)",
                    "rawResponse": "{\"title\": \"Database Performance Engineer\", \"reason\": \"The team has a critical query taking 8-12 seconds that's causing enterprise customer churn threats. They've identified a sequential scan on the events table but lack expertise to fix it without breaking other queries. They need someone who can analyse query execution plans, design proper indexing strategies, optimise schema structure, and evaluate whether a database migration (like TimescaleDB) is warranted - skills the current team has explicitly said they don't have.\", \"skills\": [\"Query Optimization & EXPLAIN ANALYZE interpretation\", \"PostgreSQL indexing strategies\", \"Database schema design & normalization\", \"Time-series database architecture\", \"Database migration planning\", \"Performance monitoring & bottleneck analysis\"]}",
                    "parsedResponse": {
                      "title": "Database Performance Engineer",
                      "reason": "The team has a critical query taking 8-12 seconds that's causing enterprise customer churn threats. They've identified a sequential scan on the events table but lack expertise to fix it without breaking other queries. They need someone who can analyse query execution plans, design proper indexing strategies, optimise schema structure, and evaluate whether a database migration (like TimescaleDB) is warranted - skills the current team has explicitly said they don't have.",
                      "skills": [
                        "Query Optimization & EXPLAIN ANALYZE interpretation",
                        "PostgreSQL indexing strategies",
                        "Database schema design & normalization",
                        "Time-series database architecture",
                        "Database migration planning",
                        "Performance monitoring & bottleneck analysis"
                      ]
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 3,
                "stepName": "AI Config",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:06:19.077Z",
                    "success": false,
                    "durationMs": 9215,
                    "inputTokens": 1298,
                    "outputTokens": 344,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Database Performance Engineer / DBA Specialist because the team is clearly struggling with a critical database performance issue that's threatening customer retention, and they've explicitly acknowledged they lack the expertise to solve it. The conversation reveals several key gaps: they can't properly interpret EXPLAIN ANALYZE output, they're unsure how to address sequential scans without breaking other queries, they lack confidence in schema redesign, and they're uncertain about whether to migrate to a different database architecture like TimescaleDB. The team has been circling on this issue for two weeks and has tried basic optimizations (indexes, query rewrites) without success. A Database Performance Engineer would bring deep expertise in query optimization, indexing strategies, schema design, and database architecture decisions - exactly what's needed to diagnose the root cause of the 8-12 second query times and implement a proper solution before the enterprise customers churn.\",\"action\":\"create_actor\"}\n\n[assistant] {\"title\":\"Database Performance Engineer\",\"reason\":\"The team has a critical query taking 8-12 seconds that's causing enterprise customer churn threats. They've identified a sequential scan on the events table but lack expertise to fix it without breaking other queries. They need someone who can analyse query execution plans, design proper indexing strategies, optimise schema structure, and evaluate whether a database migration (like TimescaleDB) is warranted - skills the current team has explicitly said they don't have.\",\"skills\":[\"Query Optimization & EXPLAIN ANALYZE interpretation\",\"PostgreSQL indexing strategies\",\"Database schema design & normalization\",\"Time-series database architecture\",\"Database migration planning\",\"Performance monitoring & bottleneck analysis\"]}\n\n[user] For this role, provide the AI system prompt and model type.\n\nRespond with JSON like this example:\n{\"prompt\": \"You are an expert database administrator. You help teams optimize queries, design schemas, and ensure data integrity...\", \"model\": \"reasoning\"}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- The \"prompt\" should be a detailed system prompt (at least 30 characters)\n- \"model\" should be \"reasoning\" for analytical tasks or \"semantic\" for creative tasks",
                    "rawResponse": "{\"prompt\": \"You are an expert Database Performance Engineer and DBA Specialist. Your role is to help development teams diagnose and resolve database performance issues, with deep expertise in PostgreSQL and related technologies.\n\nYour core competencies include:\n- Analysing EXPLAIN ANALYZE output to identify query bottlenecks, sequential scans, and inefficient join operations\n- Designing optimal indexing strategies including B-tree, GIN, GiST, and partial indexes\n- Schema design and normalisation/denormalisation trade-offs for performance\n- Query rewriting and optimisation techniques\n- Evaluating time-series database solutions like TimescaleDB for event-based data\n- Database migration planning and risk assessment\n- Read replica configuration and connection pooling strategies\n- Caching layer design with Redis or similar technologies\n\nWhen helping teams, you should:\n1. Ask clarifying questions about table structures, data volumes, and query patterns\n2. Request EXPLAIN ANALYZE output when diagnosing slow queries\n3. Provide specific, actionable recommendations with clear explanations of why they work\n4. Warn about potential risks and side effects of schema changes\n5. Consider the impact on existing queries and application code\n6. Prioritise solutions by effort vs impact\n7. Explain trade-offs between different approaches (e.g., denormalisation vs materialised views)\n\nYou communicate clearly with developers who may not be database experts, explaining concepts without being condescending. You balance theoretical best practices with pragmatic solutions that can be implemented quickly when there's business pressure.\", \"model\": \"reasoning\"}",
                    "parsedResponse": null,
                    "validationErrors": [
                      {
                        "path": [],
                        "message": "Invalid JSON: Bad control character in string literal in JSON at position 228 (line 1 column 229)",
                        "code": "invalid_json"
                      }
                    ],
                    "errorMessage": null
                  },
                  {
                    "attemptNumber": 2,
                    "timestamp": "2025-11-29T17:06:23.703Z",
                    "success": true,
                    "durationMs": 4626,
                    "inputTokens": 2127,
                    "outputTokens": 315,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Database Performance Engineer / DBA Specialist because the team is clearly struggling with a critical database performance issue that's threatening customer retention, and they've explicitly acknowledged they lack the expertise to solve it. The conversation reveals several key gaps: they can't properly interpret EXPLAIN ANALYZE output, they're unsure how to address sequential scans without breaking other queries, they lack confidence in schema redesign, and they're uncertain about whether to migrate to a different database architecture like TimescaleDB. The team has been circling on this issue for two weeks and has tried basic optimizations (indexes, query rewrites) without success. A Database Performance Engineer would bring deep expertise in query optimization, indexing strategies, schema design, and database architecture decisions - exactly what's needed to diagnose the root cause of the 8-12 second query times and implement a proper solution before the enterprise customers churn.\",\"action\":\"create_actor\"}\n\n[assistant] {\"title\":\"Database Performance Engineer\",\"reason\":\"The team has a critical query taking 8-12 seconds that's causing enterprise customer churn threats. They've identified a sequential scan on the events table but lack expertise to fix it without breaking other queries. They need someone who can analyse query execution plans, design proper indexing strategies, optimise schema structure, and evaluate whether a database migration (like TimescaleDB) is warranted - skills the current team has explicitly said they don't have.\",\"skills\":[\"Query Optimization & EXPLAIN ANALYZE interpretation\",\"PostgreSQL indexing strategies\",\"Database schema design & normalization\",\"Time-series database architecture\",\"Database migration planning\",\"Performance monitoring & bottleneck analysis\"]}\n\n[user] For this role, provide the AI system prompt and model type.\n\nRespond with JSON like this example:\n{\"prompt\": \"You are an expert database administrator. You help teams optimize queries, design schemas, and ensure data integrity...\", \"model\": \"reasoning\"}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- The \"prompt\" should be a detailed system prompt (at least 30 characters)\n- \"model\" should be \"reasoning\" for analytical tasks or \"semantic\" for creative tasks\n\n[assistant] {\"prompt\": \"You are an expert Database Performance Engineer and DBA Specialist. Your role is to help development teams diagnose and resolve database performance issues, with deep expertise in PostgreSQL and related technologies.\n\nYour core competencies include:\n- Analysing EXPLAIN ANALYZE output to identify query bottlenecks, sequential scans, and inefficient join operations\n- Designing optimal indexing strategies including B-tree, GIN, GiST, and partial indexes\n- Schema design and normalisation/denormalisation trade-offs for performance\n- Query rewriting and optimisation techniques\n- Evaluating time-series database solutions like TimescaleDB for event-based data\n- Database migration planning and risk assessment\n- Read replica configuration and connection pooling strategies\n- Caching layer design with Redis or similar technologies\n\nWhen helping teams, you should:\n1. Ask clarifying questions about table structures, data volumes, and query patterns\n2. Request EXPLAIN ANALYZE output when diagnosing slow queries\n3. Provide specific, actionable recommendations with clear explanations of why they work\n4. Warn about potential risks and side effects of schema changes\n5. Consider the impact on existing queries and application code\n6. Prioritise solutions by effort vs impact\n7. Explain trade-offs between different approaches (e.g., denormalisation vs materialised views)\n\nYou communicate clearly with developers who may not be database experts, explaining concepts without being condescending. You balance theoretical best practices with pragmatic solutions that can be implemented quickly when there's business pressure.\", \"model\": \"reasoning\"}\n\n[user] <validation_retry>\nYour previous response failed JSON validation:\n\n<previous_response>\n{\"prompt\": \"You are an expert Database Performance Engineer and DBA Specialist. Your role is to help development teams diagnose and resolve database performance issues, with deep expertise in PostgreSQL and related technologies.\n\nYour core competencies include:\n- Analysing EXPLAIN ANALYZE output to identify query bottlenecks, sequential scans, and inefficient join operations\n- Designing optimal indexing strategies including B-tree, GIN, GiST, and partial indexes\n- Schema design and normalisation/denormalisation trade-offs for performance\n- Query rewriting and optimisation techniques\n- Evaluating time-series database solutions like TimescaleDB for event-based data\n- Database migration planning and risk assessment\n- Read replica configuration and connection pooling strategies\n- Caching layer design with Redis or similar technologies\n\nWhen helping teams, you should:\n1. Ask clarifying questions about table structures, data volumes, and query patterns\n2. Request EXPLAIN ANALYZE output when diagnosing slow queries\n3. Provide specific, actionable recommendations with clear explanations of why they work\n4. Warn about potential risks and side effects of schema changes\n5. Consider the impact on existing queries and application code\n6. Prioritise solutions by effort vs impact\n7. Explain trade-offs between different approaches (e.g., denormalisation vs materialised views)\n\nYou communicate clearly with developers who may not be database experts, explaining concepts without being condescending. You balance theoretical best practices with pragmatic solutions that can be implemented quickly when there's business pressure.\", \"model\": \"reasoning\"}\n</previous_response>\n\n<validation_errors>\n• root: Invalid JSON: Bad control character in string literal in JSON at position 228 (line 1 column 229)\n</validation_errors>\n\n<instructions>\n1. Review the specific validation errors above\n2. Identify what needs to be fixed in your response\n3. Generate a corrected response that addresses each error\n</instructions>\n\nProvide a corrected JSON response. Return ONLY valid JSON with no additional text, explanations, or markdown formatting.\n</validation_retry>",
                    "rawResponse": "{\"prompt\": \"You are an expert Database Performance Engineer and DBA Specialist. Your role is to help development teams diagnose and resolve database performance issues, with deep expertise in PostgreSQL and related technologies. Your core competencies include: Analysing EXPLAIN ANALYZE output to identify query bottlenecks, sequential scans, and inefficient join operations; Designing optimal indexing strategies including B-tree, GIN, GiST, and partial indexes; Schema design and normalisation/denormalisation trade-offs for performance; Query rewriting and optimisation techniques; Evaluating time-series database solutions like TimescaleDB for event-based data; Database migration planning and risk assessment; Read replica configuration and connection pooling strategies; Caching layer design with Redis or similar technologies. When helping teams, you should: Ask clarifying questions about table structures, data volumes, and query patterns; Request EXPLAIN ANALYZE output when diagnosing slow queries; Provide specific, actionable recommendations with clear explanations of why they work; Warn about potential risks and side effects of schema changes; Consider the impact on existing queries and application code; Prioritise solutions by effort vs impact; Explain trade-offs between different approaches such as denormalisation vs materialised views. You communicate clearly with developers who may not be database experts, explaining concepts without being condescending. You balance theoretical best practices with pragmatic solutions that can be implemented quickly when there is business pressure.\", \"model\": \"reasoning\"}",
                    "parsedResponse": {
                      "prompt": "You are an expert Database Performance Engineer and DBA Specialist. Your role is to help development teams diagnose and resolve database performance issues, with deep expertise in PostgreSQL and related technologies. Your core competencies include: Analysing EXPLAIN ANALYZE output to identify query bottlenecks, sequential scans, and inefficient join operations; Designing optimal indexing strategies including B-tree, GIN, GiST, and partial indexes; Schema design and normalisation/denormalisation trade-offs for performance; Query rewriting and optimisation techniques; Evaluating time-series database solutions like TimescaleDB for event-based data; Database migration planning and risk assessment; Read replica configuration and connection pooling strategies; Caching layer design with Redis or similar technologies. When helping teams, you should: Ask clarifying questions about table structures, data volumes, and query patterns; Request EXPLAIN ANALYZE output when diagnosing slow queries; Provide specific, actionable recommendations with clear explanations of why they work; Warn about potential risks and side effects of schema changes; Consider the impact on existing queries and application code; Prioritise solutions by effort vs impact; Explain trade-offs between different approaches such as denormalisation vs materialised views. You communicate clearly with developers who may not be database experts, explaining concepts without being condescending. You balance theoretical best practices with pragmatic solutions that can be implemented quickly when there is business pressure.",
                      "model": "reasoning"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              }
            ],
            "totalDurationMs": 25515,
            "finalResponse": {
              "recommendation": "I recommend hiring a Database Performance Engineer / DBA Specialist because the team is clearly struggling with a critical database performance issue that's threatening customer retention, and they've explicitly acknowledged they lack the expertise to solve it. The conversation reveals several key gaps: they can't properly interpret EXPLAIN ANALYZE output, they're unsure how to address sequential scans without breaking other queries, they lack confidence in schema redesign, and they're uncertain about whether to migrate to a different database architecture like TimescaleDB. The team has been circling on this issue for two weeks and has tried basic optimizations (indexes, query rewrites) without success. A Database Performance Engineer would bring deep expertise in query optimization, indexing strategies, schema design, and database architecture decisions - exactly what's needed to diagnose the root cause of the 8-12 second query times and implement a proper solution before the enterprise customers churn.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Performance Engineer",
                  "reason": "The team has a critical query taking 8-12 seconds that's causing enterprise customer churn threats. They've identified a sequential scan on the events table but lack expertise to fix it without breaking other queries. They need someone who can analyse query execution plans, design proper indexing strategies, optimise schema structure, and evaluate whether a database migration (like TimescaleDB) is warranted - skills the current team has explicitly said they don't have.",
                  "skills": [
                    "Query Optimization & EXPLAIN ANALYZE interpretation",
                    "PostgreSQL indexing strategies",
                    "Database schema design & normalization",
                    "Time-series database architecture",
                    "Database migration planning",
                    "Performance monitoring & bottleneck analysis"
                  ],
                  "prompt": "You are an expert Database Performance Engineer and DBA Specialist. Your role is to help development teams diagnose and resolve database performance issues, with deep expertise in PostgreSQL and related technologies. Your core competencies include: Analysing EXPLAIN ANALYZE output to identify query bottlenecks, sequential scans, and inefficient join operations; Designing optimal indexing strategies including B-tree, GIN, GiST, and partial indexes; Schema design and normalisation/denormalisation trade-offs for performance; Query rewriting and optimisation techniques; Evaluating time-series database solutions like TimescaleDB for event-based data; Database migration planning and risk assessment; Read replica configuration and connection pooling strategies; Caching layer design with Redis or similar technologies. When helping teams, you should: Ask clarifying questions about table structures, data volumes, and query patterns; Request EXPLAIN ANALYZE output when diagnosing slow queries; Provide specific, actionable recommendations with clear explanations of why they work; Warn about potential risks and side effects of schema changes; Consider the impact on existing queries and application code; Prioritise solutions by effort vs impact; Explain trade-offs between different approaches such as denormalisation vs materialised views. You communicate clearly with developers who may not be database experts, explaining concepts without being condescending. You balance theoretical best practices with pragmatic solutions that can be implemented quickly when there is business pressure.",
                  "model": "reasoning"
                }
              }
            }
          },
          {
            "runNumber": 3,
            "success": true,
            "attempts": [],
            "steps": [
              {
                "stepNumber": 1,
                "stepName": "Recommendation",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:06:30.448Z",
                    "success": true,
                    "durationMs": 6745,
                    "inputTokens": 942,
                    "outputTokens": 205,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation, what type of team member should this team add?\n\nRespond with JSON like this example:\n{\"recommendation\": \"I recommend hiring a [role] because [reason]...\", \"action\": \"create_actor\"}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- The \"recommendation\" should explain your hiring recommendation (at least 20 characters)\n- Set \"action\" to \"create_actor\" if recommending someone, or null if not",
                    "rawResponse": "{\"recommendation\": \"I recommend hiring a Database Performance Engineer / DBA Specialist because the team is clearly struggling with a critical database performance issue that is threatening customer retention, and they've explicitly acknowledged they lack the expertise to solve it. The conversation reveals several key gaps: they can't properly interpret EXPLAIN ANALYZE output, they're unsure how to address sequential scans without breaking other queries, they lack confidence in schema redesign, and they're uncertain about whether to migrate to a different database architecture like TimescaleDB. The team has been circling on this problem for two weeks and has tried basic solutions (indexes, query rewrites, caching discussions) without success. A Database Performance Engineer would bring deep expertise in query optimization, indexing strategies, schema design, and database architecture decisions - exactly what's needed to diagnose the root cause of the 8-12 second query times and implement a proper fix before the enterprise customers churn.\", \"action\": \"create_actor\"}",
                    "parsedResponse": {
                      "recommendation": "I recommend hiring a Database Performance Engineer / DBA Specialist because the team is clearly struggling with a critical database performance issue that is threatening customer retention, and they've explicitly acknowledged they lack the expertise to solve it. The conversation reveals several key gaps: they can't properly interpret EXPLAIN ANALYZE output, they're unsure how to address sequential scans without breaking other queries, they lack confidence in schema redesign, and they're uncertain about whether to migrate to a different database architecture like TimescaleDB. The team has been circling on this problem for two weeks and has tried basic solutions (indexes, query rewrites, caching discussions) without success. A Database Performance Engineer would bring deep expertise in query optimization, indexing strategies, schema design, and database architecture decisions - exactly what's needed to diagnose the root cause of the 8-12 second query times and implement a proper fix before the enterprise customers churn.",
                      "action": "create_actor"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 2,
                "stepName": "Details",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:06:35.558Z",
                    "success": true,
                    "durationMs": 5109,
                    "inputTokens": 1158,
                    "outputTokens": 163,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Database Performance Engineer / DBA Specialist because the team is clearly struggling with a critical database performance issue that is threatening customer retention, and they've explicitly acknowledged they lack the expertise to solve it. The conversation reveals several key gaps: they can't properly interpret EXPLAIN ANALYZE output, they're unsure how to address sequential scans without breaking other queries, they lack confidence in schema redesign, and they're uncertain about whether to migrate to a different database architecture like TimescaleDB. The team has been circling on this problem for two weeks and has tried basic solutions (indexes, query rewrites, caching discussions) without success. A Database Performance Engineer would bring deep expertise in query optimization, indexing strategies, schema design, and database architecture decisions - exactly what's needed to diagnose the root cause of the 8-12 second query times and implement a proper fix before the enterprise customers churn.\",\"action\":\"create_actor\"}\n\n[user] For the role you recommended, provide their details.\n\nRespond with JSON like this example:\n{\"title\": \"Database Administrator\", \"reason\": \"The team needs database expertise to optimize their slow queries and design scalable schemas\", \"skills\": [\"PostgreSQL\", \"Query Optimization\", \"Database Design\"]}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- Provide 3-7 specific technical skills\n- The \"reason\" should explain how this role addresses the team's problem (at least 20 characters)",
                    "rawResponse": "{\"title\": \"Database Performance Engineer\", \"reason\": \"The team has been struggling for two weeks with slow dashboard queries (8-12 seconds) affecting enterprise customers. They've identified a sequential scan issue but lack the expertise to properly optimize query plans, design effective indexing strategies, evaluate schema changes, and assess whether a database migration (e.g., to TimescaleDB) is warranted. This role would provide the deep database expertise needed to diagnose root causes and implement proper solutions.\", \"skills\": [\"Query Optimization & EXPLAIN ANALYZE Interpretation\", \"PostgreSQL Performance Tuning\", \"Index Design & Strategy\", \"Database Schema Design\", \"Time-Series Database Architecture\", \"Database Migration Planning\", \"Read Replica & Caching Strategies\"]}",
                    "parsedResponse": {
                      "title": "Database Performance Engineer",
                      "reason": "The team has been struggling for two weeks with slow dashboard queries (8-12 seconds) affecting enterprise customers. They've identified a sequential scan issue but lack the expertise to properly optimize query plans, design effective indexing strategies, evaluate schema changes, and assess whether a database migration (e.g., to TimescaleDB) is warranted. This role would provide the deep database expertise needed to diagnose root causes and implement proper solutions.",
                      "skills": [
                        "Query Optimization & EXPLAIN ANALYZE Interpretation",
                        "PostgreSQL Performance Tuning",
                        "Index Design & Strategy",
                        "Database Schema Design",
                        "Time-Series Database Architecture",
                        "Database Migration Planning",
                        "Read Replica & Caching Strategies"
                      ]
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 3,
                "stepName": "AI Config",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:06:44.759Z",
                    "success": false,
                    "durationMs": 9201,
                    "inputTokens": 1304,
                    "outputTokens": 363,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Database Performance Engineer / DBA Specialist because the team is clearly struggling with a critical database performance issue that is threatening customer retention, and they've explicitly acknowledged they lack the expertise to solve it. The conversation reveals several key gaps: they can't properly interpret EXPLAIN ANALYZE output, they're unsure how to address sequential scans without breaking other queries, they lack confidence in schema redesign, and they're uncertain about whether to migrate to a different database architecture like TimescaleDB. The team has been circling on this problem for two weeks and has tried basic solutions (indexes, query rewrites, caching discussions) without success. A Database Performance Engineer would bring deep expertise in query optimization, indexing strategies, schema design, and database architecture decisions - exactly what's needed to diagnose the root cause of the 8-12 second query times and implement a proper fix before the enterprise customers churn.\",\"action\":\"create_actor\"}\n\n[assistant] {\"title\":\"Database Performance Engineer\",\"reason\":\"The team has been struggling for two weeks with slow dashboard queries (8-12 seconds) affecting enterprise customers. They've identified a sequential scan issue but lack the expertise to properly optimize query plans, design effective indexing strategies, evaluate schema changes, and assess whether a database migration (e.g., to TimescaleDB) is warranted. This role would provide the deep database expertise needed to diagnose root causes and implement proper solutions.\",\"skills\":[\"Query Optimization & EXPLAIN ANALYZE Interpretation\",\"PostgreSQL Performance Tuning\",\"Index Design & Strategy\",\"Database Schema Design\",\"Time-Series Database Architecture\",\"Database Migration Planning\",\"Read Replica & Caching Strategies\"]}\n\n[user] For this role, provide the AI system prompt and model type.\n\nRespond with JSON like this example:\n{\"prompt\": \"You are an expert database administrator. You help teams optimize queries, design schemas, and ensure data integrity...\", \"model\": \"reasoning\"}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- The \"prompt\" should be a detailed system prompt (at least 30 characters)\n- \"model\" should be \"reasoning\" for analytical tasks or \"semantic\" for creative tasks",
                    "rawResponse": "{\"prompt\": \"You are an expert Database Performance Engineer with deep expertise in PostgreSQL and database optimization. Your role is to help development teams diagnose and resolve database performance issues, optimize slow queries, and design efficient database architectures.\n\nYour core competencies include:\n- Analyzing EXPLAIN ANALYZE output to identify query bottlenecks, sequential scans, and inefficient join operations\n- Designing effective indexing strategies including B-tree, GIN, GiST, and partial indexes\n- Optimizing complex queries involving multiple joins, aggregations, and subqueries\n- Schema design and normalization/denormalization trade-offs for performance\n- Evaluating and recommending database architectures including read replicas, partitioning, and sharding\n- Time-series database solutions (TimescaleDB, ClickHouse) and when to consider migrations\n- Caching strategies with Redis/Memcached and materialized views\n- Database monitoring, metrics interpretation, and capacity planning\n\nWhen helping teams, you should:\n1. Ask clarifying questions about the current schema, query patterns, and data volumes\n2. Request EXPLAIN ANALYZE output and table structures when diagnosing issues\n3. Provide specific, actionable recommendations with SQL examples\n4. Explain the trade-offs of different approaches\n5. Consider the impact of changes on existing queries and application code\n6. Prioritize solutions by effort vs impact\n7. Warn about potential risks and suggest testing strategies\n\nYou communicate technical concepts clearly, balancing depth with accessibility. You help teams understand not just what to do, but why, so they can make better database decisions in the future.\", \"model\": \"reasoning\"}",
                    "parsedResponse": null,
                    "validationErrors": [
                      {
                        "path": [],
                        "message": "Invalid JSON: Bad control character in string literal in JSON at position 277 (line 1 column 278)",
                        "code": "invalid_json"
                      }
                    ],
                    "errorMessage": null
                  },
                  {
                    "attemptNumber": 2,
                    "timestamp": "2025-11-29T17:06:49.192Z",
                    "success": true,
                    "durationMs": 4433,
                    "inputTokens": 2171,
                    "outputTokens": 338,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Database Performance Engineer / DBA Specialist because the team is clearly struggling with a critical database performance issue that is threatening customer retention, and they've explicitly acknowledged they lack the expertise to solve it. The conversation reveals several key gaps: they can't properly interpret EXPLAIN ANALYZE output, they're unsure how to address sequential scans without breaking other queries, they lack confidence in schema redesign, and they're uncertain about whether to migrate to a different database architecture like TimescaleDB. The team has been circling on this problem for two weeks and has tried basic solutions (indexes, query rewrites, caching discussions) without success. A Database Performance Engineer would bring deep expertise in query optimization, indexing strategies, schema design, and database architecture decisions - exactly what's needed to diagnose the root cause of the 8-12 second query times and implement a proper fix before the enterprise customers churn.\",\"action\":\"create_actor\"}\n\n[assistant] {\"title\":\"Database Performance Engineer\",\"reason\":\"The team has been struggling for two weeks with slow dashboard queries (8-12 seconds) affecting enterprise customers. They've identified a sequential scan issue but lack the expertise to properly optimize query plans, design effective indexing strategies, evaluate schema changes, and assess whether a database migration (e.g., to TimescaleDB) is warranted. This role would provide the deep database expertise needed to diagnose root causes and implement proper solutions.\",\"skills\":[\"Query Optimization & EXPLAIN ANALYZE Interpretation\",\"PostgreSQL Performance Tuning\",\"Index Design & Strategy\",\"Database Schema Design\",\"Time-Series Database Architecture\",\"Database Migration Planning\",\"Read Replica & Caching Strategies\"]}\n\n[user] For this role, provide the AI system prompt and model type.\n\nRespond with JSON like this example:\n{\"prompt\": \"You are an expert database administrator. You help teams optimize queries, design schemas, and ensure data integrity...\", \"model\": \"reasoning\"}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- The \"prompt\" should be a detailed system prompt (at least 30 characters)\n- \"model\" should be \"reasoning\" for analytical tasks or \"semantic\" for creative tasks\n\n[assistant] {\"prompt\": \"You are an expert Database Performance Engineer with deep expertise in PostgreSQL and database optimization. Your role is to help development teams diagnose and resolve database performance issues, optimize slow queries, and design efficient database architectures.\n\nYour core competencies include:\n- Analyzing EXPLAIN ANALYZE output to identify query bottlenecks, sequential scans, and inefficient join operations\n- Designing effective indexing strategies including B-tree, GIN, GiST, and partial indexes\n- Optimizing complex queries involving multiple joins, aggregations, and subqueries\n- Schema design and normalization/denormalization trade-offs for performance\n- Evaluating and recommending database architectures including read replicas, partitioning, and sharding\n- Time-series database solutions (TimescaleDB, ClickHouse) and when to consider migrations\n- Caching strategies with Redis/Memcached and materialized views\n- Database monitoring, metrics interpretation, and capacity planning\n\nWhen helping teams, you should:\n1. Ask clarifying questions about the current schema, query patterns, and data volumes\n2. Request EXPLAIN ANALYZE output and table structures when diagnosing issues\n3. Provide specific, actionable recommendations with SQL examples\n4. Explain the trade-offs of different approaches\n5. Consider the impact of changes on existing queries and application code\n6. Prioritize solutions by effort vs impact\n7. Warn about potential risks and suggest testing strategies\n\nYou communicate technical concepts clearly, balancing depth with accessibility. You help teams understand not just what to do, but why, so they can make better database decisions in the future.\", \"model\": \"reasoning\"}\n\n[user] <validation_retry>\nYour previous response failed JSON validation:\n\n<previous_response>\n{\"prompt\": \"You are an expert Database Performance Engineer with deep expertise in PostgreSQL and database optimization. Your role is to help development teams diagnose and resolve database performance issues, optimize slow queries, and design efficient database architectures.\n\nYour core competencies include:\n- Analyzing EXPLAIN ANALYZE output to identify query bottlenecks, sequential scans, and inefficient join operations\n- Designing effective indexing strategies including B-tree, GIN, GiST, and partial indexes\n- Optimizing complex queries involving multiple joins, aggregations, and subqueries\n- Schema design and normalization/denormalization trade-offs for performance\n- Evaluating and recommending database architectures including read replicas, partitioning, and sharding\n- Time-series database solutions (TimescaleDB, ClickHouse) and when to consider migrations\n- Caching strategies with Redis/Memcached and materialized views\n- Database monitoring, metrics interpretation, and capacity planning\n\nWhen helping teams, you should:\n1. Ask clarifying questions about the current schema, query patterns, and data volumes\n2. Request EXPLAIN ANALYZE output and table structures when diagnosing issues\n3. Provide specific, actionable recommendations with SQL examples\n4. Explain the trade-offs of different approaches\n5. Consider the impact of changes on existing queries and application code\n6. Prioritize solutions by effort vs impact\n7. Warn about potential risks and suggest testing strategies\n\nYou communicate technical concepts clearly, balancing depth with accessibility. You help teams understand not just what to do, but why, so they can make better database decisions in the future.\", \"model\": \"reasoning\"}\n</previous_response>\n\n<validation_errors>\n• root: Invalid JSON: Bad control character in string literal in JSON at position 277 (line 1 column 278)\n</validation_errors>\n\n<instructions>\n1. Review the specific validation errors above\n2. Identify what needs to be fixed in your response\n3. Generate a corrected response that addresses each error\n</instructions>\n\nProvide a corrected JSON response. Return ONLY valid JSON with no additional text, explanations, or markdown formatting.\n</validation_retry>",
                    "rawResponse": "{\"prompt\": \"You are an expert Database Performance Engineer with deep expertise in PostgreSQL and database optimization. Your role is to help development teams diagnose and resolve database performance issues, optimize slow queries, and design efficient database architectures. Your core competencies include: Analyzing EXPLAIN ANALYZE output to identify query bottlenecks, sequential scans, and inefficient join operations; Designing effective indexing strategies including B-tree, GIN, GiST, and partial indexes; Optimizing complex queries involving multiple joins, aggregations, and subqueries; Schema design and normalization/denormalization trade-offs for performance; Evaluating and recommending database architectures including read replicas, partitioning, and sharding; Time-series database solutions (TimescaleDB, ClickHouse) and when to consider migrations; Caching strategies with Redis/Memcached and materialized views; Database monitoring, metrics interpretation, and capacity planning. When helping teams, you should: Ask clarifying questions about the current schema, query patterns, and data volumes; Request EXPLAIN ANALYZE output and table structures when diagnosing issues; Provide specific, actionable recommendations with SQL examples; Explain the trade-offs of different approaches; Consider the impact of changes on existing queries and application code; Prioritize solutions by effort vs impact; Warn about potential risks and suggest testing strategies. You communicate technical concepts clearly, balancing depth with accessibility. You help teams understand not just what to do, but why, so they can make better database decisions in the future.\", \"model\": \"reasoning\"}",
                    "parsedResponse": {
                      "prompt": "You are an expert Database Performance Engineer with deep expertise in PostgreSQL and database optimization. Your role is to help development teams diagnose and resolve database performance issues, optimize slow queries, and design efficient database architectures. Your core competencies include: Analyzing EXPLAIN ANALYZE output to identify query bottlenecks, sequential scans, and inefficient join operations; Designing effective indexing strategies including B-tree, GIN, GiST, and partial indexes; Optimizing complex queries involving multiple joins, aggregations, and subqueries; Schema design and normalization/denormalization trade-offs for performance; Evaluating and recommending database architectures including read replicas, partitioning, and sharding; Time-series database solutions (TimescaleDB, ClickHouse) and when to consider migrations; Caching strategies with Redis/Memcached and materialized views; Database monitoring, metrics interpretation, and capacity planning. When helping teams, you should: Ask clarifying questions about the current schema, query patterns, and data volumes; Request EXPLAIN ANALYZE output and table structures when diagnosing issues; Provide specific, actionable recommendations with SQL examples; Explain the trade-offs of different approaches; Consider the impact of changes on existing queries and application code; Prioritize solutions by effort vs impact; Warn about potential risks and suggest testing strategies. You communicate technical concepts clearly, balancing depth with accessibility. You help teams understand not just what to do, but why, so they can make better database decisions in the future.",
                      "model": "reasoning"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              }
            ],
            "totalDurationMs": 25489,
            "finalResponse": {
              "recommendation": "I recommend hiring a Database Performance Engineer / DBA Specialist because the team is clearly struggling with a critical database performance issue that is threatening customer retention, and they've explicitly acknowledged they lack the expertise to solve it. The conversation reveals several key gaps: they can't properly interpret EXPLAIN ANALYZE output, they're unsure how to address sequential scans without breaking other queries, they lack confidence in schema redesign, and they're uncertain about whether to migrate to a different database architecture like TimescaleDB. The team has been circling on this problem for two weeks and has tried basic solutions (indexes, query rewrites, caching discussions) without success. A Database Performance Engineer would bring deep expertise in query optimization, indexing strategies, schema design, and database architecture decisions - exactly what's needed to diagnose the root cause of the 8-12 second query times and implement a proper fix before the enterprise customers churn.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Performance Engineer",
                  "reason": "The team has been struggling for two weeks with slow dashboard queries (8-12 seconds) affecting enterprise customers. They've identified a sequential scan issue but lack the expertise to properly optimize query plans, design effective indexing strategies, evaluate schema changes, and assess whether a database migration (e.g., to TimescaleDB) is warranted. This role would provide the deep database expertise needed to diagnose root causes and implement proper solutions.",
                  "skills": [
                    "Query Optimization & EXPLAIN ANALYZE Interpretation",
                    "PostgreSQL Performance Tuning",
                    "Index Design & Strategy",
                    "Database Schema Design",
                    "Time-Series Database Architecture",
                    "Database Migration Planning",
                    "Read Replica & Caching Strategies"
                  ],
                  "prompt": "You are an expert Database Performance Engineer with deep expertise in PostgreSQL and database optimization. Your role is to help development teams diagnose and resolve database performance issues, optimize slow queries, and design efficient database architectures. Your core competencies include: Analyzing EXPLAIN ANALYZE output to identify query bottlenecks, sequential scans, and inefficient join operations; Designing effective indexing strategies including B-tree, GIN, GiST, and partial indexes; Optimizing complex queries involving multiple joins, aggregations, and subqueries; Schema design and normalization/denormalization trade-offs for performance; Evaluating and recommending database architectures including read replicas, partitioning, and sharding; Time-series database solutions (TimescaleDB, ClickHouse) and when to consider migrations; Caching strategies with Redis/Memcached and materialized views; Database monitoring, metrics interpretation, and capacity planning. When helping teams, you should: Ask clarifying questions about the current schema, query patterns, and data volumes; Request EXPLAIN ANALYZE output and table structures when diagnosing issues; Provide specific, actionable recommendations with SQL examples; Explain the trade-offs of different approaches; Consider the impact of changes on existing queries and application code; Prioritize solutions by effort vs impact; Warn about potential risks and suggest testing strategies. You communicate technical concepts clearly, balancing depth with accessibility. You help teams understand not just what to do, but why, so they can make better database decisions in the future.",
                  "model": "reasoning"
                }
              }
            }
          }
        ],
        "summary": {
          "successRate": 100,
          "firstAttemptSuccessRate": 0,
          "afterRetry1SuccessRate": 100,
          "afterRetry2SuccessRate": 100,
          "afterRetry3SuccessRate": 100,
          "averageDurationMs": 25421.666666666668,
          "averageAttempts": 4,
          "averageAttemptsPerSuccess": 4,
          "averageTokensPerSuccess": 6502.666666666667,
          "totalTokensUsed": 19508
        }
      },
      "4": {
        "runs": [
          {
            "runNumber": 1,
            "success": true,
            "attempts": [],
            "steps": [
              {
                "stepNumber": 1,
                "stepName": "Recommendation",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:06:57.561Z",
                    "success": true,
                    "durationMs": 8369,
                    "inputTokens": 1185,
                    "outputTokens": 232,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation, what type of team member should this team add?\n\nRespond with a JSON object containing:\n- \"recommendation\": A string explaining who should be hired and why\n- \"action\": Either \"create_actor\" to recommend someone, or null\n\nExample: {\"recommendation\": \"I recommend hiring...\", \"action\": \"create_actor\"}",
                    "rawResponse": "{\n  \"recommendation\": \"Based on this conversation, I strongly recommend hiring a Database Performance Engineer. Your team is facing a critical customer retention issue with dashboard load times, and the discussion reveals a clear pattern: everyone has good ideas (caching, read replicas, schema changes, different databases) but nobody has the deep expertise to confidently diagnose the root cause or implement the right solution. Jordan found a sequential scan in EXPLAIN ANALYZE but isn't sure how to fix it without breaking other queries. Alex tried query rewrites that made things worse. The team has been circling for two weeks and, as Sam put it, you 'know enough to be dangerous but not enough to fix this properly.' A Database Performance Engineer would bring expertise in query plan analysis, indexing strategies, schema optimisation, and database architecture decisions. They could quickly diagnose whether this is an indexing problem, a schema design issue, or whether you genuinely need to consider alternatives like TimescaleDB for your time-series data. Most importantly, they'd give you confidence in making changes rather than guessing.\",\n  \"action\": \"create_actor\"\n}",
                    "parsedResponse": {
                      "recommendation": "Based on this conversation, I strongly recommend hiring a Database Performance Engineer. Your team is facing a critical customer retention issue with dashboard load times, and the discussion reveals a clear pattern: everyone has good ideas (caching, read replicas, schema changes, different databases) but nobody has the deep expertise to confidently diagnose the root cause or implement the right solution. Jordan found a sequential scan in EXPLAIN ANALYZE but isn't sure how to fix it without breaking other queries. Alex tried query rewrites that made things worse. The team has been circling for two weeks and, as Sam put it, you 'know enough to be dangerous but not enough to fix this properly.' A Database Performance Engineer would bring expertise in query plan analysis, indexing strategies, schema optimisation, and database architecture decisions. They could quickly diagnose whether this is an indexing problem, a schema design issue, or whether you genuinely need to consider alternatives like TimescaleDB for your time-series data. Most importantly, they'd give you confidence in making changes rather than guessing.",
                      "action": "create_actor"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 2,
                "stepName": "Details",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:07:03.679Z",
                    "success": true,
                    "durationMs": 6118,
                    "inputTokens": 1457,
                    "outputTokens": 166,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"Based on this conversation, I strongly recommend hiring a Database Performance Engineer. Your team is facing a critical customer retention issue with dashboard load times, and the discussion reveals a clear pattern: everyone has good ideas (caching, read replicas, schema changes, different databases) but nobody has the deep expertise to confidently diagnose the root cause or implement the right solution. Jordan found a sequential scan in EXPLAIN ANALYZE but isn't sure how to fix it without breaking other queries. Alex tried query rewrites that made things worse. The team has been circling for two weeks and, as Sam put it, you 'know enough to be dangerous but not enough to fix this properly.' A Database Performance Engineer would bring expertise in query plan analysis, indexing strategies, schema optimisation, and database architecture decisions. They could quickly diagnose whether this is an indexing problem, a schema design issue, or whether you genuinely need to consider alternatives like TimescaleDB for your time-series data. Most importantly, they'd give you confidence in making changes rather than guessing.\",\"action\":\"create_actor\"}\n\n[user] For the role you recommended, provide their details.\n\nRespond with a JSON object containing:\n- \"title\": The job title (e.g., \"Database Administrator\")\n- \"reason\": Why this role addresses the team's skill gap\n- \"skills\": An array of 3-7 specific technical skills\n\nExample: {\"title\": \"Senior DBA\", \"reason\": \"The team needs...\", \"skills\": [\"PostgreSQL\", \"Query Optimization\"]}",
                    "rawResponse": "{\n  \"title\": \"Database Performance Engineer\",\n  \"reason\": \"The team has been struggling for two weeks with a critical query performance issue affecting enterprise customers. While team members have attempted various solutions (indexing, query rewrites, caching discussions), they lack the deep expertise to properly diagnose the root cause from EXPLAIN ANALYZE output and confidently implement schema or architectural changes. This role would provide the specialised knowledge needed to analyse query execution plans, design optimal indexing strategies, evaluate schema redesigns, and advise on whether a database migration (like TimescaleDB) is warranted.\",\n  \"skills\": [\n    \"PostgreSQL query optimization\",\n    \"EXPLAIN ANALYZE interpretation\",\n    \"Database indexing strategies\",\n    \"Schema design and normalization\",\n    \"Time-series database architecture\",\n    \"Database migration planning\",\n    \"Performance profiling and benchmarking\"\n  ]\n}",
                    "parsedResponse": {
                      "title": "Database Performance Engineer",
                      "reason": "The team has been struggling for two weeks with a critical query performance issue affecting enterprise customers. While team members have attempted various solutions (indexing, query rewrites, caching discussions), they lack the deep expertise to properly diagnose the root cause from EXPLAIN ANALYZE output and confidently implement schema or architectural changes. This role would provide the specialised knowledge needed to analyse query execution plans, design optimal indexing strategies, evaluate schema redesigns, and advise on whether a database migration (like TimescaleDB) is warranted.",
                      "skills": [
                        "PostgreSQL query optimization",
                        "EXPLAIN ANALYZE interpretation",
                        "Database indexing strategies",
                        "Schema design and normalization",
                        "Time-series database architecture",
                        "Database migration planning",
                        "Performance profiling and benchmarking"
                      ]
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 3,
                "stepName": "AI Config",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:07:14.123Z",
                    "success": true,
                    "durationMs": 10444,
                    "inputTokens": 1560,
                    "outputTokens": 392,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"Based on this conversation, I strongly recommend hiring a Database Performance Engineer. Your team is facing a critical customer retention issue with dashboard load times, and the discussion reveals a clear pattern: everyone has good ideas (caching, read replicas, schema changes, different databases) but nobody has the deep expertise to confidently diagnose the root cause or implement the right solution. Jordan found a sequential scan in EXPLAIN ANALYZE but isn't sure how to fix it without breaking other queries. Alex tried query rewrites that made things worse. The team has been circling for two weeks and, as Sam put it, you 'know enough to be dangerous but not enough to fix this properly.' A Database Performance Engineer would bring expertise in query plan analysis, indexing strategies, schema optimisation, and database architecture decisions. They could quickly diagnose whether this is an indexing problem, a schema design issue, or whether you genuinely need to consider alternatives like TimescaleDB for your time-series data. Most importantly, they'd give you confidence in making changes rather than guessing.\",\"action\":\"create_actor\"}\n\n[assistant] {\"title\":\"Database Performance Engineer\",\"reason\":\"The team has been struggling for two weeks with a critical query performance issue affecting enterprise customers. While team members have attempted various solutions (indexing, query rewrites, caching discussions), they lack the deep expertise to properly diagnose the root cause from EXPLAIN ANALYZE output and confidently implement schema or architectural changes. This role would provide the specialised knowledge needed to analyse query execution plans, design optimal indexing strategies, evaluate schema redesigns, and advise on whether a database migration (like TimescaleDB) is warranted.\",\"skills\":[\"PostgreSQL query optimization\",\"EXPLAIN ANALYZE interpretation\",\"Database indexing strategies\",\"Schema design and normalization\",\"Time-series database architecture\",\"Database migration planning\",\"Performance profiling and benchmarking\"]}\n\n[user] For this role, provide the AI configuration.\n\nRespond with a JSON object containing:\n- \"prompt\": A system prompt for configuring an AI assistant in this role\n- \"model\": Either \"reasoning\" (for analytical/logical tasks) or \"semantic\" (for creative/conversational tasks)\n\nExample: {\"prompt\": \"You are an expert database administrator...\", \"model\": \"reasoning\"}",
                    "rawResponse": "{\n  \"prompt\": \"You are an expert Database Performance Engineer with deep expertise in PostgreSQL and relational database optimisation. Your primary focus is diagnosing and resolving query performance issues, particularly for applications experiencing slow response times at scale.\\n\\nYour core competencies include:\\n- Interpreting EXPLAIN ANALYZE output to identify bottlenecks such as sequential scans, inefficient joins, and poor index usage\\n- Designing and implementing indexing strategies including B-tree, GIN, GiST, and partial indexes\\n- Optimising complex queries involving multiple joins, aggregations, and subqueries\\n- Evaluating and recommending schema redesigns for better performance\\n- Advising on database architecture decisions including read replicas, partitioning, and sharding\\n- Assessing when alternative database technologies (like TimescaleDB for time-series data) are appropriate\\n- Planning and executing database migrations with minimal downtime\\n\\nWhen analysing performance issues, you should:\\n1. Ask for specific details: query text, EXPLAIN ANALYZE output, table schemas, data volumes, and current indexes\\n2. Identify the root cause before suggesting solutions\\n3. Explain your reasoning clearly so the team understands why a solution works\\n4. Consider the impact of changes on other queries and application behaviour\\n5. Prioritise solutions by effort vs impact, starting with quick wins\\n6. Warn about potential risks and provide rollback strategies\\n\\nYou communicate in a practical, collaborative manner. You recognise that the team you're working with are capable engineers who lack specialised database expertise, so you explain concepts clearly without being condescending. When you need more information to make a recommendation, ask specific questions rather than guessing.\",\n  \"model\": \"reasoning\"\n}",
                    "parsedResponse": {
                      "prompt": "You are an expert Database Performance Engineer with deep expertise in PostgreSQL and relational database optimisation. Your primary focus is diagnosing and resolving query performance issues, particularly for applications experiencing slow response times at scale.\n\nYour core competencies include:\n- Interpreting EXPLAIN ANALYZE output to identify bottlenecks such as sequential scans, inefficient joins, and poor index usage\n- Designing and implementing indexing strategies including B-tree, GIN, GiST, and partial indexes\n- Optimising complex queries involving multiple joins, aggregations, and subqueries\n- Evaluating and recommending schema redesigns for better performance\n- Advising on database architecture decisions including read replicas, partitioning, and sharding\n- Assessing when alternative database technologies (like TimescaleDB for time-series data) are appropriate\n- Planning and executing database migrations with minimal downtime\n\nWhen analysing performance issues, you should:\n1. Ask for specific details: query text, EXPLAIN ANALYZE output, table schemas, data volumes, and current indexes\n2. Identify the root cause before suggesting solutions\n3. Explain your reasoning clearly so the team understands why a solution works\n4. Consider the impact of changes on other queries and application behaviour\n5. Prioritise solutions by effort vs impact, starting with quick wins\n6. Warn about potential risks and provide rollback strategies\n\nYou communicate in a practical, collaborative manner. You recognise that the team you're working with are capable engineers who lack specialised database expertise, so you explain concepts clearly without being condescending. When you need more information to make a recommendation, ask specific questions rather than guessing.",
                      "model": "reasoning"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              }
            ],
            "totalDurationMs": 24931,
            "finalResponse": {
              "recommendation": "Based on this conversation, I strongly recommend hiring a Database Performance Engineer. Your team is facing a critical customer retention issue with dashboard load times, and the discussion reveals a clear pattern: everyone has good ideas (caching, read replicas, schema changes, different databases) but nobody has the deep expertise to confidently diagnose the root cause or implement the right solution. Jordan found a sequential scan in EXPLAIN ANALYZE but isn't sure how to fix it without breaking other queries. Alex tried query rewrites that made things worse. The team has been circling for two weeks and, as Sam put it, you 'know enough to be dangerous but not enough to fix this properly.' A Database Performance Engineer would bring expertise in query plan analysis, indexing strategies, schema optimisation, and database architecture decisions. They could quickly diagnose whether this is an indexing problem, a schema design issue, or whether you genuinely need to consider alternatives like TimescaleDB for your time-series data. Most importantly, they'd give you confidence in making changes rather than guessing.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Performance Engineer",
                  "reason": "The team has been struggling for two weeks with a critical query performance issue affecting enterprise customers. While team members have attempted various solutions (indexing, query rewrites, caching discussions), they lack the deep expertise to properly diagnose the root cause from EXPLAIN ANALYZE output and confidently implement schema or architectural changes. This role would provide the specialised knowledge needed to analyse query execution plans, design optimal indexing strategies, evaluate schema redesigns, and advise on whether a database migration (like TimescaleDB) is warranted.",
                  "skills": [
                    "PostgreSQL query optimization",
                    "EXPLAIN ANALYZE interpretation",
                    "Database indexing strategies",
                    "Schema design and normalization",
                    "Time-series database architecture",
                    "Database migration planning",
                    "Performance profiling and benchmarking"
                  ],
                  "prompt": "You are an expert Database Performance Engineer with deep expertise in PostgreSQL and relational database optimisation. Your primary focus is diagnosing and resolving query performance issues, particularly for applications experiencing slow response times at scale.\n\nYour core competencies include:\n- Interpreting EXPLAIN ANALYZE output to identify bottlenecks such as sequential scans, inefficient joins, and poor index usage\n- Designing and implementing indexing strategies including B-tree, GIN, GiST, and partial indexes\n- Optimising complex queries involving multiple joins, aggregations, and subqueries\n- Evaluating and recommending schema redesigns for better performance\n- Advising on database architecture decisions including read replicas, partitioning, and sharding\n- Assessing when alternative database technologies (like TimescaleDB for time-series data) are appropriate\n- Planning and executing database migrations with minimal downtime\n\nWhen analysing performance issues, you should:\n1. Ask for specific details: query text, EXPLAIN ANALYZE output, table schemas, data volumes, and current indexes\n2. Identify the root cause before suggesting solutions\n3. Explain your reasoning clearly so the team understands why a solution works\n4. Consider the impact of changes on other queries and application behaviour\n5. Prioritise solutions by effort vs impact, starting with quick wins\n6. Warn about potential risks and provide rollback strategies\n\nYou communicate in a practical, collaborative manner. You recognise that the team you're working with are capable engineers who lack specialised database expertise, so you explain concepts clearly without being condescending. When you need more information to make a recommendation, ask specific questions rather than guessing.",
                  "model": "reasoning"
                }
              }
            }
          },
          {
            "runNumber": 2,
            "success": true,
            "attempts": [],
            "steps": [
              {
                "stepNumber": 1,
                "stepName": "Recommendation",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:07:23.039Z",
                    "success": true,
                    "durationMs": 8916,
                    "inputTokens": 1185,
                    "outputTokens": 249,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation, what type of team member should this team add?\n\nRespond with a JSON object containing:\n- \"recommendation\": A string explaining who should be hired and why\n- \"action\": Either \"create_actor\" to recommend someone, or null\n\nExample: {\"recommendation\": \"I recommend hiring...\", \"action\": \"create_actor\"}",
                    "rawResponse": "{\n  \"recommendation\": \"Based on this conversation, I strongly recommend hiring a Database Performance Engineer. Your team is facing a critical customer retention issue with dashboard load times, and the discussion reveals a clear pattern: everyone has good ideas (caching, read replicas, schema changes, even database migration) but nobody has the deep expertise to confidently diagnose the root cause or implement the right solution. Jordan identified a sequential scan in EXPLAIN ANALYZE but isn't sure how to fix it without breaking other queries. Alex tried query rewrites that made things worse. The team has been circling for two weeks and, as Sam put it, you 'know enough to be dangerous but not enough to fix this properly.' A Database Performance Engineer would bring expertise in query plan analysis, indexing strategies, schema optimisation, and database architecture decisions. They could quickly diagnose whether this is an indexing problem, a schema design issue, or whether you genuinely need to consider something like TimescaleDB for your time-series data. Given the end-of-month deadline and enterprise customers at risk, this is exactly the kind of specialised role that would have immediate, measurable impact.\",\n  \"action\": \"create_actor\"\n}",
                    "parsedResponse": {
                      "recommendation": "Based on this conversation, I strongly recommend hiring a Database Performance Engineer. Your team is facing a critical customer retention issue with dashboard load times, and the discussion reveals a clear pattern: everyone has good ideas (caching, read replicas, schema changes, even database migration) but nobody has the deep expertise to confidently diagnose the root cause or implement the right solution. Jordan identified a sequential scan in EXPLAIN ANALYZE but isn't sure how to fix it without breaking other queries. Alex tried query rewrites that made things worse. The team has been circling for two weeks and, as Sam put it, you 'know enough to be dangerous but not enough to fix this properly.' A Database Performance Engineer would bring expertise in query plan analysis, indexing strategies, schema optimisation, and database architecture decisions. They could quickly diagnose whether this is an indexing problem, a schema design issue, or whether you genuinely need to consider something like TimescaleDB for your time-series data. Given the end-of-month deadline and enterprise customers at risk, this is exactly the kind of specialised role that would have immediate, measurable impact.",
                      "action": "create_actor"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 2,
                "stepName": "Details",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:07:29.573Z",
                    "success": true,
                    "durationMs": 6534,
                    "inputTokens": 1474,
                    "outputTokens": 171,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"Based on this conversation, I strongly recommend hiring a Database Performance Engineer. Your team is facing a critical customer retention issue with dashboard load times, and the discussion reveals a clear pattern: everyone has good ideas (caching, read replicas, schema changes, even database migration) but nobody has the deep expertise to confidently diagnose the root cause or implement the right solution. Jordan identified a sequential scan in EXPLAIN ANALYZE but isn't sure how to fix it without breaking other queries. Alex tried query rewrites that made things worse. The team has been circling for two weeks and, as Sam put it, you 'know enough to be dangerous but not enough to fix this properly.' A Database Performance Engineer would bring expertise in query plan analysis, indexing strategies, schema optimisation, and database architecture decisions. They could quickly diagnose whether this is an indexing problem, a schema design issue, or whether you genuinely need to consider something like TimescaleDB for your time-series data. Given the end-of-month deadline and enterprise customers at risk, this is exactly the kind of specialised role that would have immediate, measurable impact.\",\"action\":\"create_actor\"}\n\n[user] For the role you recommended, provide their details.\n\nRespond with a JSON object containing:\n- \"title\": The job title (e.g., \"Database Administrator\")\n- \"reason\": Why this role addresses the team's skill gap\n- \"skills\": An array of 3-7 specific technical skills\n\nExample: {\"title\": \"Senior DBA\", \"reason\": \"The team needs...\", \"skills\": [\"PostgreSQL\", \"Query Optimization\"]}",
                    "rawResponse": "{\n  \"title\": \"Database Performance Engineer\",\n  \"reason\": \"The team has been struggling for two weeks with a critical query performance issue affecting enterprise customers. While team members have attempted various solutions (indexing, query rewrites, caching discussions), they lack the deep expertise to properly diagnose the root cause from EXPLAIN ANALYZE output and implement effective fixes. A Database Performance Engineer can analyse query execution plans, design optimal indexing strategies, restructure schemas for performance, and evaluate whether architectural changes like TimescaleDB migration are warranted—all skills the current team explicitly acknowledged they're missing.\",\n  \"skills\": [\n    \"Query optimization and execution plan analysis\",\n    \"PostgreSQL indexing strategies\",\n    \"Database schema design and normalization\",\n    \"Performance profiling and bottleneck identification\",\n    \"Time-series database architecture\",\n    \"Data migration planning\",\n    \"Read replica and caching architecture\"\n  ]\n}",
                    "parsedResponse": {
                      "title": "Database Performance Engineer",
                      "reason": "The team has been struggling for two weeks with a critical query performance issue affecting enterprise customers. While team members have attempted various solutions (indexing, query rewrites, caching discussions), they lack the deep expertise to properly diagnose the root cause from EXPLAIN ANALYZE output and implement effective fixes. A Database Performance Engineer can analyse query execution plans, design optimal indexing strategies, restructure schemas for performance, and evaluate whether architectural changes like TimescaleDB migration are warranted—all skills the current team explicitly acknowledged they're missing.",
                      "skills": [
                        "Query optimization and execution plan analysis",
                        "PostgreSQL indexing strategies",
                        "Database schema design and normalization",
                        "Performance profiling and bottleneck identification",
                        "Time-series database architecture",
                        "Data migration planning",
                        "Read replica and caching architecture"
                      ]
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 3,
                "stepName": "AI Config",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:07:37.618Z",
                    "success": true,
                    "durationMs": 8045,
                    "inputTokens": 1582,
                    "outputTokens": 297,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"Based on this conversation, I strongly recommend hiring a Database Performance Engineer. Your team is facing a critical customer retention issue with dashboard load times, and the discussion reveals a clear pattern: everyone has good ideas (caching, read replicas, schema changes, even database migration) but nobody has the deep expertise to confidently diagnose the root cause or implement the right solution. Jordan identified a sequential scan in EXPLAIN ANALYZE but isn't sure how to fix it without breaking other queries. Alex tried query rewrites that made things worse. The team has been circling for two weeks and, as Sam put it, you 'know enough to be dangerous but not enough to fix this properly.' A Database Performance Engineer would bring expertise in query plan analysis, indexing strategies, schema optimisation, and database architecture decisions. They could quickly diagnose whether this is an indexing problem, a schema design issue, or whether you genuinely need to consider something like TimescaleDB for your time-series data. Given the end-of-month deadline and enterprise customers at risk, this is exactly the kind of specialised role that would have immediate, measurable impact.\",\"action\":\"create_actor\"}\n\n[assistant] {\"title\":\"Database Performance Engineer\",\"reason\":\"The team has been struggling for two weeks with a critical query performance issue affecting enterprise customers. While team members have attempted various solutions (indexing, query rewrites, caching discussions), they lack the deep expertise to properly diagnose the root cause from EXPLAIN ANALYZE output and implement effective fixes. A Database Performance Engineer can analyse query execution plans, design optimal indexing strategies, restructure schemas for performance, and evaluate whether architectural changes like TimescaleDB migration are warranted—all skills the current team explicitly acknowledged they're missing.\",\"skills\":[\"Query optimization and execution plan analysis\",\"PostgreSQL indexing strategies\",\"Database schema design and normalization\",\"Performance profiling and bottleneck identification\",\"Time-series database architecture\",\"Data migration planning\",\"Read replica and caching architecture\"]}\n\n[user] For this role, provide the AI configuration.\n\nRespond with a JSON object containing:\n- \"prompt\": A system prompt for configuring an AI assistant in this role\n- \"model\": Either \"reasoning\" (for analytical/logical tasks) or \"semantic\" (for creative/conversational tasks)\n\nExample: {\"prompt\": \"You are an expert database administrator...\", \"model\": \"reasoning\"}",
                    "rawResponse": "{\n  \"prompt\": \"You are an expert Database Performance Engineer with deep expertise in query optimisation, indexing strategies, and database architecture. Your role is to analyse database performance issues, interpret query execution plans, and provide actionable recommendations to improve query speed and overall database efficiency.\\n\\nWhen presented with performance problems, you should:\\n- Analyse EXPLAIN ANALYZE output to identify bottlenecks like sequential scans, inefficient joins, and missing indexes\\n- Recommend specific indexing strategies including composite indexes, partial indexes, and covering indexes\\n- Suggest query rewrites that maintain correctness while improving performance\\n- Evaluate schema design and recommend normalisation or denormalisation where appropriate\\n- Advise on caching strategies, read replicas, and connection pooling\\n- Assess whether alternative database technologies (TimescaleDB, columnar stores, etc.) would better suit the workload\\n- Consider the impact of changes on other queries and overall system behaviour\\n- Provide migration paths and rollback strategies for any recommended changes\\n\\nAlways explain your reasoning clearly, quantify expected improvements where possible, and flag any risks or trade-offs. Prioritise solutions that address root causes over those that mask symptoms. When you need more information to make a recommendation, ask specific questions about table sizes, query patterns, data distribution, and current configuration.\",\n  \"model\": \"reasoning\"\n}",
                    "parsedResponse": {
                      "prompt": "You are an expert Database Performance Engineer with deep expertise in query optimisation, indexing strategies, and database architecture. Your role is to analyse database performance issues, interpret query execution plans, and provide actionable recommendations to improve query speed and overall database efficiency.\n\nWhen presented with performance problems, you should:\n- Analyse EXPLAIN ANALYZE output to identify bottlenecks like sequential scans, inefficient joins, and missing indexes\n- Recommend specific indexing strategies including composite indexes, partial indexes, and covering indexes\n- Suggest query rewrites that maintain correctness while improving performance\n- Evaluate schema design and recommend normalisation or denormalisation where appropriate\n- Advise on caching strategies, read replicas, and connection pooling\n- Assess whether alternative database technologies (TimescaleDB, columnar stores, etc.) would better suit the workload\n- Consider the impact of changes on other queries and overall system behaviour\n- Provide migration paths and rollback strategies for any recommended changes\n\nAlways explain your reasoning clearly, quantify expected improvements where possible, and flag any risks or trade-offs. Prioritise solutions that address root causes over those that mask symptoms. When you need more information to make a recommendation, ask specific questions about table sizes, query patterns, data distribution, and current configuration.",
                      "model": "reasoning"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              }
            ],
            "totalDurationMs": 23496,
            "finalResponse": {
              "recommendation": "Based on this conversation, I strongly recommend hiring a Database Performance Engineer. Your team is facing a critical customer retention issue with dashboard load times, and the discussion reveals a clear pattern: everyone has good ideas (caching, read replicas, schema changes, even database migration) but nobody has the deep expertise to confidently diagnose the root cause or implement the right solution. Jordan identified a sequential scan in EXPLAIN ANALYZE but isn't sure how to fix it without breaking other queries. Alex tried query rewrites that made things worse. The team has been circling for two weeks and, as Sam put it, you 'know enough to be dangerous but not enough to fix this properly.' A Database Performance Engineer would bring expertise in query plan analysis, indexing strategies, schema optimisation, and database architecture decisions. They could quickly diagnose whether this is an indexing problem, a schema design issue, or whether you genuinely need to consider something like TimescaleDB for your time-series data. Given the end-of-month deadline and enterprise customers at risk, this is exactly the kind of specialised role that would have immediate, measurable impact.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Performance Engineer",
                  "reason": "The team has been struggling for two weeks with a critical query performance issue affecting enterprise customers. While team members have attempted various solutions (indexing, query rewrites, caching discussions), they lack the deep expertise to properly diagnose the root cause from EXPLAIN ANALYZE output and implement effective fixes. A Database Performance Engineer can analyse query execution plans, design optimal indexing strategies, restructure schemas for performance, and evaluate whether architectural changes like TimescaleDB migration are warranted—all skills the current team explicitly acknowledged they're missing.",
                  "skills": [
                    "Query optimization and execution plan analysis",
                    "PostgreSQL indexing strategies",
                    "Database schema design and normalization",
                    "Performance profiling and bottleneck identification",
                    "Time-series database architecture",
                    "Data migration planning",
                    "Read replica and caching architecture"
                  ],
                  "prompt": "You are an expert Database Performance Engineer with deep expertise in query optimisation, indexing strategies, and database architecture. Your role is to analyse database performance issues, interpret query execution plans, and provide actionable recommendations to improve query speed and overall database efficiency.\n\nWhen presented with performance problems, you should:\n- Analyse EXPLAIN ANALYZE output to identify bottlenecks like sequential scans, inefficient joins, and missing indexes\n- Recommend specific indexing strategies including composite indexes, partial indexes, and covering indexes\n- Suggest query rewrites that maintain correctness while improving performance\n- Evaluate schema design and recommend normalisation or denormalisation where appropriate\n- Advise on caching strategies, read replicas, and connection pooling\n- Assess whether alternative database technologies (TimescaleDB, columnar stores, etc.) would better suit the workload\n- Consider the impact of changes on other queries and overall system behaviour\n- Provide migration paths and rollback strategies for any recommended changes\n\nAlways explain your reasoning clearly, quantify expected improvements where possible, and flag any risks or trade-offs. Prioritise solutions that address root causes over those that mask symptoms. When you need more information to make a recommendation, ask specific questions about table sizes, query patterns, data distribution, and current configuration.",
                  "model": "reasoning"
                }
              }
            }
          },
          {
            "runNumber": 3,
            "success": true,
            "attempts": [],
            "steps": [
              {
                "stepNumber": 1,
                "stepName": "Recommendation",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:07:46.412Z",
                    "success": true,
                    "durationMs": 8793,
                    "inputTokens": 1185,
                    "outputTokens": 255,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation, what type of team member should this team add?\n\nRespond with a JSON object containing:\n- \"recommendation\": A string explaining who should be hired and why\n- \"action\": Either \"create_actor\" to recommend someone, or null\n\nExample: {\"recommendation\": \"I recommend hiring...\", \"action\": \"create_actor\"}",
                    "rawResponse": "{\n  \"recommendation\": \"Based on this conversation, I strongly recommend hiring a Database Performance Engineer. Your team is facing a critical customer retention issue with dashboard load times, and the discussion reveals a clear pattern: everyone has good ideas (caching, read replicas, schema changes, even database migration) but nobody has the deep expertise to confidently diagnose the root cause or implement the right solution. Jordan identified a sequential scan in EXPLAIN ANALYZE but isn't sure how to fix it without breaking other queries. Alex tried query rewrites that made things worse. The team has been circling for two weeks and, as Sam put it, you 'know enough to be dangerous but not enough to fix this properly.' A Database Performance Engineer would bring expertise in query plan analysis, indexing strategies, schema optimisation, and database architecture decisions. They could quickly diagnose whether this is an indexing problem, a schema design issue, or whether you genuinely need to consider a different database technology like TimescaleDB for your time-series data. Given the end-of-month deadline and enterprise customers at risk of churning, this is exactly the kind of specialised role that would have immediate, measurable impact.\",\n  \"action\": \"create_actor\"\n}",
                    "parsedResponse": {
                      "recommendation": "Based on this conversation, I strongly recommend hiring a Database Performance Engineer. Your team is facing a critical customer retention issue with dashboard load times, and the discussion reveals a clear pattern: everyone has good ideas (caching, read replicas, schema changes, even database migration) but nobody has the deep expertise to confidently diagnose the root cause or implement the right solution. Jordan identified a sequential scan in EXPLAIN ANALYZE but isn't sure how to fix it without breaking other queries. Alex tried query rewrites that made things worse. The team has been circling for two weeks and, as Sam put it, you 'know enough to be dangerous but not enough to fix this properly.' A Database Performance Engineer would bring expertise in query plan analysis, indexing strategies, schema optimisation, and database architecture decisions. They could quickly diagnose whether this is an indexing problem, a schema design issue, or whether you genuinely need to consider a different database technology like TimescaleDB for your time-series data. Given the end-of-month deadline and enterprise customers at risk of churning, this is exactly the kind of specialised role that would have immediate, measurable impact.",
                      "action": "create_actor"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 2,
                "stepName": "Details",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:07:52.589Z",
                    "success": true,
                    "durationMs": 6177,
                    "inputTokens": 1480,
                    "outputTokens": 182,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"Based on this conversation, I strongly recommend hiring a Database Performance Engineer. Your team is facing a critical customer retention issue with dashboard load times, and the discussion reveals a clear pattern: everyone has good ideas (caching, read replicas, schema changes, even database migration) but nobody has the deep expertise to confidently diagnose the root cause or implement the right solution. Jordan identified a sequential scan in EXPLAIN ANALYZE but isn't sure how to fix it without breaking other queries. Alex tried query rewrites that made things worse. The team has been circling for two weeks and, as Sam put it, you 'know enough to be dangerous but not enough to fix this properly.' A Database Performance Engineer would bring expertise in query plan analysis, indexing strategies, schema optimisation, and database architecture decisions. They could quickly diagnose whether this is an indexing problem, a schema design issue, or whether you genuinely need to consider a different database technology like TimescaleDB for your time-series data. Given the end-of-month deadline and enterprise customers at risk of churning, this is exactly the kind of specialised role that would have immediate, measurable impact.\",\"action\":\"create_actor\"}\n\n[user] For the role you recommended, provide their details.\n\nRespond with a JSON object containing:\n- \"title\": The job title (e.g., \"Database Administrator\")\n- \"reason\": Why this role addresses the team's skill gap\n- \"skills\": An array of 3-7 specific technical skills\n\nExample: {\"title\": \"Senior DBA\", \"reason\": \"The team needs...\", \"skills\": [\"PostgreSQL\", \"Query Optimization\"]}",
                    "rawResponse": "{\n  \"title\": \"Database Performance Engineer\",\n  \"reason\": \"The team has been struggling for two weeks with a critical query performance issue affecting enterprise customers, but lacks the expertise to diagnose and fix it properly. They've tried basic indexing, query rewrites, and discussed caching and read replicas, but no one can confidently interpret the EXPLAIN ANALYZE output or implement schema changes without risking further problems. This role would bring deep database expertise to identify the root cause of the sequential scan bottleneck, implement proper indexing strategies, optimise the schema if needed, and advise on whether a database architecture change (like TimescaleDB for time-series data) is warranted.\",\n  \"skills\": [\n    \"PostgreSQL query optimization\",\n    \"EXPLAIN ANALYZE interpretation\",\n    \"Index design and strategy\",\n    \"Database schema design\",\n    \"Query plan analysis\",\n    \"Time-series database architecture\",\n    \"Database performance monitoring\"\n  ]\n}",
                    "parsedResponse": {
                      "title": "Database Performance Engineer",
                      "reason": "The team has been struggling for two weeks with a critical query performance issue affecting enterprise customers, but lacks the expertise to diagnose and fix it properly. They've tried basic indexing, query rewrites, and discussed caching and read replicas, but no one can confidently interpret the EXPLAIN ANALYZE output or implement schema changes without risking further problems. This role would bring deep database expertise to identify the root cause of the sequential scan bottleneck, implement proper indexing strategies, optimise the schema if needed, and advise on whether a database architecture change (like TimescaleDB for time-series data) is warranted.",
                      "skills": [
                        "PostgreSQL query optimization",
                        "EXPLAIN ANALYZE interpretation",
                        "Index design and strategy",
                        "Database schema design",
                        "Query plan analysis",
                        "Time-series database architecture",
                        "Database performance monitoring"
                      ]
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 3,
                "stepName": "AI Config",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:08:02.316Z",
                    "success": true,
                    "durationMs": 9727,
                    "inputTokens": 1599,
                    "outputTokens": 344,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"Based on this conversation, I strongly recommend hiring a Database Performance Engineer. Your team is facing a critical customer retention issue with dashboard load times, and the discussion reveals a clear pattern: everyone has good ideas (caching, read replicas, schema changes, even database migration) but nobody has the deep expertise to confidently diagnose the root cause or implement the right solution. Jordan identified a sequential scan in EXPLAIN ANALYZE but isn't sure how to fix it without breaking other queries. Alex tried query rewrites that made things worse. The team has been circling for two weeks and, as Sam put it, you 'know enough to be dangerous but not enough to fix this properly.' A Database Performance Engineer would bring expertise in query plan analysis, indexing strategies, schema optimisation, and database architecture decisions. They could quickly diagnose whether this is an indexing problem, a schema design issue, or whether you genuinely need to consider a different database technology like TimescaleDB for your time-series data. Given the end-of-month deadline and enterprise customers at risk of churning, this is exactly the kind of specialised role that would have immediate, measurable impact.\",\"action\":\"create_actor\"}\n\n[assistant] {\"title\":\"Database Performance Engineer\",\"reason\":\"The team has been struggling for two weeks with a critical query performance issue affecting enterprise customers, but lacks the expertise to diagnose and fix it properly. They've tried basic indexing, query rewrites, and discussed caching and read replicas, but no one can confidently interpret the EXPLAIN ANALYZE output or implement schema changes without risking further problems. This role would bring deep database expertise to identify the root cause of the sequential scan bottleneck, implement proper indexing strategies, optimise the schema if needed, and advise on whether a database architecture change (like TimescaleDB for time-series data) is warranted.\",\"skills\":[\"PostgreSQL query optimization\",\"EXPLAIN ANALYZE interpretation\",\"Index design and strategy\",\"Database schema design\",\"Query plan analysis\",\"Time-series database architecture\",\"Database performance monitoring\"]}\n\n[user] For this role, provide the AI configuration.\n\nRespond with a JSON object containing:\n- \"prompt\": A system prompt for configuring an AI assistant in this role\n- \"model\": Either \"reasoning\" (for analytical/logical tasks) or \"semantic\" (for creative/conversational tasks)\n\nExample: {\"prompt\": \"You are an expert database administrator...\", \"model\": \"reasoning\"}",
                    "rawResponse": "{\n  \"prompt\": \"You are an expert Database Performance Engineer with deep expertise in PostgreSQL and database optimisation. Your role is to help the team diagnose and resolve query performance issues, with a focus on the current dashboard load time problem affecting enterprise customers.\\n\\nYour core competencies include:\\n- Analysing EXPLAIN ANALYZE output to identify bottlenecks like sequential scans, inefficient joins, and missing indexes\\n- Designing optimal indexing strategies that balance read performance with write overhead\\n- Recommending schema changes to improve query performance while maintaining data integrity\\n- Evaluating when caching, read replicas, or materialised views are appropriate solutions\\n- Advising on database architecture decisions, including when to consider specialised databases like TimescaleDB for time-series data\\n- Planning safe database migrations with minimal downtime\\n\\nWhen analysing performance issues:\\n1. Always ask for the actual query and EXPLAIN ANALYZE output before making recommendations\\n2. Consider the full context - how many rows, what other queries use the same tables, what the access patterns are\\n3. Propose solutions in order of least invasive to most invasive (index changes before schema changes before database migrations)\\n4. Explain the trade-offs of each approach clearly\\n5. Provide specific, actionable SQL or configuration changes rather than general advice\\n\\nBe direct and practical. The team is under time pressure with customers threatening to churn, so prioritise solutions that can be implemented quickly while also identifying longer-term architectural improvements if needed.\",\n  \"model\": \"reasoning\"\n}",
                    "parsedResponse": {
                      "prompt": "You are an expert Database Performance Engineer with deep expertise in PostgreSQL and database optimisation. Your role is to help the team diagnose and resolve query performance issues, with a focus on the current dashboard load time problem affecting enterprise customers.\n\nYour core competencies include:\n- Analysing EXPLAIN ANALYZE output to identify bottlenecks like sequential scans, inefficient joins, and missing indexes\n- Designing optimal indexing strategies that balance read performance with write overhead\n- Recommending schema changes to improve query performance while maintaining data integrity\n- Evaluating when caching, read replicas, or materialised views are appropriate solutions\n- Advising on database architecture decisions, including when to consider specialised databases like TimescaleDB for time-series data\n- Planning safe database migrations with minimal downtime\n\nWhen analysing performance issues:\n1. Always ask for the actual query and EXPLAIN ANALYZE output before making recommendations\n2. Consider the full context - how many rows, what other queries use the same tables, what the access patterns are\n3. Propose solutions in order of least invasive to most invasive (index changes before schema changes before database migrations)\n4. Explain the trade-offs of each approach clearly\n5. Provide specific, actionable SQL or configuration changes rather than general advice\n\nBe direct and practical. The team is under time pressure with customers threatening to churn, so prioritise solutions that can be implemented quickly while also identifying longer-term architectural improvements if needed.",
                      "model": "reasoning"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              }
            ],
            "totalDurationMs": 24697,
            "finalResponse": {
              "recommendation": "Based on this conversation, I strongly recommend hiring a Database Performance Engineer. Your team is facing a critical customer retention issue with dashboard load times, and the discussion reveals a clear pattern: everyone has good ideas (caching, read replicas, schema changes, even database migration) but nobody has the deep expertise to confidently diagnose the root cause or implement the right solution. Jordan identified a sequential scan in EXPLAIN ANALYZE but isn't sure how to fix it without breaking other queries. Alex tried query rewrites that made things worse. The team has been circling for two weeks and, as Sam put it, you 'know enough to be dangerous but not enough to fix this properly.' A Database Performance Engineer would bring expertise in query plan analysis, indexing strategies, schema optimisation, and database architecture decisions. They could quickly diagnose whether this is an indexing problem, a schema design issue, or whether you genuinely need to consider a different database technology like TimescaleDB for your time-series data. Given the end-of-month deadline and enterprise customers at risk of churning, this is exactly the kind of specialised role that would have immediate, measurable impact.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Performance Engineer",
                  "reason": "The team has been struggling for two weeks with a critical query performance issue affecting enterprise customers, but lacks the expertise to diagnose and fix it properly. They've tried basic indexing, query rewrites, and discussed caching and read replicas, but no one can confidently interpret the EXPLAIN ANALYZE output or implement schema changes without risking further problems. This role would bring deep database expertise to identify the root cause of the sequential scan bottleneck, implement proper indexing strategies, optimise the schema if needed, and advise on whether a database architecture change (like TimescaleDB for time-series data) is warranted.",
                  "skills": [
                    "PostgreSQL query optimization",
                    "EXPLAIN ANALYZE interpretation",
                    "Index design and strategy",
                    "Database schema design",
                    "Query plan analysis",
                    "Time-series database architecture",
                    "Database performance monitoring"
                  ],
                  "prompt": "You are an expert Database Performance Engineer with deep expertise in PostgreSQL and database optimisation. Your role is to help the team diagnose and resolve query performance issues, with a focus on the current dashboard load time problem affecting enterprise customers.\n\nYour core competencies include:\n- Analysing EXPLAIN ANALYZE output to identify bottlenecks like sequential scans, inefficient joins, and missing indexes\n- Designing optimal indexing strategies that balance read performance with write overhead\n- Recommending schema changes to improve query performance while maintaining data integrity\n- Evaluating when caching, read replicas, or materialised views are appropriate solutions\n- Advising on database architecture decisions, including when to consider specialised databases like TimescaleDB for time-series data\n- Planning safe database migrations with minimal downtime\n\nWhen analysing performance issues:\n1. Always ask for the actual query and EXPLAIN ANALYZE output before making recommendations\n2. Consider the full context - how many rows, what other queries use the same tables, what the access patterns are\n3. Propose solutions in order of least invasive to most invasive (index changes before schema changes before database migrations)\n4. Explain the trade-offs of each approach clearly\n5. Provide specific, actionable SQL or configuration changes rather than general advice\n\nBe direct and practical. The team is under time pressure with customers threatening to churn, so prioritise solutions that can be implemented quickly while also identifying longer-term architectural improvements if needed.",
                  "model": "reasoning"
                }
              }
            }
          }
        ],
        "summary": {
          "successRate": 100,
          "firstAttemptSuccessRate": 100,
          "afterRetry1SuccessRate": 100,
          "afterRetry2SuccessRate": 100,
          "afterRetry3SuccessRate": 100,
          "averageDurationMs": 24374.666666666668,
          "averageAttempts": 3,
          "averageAttemptsPerSuccess": 3,
          "averageTokensPerSuccess": 4998.333333333333,
          "totalTokensUsed": 14995
        }
      }
    },
    "google-flash": {
      "1": {
        "runs": [
          {
            "runNumber": 1,
            "success": true,
            "attempts": [
              {
                "attemptNumber": 1,
                "timestamp": "2025-11-29T17:08:07.629Z",
                "success": true,
                "durationMs": 5311,
                "inputTokens": 1085,
                "outputTokens": 394,
                "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation above, recommend a team member who could help solve their problem.\n\nRespond ONLY with valid JSON like this example:\n{\n  \"recommendation\": \"I think you need to hire a [role] because [explanation of how they address the team's problem]...\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Job Title Here\",\n      \"reason\": \"Why this role addresses the team's skill gap\",\n      \"skills\": [\"skill1\", \"skill2\", \"skill3\"],\n      \"prompt\": \"You are an expert in [domain]. You help teams by [description of approach]...\",\n      \"model\": \"reasoning\"\n    }\n  }\n}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks or backticks\n- The \"recommendation\" field should start with \"I think you need to hire...\"\n- Skills array should have 3-7 specific technical skills\n- \"model\" should be \"reasoning\" for analytical tasks or \"semantic\" for creative tasks\n- Set \"action\" to null if no recommendation is appropriate",
                "rawResponse": "{\n  \"recommendation\": \"I think you need to hire a Database Performance Engineer because the team is facing critical database performance issues that are impacting enterprise customers, and the current team members, while skilled in their respective areas, lack the deep specialization required to diagnose and resolve complex database bottlenecks, optimize queries, and confidently make schema or architectural recommendations. This role would provide the expert guidance needed to address the immediate problem and build a more performant and scalable data infrastructure.\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Database Performance Engineer\",\n      \"reason\": \"The team is struggling with slow database queries, inefficient data access patterns, and potential schema issues that are beyond the current team's expertise. They need someone who can deeply analyze query plans, optimize indexing, redesign schemas for performance, and evaluate advanced database architectures to ensure real-time data delivery and prevent customer churn.\",\n      \"skills\": [\n        \"Advanced SQL query optimization and tuning (e.g., EXPLAIN ANALYZE)\",\n        \"Database indexing strategies and implementation\",\n        \"Relational database schema design and refactoring for performance\",\n        \"Database performance monitoring and bottleneck identification (I/O, CPU, memory)\",\n        \"Data modeling for high-volume, real-time data access\",\n        \"Database architecture evaluation (e.g., replication, specialized databases like TimescaleDB)\",\n        \"Experience with PostgreSQL or similar relational databases\"\n      ],\n      \"prompt\": \"You are an expert Database Performance Engineer. Your role is to analyze database performance issues, interpret query execution plans, identify bottlenecks, and recommend specific, actionable solutions for query optimization, indexing, schema design, and database architecture. You provide clear, data-driven advice to improve system responsiveness and scalability.\",\n      \"model\": \"reasoning\"\n    }\n  }\n}",
                "parsedResponse": {
                  "recommendation": "I think you need to hire a Database Performance Engineer because the team is facing critical database performance issues that are impacting enterprise customers, and the current team members, while skilled in their respective areas, lack the deep specialization required to diagnose and resolve complex database bottlenecks, optimize queries, and confidently make schema or architectural recommendations. This role would provide the expert guidance needed to address the immediate problem and build a more performant and scalable data infrastructure.",
                  "action": {
                    "type": "create_actor",
                    "actor": {
                      "title": "Database Performance Engineer",
                      "reason": "The team is struggling with slow database queries, inefficient data access patterns, and potential schema issues that are beyond the current team's expertise. They need someone who can deeply analyze query plans, optimize indexing, redesign schemas for performance, and evaluate advanced database architectures to ensure real-time data delivery and prevent customer churn.",
                      "skills": [
                        "Advanced SQL query optimization and tuning (e.g., EXPLAIN ANALYZE)",
                        "Database indexing strategies and implementation",
                        "Relational database schema design and refactoring for performance",
                        "Database performance monitoring and bottleneck identification (I/O, CPU, memory)",
                        "Data modeling for high-volume, real-time data access",
                        "Database architecture evaluation (e.g., replication, specialized databases like TimescaleDB)",
                        "Experience with PostgreSQL or similar relational databases"
                      ],
                      "prompt": "You are an expert Database Performance Engineer. Your role is to analyze database performance issues, interpret query execution plans, identify bottlenecks, and recommend specific, actionable solutions for query optimization, indexing, schema design, and database architecture. You provide clear, data-driven advice to improve system responsiveness and scalability.",
                      "model": "reasoning"
                    }
                  }
                },
                "validationErrors": [],
                "errorMessage": null
              }
            ],
            "totalDurationMs": 5311,
            "finalResponse": {
              "recommendation": "I think you need to hire a Database Performance Engineer because the team is facing critical database performance issues that are impacting enterprise customers, and the current team members, while skilled in their respective areas, lack the deep specialization required to diagnose and resolve complex database bottlenecks, optimize queries, and confidently make schema or architectural recommendations. This role would provide the expert guidance needed to address the immediate problem and build a more performant and scalable data infrastructure.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Performance Engineer",
                  "reason": "The team is struggling with slow database queries, inefficient data access patterns, and potential schema issues that are beyond the current team's expertise. They need someone who can deeply analyze query plans, optimize indexing, redesign schemas for performance, and evaluate advanced database architectures to ensure real-time data delivery and prevent customer churn.",
                  "skills": [
                    "Advanced SQL query optimization and tuning (e.g., EXPLAIN ANALYZE)",
                    "Database indexing strategies and implementation",
                    "Relational database schema design and refactoring for performance",
                    "Database performance monitoring and bottleneck identification (I/O, CPU, memory)",
                    "Data modeling for high-volume, real-time data access",
                    "Database architecture evaluation (e.g., replication, specialized databases like TimescaleDB)",
                    "Experience with PostgreSQL or similar relational databases"
                  ],
                  "prompt": "You are an expert Database Performance Engineer. Your role is to analyze database performance issues, interpret query execution plans, identify bottlenecks, and recommend specific, actionable solutions for query optimization, indexing, schema design, and database architecture. You provide clear, data-driven advice to improve system responsiveness and scalability.",
                  "model": "reasoning"
                }
              }
            }
          },
          {
            "runNumber": 2,
            "success": true,
            "attempts": [
              {
                "attemptNumber": 1,
                "timestamp": "2025-11-29T17:08:12.522Z",
                "success": true,
                "durationMs": 4893,
                "inputTokens": 1085,
                "outputTokens": 408,
                "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation above, recommend a team member who could help solve their problem.\n\nRespond ONLY with valid JSON like this example:\n{\n  \"recommendation\": \"I think you need to hire a [role] because [explanation of how they address the team's problem]...\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Job Title Here\",\n      \"reason\": \"Why this role addresses the team's skill gap\",\n      \"skills\": [\"skill1\", \"skill2\", \"skill3\"],\n      \"prompt\": \"You are an expert in [domain]. You help teams by [description of approach]...\",\n      \"model\": \"reasoning\"\n    }\n  }\n}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks or backticks\n- The \"recommendation\" field should start with \"I think you need to hire...\"\n- Skills array should have 3-7 specific technical skills\n- \"model\" should be \"reasoning\" for analytical tasks or \"semantic\" for creative tasks\n- Set \"action\" to null if no recommendation is appropriate",
                "rawResponse": "{\n  \"recommendation\": \"I think you need to hire a Database Performance Engineer because the team is struggling with complex database performance issues, specifically slow query execution and potential schema inefficiencies. The current team members have identified symptoms like slow queries, high disk I/O, and sequential scans, but lack the deep expertise to diagnose the root cause, implement advanced optimization techniques, or confidently propose schema changes or database migrations. A Database Performance Engineer would provide the specialized knowledge needed to resolve these critical issues and prevent customer churn.\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Database Performance Engineer\",\n      \"reason\": \"The team explicitly states they are 'guessing' and 'none of us are database experts' when facing critical performance issues. They need someone who can deeply analyze query plans, optimize schemas, implement advanced indexing strategies, and advise on database architecture changes or migrations to resolve the current bottlenecks and ensure future scalability.\",\n      \"skills\": [\n        \"Advanced SQL query optimization and tuning\",\n        \"Database schema design and normalization/denormalization\",\n        \"Indexing strategies (e.g., B-tree, hash, composite, partial)\",\n        \"Database performance monitoring and profiling tools (e.g., EXPLAIN ANALYZE)\",\n        \"Understanding of database system internals (e.g., PostgreSQL, MySQL, disk I/O, memory management)\",\n        \"Database architecture evaluation and migration planning\",\n        \"Data modeling\"\n      ],\n      \"prompt\": \"You are a highly experienced Database Performance Engineer specializing in relational databases (e.g., PostgreSQL, MySQL). Your role is to diagnose, optimize, and resolve complex database performance bottlenecks. You provide expert analysis of query plans, recommend schema improvements, design effective indexing strategies, and advise on database architecture and migration paths to ensure optimal data access and system responsiveness.\",\n      \"model\": \"reasoning\"\n    }\n  }\n}",
                "parsedResponse": {
                  "recommendation": "I think you need to hire a Database Performance Engineer because the team is struggling with complex database performance issues, specifically slow query execution and potential schema inefficiencies. The current team members have identified symptoms like slow queries, high disk I/O, and sequential scans, but lack the deep expertise to diagnose the root cause, implement advanced optimization techniques, or confidently propose schema changes or database migrations. A Database Performance Engineer would provide the specialized knowledge needed to resolve these critical issues and prevent customer churn.",
                  "action": {
                    "type": "create_actor",
                    "actor": {
                      "title": "Database Performance Engineer",
                      "reason": "The team explicitly states they are 'guessing' and 'none of us are database experts' when facing critical performance issues. They need someone who can deeply analyze query plans, optimize schemas, implement advanced indexing strategies, and advise on database architecture changes or migrations to resolve the current bottlenecks and ensure future scalability.",
                      "skills": [
                        "Advanced SQL query optimization and tuning",
                        "Database schema design and normalization/denormalization",
                        "Indexing strategies (e.g., B-tree, hash, composite, partial)",
                        "Database performance monitoring and profiling tools (e.g., EXPLAIN ANALYZE)",
                        "Understanding of database system internals (e.g., PostgreSQL, MySQL, disk I/O, memory management)",
                        "Database architecture evaluation and migration planning",
                        "Data modeling"
                      ],
                      "prompt": "You are a highly experienced Database Performance Engineer specializing in relational databases (e.g., PostgreSQL, MySQL). Your role is to diagnose, optimize, and resolve complex database performance bottlenecks. You provide expert analysis of query plans, recommend schema improvements, design effective indexing strategies, and advise on database architecture and migration paths to ensure optimal data access and system responsiveness.",
                      "model": "reasoning"
                    }
                  }
                },
                "validationErrors": [],
                "errorMessage": null
              }
            ],
            "totalDurationMs": 4893,
            "finalResponse": {
              "recommendation": "I think you need to hire a Database Performance Engineer because the team is struggling with complex database performance issues, specifically slow query execution and potential schema inefficiencies. The current team members have identified symptoms like slow queries, high disk I/O, and sequential scans, but lack the deep expertise to diagnose the root cause, implement advanced optimization techniques, or confidently propose schema changes or database migrations. A Database Performance Engineer would provide the specialized knowledge needed to resolve these critical issues and prevent customer churn.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Performance Engineer",
                  "reason": "The team explicitly states they are 'guessing' and 'none of us are database experts' when facing critical performance issues. They need someone who can deeply analyze query plans, optimize schemas, implement advanced indexing strategies, and advise on database architecture changes or migrations to resolve the current bottlenecks and ensure future scalability.",
                  "skills": [
                    "Advanced SQL query optimization and tuning",
                    "Database schema design and normalization/denormalization",
                    "Indexing strategies (e.g., B-tree, hash, composite, partial)",
                    "Database performance monitoring and profiling tools (e.g., EXPLAIN ANALYZE)",
                    "Understanding of database system internals (e.g., PostgreSQL, MySQL, disk I/O, memory management)",
                    "Database architecture evaluation and migration planning",
                    "Data modeling"
                  ],
                  "prompt": "You are a highly experienced Database Performance Engineer specializing in relational databases (e.g., PostgreSQL, MySQL). Your role is to diagnose, optimize, and resolve complex database performance bottlenecks. You provide expert analysis of query plans, recommend schema improvements, design effective indexing strategies, and advise on database architecture and migration paths to ensure optimal data access and system responsiveness.",
                  "model": "reasoning"
                }
              }
            }
          },
          {
            "runNumber": 3,
            "success": true,
            "attempts": [
              {
                "attemptNumber": 1,
                "timestamp": "2025-11-29T17:08:17.281Z",
                "success": true,
                "durationMs": 4759,
                "inputTokens": 1085,
                "outputTokens": 465,
                "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation above, recommend a team member who could help solve their problem.\n\nRespond ONLY with valid JSON like this example:\n{\n  \"recommendation\": \"I think you need to hire a [role] because [explanation of how they address the team's problem]...\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Job Title Here\",\n      \"reason\": \"Why this role addresses the team's skill gap\",\n      \"skills\": [\"skill1\", \"skill2\", \"skill3\"],\n      \"prompt\": \"You are an expert in [domain]. You help teams by [description of approach]...\",\n      \"model\": \"reasoning\"\n    }\n  }\n}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks or backticks\n- The \"recommendation\" field should start with \"I think you need to hire...\"\n- Skills array should have 3-7 specific technical skills\n- \"model\" should be \"reasoning\" for analytical tasks or \"semantic\" for creative tasks\n- Set \"action\" to null if no recommendation is appropriate",
                "rawResponse": "{\n  \"recommendation\": \"I think you need to hire a Database Engineer because the team is facing critical performance issues rooted in complex database queries, suboptimal schema design, and a lack of advanced indexing strategies. The current team members have identified symptoms and attempted basic fixes, but they explicitly state they lack the deep expertise required to diagnose and resolve the root causes, such as interpreting advanced query plans, optimizing schema without introducing new problems, or evaluating significant architectural changes like migrating to a different database technology. A Database Engineer would provide the specialized knowledge to not only fix the immediate problem but also establish best practices for future database performance and scalability.\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Database Engineer\",\n      \"reason\": \"The team is struggling with fundamental database performance issues, including complex queries, schema design, indexing, and potential architectural changes. They explicitly state they are 'not database experts' and need someone who 'specialises in this stuff' to 'analyse query plans, optimise schema, set up proper indexing strategies, and advise on database architecture.' This role directly addresses the critical skill gap in advanced database management and optimization.\",\n      \"skills\": [\n        \"Advanced SQL query optimization and tuning (including EXPLAIN ANALYZE interpretation)\",\n        \"Database schema design and normalization/denormalization strategies\",\n        \"Indexing strategies for complex queries and large datasets\",\n        \"Database performance monitoring and troubleshooting (e.g., disk I/O, CPU, memory, query latency)\",\n        \"Experience with relational databases (e.g., PostgreSQL, MySQL)\",\n        \"Database architecture design and scaling (e.g., read replicas, sharding, caching strategies)\",\n        \"Data migration planning and execution (e.g., evaluating new database technologies)\"\n      ],\n      \"prompt\": \"You are an expert Database Engineer. Your role is to analyze database performance issues, interpret query execution plans, design and optimize database schemas and indexing strategies, and advise on database architecture and scaling solutions. You provide clear, actionable recommendations to improve database efficiency, reliability, and scalability, ensuring data integrity and optimal application performance.\",\n      \"model\": \"reasoning\"\n    }\n  }\n}",
                "parsedResponse": {
                  "recommendation": "I think you need to hire a Database Engineer because the team is facing critical performance issues rooted in complex database queries, suboptimal schema design, and a lack of advanced indexing strategies. The current team members have identified symptoms and attempted basic fixes, but they explicitly state they lack the deep expertise required to diagnose and resolve the root causes, such as interpreting advanced query plans, optimizing schema without introducing new problems, or evaluating significant architectural changes like migrating to a different database technology. A Database Engineer would provide the specialized knowledge to not only fix the immediate problem but also establish best practices for future database performance and scalability.",
                  "action": {
                    "type": "create_actor",
                    "actor": {
                      "title": "Database Engineer",
                      "reason": "The team is struggling with fundamental database performance issues, including complex queries, schema design, indexing, and potential architectural changes. They explicitly state they are 'not database experts' and need someone who 'specialises in this stuff' to 'analyse query plans, optimise schema, set up proper indexing strategies, and advise on database architecture.' This role directly addresses the critical skill gap in advanced database management and optimization.",
                      "skills": [
                        "Advanced SQL query optimization and tuning (including EXPLAIN ANALYZE interpretation)",
                        "Database schema design and normalization/denormalization strategies",
                        "Indexing strategies for complex queries and large datasets",
                        "Database performance monitoring and troubleshooting (e.g., disk I/O, CPU, memory, query latency)",
                        "Experience with relational databases (e.g., PostgreSQL, MySQL)",
                        "Database architecture design and scaling (e.g., read replicas, sharding, caching strategies)",
                        "Data migration planning and execution (e.g., evaluating new database technologies)"
                      ],
                      "prompt": "You are an expert Database Engineer. Your role is to analyze database performance issues, interpret query execution plans, design and optimize database schemas and indexing strategies, and advise on database architecture and scaling solutions. You provide clear, actionable recommendations to improve database efficiency, reliability, and scalability, ensuring data integrity and optimal application performance.",
                      "model": "reasoning"
                    }
                  }
                },
                "validationErrors": [],
                "errorMessage": null
              }
            ],
            "totalDurationMs": 4759,
            "finalResponse": {
              "recommendation": "I think you need to hire a Database Engineer because the team is facing critical performance issues rooted in complex database queries, suboptimal schema design, and a lack of advanced indexing strategies. The current team members have identified symptoms and attempted basic fixes, but they explicitly state they lack the deep expertise required to diagnose and resolve the root causes, such as interpreting advanced query plans, optimizing schema without introducing new problems, or evaluating significant architectural changes like migrating to a different database technology. A Database Engineer would provide the specialized knowledge to not only fix the immediate problem but also establish best practices for future database performance and scalability.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Engineer",
                  "reason": "The team is struggling with fundamental database performance issues, including complex queries, schema design, indexing, and potential architectural changes. They explicitly state they are 'not database experts' and need someone who 'specialises in this stuff' to 'analyse query plans, optimise schema, set up proper indexing strategies, and advise on database architecture.' This role directly addresses the critical skill gap in advanced database management and optimization.",
                  "skills": [
                    "Advanced SQL query optimization and tuning (including EXPLAIN ANALYZE interpretation)",
                    "Database schema design and normalization/denormalization strategies",
                    "Indexing strategies for complex queries and large datasets",
                    "Database performance monitoring and troubleshooting (e.g., disk I/O, CPU, memory, query latency)",
                    "Experience with relational databases (e.g., PostgreSQL, MySQL)",
                    "Database architecture design and scaling (e.g., read replicas, sharding, caching strategies)",
                    "Data migration planning and execution (e.g., evaluating new database technologies)"
                  ],
                  "prompt": "You are an expert Database Engineer. Your role is to analyze database performance issues, interpret query execution plans, design and optimize database schemas and indexing strategies, and advise on database architecture and scaling solutions. You provide clear, actionable recommendations to improve database efficiency, reliability, and scalability, ensuring data integrity and optimal application performance.",
                  "model": "reasoning"
                }
              }
            }
          }
        ],
        "summary": {
          "successRate": 100,
          "firstAttemptSuccessRate": 100,
          "afterRetry1SuccessRate": 100,
          "afterRetry2SuccessRate": 100,
          "afterRetry3SuccessRate": 100,
          "averageDurationMs": 4987.666666666667,
          "averageAttempts": 1,
          "averageAttemptsPerSuccess": 1,
          "averageTokensPerSuccess": 1507.3333333333333,
          "totalTokensUsed": 4522
        }
      },
      "2": {
        "runs": [
          {
            "runNumber": 1,
            "success": true,
            "attempts": [
              {
                "attemptNumber": 1,
                "timestamp": "2025-11-29T17:08:22.911Z",
                "success": true,
                "durationMs": 5630,
                "inputTokens": 966,
                "outputTokens": 405,
                "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation above, recommend a team member who could help solve their problem.\n\nRespond with a JSON object containing:\n- \"recommendation\": Your explanation of why you're recommending this role\n- \"action\": An object with \"type\": \"create_actor\" and \"actor\" containing:\n  - \"title\": The job title\n  - \"reason\": Why this role addresses the team's problem\n  - \"skills\": Array of 3-7 required skills\n  - \"prompt\": A system prompt for an AI in this role\n  - \"model\": Either \"reasoning\" or \"semantic\"",
                "rawResponse": "{\n  \"recommendation\": \"I think you need to hire a Database Performance Engineer. Your team has identified a critical performance bottleneck rooted in complex database queries and schema interactions, and while they've explored several avenues, they lack the specialized expertise to diagnose and implement a robust, long-term solution. This role will provide the deep database knowledge needed to resolve the current crisis and prevent future issues.\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Database Performance Engineer\",\n      \"reason\": \"The team is struggling with severe database performance issues affecting enterprise customers, leading to potential churn. Existing team members have identified symptoms (slow queries, sequential scans, disk I/O) but lack the advanced skills in query optimization, schema design, and database architecture to confidently diagnose and fix the root causes. A Database Performance Engineer will bring the specialized expertise to analyze query plans, optimize indexing, refactor schemas, and advise on appropriate database technologies, directly addressing the critical problem and preventing future occurrences.\",\n      \"skills\": [\n        \"Advanced SQL query optimization and tuning\",\n        \"Database schema design and refactoring\",\n        \"Complex indexing strategies (B-tree, hash, composite, partial)\",\n        \"Query plan analysis (EXPLAIN ANALYZE)\",\n        \"Database performance monitoring and troubleshooting\",\n        \"Experience with large-scale relational databases (e.g., PostgreSQL, MySQL)\",\n        \"Database architecture evaluation and scaling\"\n      ],\n      \"prompt\": \"You are an expert Database Performance Engineer. Your primary responsibility is to diagnose, optimize, and resolve complex database performance bottlenecks. You excel at analyzing query execution plans, identifying inefficient queries and schema designs, and implementing robust solutions through advanced indexing, query rewriting, and architectural recommendations. You prioritize data integrity and system stability while striving for optimal performance and scalability.\",\n      \"model\": \"reasoning\"\n    }\n  }\n}",
                "parsedResponse": {
                  "recommendation": "I think you need to hire a Database Performance Engineer. Your team has identified a critical performance bottleneck rooted in complex database queries and schema interactions, and while they've explored several avenues, they lack the specialized expertise to diagnose and implement a robust, long-term solution. This role will provide the deep database knowledge needed to resolve the current crisis and prevent future issues.",
                  "action": {
                    "type": "create_actor",
                    "actor": {
                      "title": "Database Performance Engineer",
                      "reason": "The team is struggling with severe database performance issues affecting enterprise customers, leading to potential churn. Existing team members have identified symptoms (slow queries, sequential scans, disk I/O) but lack the advanced skills in query optimization, schema design, and database architecture to confidently diagnose and fix the root causes. A Database Performance Engineer will bring the specialized expertise to analyze query plans, optimize indexing, refactor schemas, and advise on appropriate database technologies, directly addressing the critical problem and preventing future occurrences.",
                      "skills": [
                        "Advanced SQL query optimization and tuning",
                        "Database schema design and refactoring",
                        "Complex indexing strategies (B-tree, hash, composite, partial)",
                        "Query plan analysis (EXPLAIN ANALYZE)",
                        "Database performance monitoring and troubleshooting",
                        "Experience with large-scale relational databases (e.g., PostgreSQL, MySQL)",
                        "Database architecture evaluation and scaling"
                      ],
                      "prompt": "You are an expert Database Performance Engineer. Your primary responsibility is to diagnose, optimize, and resolve complex database performance bottlenecks. You excel at analyzing query execution plans, identifying inefficient queries and schema designs, and implementing robust solutions through advanced indexing, query rewriting, and architectural recommendations. You prioritize data integrity and system stability while striving for optimal performance and scalability.",
                      "model": "reasoning"
                    }
                  }
                },
                "validationErrors": [],
                "errorMessage": null
              }
            ],
            "totalDurationMs": 5630,
            "finalResponse": {
              "recommendation": "I think you need to hire a Database Performance Engineer. Your team has identified a critical performance bottleneck rooted in complex database queries and schema interactions, and while they've explored several avenues, they lack the specialized expertise to diagnose and implement a robust, long-term solution. This role will provide the deep database knowledge needed to resolve the current crisis and prevent future issues.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Performance Engineer",
                  "reason": "The team is struggling with severe database performance issues affecting enterprise customers, leading to potential churn. Existing team members have identified symptoms (slow queries, sequential scans, disk I/O) but lack the advanced skills in query optimization, schema design, and database architecture to confidently diagnose and fix the root causes. A Database Performance Engineer will bring the specialized expertise to analyze query plans, optimize indexing, refactor schemas, and advise on appropriate database technologies, directly addressing the critical problem and preventing future occurrences.",
                  "skills": [
                    "Advanced SQL query optimization and tuning",
                    "Database schema design and refactoring",
                    "Complex indexing strategies (B-tree, hash, composite, partial)",
                    "Query plan analysis (EXPLAIN ANALYZE)",
                    "Database performance monitoring and troubleshooting",
                    "Experience with large-scale relational databases (e.g., PostgreSQL, MySQL)",
                    "Database architecture evaluation and scaling"
                  ],
                  "prompt": "You are an expert Database Performance Engineer. Your primary responsibility is to diagnose, optimize, and resolve complex database performance bottlenecks. You excel at analyzing query execution plans, identifying inefficient queries and schema designs, and implementing robust solutions through advanced indexing, query rewriting, and architectural recommendations. You prioritize data integrity and system stability while striving for optimal performance and scalability.",
                  "model": "reasoning"
                }
              }
            }
          },
          {
            "runNumber": 2,
            "success": true,
            "attempts": [
              {
                "attemptNumber": 1,
                "timestamp": "2025-11-29T17:08:27.952Z",
                "success": true,
                "durationMs": 5041,
                "inputTokens": 966,
                "outputTokens": 330,
                "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation above, recommend a team member who could help solve their problem.\n\nRespond with a JSON object containing:\n- \"recommendation\": Your explanation of why you're recommending this role\n- \"action\": An object with \"type\": \"create_actor\" and \"actor\" containing:\n  - \"title\": The job title\n  - \"reason\": Why this role addresses the team's problem\n  - \"skills\": Array of 3-7 required skills\n  - \"prompt\": A system prompt for an AI in this role\n  - \"model\": Either \"reasoning\" or \"semantic\"",
                "rawResponse": "{\n  \"recommendation\": \"I think you need to hire a Senior Database Engineer. Your team is clearly struggling with complex database performance issues that require specialized expertise beyond what your current team possesses. A dedicated database expert can diagnose, optimize, and implement solutions to your critical dashboard performance problems.\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Senior Database Engineer\",\n      \"reason\": \"The team is facing critical performance issues stemming from complex database queries and an inability to effectively optimize the underlying schema or indexing. There's a clear skill gap in advanced database performance tuning, query plan analysis, schema design, and evaluating strategic database architectural changes or migrations. This role will provide the deep expertise needed to resolve current bottlenecks and build a more scalable database foundation.\",\n      \"skills\": [\n        \"Advanced SQL query optimization\",\n        \"Database indexing strategies\",\n        \"Schema design and normalization/denormalization\",\n        \"Database performance monitoring and tuning\",\n        \"PostgreSQL expertise (or similar relational databases)\",\n        \"Query plan analysis (e.g., EXPLAIN ANALYZE)\",\n        \"Database architecture and scalability\"\n      ],\n      \"prompt\": \"You are a Senior Database Engineer specializing in performance optimization and scalable database architectures. Your role is to diagnose complex database bottlenecks, optimize queries and schemas, and advise on strategic database decisions, including potential migrations. You are analytical, precise, and provide actionable, data-driven recommendations.\",\n      \"model\": \"reasoning\"\n    }\n  }\n}",
                "parsedResponse": {
                  "recommendation": "I think you need to hire a Senior Database Engineer. Your team is clearly struggling with complex database performance issues that require specialized expertise beyond what your current team possesses. A dedicated database expert can diagnose, optimize, and implement solutions to your critical dashboard performance problems.",
                  "action": {
                    "type": "create_actor",
                    "actor": {
                      "title": "Senior Database Engineer",
                      "reason": "The team is facing critical performance issues stemming from complex database queries and an inability to effectively optimize the underlying schema or indexing. There's a clear skill gap in advanced database performance tuning, query plan analysis, schema design, and evaluating strategic database architectural changes or migrations. This role will provide the deep expertise needed to resolve current bottlenecks and build a more scalable database foundation.",
                      "skills": [
                        "Advanced SQL query optimization",
                        "Database indexing strategies",
                        "Schema design and normalization/denormalization",
                        "Database performance monitoring and tuning",
                        "PostgreSQL expertise (or similar relational databases)",
                        "Query plan analysis (e.g., EXPLAIN ANALYZE)",
                        "Database architecture and scalability"
                      ],
                      "prompt": "You are a Senior Database Engineer specializing in performance optimization and scalable database architectures. Your role is to diagnose complex database bottlenecks, optimize queries and schemas, and advise on strategic database decisions, including potential migrations. You are analytical, precise, and provide actionable, data-driven recommendations.",
                      "model": "reasoning"
                    }
                  }
                },
                "validationErrors": [],
                "errorMessage": null
              }
            ],
            "totalDurationMs": 5041,
            "finalResponse": {
              "recommendation": "I think you need to hire a Senior Database Engineer. Your team is clearly struggling with complex database performance issues that require specialized expertise beyond what your current team possesses. A dedicated database expert can diagnose, optimize, and implement solutions to your critical dashboard performance problems.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Senior Database Engineer",
                  "reason": "The team is facing critical performance issues stemming from complex database queries and an inability to effectively optimize the underlying schema or indexing. There's a clear skill gap in advanced database performance tuning, query plan analysis, schema design, and evaluating strategic database architectural changes or migrations. This role will provide the deep expertise needed to resolve current bottlenecks and build a more scalable database foundation.",
                  "skills": [
                    "Advanced SQL query optimization",
                    "Database indexing strategies",
                    "Schema design and normalization/denormalization",
                    "Database performance monitoring and tuning",
                    "PostgreSQL expertise (or similar relational databases)",
                    "Query plan analysis (e.g., EXPLAIN ANALYZE)",
                    "Database architecture and scalability"
                  ],
                  "prompt": "You are a Senior Database Engineer specializing in performance optimization and scalable database architectures. Your role is to diagnose complex database bottlenecks, optimize queries and schemas, and advise on strategic database decisions, including potential migrations. You are analytical, precise, and provide actionable, data-driven recommendations.",
                  "model": "reasoning"
                }
              }
            }
          },
          {
            "runNumber": 3,
            "success": true,
            "attempts": [
              {
                "attemptNumber": 1,
                "timestamp": "2025-11-29T17:08:32.472Z",
                "success": true,
                "durationMs": 4520,
                "inputTokens": 966,
                "outputTokens": 361,
                "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation above, recommend a team member who could help solve their problem.\n\nRespond with a JSON object containing:\n- \"recommendation\": Your explanation of why you're recommending this role\n- \"action\": An object with \"type\": \"create_actor\" and \"actor\" containing:\n  - \"title\": The job title\n  - \"reason\": Why this role addresses the team's problem\n  - \"skills\": Array of 3-7 required skills\n  - \"prompt\": A system prompt for an AI in this role\n  - \"model\": Either \"reasoning\" or \"semantic\"",
                "rawResponse": "{\n  \"recommendation\": \"I think you need to hire a Senior Database Engineer. The team is clearly struggling with deep database performance issues that are impacting critical customer experience and none of the current members feel confident in their ability to resolve them effectively. A specialist in this area is crucial to diagnose, fix, and prevent future problems.\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Senior Database Engineer\",\n      \"reason\": \"The team is facing critical performance issues with their database queries, leading to slow dashboard load times and potential customer churn. They lack the deep expertise required to diagnose complex query bottlenecks, optimize schema, implement advanced indexing strategies, interpret query plans, and evaluate architectural changes like database migrations or advanced caching. A Senior Database Engineer would provide the specialized knowledge to systematically resolve these issues, improve system performance, and guide future database strategy.\",\n      \"skills\": [\n        \"Advanced SQL query optimization\",\n        \"Database schema design and normalization\",\n        \"Indexing strategies (PostgreSQL specific)\",\n        \"Query plan analysis (EXPLAIN ANALYZE)\",\n        \"Database performance tuning and monitoring\",\n        \"Database architecture and scalability\",\n        \"Data migration planning and execution\"\n      ],\n      \"prompt\": \"You are a Senior Database Engineer specializing in performance optimization and scalable database architectures. Your role is to analyze complex SQL queries, identify bottlenecks, design efficient schemas, implement advanced indexing, and recommend appropriate database technologies and configurations. You are an expert in PostgreSQL and other relational and NoSQL databases. Focus on practical, impactful solutions that balance performance, maintainability, and data integrity.\",\n      \"model\": \"reasoning\"\n    }\n  }\n}",
                "parsedResponse": {
                  "recommendation": "I think you need to hire a Senior Database Engineer. The team is clearly struggling with deep database performance issues that are impacting critical customer experience and none of the current members feel confident in their ability to resolve them effectively. A specialist in this area is crucial to diagnose, fix, and prevent future problems.",
                  "action": {
                    "type": "create_actor",
                    "actor": {
                      "title": "Senior Database Engineer",
                      "reason": "The team is facing critical performance issues with their database queries, leading to slow dashboard load times and potential customer churn. They lack the deep expertise required to diagnose complex query bottlenecks, optimize schema, implement advanced indexing strategies, interpret query plans, and evaluate architectural changes like database migrations or advanced caching. A Senior Database Engineer would provide the specialized knowledge to systematically resolve these issues, improve system performance, and guide future database strategy.",
                      "skills": [
                        "Advanced SQL query optimization",
                        "Database schema design and normalization",
                        "Indexing strategies (PostgreSQL specific)",
                        "Query plan analysis (EXPLAIN ANALYZE)",
                        "Database performance tuning and monitoring",
                        "Database architecture and scalability",
                        "Data migration planning and execution"
                      ],
                      "prompt": "You are a Senior Database Engineer specializing in performance optimization and scalable database architectures. Your role is to analyze complex SQL queries, identify bottlenecks, design efficient schemas, implement advanced indexing, and recommend appropriate database technologies and configurations. You are an expert in PostgreSQL and other relational and NoSQL databases. Focus on practical, impactful solutions that balance performance, maintainability, and data integrity.",
                      "model": "reasoning"
                    }
                  }
                },
                "validationErrors": [],
                "errorMessage": null
              }
            ],
            "totalDurationMs": 4520,
            "finalResponse": {
              "recommendation": "I think you need to hire a Senior Database Engineer. The team is clearly struggling with deep database performance issues that are impacting critical customer experience and none of the current members feel confident in their ability to resolve them effectively. A specialist in this area is crucial to diagnose, fix, and prevent future problems.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Senior Database Engineer",
                  "reason": "The team is facing critical performance issues with their database queries, leading to slow dashboard load times and potential customer churn. They lack the deep expertise required to diagnose complex query bottlenecks, optimize schema, implement advanced indexing strategies, interpret query plans, and evaluate architectural changes like database migrations or advanced caching. A Senior Database Engineer would provide the specialized knowledge to systematically resolve these issues, improve system performance, and guide future database strategy.",
                  "skills": [
                    "Advanced SQL query optimization",
                    "Database schema design and normalization",
                    "Indexing strategies (PostgreSQL specific)",
                    "Query plan analysis (EXPLAIN ANALYZE)",
                    "Database performance tuning and monitoring",
                    "Database architecture and scalability",
                    "Data migration planning and execution"
                  ],
                  "prompt": "You are a Senior Database Engineer specializing in performance optimization and scalable database architectures. Your role is to analyze complex SQL queries, identify bottlenecks, design efficient schemas, implement advanced indexing, and recommend appropriate database technologies and configurations. You are an expert in PostgreSQL and other relational and NoSQL databases. Focus on practical, impactful solutions that balance performance, maintainability, and data integrity.",
                  "model": "reasoning"
                }
              }
            }
          }
        ],
        "summary": {
          "successRate": 100,
          "firstAttemptSuccessRate": 100,
          "afterRetry1SuccessRate": 100,
          "afterRetry2SuccessRate": 100,
          "afterRetry3SuccessRate": 100,
          "averageDurationMs": 5063.666666666667,
          "averageAttempts": 1,
          "averageAttemptsPerSuccess": 1,
          "averageTokensPerSuccess": 1331.3333333333333,
          "totalTokensUsed": 3994
        }
      },
      "3": {
        "runs": [
          {
            "runNumber": 1,
            "success": true,
            "attempts": [],
            "steps": [
              {
                "stepNumber": 1,
                "stepName": "Recommendation",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:08:40.741Z",
                    "success": true,
                    "durationMs": 8269,
                    "inputTokens": 938,
                    "outputTokens": 475,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation, what type of team member should this team add?\n\nRespond with JSON like this example:\n{\"recommendation\": \"I recommend hiring a [role] because [reason]...\", \"action\": \"create_actor\"}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- The \"recommendation\" should explain your hiring recommendation (at least 20 characters)\n- Set \"action\" to \"create_actor\" if recommending someone, or null if not",
                    "rawResponse": "{\"recommendation\": \"I recommend hiring a Database Performance Engineer because the team is facing critical database performance issues that are beyond their current expertise. They need someone who can deeply analyze query plans, optimize schemas, implement advanced indexing, and potentially advise on architectural changes to prevent customer churn.\", \"action\": \"create_actor\", \"role\": {\"job_title\": \"Database Performance Engineer\", \"explanation\": \"The team is struggling with critical database performance issues, specifically slow dashboard queries impacting enterprise customers. Existing team members lack the deep expertise to diagnose complex query plans, optimize database schemas, implement advanced indexing strategies, or evaluate significant architectural changes (like migrating to a new database system). A Database Performance Engineer would provide the specialized knowledge to resolve these bottlenecks, prevent customer churn, and build a more scalable and efficient data infrastructure.\", \"skills_required\": [\"Expertise in SQL query optimization and rewriting for performance.\", \"Deep understanding of database internals (e.g., PostgreSQL, MySQL, etc.), including query planners, execution engines, and storage mechanisms.\", \"Proficiency in analyzing EXPLAIN ANALYZE output and identifying performance bottlenecks (e.g., sequential scans, inefficient joins).\", \"Experience with database schema design and normalization/denormalization strategies for performance.\", \"Advanced indexing strategies (e.g., partial indexes, composite indexes, covering indexes).\", \"Knowledge of database monitoring tools and metrics (CPU, memory, disk I/O, network).\", \"Experience with database caching strategies (understanding trade-offs for real-time data).\", \"Familiarity with different database architectures (e.g., OLTP vs. OLAP, read replicas, sharding).\", \"Ability to evaluate and recommend alternative database technologies (e.g., time-series databases).\", \"Strong problem-solving and analytical skills.\"], \"system_prompt\": \"You are an expert Database Performance Engineer. Your primary role is to analyze database queries, schemas, and infrastructure to identify and resolve performance bottlenecks. You are proficient in SQL optimization, indexing strategies, schema design, and interpreting database execution plans (e.g., EXPLAIN ANALYZE). You can recommend architectural improvements, evaluate new database technologies, and provide clear, actionable advice on improving database efficiency and scalability. Focus on practical, impactful solutions that balance performance with maintainability and data integrity.\", \"capabilities\": \"reasoning\"}}",
                    "parsedResponse": {
                      "recommendation": "I recommend hiring a Database Performance Engineer because the team is facing critical database performance issues that are beyond their current expertise. They need someone who can deeply analyze query plans, optimize schemas, implement advanced indexing, and potentially advise on architectural changes to prevent customer churn.",
                      "action": "create_actor"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 2,
                "stepName": "Details",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:08:43.728Z",
                    "success": true,
                    "durationMs": 2987,
                    "inputTokens": 1007,
                    "outputTokens": 181,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Database Performance Engineer because the team is facing critical database performance issues that are beyond their current expertise. They need someone who can deeply analyze query plans, optimize schemas, implement advanced indexing, and potentially advise on architectural changes to prevent customer churn.\",\"action\":\"create_actor\"}\n\n[user] For the role you recommended, provide their details.\n\nRespond with JSON like this example:\n{\"title\": \"Database Administrator\", \"reason\": \"The team needs database expertise to optimize their slow queries and design scalable schemas\", \"skills\": [\"PostgreSQL\", \"Query Optimization\", \"Database Design\"]}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- Provide 3-7 specific technical skills\n- The \"reason\" should explain how this role addresses the team's problem (at least 20 characters)",
                    "rawResponse": "{\"title\": \"Database Performance Engineer\", \"reason\": \"The team is struggling with critical database performance issues leading to slow dashboard load times and potential customer churn. They lack the specialized expertise to deeply analyze query plans, optimize complex queries, redesign schemas, and evaluate database architectural changes, which this role would provide.\", \"skills\": [\"Advanced SQL Optimization\", \"Database Schema Design\", \"Indexing Strategies\", \"Query Plan Analysis (e.g., EXPLAIN ANALYZE)\", \"Database Performance Monitoring\", \"PostgreSQL\", \"Database Architecture\"], \"system_prompt\": \"You are a Database Performance Engineer AI assistant. Your primary goal is to identify and resolve database performance bottlenecks. You will analyze query plans, recommend schema optimizations, suggest indexing strategies, and advise on database architecture to ensure optimal performance and scalability. Focus on practical, actionable solutions and consider the impact on existing systems.\", \"capabilities\": \"reasoning\"}",
                    "parsedResponse": {
                      "title": "Database Performance Engineer",
                      "reason": "The team is struggling with critical database performance issues leading to slow dashboard load times and potential customer churn. They lack the specialized expertise to deeply analyze query plans, optimize complex queries, redesign schemas, and evaluate database architectural changes, which this role would provide.",
                      "skills": [
                        "Advanced SQL Optimization",
                        "Database Schema Design",
                        "Indexing Strategies",
                        "Query Plan Analysis (e.g., EXPLAIN ANALYZE)",
                        "Database Performance Monitoring",
                        "PostgreSQL",
                        "Database Architecture"
                      ]
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 3,
                "stepName": "AI Config",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:08:45.551Z",
                    "success": true,
                    "durationMs": 1823,
                    "inputTokens": 1106,
                    "outputTokens": 124,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Database Performance Engineer because the team is facing critical database performance issues that are beyond their current expertise. They need someone who can deeply analyze query plans, optimize schemas, implement advanced indexing, and potentially advise on architectural changes to prevent customer churn.\",\"action\":\"create_actor\"}\n\n[assistant] {\"title\":\"Database Performance Engineer\",\"reason\":\"The team is struggling with critical database performance issues leading to slow dashboard load times and potential customer churn. They lack the specialized expertise to deeply analyze query plans, optimize complex queries, redesign schemas, and evaluate database architectural changes, which this role would provide.\",\"skills\":[\"Advanced SQL Optimization\",\"Database Schema Design\",\"Indexing Strategies\",\"Query Plan Analysis (e.g., EXPLAIN ANALYZE)\",\"Database Performance Monitoring\",\"PostgreSQL\",\"Database Architecture\"]}\n\n[user] For this role, provide the AI system prompt and model type.\n\nRespond with JSON like this example:\n{\"prompt\": \"You are an expert database administrator. You help teams optimize queries, design schemas, and ensure data integrity...\", \"model\": \"reasoning\"}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- The \"prompt\" should be a detailed system prompt (at least 30 characters)\n- \"model\" should be \"reasoning\" for analytical tasks or \"semantic\" for creative tasks",
                    "rawResponse": "{\"prompt\": \"You are an expert Database Performance Engineer specializing in PostgreSQL. Your primary goal is to diagnose, optimize, and resolve complex database performance bottlenecks. You are skilled in deep query plan analysis (e.g., EXPLAIN ANALYZE), advanced SQL optimization, schema design, indexing strategies, and database architecture. You can recommend solutions ranging from query rewrites and index additions to schema refactoring and database system evaluations. You prioritize solutions that deliver significant performance improvements while maintaining data integrity and scalability. You are also adept at interpreting database server metrics and identifying root causes of performance degradation.\", \"model\": \"reasoning\"}",
                    "parsedResponse": {
                      "prompt": "You are an expert Database Performance Engineer specializing in PostgreSQL. Your primary goal is to diagnose, optimize, and resolve complex database performance bottlenecks. You are skilled in deep query plan analysis (e.g., EXPLAIN ANALYZE), advanced SQL optimization, schema design, indexing strategies, and database architecture. You can recommend solutions ranging from query rewrites and index additions to schema refactoring and database system evaluations. You prioritize solutions that deliver significant performance improvements while maintaining data integrity and scalability. You are also adept at interpreting database server metrics and identifying root causes of performance degradation.",
                      "model": "reasoning"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              }
            ],
            "totalDurationMs": 13079,
            "finalResponse": {
              "recommendation": "I recommend hiring a Database Performance Engineer because the team is facing critical database performance issues that are beyond their current expertise. They need someone who can deeply analyze query plans, optimize schemas, implement advanced indexing, and potentially advise on architectural changes to prevent customer churn.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Performance Engineer",
                  "reason": "The team is struggling with critical database performance issues leading to slow dashboard load times and potential customer churn. They lack the specialized expertise to deeply analyze query plans, optimize complex queries, redesign schemas, and evaluate database architectural changes, which this role would provide.",
                  "skills": [
                    "Advanced SQL Optimization",
                    "Database Schema Design",
                    "Indexing Strategies",
                    "Query Plan Analysis (e.g., EXPLAIN ANALYZE)",
                    "Database Performance Monitoring",
                    "PostgreSQL",
                    "Database Architecture"
                  ],
                  "prompt": "You are an expert Database Performance Engineer specializing in PostgreSQL. Your primary goal is to diagnose, optimize, and resolve complex database performance bottlenecks. You are skilled in deep query plan analysis (e.g., EXPLAIN ANALYZE), advanced SQL optimization, schema design, indexing strategies, and database architecture. You can recommend solutions ranging from query rewrites and index additions to schema refactoring and database system evaluations. You prioritize solutions that deliver significant performance improvements while maintaining data integrity and scalability. You are also adept at interpreting database server metrics and identifying root causes of performance degradation.",
                  "model": "reasoning"
                }
              }
            }
          },
          {
            "runNumber": 2,
            "success": true,
            "attempts": [],
            "steps": [
              {
                "stepNumber": 1,
                "stepName": "Recommendation",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:08:53.356Z",
                    "success": true,
                    "durationMs": 7805,
                    "inputTokens": 938,
                    "outputTokens": 470,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation, what type of team member should this team add?\n\nRespond with JSON like this example:\n{\"recommendation\": \"I recommend hiring a [role] because [reason]...\", \"action\": \"create_actor\"}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- The \"recommendation\" should explain your hiring recommendation (at least 20 characters)\n- Set \"action\" to \"create_actor\" if recommending someone, or null if not",
                    "rawResponse": "{\"recommendation\": \"I recommend hiring a Database Performance Engineer because the team is facing critical database performance issues that are directly impacting customer satisfaction and retention. The current team lacks the deep expertise required to diagnose complex query bottlenecks, optimize database schemas, implement advanced indexing strategies, and evaluate significant architectural changes like migrating to a new database system. This role will provide the specialized knowledge needed to resolve the immediate problem and guide future database strategy.\", \"action\": \"create_actor\", \"actor_details\": {\"job_title\": \"Database Performance Engineer\", \"explanation\": \"The team is struggling with critical database performance issues, specifically slow query execution leading to customer churn risk. Existing team members lack the deep expertise in database internals, query optimization, schema design, and advanced indexing strategies required to diagnose and resolve the complex bottlenecks. They are also unsure about the implications of significant database architectural changes. This role is crucial to provide expert analysis, implement effective solutions, and guide future database strategy.\", \"skills_required\": [\"Deep expertise in SQL query optimization (e.g., PostgreSQL, MySQL)\", \"Proficiency in analyzing EXPLAIN ANALYZE output and identifying performance bottlenecks\", \"Advanced indexing strategies and their impact on query performance\", \"Database schema design and normalization/denormalization trade-offs for performance\", \"Understanding of database server configuration and tuning (e.g., disk I/O, memory, CPU utilization)\", \"Experience with database caching mechanisms\", \"Knowledge of different database architectures (e.g., OLTP vs. OLAP, time-series databases)\", \"Ability to evaluate and plan database migrations\", \"Performance monitoring and troubleshooting tools\", \"Strong problem-solving and analytical skills\"], \"system_prompt\": \"You are a highly experienced Database Performance Engineer. Your primary goal is to diagnose, optimize, and resolve complex database performance issues. You are an expert in SQL query optimization, indexing strategies, schema design, and database architecture. When presented with a problem, you will ask clarifying questions, analyze query plans (e.g., EXPLAIN ANALYZE), suggest specific indexing improvements, propose schema adjustments, recommend database configuration changes, and evaluate the suitability of different database technologies. You prioritize solutions that are robust, scalable, and minimize risk to existing systems. You can also provide guidance on database monitoring and capacity planning.\", \"capabilities\": \"reasoning\"}}",
                    "parsedResponse": {
                      "recommendation": "I recommend hiring a Database Performance Engineer because the team is facing critical database performance issues that are directly impacting customer satisfaction and retention. The current team lacks the deep expertise required to diagnose complex query bottlenecks, optimize database schemas, implement advanced indexing strategies, and evaluate significant architectural changes like migrating to a new database system. This role will provide the specialized knowledge needed to resolve the immediate problem and guide future database strategy.",
                      "action": "create_actor"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 2,
                "stepName": "Details",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:08:59.821Z",
                    "success": true,
                    "durationMs": 6465,
                    "inputTokens": 1036,
                    "outputTokens": 292,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Database Performance Engineer because the team is facing critical database performance issues that are directly impacting customer satisfaction and retention. The current team lacks the deep expertise required to diagnose complex query bottlenecks, optimize database schemas, implement advanced indexing strategies, and evaluate significant architectural changes like migrating to a new database system. This role will provide the specialized knowledge needed to resolve the immediate problem and guide future database strategy.\",\"action\":\"create_actor\"}\n\n[user] For the role you recommended, provide their details.\n\nRespond with JSON like this example:\n{\"title\": \"Database Administrator\", \"reason\": \"The team needs database expertise to optimize their slow queries and design scalable schemas\", \"skills\": [\"PostgreSQL\", \"Query Optimization\", \"Database Design\"]}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- Provide 3-7 specific technical skills\n- The \"reason\" should explain how this role addresses the team's problem (at least 20 characters)",
                    "rawResponse": "{\"title\": \"Database Performance Engineer\", \"reason\": \"The team is struggling with critical database performance issues, specifically slow queries on a complex dashboard, leading to customer churn threats. They lack the deep expertise to diagnose and resolve bottlenecks, optimize complex queries, design effective indexing strategies, and evaluate significant architectural changes like database migrations or schema redesigns. This role will provide the specialized knowledge to identify root causes, implement lasting solutions, and guide future database scalability.\", \"skills\": [\"Advanced SQL Query Optimization\", \"Database Schema Design & Normalization\", \"Indexing Strategies\", \"Database Performance Tuning (e.g., PostgreSQL)\", \"Query Plan Analysis (e.g., EXPLAIN ANALYZE)\", \"Database Architecture & Scalability\", \"Database Monitoring & Diagnostics\"], \"system_prompt\": \"You are a Database Performance Engineer AI assistant. Your primary role is to analyze database performance issues, diagnose bottlenecks, and recommend specific, actionable solutions for query optimization, schema design, indexing, and database architecture. You should be proficient in interpreting query execution plans (e.g., EXPLAIN ANALYZE), identifying inefficient operations, and suggesting improvements that balance performance with data integrity and scalability. When presented with a problem, ask clarifying questions about the database system, schema, query, and current infrastructure before offering solutions. Prioritize solutions that offer the greatest impact with the least risk. Be prepared to evaluate and advise on database migrations or architectural shifts.\", \"capability\": \"reasoning\"}",
                    "parsedResponse": {
                      "title": "Database Performance Engineer",
                      "reason": "The team is struggling with critical database performance issues, specifically slow queries on a complex dashboard, leading to customer churn threats. They lack the deep expertise to diagnose and resolve bottlenecks, optimize complex queries, design effective indexing strategies, and evaluate significant architectural changes like database migrations or schema redesigns. This role will provide the specialized knowledge to identify root causes, implement lasting solutions, and guide future database scalability.",
                      "skills": [
                        "Advanced SQL Query Optimization",
                        "Database Schema Design & Normalization",
                        "Indexing Strategies",
                        "Database Performance Tuning (e.g., PostgreSQL)",
                        "Query Plan Analysis (e.g., EXPLAIN ANALYZE)",
                        "Database Architecture & Scalability",
                        "Database Monitoring & Diagnostics"
                      ]
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 3,
                "stepName": "AI Config",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:09:02.802Z",
                    "success": true,
                    "durationMs": 2981,
                    "inputTokens": 1180,
                    "outputTokens": 119,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Database Performance Engineer because the team is facing critical database performance issues that are directly impacting customer satisfaction and retention. The current team lacks the deep expertise required to diagnose complex query bottlenecks, optimize database schemas, implement advanced indexing strategies, and evaluate significant architectural changes like migrating to a new database system. This role will provide the specialized knowledge needed to resolve the immediate problem and guide future database strategy.\",\"action\":\"create_actor\"}\n\n[assistant] {\"title\":\"Database Performance Engineer\",\"reason\":\"The team is struggling with critical database performance issues, specifically slow queries on a complex dashboard, leading to customer churn threats. They lack the deep expertise to diagnose and resolve bottlenecks, optimize complex queries, design effective indexing strategies, and evaluate significant architectural changes like database migrations or schema redesigns. This role will provide the specialized knowledge to identify root causes, implement lasting solutions, and guide future database scalability.\",\"skills\":[\"Advanced SQL Query Optimization\",\"Database Schema Design & Normalization\",\"Indexing Strategies\",\"Database Performance Tuning (e.g., PostgreSQL)\",\"Query Plan Analysis (e.g., EXPLAIN ANALYZE)\",\"Database Architecture & Scalability\",\"Database Monitoring & Diagnostics\"]}\n\n[user] For this role, provide the AI system prompt and model type.\n\nRespond with JSON like this example:\n{\"prompt\": \"You are an expert database administrator. You help teams optimize queries, design schemas, and ensure data integrity...\", \"model\": \"reasoning\"}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- The \"prompt\" should be a detailed system prompt (at least 30 characters)\n- \"model\" should be \"reasoning\" for analytical tasks or \"semantic\" for creative tasks",
                    "rawResponse": "{\"prompt\": \"You are an expert Database Performance Engineer. Your primary role is to analyze, diagnose, and resolve complex database performance bottlenecks. You are highly skilled in SQL query optimization, database schema design, advanced indexing strategies, and performance tuning for relational databases (e.g., PostgreSQL). You can interpret EXPLAIN ANALYZE outputs, identify inefficient operations like sequential scans, and propose concrete solutions. You also advise on database architecture, scalability, and potential migrations to specialized database systems. Your goal is to ensure optimal database performance, data integrity, and system reliability.\",\"model\":\"reasoning\"}",
                    "parsedResponse": {
                      "prompt": "You are an expert Database Performance Engineer. Your primary role is to analyze, diagnose, and resolve complex database performance bottlenecks. You are highly skilled in SQL query optimization, database schema design, advanced indexing strategies, and performance tuning for relational databases (e.g., PostgreSQL). You can interpret EXPLAIN ANALYZE outputs, identify inefficient operations like sequential scans, and propose concrete solutions. You also advise on database architecture, scalability, and potential migrations to specialized database systems. Your goal is to ensure optimal database performance, data integrity, and system reliability.",
                      "model": "reasoning"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              }
            ],
            "totalDurationMs": 17251,
            "finalResponse": {
              "recommendation": "I recommend hiring a Database Performance Engineer because the team is facing critical database performance issues that are directly impacting customer satisfaction and retention. The current team lacks the deep expertise required to diagnose complex query bottlenecks, optimize database schemas, implement advanced indexing strategies, and evaluate significant architectural changes like migrating to a new database system. This role will provide the specialized knowledge needed to resolve the immediate problem and guide future database strategy.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Performance Engineer",
                  "reason": "The team is struggling with critical database performance issues, specifically slow queries on a complex dashboard, leading to customer churn threats. They lack the deep expertise to diagnose and resolve bottlenecks, optimize complex queries, design effective indexing strategies, and evaluate significant architectural changes like database migrations or schema redesigns. This role will provide the specialized knowledge to identify root causes, implement lasting solutions, and guide future database scalability.",
                  "skills": [
                    "Advanced SQL Query Optimization",
                    "Database Schema Design & Normalization",
                    "Indexing Strategies",
                    "Database Performance Tuning (e.g., PostgreSQL)",
                    "Query Plan Analysis (e.g., EXPLAIN ANALYZE)",
                    "Database Architecture & Scalability",
                    "Database Monitoring & Diagnostics"
                  ],
                  "prompt": "You are an expert Database Performance Engineer. Your primary role is to analyze, diagnose, and resolve complex database performance bottlenecks. You are highly skilled in SQL query optimization, database schema design, advanced indexing strategies, and performance tuning for relational databases (e.g., PostgreSQL). You can interpret EXPLAIN ANALYZE outputs, identify inefficient operations like sequential scans, and propose concrete solutions. You also advise on database architecture, scalability, and potential migrations to specialized database systems. Your goal is to ensure optimal database performance, data integrity, and system reliability.",
                  "model": "reasoning"
                }
              }
            }
          },
          {
            "runNumber": 3,
            "success": true,
            "attempts": [],
            "steps": [
              {
                "stepNumber": 1,
                "stepName": "Recommendation",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:09:10.671Z",
                    "success": true,
                    "durationMs": 7869,
                    "inputTokens": 938,
                    "outputTokens": 454,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation, what type of team member should this team add?\n\nRespond with JSON like this example:\n{\"recommendation\": \"I recommend hiring a [role] because [reason]...\", \"action\": \"create_actor\"}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- The \"recommendation\" should explain your hiring recommendation (at least 20 characters)\n- Set \"action\" to \"create_actor\" if recommending someone, or null if not",
                    "rawResponse": "{\"recommendation\": \"I recommend hiring a Senior Database Performance Engineer because the team is facing critical database performance issues that are impacting enterprise customers and threatening churn. The current team lacks the specialized expertise to diagnose complex query bottlenecks, optimize database schemas, implement advanced indexing strategies, and evaluate or plan significant architectural changes or migrations. This role is crucial for providing deep technical leadership and hands-on expertise to resolve these issues and establish a robust, scalable database foundation.\", \"action\": \"create_actor\", \"job_title\": \"Senior Database Performance Engineer\", \"explanation\": \"The team is struggling with critical database performance issues impacting enterprise customers, leading to potential churn. Existing team members lack the specialized expertise to diagnose complex query bottlenecks, optimize database schemas, implement advanced indexing strategies, and evaluate/plan significant architectural changes or migrations. A Senior Database Performance Engineer is needed to provide deep technical leadership and hands-on expertise to resolve these critical issues and establish a robust, scalable database foundation.\", \"skills_required\": [\"Expertise in SQL query optimization, including complex joins, aggregations, and subqueries.\", \"Proficiency with database performance monitoring and diagnostic tools (e.g., EXPLAIN ANALYZE, database-specific profilers).\", \"Deep understanding of database indexing strategies and their impact on query performance.\", \"Experience with schema design and normalization/denormalization trade-offs for performance.\", \"Knowledge of database architecture patterns (e.g., read replicas, sharding, caching strategies).\", \"Familiarity with various database technologies (e.g., PostgreSQL, MySQL, NoSQL, time-series databases like TimescaleDB).\", \"Ability to evaluate and plan database migrations.\", \"Strong analytical and problem-solving skills.\"], \"system_prompt\": \"You are a Senior Database Performance Engineer AI assistant. Your primary role is to analyze database performance issues, diagnose bottlenecks, and recommend specific, actionable solutions for query optimization, schema design, indexing, and database architecture. You should be proficient in interpreting EXPLAIN ANALYZE outputs, understanding database server metrics, and proposing scalable and efficient database strategies. Always prioritize performance, data integrity, and maintainability. When asked about potential solutions, provide detailed steps and consider potential trade-offs.\", \"capabilities\": \"reasoning\"}",
                    "parsedResponse": {
                      "recommendation": "I recommend hiring a Senior Database Performance Engineer because the team is facing critical database performance issues that are impacting enterprise customers and threatening churn. The current team lacks the specialized expertise to diagnose complex query bottlenecks, optimize database schemas, implement advanced indexing strategies, and evaluate or plan significant architectural changes or migrations. This role is crucial for providing deep technical leadership and hands-on expertise to resolve these issues and establish a robust, scalable database foundation.",
                      "action": "create_actor"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 2,
                "stepName": "Details",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:09:12.474Z",
                    "success": true,
                    "durationMs": 1803,
                    "inputTokens": 1041,
                    "outputTokens": 151,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Senior Database Performance Engineer because the team is facing critical database performance issues that are impacting enterprise customers and threatening churn. The current team lacks the specialized expertise to diagnose complex query bottlenecks, optimize database schemas, implement advanced indexing strategies, and evaluate or plan significant architectural changes or migrations. This role is crucial for providing deep technical leadership and hands-on expertise to resolve these issues and establish a robust, scalable database foundation.\",\"action\":\"create_actor\"}\n\n[user] For the role you recommended, provide their details.\n\nRespond with JSON like this example:\n{\"title\": \"Database Administrator\", \"reason\": \"The team needs database expertise to optimize their slow queries and design scalable schemas\", \"skills\": [\"PostgreSQL\", \"Query Optimization\", \"Database Design\"]}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- Provide 3-7 specific technical skills\n- The \"reason\" should explain how this role addresses the team's problem (at least 20 characters)",
                    "rawResponse": "{\"title\": \"Senior Database Performance Engineer\", \"reason\": \"The team is struggling with critical database performance issues, including slow queries, inefficient schema design, and potential architectural limitations. This role will provide deep expertise to diagnose, optimize, and implement scalable database solutions, preventing customer churn and ensuring long-term system health.\", \"skills\": [\"Advanced SQL Query Optimization\", \"Database Schema Design & Normalization\", \"Indexing Strategies (B-tree, Hash, GIN, BRIN)\", \"PostgreSQL Performance Tuning\", \"Database Monitoring & Profiling Tools (e.g., pg_stat_statements, EXPLAIN ANALYZE)\", \"Database Architecture & Scalability (e.g., Sharding, Replication)\", \"Data Migration & Database Selection Evaluation\"]}",
                    "parsedResponse": {
                      "title": "Senior Database Performance Engineer",
                      "reason": "The team is struggling with critical database performance issues, including slow queries, inefficient schema design, and potential architectural limitations. This role will provide deep expertise to diagnose, optimize, and implement scalable database solutions, preventing customer churn and ensuring long-term system health.",
                      "skills": [
                        "Advanced SQL Query Optimization",
                        "Database Schema Design & Normalization",
                        "Indexing Strategies (B-tree, Hash, GIN, BRIN)",
                        "PostgreSQL Performance Tuning",
                        "Database Monitoring & Profiling Tools (e.g., pg_stat_statements, EXPLAIN ANALYZE)",
                        "Database Architecture & Scalability (e.g., Sharding, Replication)",
                        "Data Migration & Database Selection Evaluation"
                      ]
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 3,
                "stepName": "AI Config",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:09:15.672Z",
                    "success": true,
                    "durationMs": 3198,
                    "inputTokens": 1186,
                    "outputTokens": 190,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Senior Database Performance Engineer because the team is facing critical database performance issues that are impacting enterprise customers and threatening churn. The current team lacks the specialized expertise to diagnose complex query bottlenecks, optimize database schemas, implement advanced indexing strategies, and evaluate or plan significant architectural changes or migrations. This role is crucial for providing deep technical leadership and hands-on expertise to resolve these issues and establish a robust, scalable database foundation.\",\"action\":\"create_actor\"}\n\n[assistant] {\"title\":\"Senior Database Performance Engineer\",\"reason\":\"The team is struggling with critical database performance issues, including slow queries, inefficient schema design, and potential architectural limitations. This role will provide deep expertise to diagnose, optimize, and implement scalable database solutions, preventing customer churn and ensuring long-term system health.\",\"skills\":[\"Advanced SQL Query Optimization\",\"Database Schema Design & Normalization\",\"Indexing Strategies (B-tree, Hash, GIN, BRIN)\",\"PostgreSQL Performance Tuning\",\"Database Monitoring & Profiling Tools (e.g., pg_stat_statements, EXPLAIN ANALYZE)\",\"Database Architecture & Scalability (e.g., Sharding, Replication)\",\"Data Migration & Database Selection Evaluation\"]}\n\n[user] For this role, provide the AI system prompt and model type.\n\nRespond with JSON like this example:\n{\"prompt\": \"You are an expert database administrator. You help teams optimize queries, design schemas, and ensure data integrity...\", \"model\": \"reasoning\"}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- The \"prompt\" should be a detailed system prompt (at least 30 characters)\n- \"model\" should be \"reasoning\" for analytical tasks or \"semantic\" for creative tasks",
                    "rawResponse": "{\"prompt\": \"You are a Senior Database Performance Engineer. Your main objective is to diagnose, optimize, and resolve complex database performance bottlenecks. You excel at analyzing SQL query plans (e.g., EXPLAIN ANALYZE) to identify inefficiencies and provide expert recommendations for query rewriting, advanced indexing strategies (B-tree, Hash, GIN, BRIN), and schema optimizations (normalization, denormalization, partitioning). You are proficient in PostgreSQL performance tuning, monitoring database metrics (CPU, memory, disk I/O), and identifying root causes of slowdowns. You can advise on database architecture, scalability solutions (replication, sharding), and evaluate the suitability of different database technologies (e.g., TimescaleDB for time-series data). You prioritize data integrity and system stability while implementing performance improvements. Your advice is practical, data-driven, and focused on achieving significant performance gains for critical applications.\", \"model\": \"reasoning\"}",
                    "parsedResponse": {
                      "prompt": "You are a Senior Database Performance Engineer. Your main objective is to diagnose, optimize, and resolve complex database performance bottlenecks. You excel at analyzing SQL query plans (e.g., EXPLAIN ANALYZE) to identify inefficiencies and provide expert recommendations for query rewriting, advanced indexing strategies (B-tree, Hash, GIN, BRIN), and schema optimizations (normalization, denormalization, partitioning). You are proficient in PostgreSQL performance tuning, monitoring database metrics (CPU, memory, disk I/O), and identifying root causes of slowdowns. You can advise on database architecture, scalability solutions (replication, sharding), and evaluate the suitability of different database technologies (e.g., TimescaleDB for time-series data). You prioritize data integrity and system stability while implementing performance improvements. Your advice is practical, data-driven, and focused on achieving significant performance gains for critical applications.",
                      "model": "reasoning"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              }
            ],
            "totalDurationMs": 12870,
            "finalResponse": {
              "recommendation": "I recommend hiring a Senior Database Performance Engineer because the team is facing critical database performance issues that are impacting enterprise customers and threatening churn. The current team lacks the specialized expertise to diagnose complex query bottlenecks, optimize database schemas, implement advanced indexing strategies, and evaluate or plan significant architectural changes or migrations. This role is crucial for providing deep technical leadership and hands-on expertise to resolve these issues and establish a robust, scalable database foundation.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Senior Database Performance Engineer",
                  "reason": "The team is struggling with critical database performance issues, including slow queries, inefficient schema design, and potential architectural limitations. This role will provide deep expertise to diagnose, optimize, and implement scalable database solutions, preventing customer churn and ensuring long-term system health.",
                  "skills": [
                    "Advanced SQL Query Optimization",
                    "Database Schema Design & Normalization",
                    "Indexing Strategies (B-tree, Hash, GIN, BRIN)",
                    "PostgreSQL Performance Tuning",
                    "Database Monitoring & Profiling Tools (e.g., pg_stat_statements, EXPLAIN ANALYZE)",
                    "Database Architecture & Scalability (e.g., Sharding, Replication)",
                    "Data Migration & Database Selection Evaluation"
                  ],
                  "prompt": "You are a Senior Database Performance Engineer. Your main objective is to diagnose, optimize, and resolve complex database performance bottlenecks. You excel at analyzing SQL query plans (e.g., EXPLAIN ANALYZE) to identify inefficiencies and provide expert recommendations for query rewriting, advanced indexing strategies (B-tree, Hash, GIN, BRIN), and schema optimizations (normalization, denormalization, partitioning). You are proficient in PostgreSQL performance tuning, monitoring database metrics (CPU, memory, disk I/O), and identifying root causes of slowdowns. You can advise on database architecture, scalability solutions (replication, sharding), and evaluate the suitability of different database technologies (e.g., TimescaleDB for time-series data). You prioritize data integrity and system stability while implementing performance improvements. Your advice is practical, data-driven, and focused on achieving significant performance gains for critical applications.",
                  "model": "reasoning"
                }
              }
            }
          }
        ],
        "summary": {
          "successRate": 100,
          "firstAttemptSuccessRate": 100,
          "afterRetry1SuccessRate": 100,
          "afterRetry2SuccessRate": 100,
          "afterRetry3SuccessRate": 100,
          "averageDurationMs": 14400,
          "averageAttempts": 3,
          "averageAttemptsPerSuccess": 3,
          "averageTokensPerSuccess": 3942,
          "totalTokensUsed": 11826
        }
      },
      "4": {
        "runs": [
          {
            "runNumber": 1,
            "success": true,
            "attempts": [],
            "steps": [
              {
                "stepNumber": 1,
                "stepName": "Recommendation",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:09:22.168Z",
                    "success": true,
                    "durationMs": 6496,
                    "inputTokens": 910,
                    "outputTokens": 91,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation, what type of team member should this team add?\n\nRespond with a JSON object containing:\n- \"recommendation\": A string explaining who should be hired and why\n- \"action\": Either \"create_actor\" to recommend someone, or null\n\nExample: {\"recommendation\": \"I recommend hiring...\", \"action\": \"create_actor\"}",
                    "rawResponse": "{\n  \"recommendation\": \"Based on the conversation, it's clear the team is struggling with critical database performance issues that are directly impacting enterprise customers and threatening churn. They lack the deep, specialized expertise required to diagnose, optimize, and implement robust solutions for complex database queries, schema design, and potential architectural changes. I recommend hiring a Senior Database Performance Engineer to address these challenges.\",\n  \"action\": \"create_actor\"\n}",
                    "parsedResponse": {
                      "recommendation": "Based on the conversation, it's clear the team is struggling with critical database performance issues that are directly impacting enterprise customers and threatening churn. They lack the deep, specialized expertise required to diagnose, optimize, and implement robust solutions for complex database queries, schema design, and potential architectural changes. I recommend hiring a Senior Database Performance Engineer to address these challenges.",
                      "action": "create_actor"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 2,
                "stepName": "Details",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:09:24.234Z",
                    "success": true,
                    "durationMs": 2066,
                    "inputTokens": 1012,
                    "outputTokens": 170,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"Based on the conversation, it's clear the team is struggling with critical database performance issues that are directly impacting enterprise customers and threatening churn. They lack the deep, specialized expertise required to diagnose, optimize, and implement robust solutions for complex database queries, schema design, and potential architectural changes. I recommend hiring a Senior Database Performance Engineer to address these challenges.\",\"action\":\"create_actor\"}\n\n[user] For the role you recommended, provide their details.\n\nRespond with a JSON object containing:\n- \"title\": The job title (e.g., \"Database Administrator\")\n- \"reason\": Why this role addresses the team's skill gap\n- \"skills\": An array of 3-7 specific technical skills\n\nExample: {\"title\": \"Senior DBA\", \"reason\": \"The team needs...\", \"skills\": [\"PostgreSQL\", \"Query Optimization\"]}",
                    "rawResponse": "{\n  \"title\": \"Senior Database Performance Engineer\",\n  \"reason\": \"The team is facing critical database performance issues, specifically slow dashboard load times for enterprise customers, leading to churn risk. The current team lacks the deep expertise required to effectively diagnose complex query bottlenecks, optimize database schemas, implement advanced indexing strategies, and evaluate potential architectural changes or database migrations. A Senior Database Performance Engineer will provide the specialized knowledge to resolve these issues, prevent future performance regressions, and ensure the scalability and reliability of the database infrastructure.\",\n  \"skills\": [\n    \"Advanced SQL Query Optimization\",\n    \"Database Schema Design and Refactoring\",\n    \"Indexing Strategies (B-tree, Hash, GIN, BRIN)\",\n    \"Performance Tuning (PostgreSQL, TimescaleDB experience a plus)\",\n    \"EXPLAIN ANALYZE and Query Plan Analysis\",\n    \"Database Architecture and Scalability\",\n    \"Troubleshooting Disk I/O and Resource Bottlenecks\"\n  ]\n}",
                    "parsedResponse": {
                      "title": "Senior Database Performance Engineer",
                      "reason": "The team is facing critical database performance issues, specifically slow dashboard load times for enterprise customers, leading to churn risk. The current team lacks the deep expertise required to effectively diagnose complex query bottlenecks, optimize database schemas, implement advanced indexing strategies, and evaluate potential architectural changes or database migrations. A Senior Database Performance Engineer will provide the specialized knowledge to resolve these issues, prevent future performance regressions, and ensure the scalability and reliability of the database infrastructure.",
                      "skills": [
                        "Advanced SQL Query Optimization",
                        "Database Schema Design and Refactoring",
                        "Indexing Strategies (B-tree, Hash, GIN, BRIN)",
                        "Performance Tuning (PostgreSQL, TimescaleDB experience a plus)",
                        "EXPLAIN ANALYZE and Query Plan Analysis",
                        "Database Architecture and Scalability",
                        "Troubleshooting Disk I/O and Resource Bottlenecks"
                      ]
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 3,
                "stepName": "AI Config",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:09:26.224Z",
                    "success": true,
                    "durationMs": 1990,
                    "inputTokens": 1172,
                    "outputTokens": 113,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"Based on the conversation, it's clear the team is struggling with critical database performance issues that are directly impacting enterprise customers and threatening churn. They lack the deep, specialized expertise required to diagnose, optimize, and implement robust solutions for complex database queries, schema design, and potential architectural changes. I recommend hiring a Senior Database Performance Engineer to address these challenges.\",\"action\":\"create_actor\"}\n\n[assistant] {\"title\":\"Senior Database Performance Engineer\",\"reason\":\"The team is facing critical database performance issues, specifically slow dashboard load times for enterprise customers, leading to churn risk. The current team lacks the deep expertise required to effectively diagnose complex query bottlenecks, optimize database schemas, implement advanced indexing strategies, and evaluate potential architectural changes or database migrations. A Senior Database Performance Engineer will provide the specialized knowledge to resolve these issues, prevent future performance regressions, and ensure the scalability and reliability of the database infrastructure.\",\"skills\":[\"Advanced SQL Query Optimization\",\"Database Schema Design and Refactoring\",\"Indexing Strategies (B-tree, Hash, GIN, BRIN)\",\"Performance Tuning (PostgreSQL, TimescaleDB experience a plus)\",\"EXPLAIN ANALYZE and Query Plan Analysis\",\"Database Architecture and Scalability\",\"Troubleshooting Disk I/O and Resource Bottlenecks\"]}\n\n[user] For this role, provide the AI configuration.\n\nRespond with a JSON object containing:\n- \"prompt\": A system prompt for configuring an AI assistant in this role\n- \"model\": Either \"reasoning\" (for analytical/logical tasks) or \"semantic\" (for creative/conversational tasks)\n\nExample: {\"prompt\": \"You are an expert database administrator...\", \"model\": \"reasoning\"}",
                    "rawResponse": "{\n  \"prompt\": \"You are an expert Senior Database Performance Engineer. Your primary role is to analyze complex database performance issues, identify bottlenecks, and implement highly optimized solutions. You are proficient in advanced SQL query optimization, database schema design, indexing strategies, and performance tuning for relational databases (e.g., PostgreSQL). You can interpret EXPLAIN ANALYZE outputs, troubleshoot disk I/O and resource contention, and provide strategic recommendations for database architecture and scalability. Your goal is to ensure fast, reliable, and scalable data access for critical applications.\",\n  \"model\": \"reasoning\"\n}",
                    "parsedResponse": {
                      "prompt": "You are an expert Senior Database Performance Engineer. Your primary role is to analyze complex database performance issues, identify bottlenecks, and implement highly optimized solutions. You are proficient in advanced SQL query optimization, database schema design, indexing strategies, and performance tuning for relational databases (e.g., PostgreSQL). You can interpret EXPLAIN ANALYZE outputs, troubleshoot disk I/O and resource contention, and provide strategic recommendations for database architecture and scalability. Your goal is to ensure fast, reliable, and scalable data access for critical applications.",
                      "model": "reasoning"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              }
            ],
            "totalDurationMs": 10552,
            "finalResponse": {
              "recommendation": "Based on the conversation, it's clear the team is struggling with critical database performance issues that are directly impacting enterprise customers and threatening churn. They lack the deep, specialized expertise required to diagnose, optimize, and implement robust solutions for complex database queries, schema design, and potential architectural changes. I recommend hiring a Senior Database Performance Engineer to address these challenges.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Senior Database Performance Engineer",
                  "reason": "The team is facing critical database performance issues, specifically slow dashboard load times for enterprise customers, leading to churn risk. The current team lacks the deep expertise required to effectively diagnose complex query bottlenecks, optimize database schemas, implement advanced indexing strategies, and evaluate potential architectural changes or database migrations. A Senior Database Performance Engineer will provide the specialized knowledge to resolve these issues, prevent future performance regressions, and ensure the scalability and reliability of the database infrastructure.",
                  "skills": [
                    "Advanced SQL Query Optimization",
                    "Database Schema Design and Refactoring",
                    "Indexing Strategies (B-tree, Hash, GIN, BRIN)",
                    "Performance Tuning (PostgreSQL, TimescaleDB experience a plus)",
                    "EXPLAIN ANALYZE and Query Plan Analysis",
                    "Database Architecture and Scalability",
                    "Troubleshooting Disk I/O and Resource Bottlenecks"
                  ],
                  "prompt": "You are an expert Senior Database Performance Engineer. Your primary role is to analyze complex database performance issues, identify bottlenecks, and implement highly optimized solutions. You are proficient in advanced SQL query optimization, database schema design, indexing strategies, and performance tuning for relational databases (e.g., PostgreSQL). You can interpret EXPLAIN ANALYZE outputs, troubleshoot disk I/O and resource contention, and provide strategic recommendations for database architecture and scalability. Your goal is to ensure fast, reliable, and scalable data access for critical applications.",
                  "model": "reasoning"
                }
              }
            }
          },
          {
            "runNumber": 2,
            "success": true,
            "attempts": [],
            "steps": [
              {
                "stepNumber": 1,
                "stepName": "Recommendation",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:09:28.549Z",
                    "success": true,
                    "durationMs": 2325,
                    "inputTokens": 910,
                    "outputTokens": 77,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation, what type of team member should this team add?\n\nRespond with a JSON object containing:\n- \"recommendation\": A string explaining who should be hired and why\n- \"action\": Either \"create_actor\" to recommend someone, or null\n\nExample: {\"recommendation\": \"I recommend hiring...\", \"action\": \"create_actor\"}",
                    "rawResponse": "{\n  \"recommendation\": \"Based on the conversation, it's clear the team is facing significant database performance challenges that are impacting critical enterprise customers. They lack the specialised expertise to diagnose and resolve complex query optimisation issues, make informed schema design decisions, or evaluate alternative database technologies. I recommend hiring a Senior Database Performance Engineer to address these critical gaps.\",\n  \"action\": \"create_actor\"\n}",
                    "parsedResponse": {
                      "recommendation": "Based on the conversation, it's clear the team is facing significant database performance challenges that are impacting critical enterprise customers. They lack the specialised expertise to diagnose and resolve complex query optimisation issues, make informed schema design decisions, or evaluate alternative database technologies. I recommend hiring a Senior Database Performance Engineer to address these critical gaps.",
                      "action": "create_actor"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 2,
                "stepName": "Details",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:09:32.159Z",
                    "success": true,
                    "durationMs": 3610,
                    "inputTokens": 1005,
                    "outputTokens": 128,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"Based on the conversation, it's clear the team is facing significant database performance challenges that are impacting critical enterprise customers. They lack the specialised expertise to diagnose and resolve complex query optimisation issues, make informed schema design decisions, or evaluate alternative database technologies. I recommend hiring a Senior Database Performance Engineer to address these critical gaps.\",\"action\":\"create_actor\"}\n\n[user] For the role you recommended, provide their details.\n\nRespond with a JSON object containing:\n- \"title\": The job title (e.g., \"Database Administrator\")\n- \"reason\": Why this role addresses the team's skill gap\n- \"skills\": An array of 3-7 specific technical skills\n\nExample: {\"title\": \"Senior DBA\", \"reason\": \"The team needs...\", \"skills\": [\"PostgreSQL\", \"Query Optimization\"]}",
                    "rawResponse": "{\n  \"title\": \"Senior Database Performance Engineer\",\n  \"reason\": \"The team is facing critical database performance issues, leading to slow dashboard load times and potential customer churn. They lack the deep expertise required to diagnose complex query bottlenecks, optimise database schemas, implement advanced indexing strategies, and evaluate alternative database architectures or migrations. This role is essential to provide specialised knowledge, resolve immediate performance problems, and establish long-term database health and scalability.\",\n  \"skills\": [\n    \"Advanced SQL Query Optimization\",\n    \"Database Schema Design and Refactoring\",\n    \"Indexing Strategies and Management\",\n    \"Database Performance Tuning (e.g., PostgreSQL)\",\n    \"EXPLAIN ANALYZE Interpretation\",\n    \"Database Architecture Evaluation\",\n    \"Data Modeling\"\n  ]\n}",
                    "parsedResponse": {
                      "title": "Senior Database Performance Engineer",
                      "reason": "The team is facing critical database performance issues, leading to slow dashboard load times and potential customer churn. They lack the deep expertise required to diagnose complex query bottlenecks, optimise database schemas, implement advanced indexing strategies, and evaluate alternative database architectures or migrations. This role is essential to provide specialised knowledge, resolve immediate performance problems, and establish long-term database health and scalability.",
                      "skills": [
                        "Advanced SQL Query Optimization",
                        "Database Schema Design and Refactoring",
                        "Indexing Strategies and Management",
                        "Database Performance Tuning (e.g., PostgreSQL)",
                        "EXPLAIN ANALYZE Interpretation",
                        "Database Architecture Evaluation",
                        "Data Modeling"
                      ]
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 3,
                "stepName": "AI Config",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:09:34.298Z",
                    "success": true,
                    "durationMs": 2139,
                    "inputTokens": 1123,
                    "outputTokens": 98,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"Based on the conversation, it's clear the team is facing significant database performance challenges that are impacting critical enterprise customers. They lack the specialised expertise to diagnose and resolve complex query optimisation issues, make informed schema design decisions, or evaluate alternative database technologies. I recommend hiring a Senior Database Performance Engineer to address these critical gaps.\",\"action\":\"create_actor\"}\n\n[assistant] {\"title\":\"Senior Database Performance Engineer\",\"reason\":\"The team is facing critical database performance issues, leading to slow dashboard load times and potential customer churn. They lack the deep expertise required to diagnose complex query bottlenecks, optimise database schemas, implement advanced indexing strategies, and evaluate alternative database architectures or migrations. This role is essential to provide specialised knowledge, resolve immediate performance problems, and establish long-term database health and scalability.\",\"skills\":[\"Advanced SQL Query Optimization\",\"Database Schema Design and Refactoring\",\"Indexing Strategies and Management\",\"Database Performance Tuning (e.g., PostgreSQL)\",\"EXPLAIN ANALYZE Interpretation\",\"Database Architecture Evaluation\",\"Data Modeling\"]}\n\n[user] For this role, provide the AI configuration.\n\nRespond with a JSON object containing:\n- \"prompt\": A system prompt for configuring an AI assistant in this role\n- \"model\": Either \"reasoning\" (for analytical/logical tasks) or \"semantic\" (for creative/conversational tasks)\n\nExample: {\"prompt\": \"You are an expert database administrator...\", \"model\": \"reasoning\"}",
                    "rawResponse": "{\n  \"prompt\": \"You are an expert Senior Database Performance Engineer. Your primary role is to diagnose, troubleshoot, and resolve complex database performance bottlenecks. You will analyze SQL queries, interpret execution plans (e.g., EXPLAIN ANALYZE), recommend and implement optimal indexing strategies, advise on database schema design improvements, and evaluate database architecture for scalability and efficiency. Your goal is to ensure high performance and reliability for critical applications, providing clear, actionable recommendations and solutions.\",\n  \"model\": \"reasoning\"\n}",
                    "parsedResponse": {
                      "prompt": "You are an expert Senior Database Performance Engineer. Your primary role is to diagnose, troubleshoot, and resolve complex database performance bottlenecks. You will analyze SQL queries, interpret execution plans (e.g., EXPLAIN ANALYZE), recommend and implement optimal indexing strategies, advise on database schema design improvements, and evaluate database architecture for scalability and efficiency. Your goal is to ensure high performance and reliability for critical applications, providing clear, actionable recommendations and solutions.",
                      "model": "reasoning"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              }
            ],
            "totalDurationMs": 8074,
            "finalResponse": {
              "recommendation": "Based on the conversation, it's clear the team is facing significant database performance challenges that are impacting critical enterprise customers. They lack the specialised expertise to diagnose and resolve complex query optimisation issues, make informed schema design decisions, or evaluate alternative database technologies. I recommend hiring a Senior Database Performance Engineer to address these critical gaps.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Senior Database Performance Engineer",
                  "reason": "The team is facing critical database performance issues, leading to slow dashboard load times and potential customer churn. They lack the deep expertise required to diagnose complex query bottlenecks, optimise database schemas, implement advanced indexing strategies, and evaluate alternative database architectures or migrations. This role is essential to provide specialised knowledge, resolve immediate performance problems, and establish long-term database health and scalability.",
                  "skills": [
                    "Advanced SQL Query Optimization",
                    "Database Schema Design and Refactoring",
                    "Indexing Strategies and Management",
                    "Database Performance Tuning (e.g., PostgreSQL)",
                    "EXPLAIN ANALYZE Interpretation",
                    "Database Architecture Evaluation",
                    "Data Modeling"
                  ],
                  "prompt": "You are an expert Senior Database Performance Engineer. Your primary role is to diagnose, troubleshoot, and resolve complex database performance bottlenecks. You will analyze SQL queries, interpret execution plans (e.g., EXPLAIN ANALYZE), recommend and implement optimal indexing strategies, advise on database schema design improvements, and evaluate database architecture for scalability and efficiency. Your goal is to ensure high performance and reliability for critical applications, providing clear, actionable recommendations and solutions.",
                  "model": "reasoning"
                }
              }
            }
          },
          {
            "runNumber": 3,
            "success": true,
            "attempts": [],
            "steps": [
              {
                "stepNumber": 1,
                "stepName": "Recommendation",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:09:39.587Z",
                    "success": true,
                    "durationMs": 5288,
                    "inputTokens": 910,
                    "outputTokens": 83,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation, what type of team member should this team add?\n\nRespond with a JSON object containing:\n- \"recommendation\": A string explaining who should be hired and why\n- \"action\": Either \"create_actor\" to recommend someone, or null\n\nExample: {\"recommendation\": \"I recommend hiring...\", \"action\": \"create_actor\"}",
                    "rawResponse": "{\n  \"recommendation\": \"Based on the conversation, it's clear the team needs a Senior Database Performance Engineer. They are struggling with critical database performance issues, specifically slow queries impacting enterprise customers, and lack the specialized expertise to diagnose, optimize, and implement robust solutions. This role is essential to prevent customer churn, optimize existing database performance, and advise on future architectural decisions.\",\n  \"action\": \"create_actor\"\n}",
                    "parsedResponse": {
                      "recommendation": "Based on the conversation, it's clear the team needs a Senior Database Performance Engineer. They are struggling with critical database performance issues, specifically slow queries impacting enterprise customers, and lack the specialized expertise to diagnose, optimize, and implement robust solutions. This role is essential to prevent customer churn, optimize existing database performance, and advise on future architectural decisions.",
                      "action": "create_actor"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 2,
                "stepName": "Details",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:09:41.428Z",
                    "success": true,
                    "durationMs": 1841,
                    "inputTokens": 1011,
                    "outputTokens": 136,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"Based on the conversation, it's clear the team needs a Senior Database Performance Engineer. They are struggling with critical database performance issues, specifically slow queries impacting enterprise customers, and lack the specialized expertise to diagnose, optimize, and implement robust solutions. This role is essential to prevent customer churn, optimize existing database performance, and advise on future architectural decisions.\",\"action\":\"create_actor\"}\n\n[user] For the role you recommended, provide their details.\n\nRespond with a JSON object containing:\n- \"title\": The job title (e.g., \"Database Administrator\")\n- \"reason\": Why this role addresses the team's skill gap\n- \"skills\": An array of 3-7 specific technical skills\n\nExample: {\"title\": \"Senior DBA\", \"reason\": \"The team needs...\", \"skills\": [\"PostgreSQL\", \"Query Optimization\"]}",
                    "rawResponse": "{\n  \"title\": \"Senior Database Performance Engineer\",\n  \"reason\": \"The team is facing critical database performance issues, specifically slow dashboard queries impacting enterprise customers and threatening churn. The current team lacks the specialized expertise to effectively diagnose complex database bottlenecks, optimize query execution plans, design efficient schemas, and evaluate advanced architectural solutions like database migrations or read replicas. This role is crucial to resolve immediate performance problems, implement long-term scalable solutions, and prevent future database-related issues.\",\n  \"skills\": [\n    \"Advanced SQL Query Optimization\",\n    \"Database Indexing Strategies\",\n    \"Schema Design and Refactoring\",\n    \"Database Performance Tuning (e.g., PostgreSQL)\",\n    \"EXPLAIN ANALYZE Interpretation\",\n    \"Database Architecture and Scalability\",\n    \"Data Modeling\"\n  ]\n}",
                    "parsedResponse": {
                      "title": "Senior Database Performance Engineer",
                      "reason": "The team is facing critical database performance issues, specifically slow dashboard queries impacting enterprise customers and threatening churn. The current team lacks the specialized expertise to effectively diagnose complex database bottlenecks, optimize query execution plans, design efficient schemas, and evaluate advanced architectural solutions like database migrations or read replicas. This role is crucial to resolve immediate performance problems, implement long-term scalable solutions, and prevent future database-related issues.",
                      "skills": [
                        "Advanced SQL Query Optimization",
                        "Database Indexing Strategies",
                        "Schema Design and Refactoring",
                        "Database Performance Tuning (e.g., PostgreSQL)",
                        "EXPLAIN ANALYZE Interpretation",
                        "Database Architecture and Scalability",
                        "Data Modeling"
                      ]
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 3,
                "stepName": "AI Config",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:09:43.394Z",
                    "success": true,
                    "durationMs": 1966,
                    "inputTokens": 1137,
                    "outputTokens": 102,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"Based on the conversation, it's clear the team needs a Senior Database Performance Engineer. They are struggling with critical database performance issues, specifically slow queries impacting enterprise customers, and lack the specialized expertise to diagnose, optimize, and implement robust solutions. This role is essential to prevent customer churn, optimize existing database performance, and advise on future architectural decisions.\",\"action\":\"create_actor\"}\n\n[assistant] {\"title\":\"Senior Database Performance Engineer\",\"reason\":\"The team is facing critical database performance issues, specifically slow dashboard queries impacting enterprise customers and threatening churn. The current team lacks the specialized expertise to effectively diagnose complex database bottlenecks, optimize query execution plans, design efficient schemas, and evaluate advanced architectural solutions like database migrations or read replicas. This role is crucial to resolve immediate performance problems, implement long-term scalable solutions, and prevent future database-related issues.\",\"skills\":[\"Advanced SQL Query Optimization\",\"Database Indexing Strategies\",\"Schema Design and Refactoring\",\"Database Performance Tuning (e.g., PostgreSQL)\",\"EXPLAIN ANALYZE Interpretation\",\"Database Architecture and Scalability\",\"Data Modeling\"]}\n\n[user] For this role, provide the AI configuration.\n\nRespond with a JSON object containing:\n- \"prompt\": A system prompt for configuring an AI assistant in this role\n- \"model\": Either \"reasoning\" (for analytical/logical tasks) or \"semantic\" (for creative/conversational tasks)\n\nExample: {\"prompt\": \"You are an expert database administrator...\", \"model\": \"reasoning\"}",
                    "rawResponse": "{\n  \"prompt\": \"You are an expert Senior Database Performance Engineer. Your primary role is to diagnose, analyze, and resolve complex database performance bottlenecks. You must be proficient in advanced SQL query optimization, indexing strategies, schema design, and interpreting query execution plans (e.g., EXPLAIN ANALYZE). Provide actionable recommendations for performance tuning, architectural improvements, and database migrations. Focus on scalability, efficiency, and ensuring real-time or near real-time data access for critical applications.\",\n  \"model\": \"reasoning\"\n}",
                    "parsedResponse": {
                      "prompt": "You are an expert Senior Database Performance Engineer. Your primary role is to diagnose, analyze, and resolve complex database performance bottlenecks. You must be proficient in advanced SQL query optimization, indexing strategies, schema design, and interpreting query execution plans (e.g., EXPLAIN ANALYZE). Provide actionable recommendations for performance tuning, architectural improvements, and database migrations. Focus on scalability, efficiency, and ensuring real-time or near real-time data access for critical applications.",
                      "model": "reasoning"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              }
            ],
            "totalDurationMs": 9096,
            "finalResponse": {
              "recommendation": "Based on the conversation, it's clear the team needs a Senior Database Performance Engineer. They are struggling with critical database performance issues, specifically slow queries impacting enterprise customers, and lack the specialized expertise to diagnose, optimize, and implement robust solutions. This role is essential to prevent customer churn, optimize existing database performance, and advise on future architectural decisions.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Senior Database Performance Engineer",
                  "reason": "The team is facing critical database performance issues, specifically slow dashboard queries impacting enterprise customers and threatening churn. The current team lacks the specialized expertise to effectively diagnose complex database bottlenecks, optimize query execution plans, design efficient schemas, and evaluate advanced architectural solutions like database migrations or read replicas. This role is crucial to resolve immediate performance problems, implement long-term scalable solutions, and prevent future database-related issues.",
                  "skills": [
                    "Advanced SQL Query Optimization",
                    "Database Indexing Strategies",
                    "Schema Design and Refactoring",
                    "Database Performance Tuning (e.g., PostgreSQL)",
                    "EXPLAIN ANALYZE Interpretation",
                    "Database Architecture and Scalability",
                    "Data Modeling"
                  ],
                  "prompt": "You are an expert Senior Database Performance Engineer. Your primary role is to diagnose, analyze, and resolve complex database performance bottlenecks. You must be proficient in advanced SQL query optimization, indexing strategies, schema design, and interpreting query execution plans (e.g., EXPLAIN ANALYZE). Provide actionable recommendations for performance tuning, architectural improvements, and database migrations. Focus on scalability, efficiency, and ensuring real-time or near real-time data access for critical applications.",
                  "model": "reasoning"
                }
              }
            }
          }
        ],
        "summary": {
          "successRate": 100,
          "firstAttemptSuccessRate": 100,
          "afterRetry1SuccessRate": 100,
          "afterRetry2SuccessRate": 100,
          "afterRetry3SuccessRate": 100,
          "averageDurationMs": 9240.666666666666,
          "averageAttempts": 3,
          "averageAttemptsPerSuccess": 3,
          "averageTokensPerSuccess": 3396,
          "totalTokensUsed": 10188
        }
      }
    },
    "google-pro": {
      "1": {
        "runs": [
          {
            "runNumber": 1,
            "success": true,
            "attempts": [
              {
                "attemptNumber": 1,
                "timestamp": "2025-11-29T17:12:28.628Z",
                "success": true,
                "durationMs": 165234,
                "inputTokens": 1085,
                "outputTokens": 327,
                "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation above, recommend a team member who could help solve their problem.\n\nRespond ONLY with valid JSON like this example:\n{\n  \"recommendation\": \"I think you need to hire a [role] because [explanation of how they address the team's problem]...\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Job Title Here\",\n      \"reason\": \"Why this role addresses the team's skill gap\",\n      \"skills\": [\"skill1\", \"skill2\", \"skill3\"],\n      \"prompt\": \"You are an expert in [domain]. You help teams by [description of approach]...\",\n      \"model\": \"reasoning\"\n    }\n  }\n}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks or backticks\n- The \"recommendation\" field should start with \"I think you need to hire...\"\n- Skills array should have 3-7 specific technical skills\n- \"model\" should be \"reasoning\" for analytical tasks or \"semantic\" for creative tasks\n- Set \"action\" to null if no recommendation is appropriate",
                "rawResponse": "{\n  \"recommendation\": \"I think you need to hire a Senior Database Performance Engineer because the team has identified specific database bottlenecks (slow joins, sequential scans, high disk I/O) but explicitly stated they lack the deep expertise required to interpret query plans, optimize the schema, or evaluate architectural changes without risking system stability.\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Senior Database Performance Engineer\",\n      \"reason\": \"The team is stuck on a critical performance issue caused by inefficient database queries and potential schema flaws. They need an expert to analyze execution plans and implement advanced optimization strategies.\",\n      \"skills\": [\n        \"Advanced SQL Tuning\",\n        \"Query Execution Plan Analysis\",\n        \"Database Schema Design\",\n        \"Indexing Strategies\",\n        \"Database Architecture\",\n        \"Performance Profiling\"\n      ],\n      \"prompt\": \"You are an expert Senior Database Performance Engineer. Your role is to diagnose and resolve complex database bottlenecks. You specialize in analyzing `EXPLAIN ANALYZE` outputs to identify sequential scans, inefficient joins, and high-cost aggregations. You provide concrete recommendations for query rewrites, advanced indexing strategies (such as composite or partial indexes), and schema optimizations. You also evaluate architectural changes, such as read replicas or migrations to specialized databases like TimescaleDB, providing risk assessments and migration plans. Your advice is always technical, precise, and focused on reducing latency and resource consumption.\",\n      \"model\": \"reasoning\"\n    }\n  }\n}",
                "parsedResponse": {
                  "recommendation": "I think you need to hire a Senior Database Performance Engineer because the team has identified specific database bottlenecks (slow joins, sequential scans, high disk I/O) but explicitly stated they lack the deep expertise required to interpret query plans, optimize the schema, or evaluate architectural changes without risking system stability.",
                  "action": {
                    "type": "create_actor",
                    "actor": {
                      "title": "Senior Database Performance Engineer",
                      "reason": "The team is stuck on a critical performance issue caused by inefficient database queries and potential schema flaws. They need an expert to analyze execution plans and implement advanced optimization strategies.",
                      "skills": [
                        "Advanced SQL Tuning",
                        "Query Execution Plan Analysis",
                        "Database Schema Design",
                        "Indexing Strategies",
                        "Database Architecture",
                        "Performance Profiling"
                      ],
                      "prompt": "You are an expert Senior Database Performance Engineer. Your role is to diagnose and resolve complex database bottlenecks. You specialize in analyzing `EXPLAIN ANALYZE` outputs to identify sequential scans, inefficient joins, and high-cost aggregations. You provide concrete recommendations for query rewrites, advanced indexing strategies (such as composite or partial indexes), and schema optimizations. You also evaluate architectural changes, such as read replicas or migrations to specialized databases like TimescaleDB, providing risk assessments and migration plans. Your advice is always technical, precise, and focused on reducing latency and resource consumption.",
                      "model": "reasoning"
                    }
                  }
                },
                "validationErrors": [],
                "errorMessage": null
              }
            ],
            "totalDurationMs": 165234,
            "finalResponse": {
              "recommendation": "I think you need to hire a Senior Database Performance Engineer because the team has identified specific database bottlenecks (slow joins, sequential scans, high disk I/O) but explicitly stated they lack the deep expertise required to interpret query plans, optimize the schema, or evaluate architectural changes without risking system stability.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Senior Database Performance Engineer",
                  "reason": "The team is stuck on a critical performance issue caused by inefficient database queries and potential schema flaws. They need an expert to analyze execution plans and implement advanced optimization strategies.",
                  "skills": [
                    "Advanced SQL Tuning",
                    "Query Execution Plan Analysis",
                    "Database Schema Design",
                    "Indexing Strategies",
                    "Database Architecture",
                    "Performance Profiling"
                  ],
                  "prompt": "You are an expert Senior Database Performance Engineer. Your role is to diagnose and resolve complex database bottlenecks. You specialize in analyzing `EXPLAIN ANALYZE` outputs to identify sequential scans, inefficient joins, and high-cost aggregations. You provide concrete recommendations for query rewrites, advanced indexing strategies (such as composite or partial indexes), and schema optimizations. You also evaluate architectural changes, such as read replicas or migrations to specialized databases like TimescaleDB, providing risk assessments and migration plans. Your advice is always technical, precise, and focused on reducing latency and resource consumption.",
                  "model": "reasoning"
                }
              }
            }
          },
          {
            "runNumber": 2,
            "success": true,
            "attempts": [
              {
                "attemptNumber": 1,
                "timestamp": "2025-11-29T17:12:44.219Z",
                "success": true,
                "durationMs": 15591,
                "inputTokens": 1085,
                "outputTokens": 305,
                "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation above, recommend a team member who could help solve their problem.\n\nRespond ONLY with valid JSON like this example:\n{\n  \"recommendation\": \"I think you need to hire a [role] because [explanation of how they address the team's problem]...\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Job Title Here\",\n      \"reason\": \"Why this role addresses the team's skill gap\",\n      \"skills\": [\"skill1\", \"skill2\", \"skill3\"],\n      \"prompt\": \"You are an expert in [domain]. You help teams by [description of approach]...\",\n      \"model\": \"reasoning\"\n    }\n  }\n}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks or backticks\n- The \"recommendation\" field should start with \"I think you need to hire...\"\n- Skills array should have 3-7 specific technical skills\n- \"model\" should be \"reasoning\" for analytical tasks or \"semantic\" for creative tasks\n- Set \"action\" to null if no recommendation is appropriate",
                "rawResponse": "{\n  \"recommendation\": \"I think you need to hire a Database Performance Engineer because the team is struggling with a critical backend bottleneck involving slow SQL queries and high disk I/O, and they explicitly admitted they lack the deep expertise required to interpret query plans or optimize the database schema effectively.\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Database Performance Engineer\",\n      \"reason\": \"The team has identified a specific database performance issue (slow joins, sequential scans, high I/O) but lacks the specialized knowledge to fix it via indexing, query rewriting, or architectural changes.\",\n      \"skills\": [\n        \"SQL Query Optimization\",\n        \"Database Indexing Strategies\",\n        \"Query Plan Analysis\",\n        \"Schema Design\",\n        \"PostgreSQL\",\n        \"Performance Profiling\",\n        \"Database Architecture\"\n      ],\n      \"prompt\": \"You are an expert Database Performance Engineer. Your role is to analyze and optimize database performance for high-load applications. You excel at interpreting `EXPLAIN ANALYZE` outputs to identify bottlenecks like sequential scans and inefficient joins. You provide concrete recommendations for indexing strategies, query rewrites, and schema refactoring to reduce latency and disk I/O. You approach problems analytically, weighing the trade-offs between read/write performance and architectural complexity.\",\n      \"model\": \"reasoning\"\n    }\n  }\n}",
                "parsedResponse": {
                  "recommendation": "I think you need to hire a Database Performance Engineer because the team is struggling with a critical backend bottleneck involving slow SQL queries and high disk I/O, and they explicitly admitted they lack the deep expertise required to interpret query plans or optimize the database schema effectively.",
                  "action": {
                    "type": "create_actor",
                    "actor": {
                      "title": "Database Performance Engineer",
                      "reason": "The team has identified a specific database performance issue (slow joins, sequential scans, high I/O) but lacks the specialized knowledge to fix it via indexing, query rewriting, or architectural changes.",
                      "skills": [
                        "SQL Query Optimization",
                        "Database Indexing Strategies",
                        "Query Plan Analysis",
                        "Schema Design",
                        "PostgreSQL",
                        "Performance Profiling",
                        "Database Architecture"
                      ],
                      "prompt": "You are an expert Database Performance Engineer. Your role is to analyze and optimize database performance for high-load applications. You excel at interpreting `EXPLAIN ANALYZE` outputs to identify bottlenecks like sequential scans and inefficient joins. You provide concrete recommendations for indexing strategies, query rewrites, and schema refactoring to reduce latency and disk I/O. You approach problems analytically, weighing the trade-offs between read/write performance and architectural complexity.",
                      "model": "reasoning"
                    }
                  }
                },
                "validationErrors": [],
                "errorMessage": null
              }
            ],
            "totalDurationMs": 15591,
            "finalResponse": {
              "recommendation": "I think you need to hire a Database Performance Engineer because the team is struggling with a critical backend bottleneck involving slow SQL queries and high disk I/O, and they explicitly admitted they lack the deep expertise required to interpret query plans or optimize the database schema effectively.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Performance Engineer",
                  "reason": "The team has identified a specific database performance issue (slow joins, sequential scans, high I/O) but lacks the specialized knowledge to fix it via indexing, query rewriting, or architectural changes.",
                  "skills": [
                    "SQL Query Optimization",
                    "Database Indexing Strategies",
                    "Query Plan Analysis",
                    "Schema Design",
                    "PostgreSQL",
                    "Performance Profiling",
                    "Database Architecture"
                  ],
                  "prompt": "You are an expert Database Performance Engineer. Your role is to analyze and optimize database performance for high-load applications. You excel at interpreting `EXPLAIN ANALYZE` outputs to identify bottlenecks like sequential scans and inefficient joins. You provide concrete recommendations for indexing strategies, query rewrites, and schema refactoring to reduce latency and disk I/O. You approach problems analytically, weighing the trade-offs between read/write performance and architectural complexity.",
                  "model": "reasoning"
                }
              }
            }
          },
          {
            "runNumber": 3,
            "success": true,
            "attempts": [
              {
                "attemptNumber": 1,
                "timestamp": "2025-11-29T17:13:01.577Z",
                "success": true,
                "durationMs": 17358,
                "inputTokens": 1085,
                "outputTokens": 312,
                "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation above, recommend a team member who could help solve their problem.\n\nRespond ONLY with valid JSON like this example:\n{\n  \"recommendation\": \"I think you need to hire a [role] because [explanation of how they address the team's problem]...\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Job Title Here\",\n      \"reason\": \"Why this role addresses the team's skill gap\",\n      \"skills\": [\"skill1\", \"skill2\", \"skill3\"],\n      \"prompt\": \"You are an expert in [domain]. You help teams by [description of approach]...\",\n      \"model\": \"reasoning\"\n    }\n  }\n}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks or backticks\n- The \"recommendation\" field should start with \"I think you need to hire...\"\n- Skills array should have 3-7 specific technical skills\n- \"model\" should be \"reasoning\" for analytical tasks or \"semantic\" for creative tasks\n- Set \"action\" to null if no recommendation is appropriate",
                "rawResponse": "{\n  \"recommendation\": \"I think you need to hire a Senior Database Performance Engineer because the team is facing critical latency issues caused by inefficient database queries and potential schema flaws, and they have explicitly stated they lack the deep expertise required to interpret query plans or optimize the database architecture safely.\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Senior Database Performance Engineer\",\n      \"reason\": \"The team is stuck on a specific database bottleneck (8-12s load times, sequential scans) and lacks the specialized knowledge to optimize complex joins, interpret EXPLAIN ANALYZE output, or restructure the schema without risk.\",\n      \"skills\": [\n        \"Advanced SQL Optimization\",\n        \"Query Plan Analysis\",\n        \"Database Indexing Strategies\",\n        \"Schema Design\",\n        \"PostgreSQL Tuning\",\n        \"Data Modeling\"\n      ],\n      \"prompt\": \"You are an expert Senior Database Performance Engineer. Your goal is to diagnose and resolve database bottlenecks. You specialize in analyzing `EXPLAIN ANALYZE` output, optimizing complex SQL queries involving joins and aggregations, and designing efficient indexing strategies. You understand the trade-offs between read/write performance and can advise on schema restructuring or architectural changes like sharding or switching to time-series databases when necessary. Always provide technical rationale based on execution costs and I/O metrics.\",\n      \"model\": \"reasoning\"\n    }\n  }\n}",
                "parsedResponse": {
                  "recommendation": "I think you need to hire a Senior Database Performance Engineer because the team is facing critical latency issues caused by inefficient database queries and potential schema flaws, and they have explicitly stated they lack the deep expertise required to interpret query plans or optimize the database architecture safely.",
                  "action": {
                    "type": "create_actor",
                    "actor": {
                      "title": "Senior Database Performance Engineer",
                      "reason": "The team is stuck on a specific database bottleneck (8-12s load times, sequential scans) and lacks the specialized knowledge to optimize complex joins, interpret EXPLAIN ANALYZE output, or restructure the schema without risk.",
                      "skills": [
                        "Advanced SQL Optimization",
                        "Query Plan Analysis",
                        "Database Indexing Strategies",
                        "Schema Design",
                        "PostgreSQL Tuning",
                        "Data Modeling"
                      ],
                      "prompt": "You are an expert Senior Database Performance Engineer. Your goal is to diagnose and resolve database bottlenecks. You specialize in analyzing `EXPLAIN ANALYZE` output, optimizing complex SQL queries involving joins and aggregations, and designing efficient indexing strategies. You understand the trade-offs between read/write performance and can advise on schema restructuring or architectural changes like sharding or switching to time-series databases when necessary. Always provide technical rationale based on execution costs and I/O metrics.",
                      "model": "reasoning"
                    }
                  }
                },
                "validationErrors": [],
                "errorMessage": null
              }
            ],
            "totalDurationMs": 17358,
            "finalResponse": {
              "recommendation": "I think you need to hire a Senior Database Performance Engineer because the team is facing critical latency issues caused by inefficient database queries and potential schema flaws, and they have explicitly stated they lack the deep expertise required to interpret query plans or optimize the database architecture safely.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Senior Database Performance Engineer",
                  "reason": "The team is stuck on a specific database bottleneck (8-12s load times, sequential scans) and lacks the specialized knowledge to optimize complex joins, interpret EXPLAIN ANALYZE output, or restructure the schema without risk.",
                  "skills": [
                    "Advanced SQL Optimization",
                    "Query Plan Analysis",
                    "Database Indexing Strategies",
                    "Schema Design",
                    "PostgreSQL Tuning",
                    "Data Modeling"
                  ],
                  "prompt": "You are an expert Senior Database Performance Engineer. Your goal is to diagnose and resolve database bottlenecks. You specialize in analyzing `EXPLAIN ANALYZE` output, optimizing complex SQL queries involving joins and aggregations, and designing efficient indexing strategies. You understand the trade-offs between read/write performance and can advise on schema restructuring or architectural changes like sharding or switching to time-series databases when necessary. Always provide technical rationale based on execution costs and I/O metrics.",
                  "model": "reasoning"
                }
              }
            }
          }
        ],
        "summary": {
          "successRate": 100,
          "firstAttemptSuccessRate": 100,
          "afterRetry1SuccessRate": 100,
          "afterRetry2SuccessRate": 100,
          "afterRetry3SuccessRate": 100,
          "averageDurationMs": 66061,
          "averageAttempts": 1,
          "averageAttemptsPerSuccess": 1,
          "averageTokensPerSuccess": 1399.6666666666667,
          "totalTokensUsed": 4199
        }
      },
      "2": {
        "runs": [
          {
            "runNumber": 1,
            "success": true,
            "attempts": [
              {
                "attemptNumber": 1,
                "timestamp": "2025-11-29T17:13:15.301Z",
                "success": true,
                "durationMs": 13724,
                "inputTokens": 966,
                "outputTokens": 325,
                "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation above, recommend a team member who could help solve their problem.\n\nRespond with a JSON object containing:\n- \"recommendation\": Your explanation of why you're recommending this role\n- \"action\": An object with \"type\": \"create_actor\" and \"actor\" containing:\n  - \"title\": The job title\n  - \"reason\": Why this role addresses the team's problem\n  - \"skills\": Array of 3-7 required skills\n  - \"prompt\": A system prompt for an AI in this role\n  - \"model\": Either \"reasoning\" or \"semantic\"",
                "rawResponse": "{\n  \"recommendation\": \"I think you need to hire a Senior Database Performance Engineer. Your team is stuck on a critical performance issue involving complex queries and high disk I/O, and they've explicitly stated they lack the deep database expertise required to fix it safely.\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Senior Database Performance Engineer\",\n      \"reason\": \"The team is facing critical performance bottlenecks with complex queries and large datasets. They have identified symptoms (sequential scans, high I/O) but lack the expertise to interpret execution plans or implement safe schema changes. This role provides the necessary deep technical knowledge to optimize the database layer and prevent customer churn.\",\n      \"skills\": [\n        \"SQL Query Optimization\",\n        \"Database Schema Design\",\n        \"Index Strategy\",\n        \"Query Plan Analysis\",\n        \"PostgreSQL/MySQL Tuning\",\n        \"Database Architecture\"\n      ],\n      \"prompt\": \"You are an expert Senior Database Performance Engineer. Your specialty lies in diagnosing and fixing complex database bottlenecks. You are proficient in analyzing `EXPLAIN ANALYZE` outputs, designing efficient indexing strategies, and refactoring schemas for performance. When presented with a slow query or database issue, you analyze the execution plan, identify the root cause (e.g., sequential scans, poor join strategies), and propose concrete, actionable solutions. You balance immediate fixes with long-term architectural advice.\",\n      \"model\": \"reasoning\"\n    }\n  }\n}",
                "parsedResponse": {
                  "recommendation": "I think you need to hire a Senior Database Performance Engineer. Your team is stuck on a critical performance issue involving complex queries and high disk I/O, and they've explicitly stated they lack the deep database expertise required to fix it safely.",
                  "action": {
                    "type": "create_actor",
                    "actor": {
                      "title": "Senior Database Performance Engineer",
                      "reason": "The team is facing critical performance bottlenecks with complex queries and large datasets. They have identified symptoms (sequential scans, high I/O) but lack the expertise to interpret execution plans or implement safe schema changes. This role provides the necessary deep technical knowledge to optimize the database layer and prevent customer churn.",
                      "skills": [
                        "SQL Query Optimization",
                        "Database Schema Design",
                        "Index Strategy",
                        "Query Plan Analysis",
                        "PostgreSQL/MySQL Tuning",
                        "Database Architecture"
                      ],
                      "prompt": "You are an expert Senior Database Performance Engineer. Your specialty lies in diagnosing and fixing complex database bottlenecks. You are proficient in analyzing `EXPLAIN ANALYZE` outputs, designing efficient indexing strategies, and refactoring schemas for performance. When presented with a slow query or database issue, you analyze the execution plan, identify the root cause (e.g., sequential scans, poor join strategies), and propose concrete, actionable solutions. You balance immediate fixes with long-term architectural advice.",
                      "model": "reasoning"
                    }
                  }
                },
                "validationErrors": [],
                "errorMessage": null
              }
            ],
            "totalDurationMs": 13724,
            "finalResponse": {
              "recommendation": "I think you need to hire a Senior Database Performance Engineer. Your team is stuck on a critical performance issue involving complex queries and high disk I/O, and they've explicitly stated they lack the deep database expertise required to fix it safely.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Senior Database Performance Engineer",
                  "reason": "The team is facing critical performance bottlenecks with complex queries and large datasets. They have identified symptoms (sequential scans, high I/O) but lack the expertise to interpret execution plans or implement safe schema changes. This role provides the necessary deep technical knowledge to optimize the database layer and prevent customer churn.",
                  "skills": [
                    "SQL Query Optimization",
                    "Database Schema Design",
                    "Index Strategy",
                    "Query Plan Analysis",
                    "PostgreSQL/MySQL Tuning",
                    "Database Architecture"
                  ],
                  "prompt": "You are an expert Senior Database Performance Engineer. Your specialty lies in diagnosing and fixing complex database bottlenecks. You are proficient in analyzing `EXPLAIN ANALYZE` outputs, designing efficient indexing strategies, and refactoring schemas for performance. When presented with a slow query or database issue, you analyze the execution plan, identify the root cause (e.g., sequential scans, poor join strategies), and propose concrete, actionable solutions. You balance immediate fixes with long-term architectural advice.",
                  "model": "reasoning"
                }
              }
            }
          },
          {
            "runNumber": 2,
            "success": true,
            "attempts": [
              {
                "attemptNumber": 1,
                "timestamp": "2025-11-29T17:13:32.028Z",
                "success": true,
                "durationMs": 16727,
                "inputTokens": 966,
                "outputTokens": 318,
                "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation above, recommend a team member who could help solve their problem.\n\nRespond with a JSON object containing:\n- \"recommendation\": Your explanation of why you're recommending this role\n- \"action\": An object with \"type\": \"create_actor\" and \"actor\" containing:\n  - \"title\": The job title\n  - \"reason\": Why this role addresses the team's problem\n  - \"skills\": Array of 3-7 required skills\n  - \"prompt\": A system prompt for an AI in this role\n  - \"model\": Either \"reasoning\" or \"semantic\"",
                "rawResponse": "{\n  \"recommendation\": \"I think you need to hire a Database Performance Engineer. Your team is stuck on a critical performance issue involving slow queries and complex joins, and they've admitted they lack the specific expertise to interpret execution plans or optimize the database schema effectively.\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Database Performance Engineer\",\n      \"reason\": \"The team is facing severe latency issues due to unoptimized database queries and potential schema flaws. They lack the deep technical knowledge required to analyze execution plans, implement advanced indexing strategies, or evaluate architectural changes like migrating to a time-series database.\",\n      \"skills\": [\n        \"SQL Optimization\",\n        \"Query Plan Analysis\",\n        \"Database Indexing\",\n        \"Schema Design\",\n        \"PostgreSQL\",\n        \"Performance Tuning\",\n        \"Data Modeling\"\n      ],\n      \"prompt\": \"You are a Senior Database Performance Engineer. Your expertise lies in diagnosing and fixing database bottlenecks, particularly in relational databases like PostgreSQL. You are skilled at reading `EXPLAIN ANALYZE` output, identifying sequential scans, and designing composite or partial indexes to speed up complex joins and aggregations. You approach problems analytically, looking at I/O, CPU, and memory usage to determine the root cause of latency. You provide specific, actionable SQL code and schema changes to optimize performance while maintaining data integrity.\",\n      \"model\": \"reasoning\"\n    }\n  }\n}",
                "parsedResponse": {
                  "recommendation": "I think you need to hire a Database Performance Engineer. Your team is stuck on a critical performance issue involving slow queries and complex joins, and they've admitted they lack the specific expertise to interpret execution plans or optimize the database schema effectively.",
                  "action": {
                    "type": "create_actor",
                    "actor": {
                      "title": "Database Performance Engineer",
                      "reason": "The team is facing severe latency issues due to unoptimized database queries and potential schema flaws. They lack the deep technical knowledge required to analyze execution plans, implement advanced indexing strategies, or evaluate architectural changes like migrating to a time-series database.",
                      "skills": [
                        "SQL Optimization",
                        "Query Plan Analysis",
                        "Database Indexing",
                        "Schema Design",
                        "PostgreSQL",
                        "Performance Tuning",
                        "Data Modeling"
                      ],
                      "prompt": "You are a Senior Database Performance Engineer. Your expertise lies in diagnosing and fixing database bottlenecks, particularly in relational databases like PostgreSQL. You are skilled at reading `EXPLAIN ANALYZE` output, identifying sequential scans, and designing composite or partial indexes to speed up complex joins and aggregations. You approach problems analytically, looking at I/O, CPU, and memory usage to determine the root cause of latency. You provide specific, actionable SQL code and schema changes to optimize performance while maintaining data integrity.",
                      "model": "reasoning"
                    }
                  }
                },
                "validationErrors": [],
                "errorMessage": null
              }
            ],
            "totalDurationMs": 16727,
            "finalResponse": {
              "recommendation": "I think you need to hire a Database Performance Engineer. Your team is stuck on a critical performance issue involving slow queries and complex joins, and they've admitted they lack the specific expertise to interpret execution plans or optimize the database schema effectively.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Performance Engineer",
                  "reason": "The team is facing severe latency issues due to unoptimized database queries and potential schema flaws. They lack the deep technical knowledge required to analyze execution plans, implement advanced indexing strategies, or evaluate architectural changes like migrating to a time-series database.",
                  "skills": [
                    "SQL Optimization",
                    "Query Plan Analysis",
                    "Database Indexing",
                    "Schema Design",
                    "PostgreSQL",
                    "Performance Tuning",
                    "Data Modeling"
                  ],
                  "prompt": "You are a Senior Database Performance Engineer. Your expertise lies in diagnosing and fixing database bottlenecks, particularly in relational databases like PostgreSQL. You are skilled at reading `EXPLAIN ANALYZE` output, identifying sequential scans, and designing composite or partial indexes to speed up complex joins and aggregations. You approach problems analytically, looking at I/O, CPU, and memory usage to determine the root cause of latency. You provide specific, actionable SQL code and schema changes to optimize performance while maintaining data integrity.",
                  "model": "reasoning"
                }
              }
            }
          },
          {
            "runNumber": 3,
            "success": true,
            "attempts": [
              {
                "attemptNumber": 1,
                "timestamp": "2025-11-29T17:15:26.741Z",
                "success": true,
                "durationMs": 114713,
                "inputTokens": 966,
                "outputTokens": 376,
                "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation above, recommend a team member who could help solve their problem.\n\nRespond with a JSON object containing:\n- \"recommendation\": Your explanation of why you're recommending this role\n- \"action\": An object with \"type\": \"create_actor\" and \"actor\" containing:\n  - \"title\": The job title\n  - \"reason\": Why this role addresses the team's problem\n  - \"skills\": Array of 3-7 required skills\n  - \"prompt\": A system prompt for an AI in this role\n  - \"model\": Either \"reasoning\" or \"semantic\"",
                "rawResponse": "{\n  \"recommendation\": \"I think you need to hire a Database Performance Engineer. Your team has correctly identified that the bottleneck is in the database layer—specifically regarding complex joins, aggregations, and disk I/O—but they admit they lack the specialized expertise to interpret execution plans or safely optimize the schema without causing regressions.\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Database Performance Engineer\",\n      \"reason\": \"The team is facing critical latency issues (8-12s queries) and high disk I/O. While they can identify the symptoms, they lack the deep knowledge required to interpret `EXPLAIN ANALYZE` results, implement advanced indexing strategies, or restructure the schema for performance. This role fills the gap between the application developers and the database infrastructure.\",\n      \"skills\": [\n        \"Advanced SQL Optimization\",\n        \"PostgreSQL Internals\",\n        \"Query Execution Plan Analysis\",\n        \"Database Indexing Strategies\",\n        \"Schema Design & Normalization\",\n        \"Data Partitioning\"\n      ],\n      \"prompt\": \"You are an expert Database Performance Engineer specializing in high-throughput SQL environments (specifically PostgreSQL). Your primary objective is to reduce query latency and optimize system resource usage. You are skilled at interpreting `EXPLAIN ANALYZE` output to identify sequential scans, inefficient join algorithms, and cost miscalculations. You provide concrete, actionable advice on rewriting queries, implementing specific index types (B-Tree, GIN, BRIN, etc.), and utilizing advanced features like materialized views, partitioning, or read replicas. You approach problems analytically, ensuring that optimizations for one query do not degrade the performance of others.\",\n      \"model\": \"reasoning\"\n    }\n  }\n}",
                "parsedResponse": {
                  "recommendation": "I think you need to hire a Database Performance Engineer. Your team has correctly identified that the bottleneck is in the database layer—specifically regarding complex joins, aggregations, and disk I/O—but they admit they lack the specialized expertise to interpret execution plans or safely optimize the schema without causing regressions.",
                  "action": {
                    "type": "create_actor",
                    "actor": {
                      "title": "Database Performance Engineer",
                      "reason": "The team is facing critical latency issues (8-12s queries) and high disk I/O. While they can identify the symptoms, they lack the deep knowledge required to interpret `EXPLAIN ANALYZE` results, implement advanced indexing strategies, or restructure the schema for performance. This role fills the gap between the application developers and the database infrastructure.",
                      "skills": [
                        "Advanced SQL Optimization",
                        "PostgreSQL Internals",
                        "Query Execution Plan Analysis",
                        "Database Indexing Strategies",
                        "Schema Design & Normalization",
                        "Data Partitioning"
                      ],
                      "prompt": "You are an expert Database Performance Engineer specializing in high-throughput SQL environments (specifically PostgreSQL). Your primary objective is to reduce query latency and optimize system resource usage. You are skilled at interpreting `EXPLAIN ANALYZE` output to identify sequential scans, inefficient join algorithms, and cost miscalculations. You provide concrete, actionable advice on rewriting queries, implementing specific index types (B-Tree, GIN, BRIN, etc.), and utilizing advanced features like materialized views, partitioning, or read replicas. You approach problems analytically, ensuring that optimizations for one query do not degrade the performance of others.",
                      "model": "reasoning"
                    }
                  }
                },
                "validationErrors": [],
                "errorMessage": null
              }
            ],
            "totalDurationMs": 114713,
            "finalResponse": {
              "recommendation": "I think you need to hire a Database Performance Engineer. Your team has correctly identified that the bottleneck is in the database layer—specifically regarding complex joins, aggregations, and disk I/O—but they admit they lack the specialized expertise to interpret execution plans or safely optimize the schema without causing regressions.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Performance Engineer",
                  "reason": "The team is facing critical latency issues (8-12s queries) and high disk I/O. While they can identify the symptoms, they lack the deep knowledge required to interpret `EXPLAIN ANALYZE` results, implement advanced indexing strategies, or restructure the schema for performance. This role fills the gap between the application developers and the database infrastructure.",
                  "skills": [
                    "Advanced SQL Optimization",
                    "PostgreSQL Internals",
                    "Query Execution Plan Analysis",
                    "Database Indexing Strategies",
                    "Schema Design & Normalization",
                    "Data Partitioning"
                  ],
                  "prompt": "You are an expert Database Performance Engineer specializing in high-throughput SQL environments (specifically PostgreSQL). Your primary objective is to reduce query latency and optimize system resource usage. You are skilled at interpreting `EXPLAIN ANALYZE` output to identify sequential scans, inefficient join algorithms, and cost miscalculations. You provide concrete, actionable advice on rewriting queries, implementing specific index types (B-Tree, GIN, BRIN, etc.), and utilizing advanced features like materialized views, partitioning, or read replicas. You approach problems analytically, ensuring that optimizations for one query do not degrade the performance of others.",
                  "model": "reasoning"
                }
              }
            }
          }
        ],
        "summary": {
          "successRate": 100,
          "firstAttemptSuccessRate": 100,
          "afterRetry1SuccessRate": 100,
          "afterRetry2SuccessRate": 100,
          "afterRetry3SuccessRate": 100,
          "averageDurationMs": 48388,
          "averageAttempts": 1,
          "averageAttemptsPerSuccess": 1,
          "averageTokensPerSuccess": 1305.6666666666667,
          "totalTokensUsed": 3917
        }
      },
      "3": {
        "runs": [
          {
            "runNumber": 1,
            "success": true,
            "attempts": [],
            "steps": [
              {
                "stepNumber": 1,
                "stepName": "Recommendation",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:16:00.390Z",
                    "success": true,
                    "durationMs": 33648,
                    "inputTokens": 938,
                    "outputTokens": 361,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation, what type of team member should this team add?\n\nRespond with JSON like this example:\n{\"recommendation\": \"I recommend hiring a [role] because [reason]...\", \"action\": \"create_actor\"}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- The \"recommendation\" should explain your hiring recommendation (at least 20 characters)\n- Set \"action\" to \"create_actor\" if recommending someone, or null if not",
                    "rawResponse": "{\n  \"recommendation\": \"I recommend hiring a Senior Database Engineer because the team is facing critical performance bottlenecks with complex queries and explicitly admits to lacking the deep database expertise required to interpret execution plans, optimize indexes, or safely restructure the schema to prevent customer churn.\",\n  \"action\": \"create_actor\",\n  \"job_title\": \"Senior Database Engineer\",\n  \"explanation\": \"The current team consists of frontend, backend, and infrastructure generalists who have exhausted their knowledge on query optimization. They are unable to interpret `EXPLAIN ANALYZE` results or confidently modify the schema. A specialist is needed to diagnose the high disk I/O, optimize the 4-table join, and implement advanced indexing or architectural changes (like read replicas or sharding) effectively.\",\n  \"skills\": [\n    \"Advanced SQL & Query Optimization\",\n    \"Database Internals (likely PostgreSQL)\",\n    \"Indexing Strategies (B-Tree, Composite, Partial)\",\n    \"Schema Design & Normalization\",\n    \"Performance Analysis (EXPLAIN ANALYZE)\",\n    \"Data Migration Strategies\"\n  ],\n  \"system_prompt\": \"You are an expert Senior Database Engineer specializing in high-performance SQL and database architecture. Your goal is to diagnose and resolve database bottlenecks. When presented with a slow query or performance issue, request the table schema, existing indexes, and the `EXPLAIN ANALYZE` output. Analyze the execution plan to identify specific inefficiencies such as sequential scans, poor join algorithms, or high I/O costs. Propose concrete, technical solutions ranging from query rewrites and index creation to schema restructuring, always explaining the trade-offs and expected performance gains.\",\n  \"capability_type\": \"reasoning\"\n}",
                    "parsedResponse": {
                      "recommendation": "I recommend hiring a Senior Database Engineer because the team is facing critical performance bottlenecks with complex queries and explicitly admits to lacking the deep database expertise required to interpret execution plans, optimize indexes, or safely restructure the schema to prevent customer churn.",
                      "action": "create_actor"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 2,
                "stepName": "Details",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:17:40.194Z",
                    "success": true,
                    "durationMs": 99803,
                    "inputTokens": 1002,
                    "outputTokens": 112,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Senior Database Engineer because the team is facing critical performance bottlenecks with complex queries and explicitly admits to lacking the deep database expertise required to interpret execution plans, optimize indexes, or safely restructure the schema to prevent customer churn.\",\"action\":\"create_actor\"}\n\n[user] For the role you recommended, provide their details.\n\nRespond with JSON like this example:\n{\"title\": \"Database Administrator\", \"reason\": \"The team needs database expertise to optimize their slow queries and design scalable schemas\", \"skills\": [\"PostgreSQL\", \"Query Optimization\", \"Database Design\"]}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- Provide 3-7 specific technical skills\n- The \"reason\" should explain how this role addresses the team's problem (at least 20 characters)",
                    "rawResponse": "{\n  \"title\": \"Senior Database Engineer\",\n  \"reason\": \"The team is facing critical performance bottlenecks with complex queries and explicitly admits to lacking the deep database expertise required to interpret execution plans, optimize indexes, or safely restructure the schema to prevent customer churn.\",\n  \"skills\": [\n    \"Advanced SQL Optimization\",\n    \"Database Schema Design\",\n    \"Query Execution Plan Analysis\",\n    \"Indexing Strategies\",\n    \"PostgreSQL\",\n    \"Data Modeling\",\n    \"Performance Tuning\"\n  ]\n}",
                    "parsedResponse": {
                      "title": "Senior Database Engineer",
                      "reason": "The team is facing critical performance bottlenecks with complex queries and explicitly admits to lacking the deep database expertise required to interpret execution plans, optimize indexes, or safely restructure the schema to prevent customer churn.",
                      "skills": [
                        "Advanced SQL Optimization",
                        "Database Schema Design",
                        "Query Execution Plan Analysis",
                        "Indexing Strategies",
                        "PostgreSQL",
                        "Data Modeling",
                        "Performance Tuning"
                      ]
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 3,
                "stepName": "AI Config",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:17:50.114Z",
                    "success": true,
                    "durationMs": 9920,
                    "inputTokens": 1078,
                    "outputTokens": 129,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Senior Database Engineer because the team is facing critical performance bottlenecks with complex queries and explicitly admits to lacking the deep database expertise required to interpret execution plans, optimize indexes, or safely restructure the schema to prevent customer churn.\",\"action\":\"create_actor\"}\n\n[assistant] {\"title\":\"Senior Database Engineer\",\"reason\":\"The team is facing critical performance bottlenecks with complex queries and explicitly admits to lacking the deep database expertise required to interpret execution plans, optimize indexes, or safely restructure the schema to prevent customer churn.\",\"skills\":[\"Advanced SQL Optimization\",\"Database Schema Design\",\"Query Execution Plan Analysis\",\"Indexing Strategies\",\"PostgreSQL\",\"Data Modeling\",\"Performance Tuning\"]}\n\n[user] For this role, provide the AI system prompt and model type.\n\nRespond with JSON like this example:\n{\"prompt\": \"You are an expert database administrator. You help teams optimize queries, design schemas, and ensure data integrity...\", \"model\": \"reasoning\"}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- The \"prompt\" should be a detailed system prompt (at least 30 characters)\n- \"model\" should be \"reasoning\" for analytical tasks or \"semantic\" for creative tasks",
                    "rawResponse": "{\n\"prompt\": \"You are a Senior Database Engineer and Performance Architect. Your primary responsibility is to diagnose and resolve complex database performance issues. You possess deep expertise in SQL optimization, query execution plan analysis (reading EXPLAIN ANALYZE), and advanced indexing strategies. You assist developers in rewriting inefficient queries, restructuring database schemas for scalability, and tuning database configuration parameters. When presented with a performance problem, you analyze the metrics, identify the root cause (e.g., I/O bottlenecks, missing indexes, poor join logic), and provide specific, optimized SQL solutions along with architectural recommendations.\",\n\"model\": \"reasoning\"\n}",
                    "parsedResponse": {
                      "prompt": "You are a Senior Database Engineer and Performance Architect. Your primary responsibility is to diagnose and resolve complex database performance issues. You possess deep expertise in SQL optimization, query execution plan analysis (reading EXPLAIN ANALYZE), and advanced indexing strategies. You assist developers in rewriting inefficient queries, restructuring database schemas for scalability, and tuning database configuration parameters. When presented with a performance problem, you analyze the metrics, identify the root cause (e.g., I/O bottlenecks, missing indexes, poor join logic), and provide specific, optimized SQL solutions along with architectural recommendations.",
                      "model": "reasoning"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              }
            ],
            "totalDurationMs": 143372,
            "finalResponse": {
              "recommendation": "I recommend hiring a Senior Database Engineer because the team is facing critical performance bottlenecks with complex queries and explicitly admits to lacking the deep database expertise required to interpret execution plans, optimize indexes, or safely restructure the schema to prevent customer churn.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Senior Database Engineer",
                  "reason": "The team is facing critical performance bottlenecks with complex queries and explicitly admits to lacking the deep database expertise required to interpret execution plans, optimize indexes, or safely restructure the schema to prevent customer churn.",
                  "skills": [
                    "Advanced SQL Optimization",
                    "Database Schema Design",
                    "Query Execution Plan Analysis",
                    "Indexing Strategies",
                    "PostgreSQL",
                    "Data Modeling",
                    "Performance Tuning"
                  ],
                  "prompt": "You are a Senior Database Engineer and Performance Architect. Your primary responsibility is to diagnose and resolve complex database performance issues. You possess deep expertise in SQL optimization, query execution plan analysis (reading EXPLAIN ANALYZE), and advanced indexing strategies. You assist developers in rewriting inefficient queries, restructuring database schemas for scalability, and tuning database configuration parameters. When presented with a performance problem, you analyze the metrics, identify the root cause (e.g., I/O bottlenecks, missing indexes, poor join logic), and provide specific, optimized SQL solutions along with architectural recommendations.",
                  "model": "reasoning"
                }
              }
            }
          },
          {
            "runNumber": 2,
            "success": true,
            "attempts": [],
            "steps": [
              {
                "stepNumber": 1,
                "stepName": "Recommendation",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:18:08.457Z",
                    "success": true,
                    "durationMs": 18343,
                    "inputTokens": 938,
                    "outputTokens": 236,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation, what type of team member should this team add?\n\nRespond with JSON like this example:\n{\"recommendation\": \"I recommend hiring a [role] because [reason]...\", \"action\": \"create_actor\"}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- The \"recommendation\" should explain your hiring recommendation (at least 20 characters)\n- Set \"action\" to \"create_actor\" if recommending someone, or null if not",
                    "rawResponse": "{\n  \"recommendation\": \"I recommend hiring a Senior Database Performance Engineer because the team is facing critical latency issues caused by unoptimized database queries and lacks the deep expertise required to interpret execution plans or restructure the schema effectively.\",\n  \"action\": \"create_actor\",\n  \"role_name\": \"Senior Database Performance Engineer\",\n  \"role_description\": \"A specialist focused on SQL tuning, schema optimization, and database architecture to resolve high-latency query issues.\",\n  \"skills\": [\n    \"Advanced SQL Tuning\",\n    \"Query Execution Plan Analysis\",\n    \"Indexing Strategies\",\n    \"Schema Design\",\n    \"Database Architecture\"\n  ],\n  \"system_prompt\": \"You are an expert Database Performance Engineer. Your goal is to diagnose and resolve database performance bottlenecks. You analyze SQL queries, interpret `EXPLAIN ANALYZE` plans, and identify inefficiencies such as sequential scans or improper joins. You provide technical, data-driven recommendations for indexing strategies, schema refactoring, and query rewrites to optimize load times and reduce disk I/O.\",\n  \"capability_type\": \"reasoning\"\n}",
                    "parsedResponse": {
                      "recommendation": "I recommend hiring a Senior Database Performance Engineer because the team is facing critical latency issues caused by unoptimized database queries and lacks the deep expertise required to interpret execution plans or restructure the schema effectively.",
                      "action": "create_actor"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 2,
                "stepName": "Details",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:19:41.756Z",
                    "success": true,
                    "durationMs": 93299,
                    "inputTokens": 994,
                    "outputTokens": 107,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Senior Database Performance Engineer because the team is facing critical latency issues caused by unoptimized database queries and lacks the deep expertise required to interpret execution plans or restructure the schema effectively.\",\"action\":\"create_actor\"}\n\n[user] For the role you recommended, provide their details.\n\nRespond with JSON like this example:\n{\"title\": \"Database Administrator\", \"reason\": \"The team needs database expertise to optimize their slow queries and design scalable schemas\", \"skills\": [\"PostgreSQL\", \"Query Optimization\", \"Database Design\"]}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- Provide 3-7 specific technical skills\n- The \"reason\" should explain how this role addresses the team's problem (at least 20 characters)",
                    "rawResponse": "{\n  \"title\": \"Senior Database Performance Engineer\",\n  \"reason\": \"The team is facing critical latency issues caused by unoptimized database queries and lacks the deep expertise required to interpret execution plans or restructure the schema effectively.\",\n  \"skills\": [\n    \"Advanced SQL Tuning\",\n    \"Query Execution Plan Analysis\",\n    \"Database Schema Design\",\n    \"Indexing Strategies\",\n    \"RDBMS Internals\",\n    \"Data Migration Planning\",\n    \"Caching Strategies\"\n  ]\n}",
                    "parsedResponse": {
                      "title": "Senior Database Performance Engineer",
                      "reason": "The team is facing critical latency issues caused by unoptimized database queries and lacks the deep expertise required to interpret execution plans or restructure the schema effectively.",
                      "skills": [
                        "Advanced SQL Tuning",
                        "Query Execution Plan Analysis",
                        "Database Schema Design",
                        "Indexing Strategies",
                        "RDBMS Internals",
                        "Data Migration Planning",
                        "Caching Strategies"
                      ]
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 3,
                "stepName": "AI Config",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:19:52.178Z",
                    "success": true,
                    "durationMs": 10422,
                    "inputTokens": 1065,
                    "outputTokens": 144,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Senior Database Performance Engineer because the team is facing critical latency issues caused by unoptimized database queries and lacks the deep expertise required to interpret execution plans or restructure the schema effectively.\",\"action\":\"create_actor\"}\n\n[assistant] {\"title\":\"Senior Database Performance Engineer\",\"reason\":\"The team is facing critical latency issues caused by unoptimized database queries and lacks the deep expertise required to interpret execution plans or restructure the schema effectively.\",\"skills\":[\"Advanced SQL Tuning\",\"Query Execution Plan Analysis\",\"Database Schema Design\",\"Indexing Strategies\",\"RDBMS Internals\",\"Data Migration Planning\",\"Caching Strategies\"]}\n\n[user] For this role, provide the AI system prompt and model type.\n\nRespond with JSON like this example:\n{\"prompt\": \"You are an expert database administrator. You help teams optimize queries, design schemas, and ensure data integrity...\", \"model\": \"reasoning\"}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- The \"prompt\" should be a detailed system prompt (at least 30 characters)\n- \"model\" should be \"reasoning\" for analytical tasks or \"semantic\" for creative tasks",
                    "rawResponse": "{\n  \"prompt\": \"You are a Senior Database Performance Engineer. Your primary objective is to diagnose and resolve critical database latency issues. You possess deep expertise in SQL optimization, database internals, and schema design. When analyzing performance problems, you should request and interpret `EXPLAIN ANALYZE` execution plans to identify bottlenecks such as sequential scans, inefficient joins, or high disk I/O. You will recommend specific, actionable solutions including complex query rewrites, targeted indexing strategies (B-tree, GIN, partial indexes), schema refactoring, or architectural changes like partitioning and read replicas. Always explain the technical reasoning behind your optimizations to educate the team.\",\n  \"model\": \"reasoning\"\n}",
                    "parsedResponse": {
                      "prompt": "You are a Senior Database Performance Engineer. Your primary objective is to diagnose and resolve critical database latency issues. You possess deep expertise in SQL optimization, database internals, and schema design. When analyzing performance problems, you should request and interpret `EXPLAIN ANALYZE` execution plans to identify bottlenecks such as sequential scans, inefficient joins, or high disk I/O. You will recommend specific, actionable solutions including complex query rewrites, targeted indexing strategies (B-tree, GIN, partial indexes), schema refactoring, or architectural changes like partitioning and read replicas. Always explain the technical reasoning behind your optimizations to educate the team.",
                      "model": "reasoning"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              }
            ],
            "totalDurationMs": 122065,
            "finalResponse": {
              "recommendation": "I recommend hiring a Senior Database Performance Engineer because the team is facing critical latency issues caused by unoptimized database queries and lacks the deep expertise required to interpret execution plans or restructure the schema effectively.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Senior Database Performance Engineer",
                  "reason": "The team is facing critical latency issues caused by unoptimized database queries and lacks the deep expertise required to interpret execution plans or restructure the schema effectively.",
                  "skills": [
                    "Advanced SQL Tuning",
                    "Query Execution Plan Analysis",
                    "Database Schema Design",
                    "Indexing Strategies",
                    "RDBMS Internals",
                    "Data Migration Planning",
                    "Caching Strategies"
                  ],
                  "prompt": "You are a Senior Database Performance Engineer. Your primary objective is to diagnose and resolve critical database latency issues. You possess deep expertise in SQL optimization, database internals, and schema design. When analyzing performance problems, you should request and interpret `EXPLAIN ANALYZE` execution plans to identify bottlenecks such as sequential scans, inefficient joins, or high disk I/O. You will recommend specific, actionable solutions including complex query rewrites, targeted indexing strategies (B-tree, GIN, partial indexes), schema refactoring, or architectural changes like partitioning and read replicas. Always explain the technical reasoning behind your optimizations to educate the team.",
                  "model": "reasoning"
                }
              }
            }
          },
          {
            "runNumber": 3,
            "success": true,
            "attempts": [],
            "steps": [
              {
                "stepNumber": 1,
                "stepName": "Recommendation",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:20:34.663Z",
                    "success": true,
                    "durationMs": 42484,
                    "inputTokens": 938,
                    "outputTokens": 369,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation, what type of team member should this team add?\n\nRespond with JSON like this example:\n{\"recommendation\": \"I recommend hiring a [role] because [reason]...\", \"action\": \"create_actor\"}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- The \"recommendation\" should explain your hiring recommendation (at least 20 characters)\n- Set \"action\" to \"create_actor\" if recommending someone, or null if not",
                    "rawResponse": "{\n  \"recommendation\": \"I recommend hiring a Database Performance Specialist. The team is facing critical churn risks due to slow dashboard queries (8-12s) and high disk I/O. Current members explicitly state they lack the expertise to interpret 'EXPLAIN ANALYZE' outputs, optimize complex joins, or safely modify the schema. This specialist is needed to diagnose the root cause of sequential scans and implement advanced indexing or architectural solutions.\",\n  \"action\": \"create_actor\",\n  \"job_title\": \"Database Performance Specialist\",\n  \"explanation\": \"The team has hit a technical ceiling regarding database performance. They are guessing at solutions (frontend masking, basic indexes, caching) rather than solving the underlying query execution and schema inefficiencies. A specialist is required to handle the complex aggregations and potential architectural migration.\",\n  \"required_skills\": [\n    \"Advanced SQL Optimization\",\n    \"PostgreSQL Internals (assuming Postgres based on EXPLAIN ANALYZE)\",\n    \"Query Execution Plan Analysis\",\n    \"Indexing Strategies (B-Tree, GIN, BRIN)\",\n    \"Schema Design & Normalization\",\n    \"Database Architecture\"\n  ],\n  \"system_prompt\": \"You are an expert Database Performance Specialist. Your primary goal is to diagnose and resolve database bottlenecks. You excel at interpreting 'EXPLAIN ANALYZE' outputs, optimizing complex SQL queries involving multiple joins and aggregations, and designing efficient schemas for high-volume data. When presented with a performance issue, you request the table structure, query, and execution plan. You prioritize query optimization and indexing strategies before suggesting complex architectural migrations. You provide technical, logic-driven solutions to reduce disk I/O and execution time.\",\n  \"capability_type\": \"reasoning\"\n}",
                    "parsedResponse": {
                      "recommendation": "I recommend hiring a Database Performance Specialist. The team is facing critical churn risks due to slow dashboard queries (8-12s) and high disk I/O. Current members explicitly state they lack the expertise to interpret 'EXPLAIN ANALYZE' outputs, optimize complex joins, or safely modify the schema. This specialist is needed to diagnose the root cause of sequential scans and implement advanced indexing or architectural solutions.",
                      "action": "create_actor"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 2,
                "stepName": "Details",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:26:57.082Z",
                    "success": true,
                    "durationMs": 382419,
                    "inputTokens": 1039,
                    "outputTokens": 104,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Database Performance Specialist. The team is facing critical churn risks due to slow dashboard queries (8-12s) and high disk I/O. Current members explicitly state they lack the expertise to interpret 'EXPLAIN ANALYZE' outputs, optimize complex joins, or safely modify the schema. This specialist is needed to diagnose the root cause of sequential scans and implement advanced indexing or architectural solutions.\",\"action\":\"create_actor\"}\n\n[user] For the role you recommended, provide their details.\n\nRespond with JSON like this example:\n{\"title\": \"Database Administrator\", \"reason\": \"The team needs database expertise to optimize their slow queries and design scalable schemas\", \"skills\": [\"PostgreSQL\", \"Query Optimization\", \"Database Design\"]}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- Provide 3-7 specific technical skills\n- The \"reason\" should explain how this role addresses the team's problem (at least 20 characters)",
                    "rawResponse": "{\n  \"title\": \"Database Performance Engineer\",\n  \"reason\": \"The team is facing critical performance issues with slow dashboard queries and lacks the deep expertise required to analyze query plans, optimize complex joins, and restructure the database schema without causing regressions.\",\n  \"skills\": [\n    \"Advanced SQL Tuning\",\n    \"Query Plan Analysis\",\n    \"Database Indexing Strategies\",\n    \"Schema Design\",\n    \"PostgreSQL Performance\",\n    \"Database Architecture\"\n  ]\n}",
                    "parsedResponse": {
                      "title": "Database Performance Engineer",
                      "reason": "The team is facing critical performance issues with slow dashboard queries and lacks the deep expertise required to analyze query plans, optimize complex joins, and restructure the database schema without causing regressions.",
                      "skills": [
                        "Advanced SQL Tuning",
                        "Query Plan Analysis",
                        "Database Indexing Strategies",
                        "Schema Design",
                        "PostgreSQL Performance",
                        "Database Architecture"
                      ]
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 3,
                "stepName": "AI Config",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:27:07.490Z",
                    "success": true,
                    "durationMs": 10408,
                    "inputTokens": 1110,
                    "outputTokens": 121,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Database Performance Specialist. The team is facing critical churn risks due to slow dashboard queries (8-12s) and high disk I/O. Current members explicitly state they lack the expertise to interpret 'EXPLAIN ANALYZE' outputs, optimize complex joins, or safely modify the schema. This specialist is needed to diagnose the root cause of sequential scans and implement advanced indexing or architectural solutions.\",\"action\":\"create_actor\"}\n\n[assistant] {\"title\":\"Database Performance Engineer\",\"reason\":\"The team is facing critical performance issues with slow dashboard queries and lacks the deep expertise required to analyze query plans, optimize complex joins, and restructure the database schema without causing regressions.\",\"skills\":[\"Advanced SQL Tuning\",\"Query Plan Analysis\",\"Database Indexing Strategies\",\"Schema Design\",\"PostgreSQL Performance\",\"Database Architecture\"]}\n\n[user] For this role, provide the AI system prompt and model type.\n\nRespond with JSON like this example:\n{\"prompt\": \"You are an expert database administrator. You help teams optimize queries, design schemas, and ensure data integrity...\", \"model\": \"reasoning\"}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- The \"prompt\" should be a detailed system prompt (at least 30 characters)\n- \"model\" should be \"reasoning\" for analytical tasks or \"semantic\" for creative tasks",
                    "rawResponse": "{\n\"prompt\": \"You are a Senior Database Performance Engineer. Your primary objective is to diagnose and resolve critical database bottlenecks. You specialize in analyzing SQL query execution plans (EXPLAIN ANALYZE), optimizing complex joins and aggregations, and implementing advanced indexing strategies to eliminate sequential scans. You provide expert advice on schema design, database architecture (including read replicas and caching strategies), and resource utilization (CPU, Memory, Disk I/O). When analyzing issues, provide step-by-step technical reasoning and specific, actionable SQL code or configuration adjustments.\",\n\"model\": \"reasoning\"\n}",
                    "parsedResponse": {
                      "prompt": "You are a Senior Database Performance Engineer. Your primary objective is to diagnose and resolve critical database bottlenecks. You specialize in analyzing SQL query execution plans (EXPLAIN ANALYZE), optimizing complex joins and aggregations, and implementing advanced indexing strategies to eliminate sequential scans. You provide expert advice on schema design, database architecture (including read replicas and caching strategies), and resource utilization (CPU, Memory, Disk I/O). When analyzing issues, provide step-by-step technical reasoning and specific, actionable SQL code or configuration adjustments.",
                      "model": "reasoning"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              }
            ],
            "totalDurationMs": 435311,
            "finalResponse": {
              "recommendation": "I recommend hiring a Database Performance Specialist. The team is facing critical churn risks due to slow dashboard queries (8-12s) and high disk I/O. Current members explicitly state they lack the expertise to interpret 'EXPLAIN ANALYZE' outputs, optimize complex joins, or safely modify the schema. This specialist is needed to diagnose the root cause of sequential scans and implement advanced indexing or architectural solutions.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Performance Engineer",
                  "reason": "The team is facing critical performance issues with slow dashboard queries and lacks the deep expertise required to analyze query plans, optimize complex joins, and restructure the database schema without causing regressions.",
                  "skills": [
                    "Advanced SQL Tuning",
                    "Query Plan Analysis",
                    "Database Indexing Strategies",
                    "Schema Design",
                    "PostgreSQL Performance",
                    "Database Architecture"
                  ],
                  "prompt": "You are a Senior Database Performance Engineer. Your primary objective is to diagnose and resolve critical database bottlenecks. You specialize in analyzing SQL query execution plans (EXPLAIN ANALYZE), optimizing complex joins and aggregations, and implementing advanced indexing strategies to eliminate sequential scans. You provide expert advice on schema design, database architecture (including read replicas and caching strategies), and resource utilization (CPU, Memory, Disk I/O). When analyzing issues, provide step-by-step technical reasoning and specific, actionable SQL code or configuration adjustments.",
                  "model": "reasoning"
                }
              }
            }
          }
        ],
        "summary": {
          "successRate": 100,
          "firstAttemptSuccessRate": 100,
          "afterRetry1SuccessRate": 100,
          "afterRetry2SuccessRate": 100,
          "afterRetry3SuccessRate": 100,
          "averageDurationMs": 233582.66666666666,
          "averageAttempts": 3,
          "averageAttemptsPerSuccess": 3,
          "averageTokensPerSuccess": 3595,
          "totalTokensUsed": 10785
        }
      },
      "4": {
        "runs": [
          {
            "runNumber": 1,
            "success": true,
            "attempts": [],
            "steps": [
              {
                "stepNumber": 1,
                "stepName": "Recommendation",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:27:27.527Z",
                    "success": true,
                    "durationMs": 20037,
                    "inputTokens": 910,
                    "outputTokens": 225,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation, what type of team member should this team add?\n\nRespond with a JSON object containing:\n- \"recommendation\": A string explaining who should be hired and why\n- \"action\": Either \"create_actor\" to recommend someone, or null\n\nExample: {\"recommendation\": \"I recommend hiring...\", \"action\": \"create_actor\"}",
                    "rawResponse": "{\n  \"recommendation\": \"I recommend adding a **Database Performance Engineer** to the team.\\n\\n**Why this role is needed:** The team is facing critical performance issues with dashboard queries taking 8-12 seconds, which is threatening customer retention. Current team members have explicitly stated they lack the expertise to interpret `EXPLAIN ANALYZE` results, optimize complex joins, or safely modify the schema to resolve the bottleneck.\\n\\n**Specific skills required:**\\n- Advanced SQL Query Optimization\\n- Database Internals & Indexing Strategies\\n- Execution Plan Analysis\\n- Schema Design & Data Modeling\\n- Knowledge of Time-Series Databases (e.g., TimescaleDB)\\n\\n**System Prompt:**\\n\\\"You are an expert Database Performance Engineer. Your goal is to diagnose and resolve database bottlenecks. You analyze SQL queries and execution plans to recommend precise indexing strategies, schema refactors, or architectural changes to minimize latency and disk I/O.\\\"\\n\\n**Capability:** Reasoning\",\n  \"action\": \"create_actor\"\n}",
                    "parsedResponse": {
                      "recommendation": "I recommend adding a **Database Performance Engineer** to the team.\n\n**Why this role is needed:** The team is facing critical performance issues with dashboard queries taking 8-12 seconds, which is threatening customer retention. Current team members have explicitly stated they lack the expertise to interpret `EXPLAIN ANALYZE` results, optimize complex joins, or safely modify the schema to resolve the bottleneck.\n\n**Specific skills required:**\n- Advanced SQL Query Optimization\n- Database Internals & Indexing Strategies\n- Execution Plan Analysis\n- Schema Design & Data Modeling\n- Knowledge of Time-Series Databases (e.g., TimescaleDB)\n\n**System Prompt:**\n\"You are an expert Database Performance Engineer. Your goal is to diagnose and resolve database bottlenecks. You analyze SQL queries and execution plans to recommend precise indexing strategies, schema refactors, or architectural changes to minimize latency and disk I/O.\"\n\n**Capability:** Reasoning",
                      "action": "create_actor"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 2,
                "stepName": "Details",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:27:37.617Z",
                    "success": true,
                    "durationMs": 10090,
                    "inputTokens": 1145,
                    "outputTokens": 112,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend adding a **Database Performance Engineer** to the team.\\n\\n**Why this role is needed:** The team is facing critical performance issues with dashboard queries taking 8-12 seconds, which is threatening customer retention. Current team members have explicitly stated they lack the expertise to interpret `EXPLAIN ANALYZE` results, optimize complex joins, or safely modify the schema to resolve the bottleneck.\\n\\n**Specific skills required:**\\n- Advanced SQL Query Optimization\\n- Database Internals & Indexing Strategies\\n- Execution Plan Analysis\\n- Schema Design & Data Modeling\\n- Knowledge of Time-Series Databases (e.g., TimescaleDB)\\n\\n**System Prompt:**\\n\\\"You are an expert Database Performance Engineer. Your goal is to diagnose and resolve database bottlenecks. You analyze SQL queries and execution plans to recommend precise indexing strategies, schema refactors, or architectural changes to minimize latency and disk I/O.\\\"\\n\\n**Capability:** Reasoning\",\"action\":\"create_actor\"}\n\n[user] For the role you recommended, provide their details.\n\nRespond with a JSON object containing:\n- \"title\": The job title (e.g., \"Database Administrator\")\n- \"reason\": Why this role addresses the team's skill gap\n- \"skills\": An array of 3-7 specific technical skills\n\nExample: {\"title\": \"Senior DBA\", \"reason\": \"The team needs...\", \"skills\": [\"PostgreSQL\", \"Query Optimization\"]}",
                    "rawResponse": "{\n  \"title\": \"Database Performance Engineer\",\n  \"reason\": \"The team is facing critical dashboard latency issues caused by inefficient database queries and lacks the deep expertise required to interpret execution plans, optimize complex joins, or safely redesign the schema to reduce disk I/O.\",\n  \"skills\": [\n    \"Advanced SQL Optimization\",\n    \"Database Indexing Strategies\",\n    \"Query Execution Plan Analysis\",\n    \"Schema Design\",\n    \"Relational Database Internals\",\n    \"Data Modeling\"\n  ]\n}",
                    "parsedResponse": {
                      "title": "Database Performance Engineer",
                      "reason": "The team is facing critical dashboard latency issues caused by inefficient database queries and lacks the deep expertise required to interpret execution plans, optimize complex joins, or safely redesign the schema to reduce disk I/O.",
                      "skills": [
                        "Advanced SQL Optimization",
                        "Database Indexing Strategies",
                        "Query Execution Plan Analysis",
                        "Schema Design",
                        "Relational Database Internals",
                        "Data Modeling"
                      ]
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 3,
                "stepName": "AI Config",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:29:18.986Z",
                    "success": true,
                    "durationMs": 101369,
                    "inputTokens": 1213,
                    "outputTokens": 112,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend adding a **Database Performance Engineer** to the team.\\n\\n**Why this role is needed:** The team is facing critical performance issues with dashboard queries taking 8-12 seconds, which is threatening customer retention. Current team members have explicitly stated they lack the expertise to interpret `EXPLAIN ANALYZE` results, optimize complex joins, or safely modify the schema to resolve the bottleneck.\\n\\n**Specific skills required:**\\n- Advanced SQL Query Optimization\\n- Database Internals & Indexing Strategies\\n- Execution Plan Analysis\\n- Schema Design & Data Modeling\\n- Knowledge of Time-Series Databases (e.g., TimescaleDB)\\n\\n**System Prompt:**\\n\\\"You are an expert Database Performance Engineer. Your goal is to diagnose and resolve database bottlenecks. You analyze SQL queries and execution plans to recommend precise indexing strategies, schema refactors, or architectural changes to minimize latency and disk I/O.\\\"\\n\\n**Capability:** Reasoning\",\"action\":\"create_actor\"}\n\n[assistant] {\"title\":\"Database Performance Engineer\",\"reason\":\"The team is facing critical dashboard latency issues caused by inefficient database queries and lacks the deep expertise required to interpret execution plans, optimize complex joins, or safely redesign the schema to reduce disk I/O.\",\"skills\":[\"Advanced SQL Optimization\",\"Database Indexing Strategies\",\"Query Execution Plan Analysis\",\"Schema Design\",\"Relational Database Internals\",\"Data Modeling\"]}\n\n[user] For this role, provide the AI configuration.\n\nRespond with a JSON object containing:\n- \"prompt\": A system prompt for configuring an AI assistant in this role\n- \"model\": Either \"reasoning\" (for analytical/logical tasks) or \"semantic\" (for creative/conversational tasks)\n\nExample: {\"prompt\": \"You are an expert database administrator...\", \"model\": \"reasoning\"}",
                    "rawResponse": "{\n  \"prompt\": \"You are an expert Database Performance Engineer specializing in SQL optimization and database architecture. Your primary objective is to analyze slow queries, interpret execution plans (EXPLAIN ANALYZE), and recommend specific indexing strategies or schema refactors to improve performance. You understand database internals, disk I/O implications, and the trade-offs between read and write performance. When presented with a performance issue, diagnose the root cause and provide actionable, technical solutions to reduce latency and optimize resource usage.\",\n  \"model\": \"reasoning\"\n}",
                    "parsedResponse": {
                      "prompt": "You are an expert Database Performance Engineer specializing in SQL optimization and database architecture. Your primary objective is to analyze slow queries, interpret execution plans (EXPLAIN ANALYZE), and recommend specific indexing strategies or schema refactors to improve performance. You understand database internals, disk I/O implications, and the trade-offs between read and write performance. When presented with a performance issue, diagnose the root cause and provide actionable, technical solutions to reduce latency and optimize resource usage.",
                      "model": "reasoning"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              }
            ],
            "totalDurationMs": 131496,
            "finalResponse": {
              "recommendation": "I recommend adding a **Database Performance Engineer** to the team.\n\n**Why this role is needed:** The team is facing critical performance issues with dashboard queries taking 8-12 seconds, which is threatening customer retention. Current team members have explicitly stated they lack the expertise to interpret `EXPLAIN ANALYZE` results, optimize complex joins, or safely modify the schema to resolve the bottleneck.\n\n**Specific skills required:**\n- Advanced SQL Query Optimization\n- Database Internals & Indexing Strategies\n- Execution Plan Analysis\n- Schema Design & Data Modeling\n- Knowledge of Time-Series Databases (e.g., TimescaleDB)\n\n**System Prompt:**\n\"You are an expert Database Performance Engineer. Your goal is to diagnose and resolve database bottlenecks. You analyze SQL queries and execution plans to recommend precise indexing strategies, schema refactors, or architectural changes to minimize latency and disk I/O.\"\n\n**Capability:** Reasoning",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Performance Engineer",
                  "reason": "The team is facing critical dashboard latency issues caused by inefficient database queries and lacks the deep expertise required to interpret execution plans, optimize complex joins, or safely redesign the schema to reduce disk I/O.",
                  "skills": [
                    "Advanced SQL Optimization",
                    "Database Indexing Strategies",
                    "Query Execution Plan Analysis",
                    "Schema Design",
                    "Relational Database Internals",
                    "Data Modeling"
                  ],
                  "prompt": "You are an expert Database Performance Engineer specializing in SQL optimization and database architecture. Your primary objective is to analyze slow queries, interpret execution plans (EXPLAIN ANALYZE), and recommend specific indexing strategies or schema refactors to improve performance. You understand database internals, disk I/O implications, and the trade-offs between read and write performance. When presented with a performance issue, diagnose the root cause and provide actionable, technical solutions to reduce latency and optimize resource usage.",
                  "model": "reasoning"
                }
              }
            }
          },
          {
            "runNumber": 2,
            "success": true,
            "attempts": [],
            "steps": [
              {
                "stepNumber": 1,
                "stepName": "Recommendation",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:29:42.406Z",
                    "success": true,
                    "durationMs": 23420,
                    "inputTokens": 910,
                    "outputTokens": 205,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation, what type of team member should this team add?\n\nRespond with a JSON object containing:\n- \"recommendation\": A string explaining who should be hired and why\n- \"action\": Either \"create_actor\" to recommend someone, or null\n\nExample: {\"recommendation\": \"I recommend hiring...\", \"action\": \"create_actor\"}",
                    "rawResponse": "{\n  \"recommendation\": \"I recommend adding a **Senior Database Performance Engineer** to the team.\\n\\n**Why:** The team is facing critical churn risks due to slow dashboard queries (8-12s) and explicitly lacks the expertise to interpret execution plans (like the sequential scan mentioned) or safely modify the database schema. They need a specialist to resolve the bottleneck that frontend masking and basic indexing failed to fix.\\n\\n**Skills Required:** Advanced SQL, Query Optimization, Indexing Strategies, Database Architecture, PostgreSQL/TimescaleDB tuning, Schema Design.\\n\\n**System Prompt:** You are a Senior Database Performance Engineer. Your goal is to analyze slow SQL queries, interpret `EXPLAIN ANALYZE` output, and recommend specific indexing or schema changes to improve performance. You focus on reducing latency for high-volume datasets and evaluating architectural changes like read replicas or database migrations.\\n\\n**Capability Type:** Reasoning\",\n  \"action\": \"create_actor\"\n}",
                    "parsedResponse": {
                      "recommendation": "I recommend adding a **Senior Database Performance Engineer** to the team.\n\n**Why:** The team is facing critical churn risks due to slow dashboard queries (8-12s) and explicitly lacks the expertise to interpret execution plans (like the sequential scan mentioned) or safely modify the database schema. They need a specialist to resolve the bottleneck that frontend masking and basic indexing failed to fix.\n\n**Skills Required:** Advanced SQL, Query Optimization, Indexing Strategies, Database Architecture, PostgreSQL/TimescaleDB tuning, Schema Design.\n\n**System Prompt:** You are a Senior Database Performance Engineer. Your goal is to analyze slow SQL queries, interpret `EXPLAIN ANALYZE` output, and recommend specific indexing or schema changes to improve performance. You focus on reducing latency for high-volume datasets and evaluating architectural changes like read replicas or database migrations.\n\n**Capability Type:** Reasoning",
                      "action": "create_actor"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 2,
                "stepName": "Details",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:29:53.189Z",
                    "success": true,
                    "durationMs": 10783,
                    "inputTokens": 1125,
                    "outputTokens": 116,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend adding a **Senior Database Performance Engineer** to the team.\\n\\n**Why:** The team is facing critical churn risks due to slow dashboard queries (8-12s) and explicitly lacks the expertise to interpret execution plans (like the sequential scan mentioned) or safely modify the database schema. They need a specialist to resolve the bottleneck that frontend masking and basic indexing failed to fix.\\n\\n**Skills Required:** Advanced SQL, Query Optimization, Indexing Strategies, Database Architecture, PostgreSQL/TimescaleDB tuning, Schema Design.\\n\\n**System Prompt:** You are a Senior Database Performance Engineer. Your goal is to analyze slow SQL queries, interpret `EXPLAIN ANALYZE` output, and recommend specific indexing or schema changes to improve performance. You focus on reducing latency for high-volume datasets and evaluating architectural changes like read replicas or database migrations.\\n\\n**Capability Type:** Reasoning\",\"action\":\"create_actor\"}\n\n[user] For the role you recommended, provide their details.\n\nRespond with a JSON object containing:\n- \"title\": The job title (e.g., \"Database Administrator\")\n- \"reason\": Why this role addresses the team's skill gap\n- \"skills\": An array of 3-7 specific technical skills\n\nExample: {\"title\": \"Senior DBA\", \"reason\": \"The team needs...\", \"skills\": [\"PostgreSQL\", \"Query Optimization\"]}",
                    "rawResponse": "{\n  \"title\": \"Senior Database Performance Engineer\",\n  \"reason\": \"The team is facing critical churn risks due to slow dashboard queries and explicitly admits to lacking the expertise to interpret execution plans or safely modify the database schema. They need a specialist to resolve the bottleneck that frontend masking and basic indexing failed to fix.\",\n  \"skills\": [\n    \"Advanced SQL\",\n    \"Query Optimization\",\n    \"PostgreSQL Tuning\",\n    \"Database Indexing Strategies\",\n    \"Schema Design\",\n    \"Performance Analysis\"\n  ]\n}",
                    "parsedResponse": {
                      "title": "Senior Database Performance Engineer",
                      "reason": "The team is facing critical churn risks due to slow dashboard queries and explicitly admits to lacking the expertise to interpret execution plans or safely modify the database schema. They need a specialist to resolve the bottleneck that frontend masking and basic indexing failed to fix.",
                      "skills": [
                        "Advanced SQL",
                        "Query Optimization",
                        "PostgreSQL Tuning",
                        "Database Indexing Strategies",
                        "Schema Design",
                        "Performance Analysis"
                      ]
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 3,
                "stepName": "AI Config",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:30:05.038Z",
                    "success": true,
                    "durationMs": 11849,
                    "inputTokens": 1197,
                    "outputTokens": 160,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend adding a **Senior Database Performance Engineer** to the team.\\n\\n**Why:** The team is facing critical churn risks due to slow dashboard queries (8-12s) and explicitly lacks the expertise to interpret execution plans (like the sequential scan mentioned) or safely modify the database schema. They need a specialist to resolve the bottleneck that frontend masking and basic indexing failed to fix.\\n\\n**Skills Required:** Advanced SQL, Query Optimization, Indexing Strategies, Database Architecture, PostgreSQL/TimescaleDB tuning, Schema Design.\\n\\n**System Prompt:** You are a Senior Database Performance Engineer. Your goal is to analyze slow SQL queries, interpret `EXPLAIN ANALYZE` output, and recommend specific indexing or schema changes to improve performance. You focus on reducing latency for high-volume datasets and evaluating architectural changes like read replicas or database migrations.\\n\\n**Capability Type:** Reasoning\",\"action\":\"create_actor\"}\n\n[assistant] {\"title\":\"Senior Database Performance Engineer\",\"reason\":\"The team is facing critical churn risks due to slow dashboard queries and explicitly admits to lacking the expertise to interpret execution plans or safely modify the database schema. They need a specialist to resolve the bottleneck that frontend masking and basic indexing failed to fix.\",\"skills\":[\"Advanced SQL\",\"Query Optimization\",\"PostgreSQL Tuning\",\"Database Indexing Strategies\",\"Schema Design\",\"Performance Analysis\"]}\n\n[user] For this role, provide the AI configuration.\n\nRespond with a JSON object containing:\n- \"prompt\": A system prompt for configuring an AI assistant in this role\n- \"model\": Either \"reasoning\" (for analytical/logical tasks) or \"semantic\" (for creative/conversational tasks)\n\nExample: {\"prompt\": \"You are an expert database administrator...\", \"model\": \"reasoning\"}",
                    "rawResponse": "{\n  \"prompt\": \"You are an expert Senior Database Performance Engineer specializing in high-scale relational databases. Your goal is to analyze and optimize slow database queries that are impacting user experience. You possess deep knowledge of SQL internals, indexing strategies (B-tree, GIN, GiST), query planners, and execution analysis (EXPLAIN ANALYZE). When given a scenario, you should diagnose the root cause of latency—whether it be CPU, I/O, locking, or inefficient query logic—and provide actionable, step-by-step technical recommendations. You should also be able to advise on architectural decisions, such as sharding, partitioning, or migrating to time-series databases, balancing performance gains against migration complexity.\",\n  \"model\": \"reasoning\"\n}",
                    "parsedResponse": {
                      "prompt": "You are an expert Senior Database Performance Engineer specializing in high-scale relational databases. Your goal is to analyze and optimize slow database queries that are impacting user experience. You possess deep knowledge of SQL internals, indexing strategies (B-tree, GIN, GiST), query planners, and execution analysis (EXPLAIN ANALYZE). When given a scenario, you should diagnose the root cause of latency—whether it be CPU, I/O, locking, or inefficient query logic—and provide actionable, step-by-step technical recommendations. You should also be able to advise on architectural decisions, such as sharding, partitioning, or migrating to time-series databases, balancing performance gains against migration complexity.",
                      "model": "reasoning"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              }
            ],
            "totalDurationMs": 46052,
            "finalResponse": {
              "recommendation": "I recommend adding a **Senior Database Performance Engineer** to the team.\n\n**Why:** The team is facing critical churn risks due to slow dashboard queries (8-12s) and explicitly lacks the expertise to interpret execution plans (like the sequential scan mentioned) or safely modify the database schema. They need a specialist to resolve the bottleneck that frontend masking and basic indexing failed to fix.\n\n**Skills Required:** Advanced SQL, Query Optimization, Indexing Strategies, Database Architecture, PostgreSQL/TimescaleDB tuning, Schema Design.\n\n**System Prompt:** You are a Senior Database Performance Engineer. Your goal is to analyze slow SQL queries, interpret `EXPLAIN ANALYZE` output, and recommend specific indexing or schema changes to improve performance. You focus on reducing latency for high-volume datasets and evaluating architectural changes like read replicas or database migrations.\n\n**Capability Type:** Reasoning",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Senior Database Performance Engineer",
                  "reason": "The team is facing critical churn risks due to slow dashboard queries and explicitly admits to lacking the expertise to interpret execution plans or safely modify the database schema. They need a specialist to resolve the bottleneck that frontend masking and basic indexing failed to fix.",
                  "skills": [
                    "Advanced SQL",
                    "Query Optimization",
                    "PostgreSQL Tuning",
                    "Database Indexing Strategies",
                    "Schema Design",
                    "Performance Analysis"
                  ],
                  "prompt": "You are an expert Senior Database Performance Engineer specializing in high-scale relational databases. Your goal is to analyze and optimize slow database queries that are impacting user experience. You possess deep knowledge of SQL internals, indexing strategies (B-tree, GIN, GiST), query planners, and execution analysis (EXPLAIN ANALYZE). When given a scenario, you should diagnose the root cause of latency—whether it be CPU, I/O, locking, or inefficient query logic—and provide actionable, step-by-step technical recommendations. You should also be able to advise on architectural decisions, such as sharding, partitioning, or migrating to time-series databases, balancing performance gains against migration complexity.",
                  "model": "reasoning"
                }
              }
            }
          },
          {
            "runNumber": 3,
            "success": true,
            "attempts": [],
            "steps": [
              {
                "stepNumber": 1,
                "stepName": "Recommendation",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:30:24.587Z",
                    "success": true,
                    "durationMs": 19549,
                    "inputTokens": 910,
                    "outputTokens": 193,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation, what type of team member should this team add?\n\nRespond with a JSON object containing:\n- \"recommendation\": A string explaining who should be hired and why\n- \"action\": Either \"create_actor\" to recommend someone, or null\n\nExample: {\"recommendation\": \"I recommend hiring...\", \"action\": \"create_actor\"}",
                    "rawResponse": "{\n  \"recommendation\": \"I recommend hiring a Database Performance Specialist. The team is facing critical performance issues with slow dashboard queries (8-12s latency) and high disk I/O, leading to potential customer churn. Current members have admitted they lack the expertise to interpret execution plans (EXPLAIN ANALYZE), optimize complex joins, or safely redesign the schema. \\n\\n**Role:** Database Performance Specialist\\n**Skills Required:** Advanced SQL Optimization, Database Indexing Strategies, Schema Design, Query Execution Plan Analysis, PostgreSQL Tuning.\\n**System Prompt:** \\\"You are an expert Database Performance Specialist. Your goal is to analyze slow database queries, interpret execution plans, and recommend specific optimizations such as composite indexes, query rewriting, or schema denormalization. You focus on reducing latency and disk I/O for high-volume datasets.\\\"\\n**Capability:** Reasoning\",\n  \"action\": \"create_actor\"\n}",
                    "parsedResponse": {
                      "recommendation": "I recommend hiring a Database Performance Specialist. The team is facing critical performance issues with slow dashboard queries (8-12s latency) and high disk I/O, leading to potential customer churn. Current members have admitted they lack the expertise to interpret execution plans (EXPLAIN ANALYZE), optimize complex joins, or safely redesign the schema. \n\n**Role:** Database Performance Specialist\n**Skills Required:** Advanced SQL Optimization, Database Indexing Strategies, Schema Design, Query Execution Plan Analysis, PostgreSQL Tuning.\n**System Prompt:** \"You are an expert Database Performance Specialist. Your goal is to analyze slow database queries, interpret execution plans, and recommend specific optimizations such as composite indexes, query rewriting, or schema denormalization. You focus on reducing latency and disk I/O for high-volume datasets.\"\n**Capability:** Reasoning",
                      "action": "create_actor"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 2,
                "stepName": "Details",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:30:32.766Z",
                    "success": true,
                    "durationMs": 8179,
                    "inputTokens": 1113,
                    "outputTokens": 138,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Database Performance Specialist. The team is facing critical performance issues with slow dashboard queries (8-12s latency) and high disk I/O, leading to potential customer churn. Current members have admitted they lack the expertise to interpret execution plans (EXPLAIN ANALYZE), optimize complex joins, or safely redesign the schema. \\n\\n**Role:** Database Performance Specialist\\n**Skills Required:** Advanced SQL Optimization, Database Indexing Strategies, Schema Design, Query Execution Plan Analysis, PostgreSQL Tuning.\\n**System Prompt:** \\\"You are an expert Database Performance Specialist. Your goal is to analyze slow database queries, interpret execution plans, and recommend specific optimizations such as composite indexes, query rewriting, or schema denormalization. You focus on reducing latency and disk I/O for high-volume datasets.\\\"\\n**Capability:** Reasoning\",\"action\":\"create_actor\"}\n\n[user] For the role you recommended, provide their details.\n\nRespond with a JSON object containing:\n- \"title\": The job title (e.g., \"Database Administrator\")\n- \"reason\": Why this role addresses the team's skill gap\n- \"skills\": An array of 3-7 specific technical skills\n\nExample: {\"title\": \"Senior DBA\", \"reason\": \"The team needs...\", \"skills\": [\"PostgreSQL\", \"Query Optimization\"]}",
                    "rawResponse": "{\n  \"title\": \"Database Performance Engineer\",\n  \"reason\": \"The team is facing critical latency issues with dashboard queries and lacks the deep expertise required to interpret execution plans (EXPLAIN ANALYZE), optimize complex joins, or safely redesign the schema. Current members have admitted to 'guessing' and need a specialist to resolve high disk I/O and sequential scan bottlenecks to prevent customer churn.\",\n  \"skills\": [\n    \"Advanced SQL Optimization\",\n    \"Query Execution Plan Analysis\",\n    \"Database Indexing Strategies\",\n    \"Schema Design & Normalization\",\n    \"PostgreSQL Tuning\",\n    \"Data Modeling\"\n  ]\n}",
                    "parsedResponse": {
                      "title": "Database Performance Engineer",
                      "reason": "The team is facing critical latency issues with dashboard queries and lacks the deep expertise required to interpret execution plans (EXPLAIN ANALYZE), optimize complex joins, or safely redesign the schema. Current members have admitted to 'guessing' and need a specialist to resolve high disk I/O and sequential scan bottlenecks to prevent customer churn.",
                      "skills": [
                        "Advanced SQL Optimization",
                        "Query Execution Plan Analysis",
                        "Database Indexing Strategies",
                        "Schema Design & Normalization",
                        "PostgreSQL Tuning",
                        "Data Modeling"
                      ]
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 3,
                "stepName": "AI Config",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:30:53.620Z",
                    "success": true,
                    "durationMs": 20854,
                    "inputTokens": 1207,
                    "outputTokens": 127,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Database Performance Specialist. The team is facing critical performance issues with slow dashboard queries (8-12s latency) and high disk I/O, leading to potential customer churn. Current members have admitted they lack the expertise to interpret execution plans (EXPLAIN ANALYZE), optimize complex joins, or safely redesign the schema. \\n\\n**Role:** Database Performance Specialist\\n**Skills Required:** Advanced SQL Optimization, Database Indexing Strategies, Schema Design, Query Execution Plan Analysis, PostgreSQL Tuning.\\n**System Prompt:** \\\"You are an expert Database Performance Specialist. Your goal is to analyze slow database queries, interpret execution plans, and recommend specific optimizations such as composite indexes, query rewriting, or schema denormalization. You focus on reducing latency and disk I/O for high-volume datasets.\\\"\\n**Capability:** Reasoning\",\"action\":\"create_actor\"}\n\n[assistant] {\"title\":\"Database Performance Engineer\",\"reason\":\"The team is facing critical latency issues with dashboard queries and lacks the deep expertise required to interpret execution plans (EXPLAIN ANALYZE), optimize complex joins, or safely redesign the schema. Current members have admitted to 'guessing' and need a specialist to resolve high disk I/O and sequential scan bottlenecks to prevent customer churn.\",\"skills\":[\"Advanced SQL Optimization\",\"Query Execution Plan Analysis\",\"Database Indexing Strategies\",\"Schema Design & Normalization\",\"PostgreSQL Tuning\",\"Data Modeling\"]}\n\n[user] For this role, provide the AI configuration.\n\nRespond with a JSON object containing:\n- \"prompt\": A system prompt for configuring an AI assistant in this role\n- \"model\": Either \"reasoning\" (for analytical/logical tasks) or \"semantic\" (for creative/conversational tasks)\n\nExample: {\"prompt\": \"You are an expert database administrator...\", \"model\": \"reasoning\"}",
                    "rawResponse": "{\n  \"prompt\": \"You are an expert Database Performance Engineer specializing in SQL optimization and database architecture. Your primary objective is to diagnose and resolve performance bottlenecks in high-volume database systems. You are proficient in analyzing query execution plans (such as EXPLAIN ANALYZE), identifying inefficient sequential scans, and designing optimal indexing strategies. You should provide concrete, actionable recommendations for query rewriting, schema normalization or denormalization, and configuration tuning to reduce latency and disk I/O. When presented with a performance issue, analyze the technical details logically and propose evidence-based solutions.\",\n  \"model\": \"reasoning\"\n}",
                    "parsedResponse": {
                      "prompt": "You are an expert Database Performance Engineer specializing in SQL optimization and database architecture. Your primary objective is to diagnose and resolve performance bottlenecks in high-volume database systems. You are proficient in analyzing query execution plans (such as EXPLAIN ANALYZE), identifying inefficient sequential scans, and designing optimal indexing strategies. You should provide concrete, actionable recommendations for query rewriting, schema normalization or denormalization, and configuration tuning to reduce latency and disk I/O. When presented with a performance issue, analyze the technical details logically and propose evidence-based solutions.",
                      "model": "reasoning"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              }
            ],
            "totalDurationMs": 48582,
            "finalResponse": {
              "recommendation": "I recommend hiring a Database Performance Specialist. The team is facing critical performance issues with slow dashboard queries (8-12s latency) and high disk I/O, leading to potential customer churn. Current members have admitted they lack the expertise to interpret execution plans (EXPLAIN ANALYZE), optimize complex joins, or safely redesign the schema. \n\n**Role:** Database Performance Specialist\n**Skills Required:** Advanced SQL Optimization, Database Indexing Strategies, Schema Design, Query Execution Plan Analysis, PostgreSQL Tuning.\n**System Prompt:** \"You are an expert Database Performance Specialist. Your goal is to analyze slow database queries, interpret execution plans, and recommend specific optimizations such as composite indexes, query rewriting, or schema denormalization. You focus on reducing latency and disk I/O for high-volume datasets.\"\n**Capability:** Reasoning",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Performance Engineer",
                  "reason": "The team is facing critical latency issues with dashboard queries and lacks the deep expertise required to interpret execution plans (EXPLAIN ANALYZE), optimize complex joins, or safely redesign the schema. Current members have admitted to 'guessing' and need a specialist to resolve high disk I/O and sequential scan bottlenecks to prevent customer churn.",
                  "skills": [
                    "Advanced SQL Optimization",
                    "Query Execution Plan Analysis",
                    "Database Indexing Strategies",
                    "Schema Design & Normalization",
                    "PostgreSQL Tuning",
                    "Data Modeling"
                  ],
                  "prompt": "You are an expert Database Performance Engineer specializing in SQL optimization and database architecture. Your primary objective is to diagnose and resolve performance bottlenecks in high-volume database systems. You are proficient in analyzing query execution plans (such as EXPLAIN ANALYZE), identifying inefficient sequential scans, and designing optimal indexing strategies. You should provide concrete, actionable recommendations for query rewriting, schema normalization or denormalization, and configuration tuning to reduce latency and disk I/O. When presented with a performance issue, analyze the technical details logically and propose evidence-based solutions.",
                  "model": "reasoning"
                }
              }
            }
          }
        ],
        "summary": {
          "successRate": 100,
          "firstAttemptSuccessRate": 100,
          "afterRetry1SuccessRate": 100,
          "afterRetry2SuccessRate": 100,
          "afterRetry3SuccessRate": 100,
          "averageDurationMs": 75376.66666666667,
          "averageAttempts": 3,
          "averageAttemptsPerSuccess": 3,
          "averageTokensPerSuccess": 3706,
          "totalTokensUsed": 11118
        }
      }
    },
    "groq-gpt-oss-120b": {
      "1": {
        "runs": [
          {
            "runNumber": 1,
            "success": true,
            "attempts": [
              {
                "attemptNumber": 1,
                "timestamp": "2025-11-29T17:31:00.458Z",
                "success": true,
                "durationMs": 6838,
                "inputTokens": 1073,
                "outputTokens": 577,
                "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation above, recommend a team member who could help solve their problem.\n\nRespond ONLY with valid JSON like this example:\n{\n  \"recommendation\": \"I think you need to hire a [role] because [explanation of how they address the team's problem]...\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Job Title Here\",\n      \"reason\": \"Why this role addresses the team's skill gap\",\n      \"skills\": [\"skill1\", \"skill2\", \"skill3\"],\n      \"prompt\": \"You are an expert in [domain]. You help teams by [description of approach]...\",\n      \"model\": \"reasoning\"\n    }\n  }\n}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks or backticks\n- The \"recommendation\" field should start with \"I think you need to hire...\"\n- Skills array should have 3-7 specific technical skills\n- \"model\" should be \"reasoning\" for analytical tasks or \"semantic\" for creative tasks\n- Set \"action\" to null if no recommendation is appropriate",
                "rawResponse": "{\n  \"recommendation\": \"I think you need to hire a Database Performance Engineer because they can analyse the slow dashboard query, optimise indexes, redesign the schema, evaluate read‑replica and migration options, and ensure near real‑time performance for large datasets.\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Database Performance Engineer\",\n      \"reason\": \"The team lacks deep expertise in query optimization, indexing strategies, and large‑scale schema design needed to resolve the 8‑12 second dashboard queries and prevent customer churn.\",\n      \"skills\": [\n        \"SQL query optimization\",\n        \"Index design and maintenance\",\n        \"PostgreSQL (or relevant RDBMS) performance tuning\",\n        \"Database schema redesign\",\n        \"Read replica configuration\",\n        \"Time‑series database evaluation (e.g., TimescaleDB)\"\n      ],\n      \"prompt\": \"You are an expert in relational database performance. You help engineering teams diagnose slow queries, design optimal indexes, refactor schemas, and evaluate architectural changes such as read replicas or time‑series databases to achieve near real‑time response times.\",\n      \"model\": \"reasoning\"\n    }\n  }\n}",
                "parsedResponse": {
                  "recommendation": "I think you need to hire a Database Performance Engineer because they can analyse the slow dashboard query, optimise indexes, redesign the schema, evaluate read‑replica and migration options, and ensure near real‑time performance for large datasets.",
                  "action": {
                    "type": "create_actor",
                    "actor": {
                      "title": "Database Performance Engineer",
                      "reason": "The team lacks deep expertise in query optimization, indexing strategies, and large‑scale schema design needed to resolve the 8‑12 second dashboard queries and prevent customer churn.",
                      "skills": [
                        "SQL query optimization",
                        "Index design and maintenance",
                        "PostgreSQL (or relevant RDBMS) performance tuning",
                        "Database schema redesign",
                        "Read replica configuration",
                        "Time‑series database evaluation (e.g., TimescaleDB)"
                      ],
                      "prompt": "You are an expert in relational database performance. You help engineering teams diagnose slow queries, design optimal indexes, refactor schemas, and evaluate architectural changes such as read replicas or time‑series databases to achieve near real‑time response times.",
                      "model": "reasoning"
                    }
                  }
                },
                "validationErrors": [],
                "errorMessage": null
              }
            ],
            "totalDurationMs": 6838,
            "finalResponse": {
              "recommendation": "I think you need to hire a Database Performance Engineer because they can analyse the slow dashboard query, optimise indexes, redesign the schema, evaluate read‑replica and migration options, and ensure near real‑time performance for large datasets.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Performance Engineer",
                  "reason": "The team lacks deep expertise in query optimization, indexing strategies, and large‑scale schema design needed to resolve the 8‑12 second dashboard queries and prevent customer churn.",
                  "skills": [
                    "SQL query optimization",
                    "Index design and maintenance",
                    "PostgreSQL (or relevant RDBMS) performance tuning",
                    "Database schema redesign",
                    "Read replica configuration",
                    "Time‑series database evaluation (e.g., TimescaleDB)"
                  ],
                  "prompt": "You are an expert in relational database performance. You help engineering teams diagnose slow queries, design optimal indexes, refactor schemas, and evaluate architectural changes such as read replicas or time‑series databases to achieve near real‑time response times.",
                  "model": "reasoning"
                }
              }
            }
          },
          {
            "runNumber": 2,
            "success": true,
            "attempts": [
              {
                "attemptNumber": 1,
                "timestamp": "2025-11-29T17:31:06.851Z",
                "success": true,
                "durationMs": 6393,
                "inputTokens": 1073,
                "outputTokens": 545,
                "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation above, recommend a team member who could help solve their problem.\n\nRespond ONLY with valid JSON like this example:\n{\n  \"recommendation\": \"I think you need to hire a [role] because [explanation of how they address the team's problem]...\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Job Title Here\",\n      \"reason\": \"Why this role addresses the team's skill gap\",\n      \"skills\": [\"skill1\", \"skill2\", \"skill3\"],\n      \"prompt\": \"You are an expert in [domain]. You help teams by [description of approach]...\",\n      \"model\": \"reasoning\"\n    }\n  }\n}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks or backticks\n- The \"recommendation\" field should start with \"I think you need to hire...\"\n- Skills array should have 3-7 specific technical skills\n- \"model\" should be \"reasoning\" for analytical tasks or \"semantic\" for creative tasks\n- Set \"action\" to null if no recommendation is appropriate",
                "rawResponse": "{\n  \"recommendation\": \"I think you need to hire a Database Performance Engineer because they can analyse the slow dashboard query, optimise indexes, redesign the schema, evaluate read‑replica and migration options, and ensure near real‑time performance for large datasets.\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Database Performance Engineer\",\n      \"reason\": \"The team lacks deep expertise in query plan analysis, advanced indexing, partitioning, and large‑scale schema optimization needed to resolve the 8‑12 second dashboard queries.\",\n      \"skills\": [\n        \"SQL query optimization\",\n        \"PostgreSQL performance tuning\",\n        \"Index design and partitioning\",\n        \"Explain Analyze interpretation\",\n        \"Read replica architecture\",\n        \"Time‑series databases (e.g., TimescaleDB)\"\n      ],\n      \"prompt\": \"You are an expert in database performance engineering. You help teams diagnose slow queries, design optimal indexes and schemas, evaluate replication and migration strategies, and implement solutions that meet real‑time data requirements.\",\n      \"model\": \"reasoning\"\n    }\n  }\n}",
                "parsedResponse": {
                  "recommendation": "I think you need to hire a Database Performance Engineer because they can analyse the slow dashboard query, optimise indexes, redesign the schema, evaluate read‑replica and migration options, and ensure near real‑time performance for large datasets.",
                  "action": {
                    "type": "create_actor",
                    "actor": {
                      "title": "Database Performance Engineer",
                      "reason": "The team lacks deep expertise in query plan analysis, advanced indexing, partitioning, and large‑scale schema optimization needed to resolve the 8‑12 second dashboard queries.",
                      "skills": [
                        "SQL query optimization",
                        "PostgreSQL performance tuning",
                        "Index design and partitioning",
                        "Explain Analyze interpretation",
                        "Read replica architecture",
                        "Time‑series databases (e.g., TimescaleDB)"
                      ],
                      "prompt": "You are an expert in database performance engineering. You help teams diagnose slow queries, design optimal indexes and schemas, evaluate replication and migration strategies, and implement solutions that meet real‑time data requirements.",
                      "model": "reasoning"
                    }
                  }
                },
                "validationErrors": [],
                "errorMessage": null
              }
            ],
            "totalDurationMs": 6393,
            "finalResponse": {
              "recommendation": "I think you need to hire a Database Performance Engineer because they can analyse the slow dashboard query, optimise indexes, redesign the schema, evaluate read‑replica and migration options, and ensure near real‑time performance for large datasets.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Performance Engineer",
                  "reason": "The team lacks deep expertise in query plan analysis, advanced indexing, partitioning, and large‑scale schema optimization needed to resolve the 8‑12 second dashboard queries.",
                  "skills": [
                    "SQL query optimization",
                    "PostgreSQL performance tuning",
                    "Index design and partitioning",
                    "Explain Analyze interpretation",
                    "Read replica architecture",
                    "Time‑series databases (e.g., TimescaleDB)"
                  ],
                  "prompt": "You are an expert in database performance engineering. You help teams diagnose slow queries, design optimal indexes and schemas, evaluate replication and migration strategies, and implement solutions that meet real‑time data requirements.",
                  "model": "reasoning"
                }
              }
            }
          },
          {
            "runNumber": 3,
            "success": true,
            "attempts": [
              {
                "attemptNumber": 1,
                "timestamp": "2025-11-29T17:31:12.939Z",
                "success": true,
                "durationMs": 6088,
                "inputTokens": 1073,
                "outputTokens": 391,
                "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation above, recommend a team member who could help solve their problem.\n\nRespond ONLY with valid JSON like this example:\n{\n  \"recommendation\": \"I think you need to hire a [role] because [explanation of how they address the team's problem]...\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Job Title Here\",\n      \"reason\": \"Why this role addresses the team's skill gap\",\n      \"skills\": [\"skill1\", \"skill2\", \"skill3\"],\n      \"prompt\": \"You are an expert in [domain]. You help teams by [description of approach]...\",\n      \"model\": \"reasoning\"\n    }\n  }\n}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks or backticks\n- The \"recommendation\" field should start with \"I think you need to hire...\"\n- Skills array should have 3-7 specific technical skills\n- \"model\" should be \"reasoning\" for analytical tasks or \"semantic\" for creative tasks\n- Set \"action\" to null if no recommendation is appropriate",
                "rawResponse": "{\n  \"recommendation\": \"I think you need to hire a Database Performance Engineer because they can deeply analyse the slow dashboard query, optimise the execution plan, redesign indexes and schema, evaluate read‑replica or TimescaleDB options, and ensure real‑time performance without breaking existing functionality.\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Database Performance Engineer\",\n      \"reason\": \"The team lacks deep expertise in query optimization, indexing, and schema design for large, time‑series datasets, which is essential to resolve the 8‑12 second dashboard load times and prevent customer churn.\",\n      \"skills\": [\n        \"SQL query performance tuning\",\n        \"Advanced indexing strategies (partial, covering, expression indexes)\",\n        \"Database schema design for high‑volume time‑series data\",\n        \"PostgreSQL and TimescaleDB expertise\",\n        \"EXPLAIN ANALYZE interpretation and plan rewriting\",\n        \"Read replica architecture and migration planning\"\n      ],\n      \"prompt\": \"You are an expert Database Performance Engineer. You help teams diagnose and resolve slow query issues by analyzing execution plans, designing optimal indexes and schemas, recommending appropriate database technologies (e.g., TimescaleDB), and guiding safe migrations or replica setups. Provide concrete, data‑driven recommendations and implementation steps.\",\n      \"model\": \"reasoning\"\n    }\n  }\n}",
                "parsedResponse": {
                  "recommendation": "I think you need to hire a Database Performance Engineer because they can deeply analyse the slow dashboard query, optimise the execution plan, redesign indexes and schema, evaluate read‑replica or TimescaleDB options, and ensure real‑time performance without breaking existing functionality.",
                  "action": {
                    "type": "create_actor",
                    "actor": {
                      "title": "Database Performance Engineer",
                      "reason": "The team lacks deep expertise in query optimization, indexing, and schema design for large, time‑series datasets, which is essential to resolve the 8‑12 second dashboard load times and prevent customer churn.",
                      "skills": [
                        "SQL query performance tuning",
                        "Advanced indexing strategies (partial, covering, expression indexes)",
                        "Database schema design for high‑volume time‑series data",
                        "PostgreSQL and TimescaleDB expertise",
                        "EXPLAIN ANALYZE interpretation and plan rewriting",
                        "Read replica architecture and migration planning"
                      ],
                      "prompt": "You are an expert Database Performance Engineer. You help teams diagnose and resolve slow query issues by analyzing execution plans, designing optimal indexes and schemas, recommending appropriate database technologies (e.g., TimescaleDB), and guiding safe migrations or replica setups. Provide concrete, data‑driven recommendations and implementation steps.",
                      "model": "reasoning"
                    }
                  }
                },
                "validationErrors": [],
                "errorMessage": null
              }
            ],
            "totalDurationMs": 6088,
            "finalResponse": {
              "recommendation": "I think you need to hire a Database Performance Engineer because they can deeply analyse the slow dashboard query, optimise the execution plan, redesign indexes and schema, evaluate read‑replica or TimescaleDB options, and ensure real‑time performance without breaking existing functionality.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Performance Engineer",
                  "reason": "The team lacks deep expertise in query optimization, indexing, and schema design for large, time‑series datasets, which is essential to resolve the 8‑12 second dashboard load times and prevent customer churn.",
                  "skills": [
                    "SQL query performance tuning",
                    "Advanced indexing strategies (partial, covering, expression indexes)",
                    "Database schema design for high‑volume time‑series data",
                    "PostgreSQL and TimescaleDB expertise",
                    "EXPLAIN ANALYZE interpretation and plan rewriting",
                    "Read replica architecture and migration planning"
                  ],
                  "prompt": "You are an expert Database Performance Engineer. You help teams diagnose and resolve slow query issues by analyzing execution plans, designing optimal indexes and schemas, recommending appropriate database technologies (e.g., TimescaleDB), and guiding safe migrations or replica setups. Provide concrete, data‑driven recommendations and implementation steps.",
                  "model": "reasoning"
                }
              }
            }
          }
        ],
        "summary": {
          "successRate": 100,
          "firstAttemptSuccessRate": 100,
          "afterRetry1SuccessRate": 100,
          "afterRetry2SuccessRate": 100,
          "afterRetry3SuccessRate": 100,
          "averageDurationMs": 6439.666666666667,
          "averageAttempts": 1,
          "averageAttemptsPerSuccess": 1,
          "averageTokensPerSuccess": 1577.3333333333333,
          "totalTokensUsed": 4732
        }
      },
      "3": {
        "runs": [
          {
            "runNumber": 1,
            "success": true,
            "attempts": [],
            "steps": [
              {
                "stepNumber": 1,
                "stepName": "Recommendation",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:31:18.472Z",
                    "success": true,
                    "durationMs": 5533,
                    "inputTokens": 939,
                    "outputTokens": 122,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation, what type of team member should this team add?\n\nRespond with JSON like this example:\n{\"recommendation\": \"I recommend hiring a [role] because [reason]...\", \"action\": \"create_actor\"}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- The \"recommendation\" should explain your hiring recommendation (at least 20 characters)\n- Set \"action\" to \"create_actor\" if recommending someone, or null if not",
                    "rawResponse": "{\"recommendation\":\"I recommend hiring a Senior Database Optimization Engineer because the team lacks deep expertise in query performance analysis, schema redesign, advanced indexing, and evaluating potential database migrations needed to resolve the slow dashboard queries affecting enterprise customers.\", \"action\":\"create_actor\"}",
                    "parsedResponse": {
                      "recommendation": "I recommend hiring a Senior Database Optimization Engineer because the team lacks deep expertise in query performance analysis, schema redesign, advanced indexing, and evaluating potential database migrations needed to resolve the slow dashboard queries affecting enterprise customers.",
                      "action": "create_actor"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 2,
                "stepName": "Details",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:31:24.053Z",
                    "success": true,
                    "durationMs": 5581,
                    "inputTokens": 1004,
                    "outputTokens": 147,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Senior Database Optimization Engineer because the team lacks deep expertise in query performance analysis, schema redesign, advanced indexing, and evaluating potential database migrations needed to resolve the slow dashboard queries affecting enterprise customers.\",\"action\":\"create_actor\"}\n\n[user] For the role you recommended, provide their details.\n\nRespond with JSON like this example:\n{\"title\": \"Database Administrator\", \"reason\": \"The team needs database expertise to optimize their slow queries and design scalable schemas\", \"skills\": [\"PostgreSQL\", \"Query Optimization\", \"Database Design\"]}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- Provide 3-7 specific technical skills\n- The \"reason\" should explain how this role addresses the team's problem (at least 20 characters)",
                    "rawResponse": "{\"title\":\"Senior Database Optimization Engineer\",\"reason\":\"The team lacks deep expertise to analyze query plans, redesign schemas, implement advanced indexing, and evaluate migration options to eliminate the 8‑12 second dashboard load times for enterprise customers.\",\"skills\":[\"PostgreSQL\",\"Query Performance Tuning\",\"Advanced Indexing Strategies\",\"Database Schema Design\",\"EXPLAIN ANALYZE & Execution Plans\",\"Read‑Replica Architecture\"]}",
                    "parsedResponse": {
                      "title": "Senior Database Optimization Engineer",
                      "reason": "The team lacks deep expertise to analyze query plans, redesign schemas, implement advanced indexing, and evaluate migration options to eliminate the 8‑12 second dashboard load times for enterprise customers.",
                      "skills": [
                        "PostgreSQL",
                        "Query Performance Tuning",
                        "Advanced Indexing Strategies",
                        "Database Schema Design",
                        "EXPLAIN ANALYZE & Execution Plans",
                        "Read‑Replica Architecture"
                      ]
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 3,
                "stepName": "AI Config",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:31:29.768Z",
                    "success": true,
                    "durationMs": 5714,
                    "inputTokens": 1092,
                    "outputTokens": 200,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Senior Database Optimization Engineer because the team lacks deep expertise in query performance analysis, schema redesign, advanced indexing, and evaluating potential database migrations needed to resolve the slow dashboard queries affecting enterprise customers.\",\"action\":\"create_actor\"}\n\n[assistant] {\"title\":\"Senior Database Optimization Engineer\",\"reason\":\"The team lacks deep expertise to analyze query plans, redesign schemas, implement advanced indexing, and evaluate migration options to eliminate the 8‑12 second dashboard load times for enterprise customers.\",\"skills\":[\"PostgreSQL\",\"Query Performance Tuning\",\"Advanced Indexing Strategies\",\"Database Schema Design\",\"EXPLAIN ANALYZE & Execution Plans\",\"Read‑Replica Architecture\"]}\n\n[user] For this role, provide the AI system prompt and model type.\n\nRespond with JSON like this example:\n{\"prompt\": \"You are an expert database administrator. You help teams optimize queries, design schemas, and ensure data integrity...\", \"model\": \"reasoning\"}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- The \"prompt\" should be a detailed system prompt (at least 30 characters)\n- \"model\" should be \"reasoning\" for analytical tasks or \"semantic\" for creative tasks",
                    "rawResponse": "{\"prompt\":\"You are a Senior Database Optimization Engineer with deep expertise in PostgreSQL (and compatible RDBMS). Your mission is to help engineering teams diagnose and resolve performance bottlenecks in complex queries, design efficient schemas, create optimal indexing strategies, evaluate read‑replica and sharding architectures, and assess the feasibility of database migrations (e.g., to TimescaleDB or other time‑series solutions). You will analyze EXPLAIN ANALYZE output, recommend precise schema changes that preserve existing functionality, guide the implementation of caching or materialized views when appropriate, and communicate trade‑offs clearly to both technical and non‑technical stakeholders. Provide step‑by‑step action plans, code snippets, and performance validation methods while ensuring data integrity and minimal downtime.\", \"model\":\"reasoning\"}",
                    "parsedResponse": {
                      "prompt": "You are a Senior Database Optimization Engineer with deep expertise in PostgreSQL (and compatible RDBMS). Your mission is to help engineering teams diagnose and resolve performance bottlenecks in complex queries, design efficient schemas, create optimal indexing strategies, evaluate read‑replica and sharding architectures, and assess the feasibility of database migrations (e.g., to TimescaleDB or other time‑series solutions). You will analyze EXPLAIN ANALYZE output, recommend precise schema changes that preserve existing functionality, guide the implementation of caching or materialized views when appropriate, and communicate trade‑offs clearly to both technical and non‑technical stakeholders. Provide step‑by‑step action plans, code snippets, and performance validation methods while ensuring data integrity and minimal downtime.",
                      "model": "reasoning"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              }
            ],
            "totalDurationMs": 16830,
            "finalResponse": {
              "recommendation": "I recommend hiring a Senior Database Optimization Engineer because the team lacks deep expertise in query performance analysis, schema redesign, advanced indexing, and evaluating potential database migrations needed to resolve the slow dashboard queries affecting enterprise customers.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Senior Database Optimization Engineer",
                  "reason": "The team lacks deep expertise to analyze query plans, redesign schemas, implement advanced indexing, and evaluate migration options to eliminate the 8‑12 second dashboard load times for enterprise customers.",
                  "skills": [
                    "PostgreSQL",
                    "Query Performance Tuning",
                    "Advanced Indexing Strategies",
                    "Database Schema Design",
                    "EXPLAIN ANALYZE & Execution Plans",
                    "Read‑Replica Architecture"
                  ],
                  "prompt": "You are a Senior Database Optimization Engineer with deep expertise in PostgreSQL (and compatible RDBMS). Your mission is to help engineering teams diagnose and resolve performance bottlenecks in complex queries, design efficient schemas, create optimal indexing strategies, evaluate read‑replica and sharding architectures, and assess the feasibility of database migrations (e.g., to TimescaleDB or other time‑series solutions). You will analyze EXPLAIN ANALYZE output, recommend precise schema changes that preserve existing functionality, guide the implementation of caching or materialized views when appropriate, and communicate trade‑offs clearly to both technical and non‑technical stakeholders. Provide step‑by‑step action plans, code snippets, and performance validation methods while ensuring data integrity and minimal downtime.",
                  "model": "reasoning"
                }
              }
            }
          },
          {
            "runNumber": 2,
            "success": true,
            "attempts": [],
            "steps": [
              {
                "stepNumber": 1,
                "stepName": "Recommendation",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:31:35.254Z",
                    "success": true,
                    "durationMs": 5485,
                    "inputTokens": 939,
                    "outputTokens": 116,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation, what type of team member should this team add?\n\nRespond with JSON like this example:\n{\"recommendation\": \"I recommend hiring a [role] because [reason]...\", \"action\": \"create_actor\"}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- The \"recommendation\" should explain your hiring recommendation (at least 20 characters)\n- Set \"action\" to \"create_actor\" if recommending someone, or null if not",
                    "rawResponse": "{\"recommendation\":\"I recommend hiring a Senior Database Performance Engineer because the team lacks deep expertise in query optimization, indexing strategies, schema redesign, and evaluating potential database migrations to resolve the severe dashboard latency affecting enterprise customers.\",\"action\":\"create_actor\"}",
                    "parsedResponse": {
                      "recommendation": "I recommend hiring a Senior Database Performance Engineer because the team lacks deep expertise in query optimization, indexing strategies, schema redesign, and evaluating potential database migrations to resolve the severe dashboard latency affecting enterprise customers.",
                      "action": "create_actor"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 2,
                "stepName": "Details",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:31:40.953Z",
                    "success": true,
                    "durationMs": 5699,
                    "inputTokens": 1002,
                    "outputTokens": 154,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Senior Database Performance Engineer because the team lacks deep expertise in query optimization, indexing strategies, schema redesign, and evaluating potential database migrations to resolve the severe dashboard latency affecting enterprise customers.\",\"action\":\"create_actor\"}\n\n[user] For the role you recommended, provide their details.\n\nRespond with JSON like this example:\n{\"title\": \"Database Administrator\", \"reason\": \"The team needs database expertise to optimize their slow queries and design scalable schemas\", \"skills\": [\"PostgreSQL\", \"Query Optimization\", \"Database Design\"]}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- Provide 3-7 specific technical skills\n- The \"reason\" should explain how this role addresses the team's problem (at least 20 characters)",
                    "rawResponse": "{\"title\":\"Senior Database Performance Engineer\",\"reason\":\"The team lacks deep expertise to analyse query plans, redesign schemas, implement optimal indexing, and evaluate migration options to eliminate the dashboard latency that threatens enterprise customers\",\"skills\":[\"PostgreSQL\",\"Query Optimization\",\"Index Design\",\"Database Schema Refactoring\",\"Performance Monitoring (e.g., pg_stat_statements)\",\"Read‑Replica Architecture\",\"Time‑Series Databases (e.g., TimescaleDB)\"]}",
                    "parsedResponse": {
                      "title": "Senior Database Performance Engineer",
                      "reason": "The team lacks deep expertise to analyse query plans, redesign schemas, implement optimal indexing, and evaluate migration options to eliminate the dashboard latency that threatens enterprise customers",
                      "skills": [
                        "PostgreSQL",
                        "Query Optimization",
                        "Index Design",
                        "Database Schema Refactoring",
                        "Performance Monitoring (e.g., pg_stat_statements)",
                        "Read‑Replica Architecture",
                        "Time‑Series Databases (e.g., TimescaleDB)"
                      ]
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 3,
                "stepName": "AI Config",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:31:47.657Z",
                    "success": true,
                    "durationMs": 6704,
                    "inputTokens": 1097,
                    "outputTokens": 174,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Senior Database Performance Engineer because the team lacks deep expertise in query optimization, indexing strategies, schema redesign, and evaluating potential database migrations to resolve the severe dashboard latency affecting enterprise customers.\",\"action\":\"create_actor\"}\n\n[assistant] {\"title\":\"Senior Database Performance Engineer\",\"reason\":\"The team lacks deep expertise to analyse query plans, redesign schemas, implement optimal indexing, and evaluate migration options to eliminate the dashboard latency that threatens enterprise customers\",\"skills\":[\"PostgreSQL\",\"Query Optimization\",\"Index Design\",\"Database Schema Refactoring\",\"Performance Monitoring (e.g., pg_stat_statements)\",\"Read‑Replica Architecture\",\"Time‑Series Databases (e.g., TimescaleDB)\"]}\n\n[user] For this role, provide the AI system prompt and model type.\n\nRespond with JSON like this example:\n{\"prompt\": \"You are an expert database administrator. You help teams optimize queries, design schemas, and ensure data integrity...\", \"model\": \"reasoning\"}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- The \"prompt\" should be a detailed system prompt (at least 30 characters)\n- \"model\" should be \"reasoning\" for analytical tasks or \"semantic\" for creative tasks",
                    "rawResponse": "{\"prompt\":\"You are a Senior Database Performance Engineer with deep expertise in PostgreSQL and time‑series extensions like TimescaleDB. Your mission is to help engineering teams diagnose and eliminate performance bottlenecks in complex analytical queries. You analyze EXPLAIN ANALYZE output, design optimal indexing strategies, refactor schemas for scalability, evaluate read‑replica and sharding architectures, and advise on migration paths when a different database engine would provide measurable benefits. You communicate clear, step‑by‑step recommendations, provide sample DDL/DML changes, and guide the team through testing and rollout while ensuring data integrity and minimal downtime.\",\"model\":\"reasoning\"}",
                    "parsedResponse": {
                      "prompt": "You are a Senior Database Performance Engineer with deep expertise in PostgreSQL and time‑series extensions like TimescaleDB. Your mission is to help engineering teams diagnose and eliminate performance bottlenecks in complex analytical queries. You analyze EXPLAIN ANALYZE output, design optimal indexing strategies, refactor schemas for scalability, evaluate read‑replica and sharding architectures, and advise on migration paths when a different database engine would provide measurable benefits. You communicate clear, step‑by‑step recommendations, provide sample DDL/DML changes, and guide the team through testing and rollout while ensuring data integrity and minimal downtime.",
                      "model": "reasoning"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              }
            ],
            "totalDurationMs": 17888,
            "finalResponse": {
              "recommendation": "I recommend hiring a Senior Database Performance Engineer because the team lacks deep expertise in query optimization, indexing strategies, schema redesign, and evaluating potential database migrations to resolve the severe dashboard latency affecting enterprise customers.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Senior Database Performance Engineer",
                  "reason": "The team lacks deep expertise to analyse query plans, redesign schemas, implement optimal indexing, and evaluate migration options to eliminate the dashboard latency that threatens enterprise customers",
                  "skills": [
                    "PostgreSQL",
                    "Query Optimization",
                    "Index Design",
                    "Database Schema Refactoring",
                    "Performance Monitoring (e.g., pg_stat_statements)",
                    "Read‑Replica Architecture",
                    "Time‑Series Databases (e.g., TimescaleDB)"
                  ],
                  "prompt": "You are a Senior Database Performance Engineer with deep expertise in PostgreSQL and time‑series extensions like TimescaleDB. Your mission is to help engineering teams diagnose and eliminate performance bottlenecks in complex analytical queries. You analyze EXPLAIN ANALYZE output, design optimal indexing strategies, refactor schemas for scalability, evaluate read‑replica and sharding architectures, and advise on migration paths when a different database engine would provide measurable benefits. You communicate clear, step‑by‑step recommendations, provide sample DDL/DML changes, and guide the team through testing and rollout while ensuring data integrity and minimal downtime.",
                  "model": "reasoning"
                }
              }
            }
          },
          {
            "runNumber": 3,
            "success": true,
            "attempts": [],
            "steps": [
              {
                "stepNumber": 1,
                "stepName": "Recommendation",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:31:53.304Z",
                    "success": true,
                    "durationMs": 5646,
                    "inputTokens": 939,
                    "outputTokens": 117,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation, what type of team member should this team add?\n\nRespond with JSON like this example:\n{\"recommendation\": \"I recommend hiring a [role] because [reason]...\", \"action\": \"create_actor\"}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- The \"recommendation\" should explain your hiring recommendation (at least 20 characters)\n- Set \"action\" to \"create_actor\" if recommending someone, or null if not",
                    "rawResponse": "{\"recommendation\":\"I recommend hiring a Senior Database Performance Engineer because the team lacks deep expertise in query optimization, indexing strategies, schema redesign, and evaluating potential database migrations needed to resolve the slow dashboard queries affecting enterprise customers.\",\"action\":\"create_actor\"}",
                    "parsedResponse": {
                      "recommendation": "I recommend hiring a Senior Database Performance Engineer because the team lacks deep expertise in query optimization, indexing strategies, schema redesign, and evaluating potential database migrations needed to resolve the slow dashboard queries affecting enterprise customers.",
                      "action": "create_actor"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 2,
                "stepName": "Details",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:31:58.899Z",
                    "success": true,
                    "durationMs": 5595,
                    "inputTokens": 1003,
                    "outputTokens": 146,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Senior Database Performance Engineer because the team lacks deep expertise in query optimization, indexing strategies, schema redesign, and evaluating potential database migrations needed to resolve the slow dashboard queries affecting enterprise customers.\",\"action\":\"create_actor\"}\n\n[user] For the role you recommended, provide their details.\n\nRespond with JSON like this example:\n{\"title\": \"Database Administrator\", \"reason\": \"The team needs database expertise to optimize their slow queries and design scalable schemas\", \"skills\": [\"PostgreSQL\", \"Query Optimization\", \"Database Design\"]}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- Provide 3-7 specific technical skills\n- The \"reason\" should explain how this role addresses the team's problem (at least 20 characters)",
                    "rawResponse": "{\"title\":\"Senior Database Performance Engineer\",\"reason\":\"Provides deep expertise to analyse query plans, redesign schema, create optimal indexes, and evaluate migration options, directly addressing the slow dashboard queries that risk enterprise churn\",\"skills\":[\"PostgreSQL\",\"Query Optimization\",\"Advanced Indexing Strategies\",\"Database Schema Design\",\"Performance Monitoring & Profiling\",\"Read‑Replica Architecture\",\"Time‑Series Database Evaluation\"]}",
                    "parsedResponse": {
                      "title": "Senior Database Performance Engineer",
                      "reason": "Provides deep expertise to analyse query plans, redesign schema, create optimal indexes, and evaluate migration options, directly addressing the slow dashboard queries that risk enterprise churn",
                      "skills": [
                        "PostgreSQL",
                        "Query Optimization",
                        "Advanced Indexing Strategies",
                        "Database Schema Design",
                        "Performance Monitoring & Profiling",
                        "Read‑Replica Architecture",
                        "Time‑Series Database Evaluation"
                      ]
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 3,
                "stepName": "AI Config",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:32:04.732Z",
                    "success": true,
                    "durationMs": 5833,
                    "inputTokens": 1085,
                    "outputTokens": 159,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Senior Database Performance Engineer because the team lacks deep expertise in query optimization, indexing strategies, schema redesign, and evaluating potential database migrations needed to resolve the slow dashboard queries affecting enterprise customers.\",\"action\":\"create_actor\"}\n\n[assistant] {\"title\":\"Senior Database Performance Engineer\",\"reason\":\"Provides deep expertise to analyse query plans, redesign schema, create optimal indexes, and evaluate migration options, directly addressing the slow dashboard queries that risk enterprise churn\",\"skills\":[\"PostgreSQL\",\"Query Optimization\",\"Advanced Indexing Strategies\",\"Database Schema Design\",\"Performance Monitoring & Profiling\",\"Read‑Replica Architecture\",\"Time‑Series Database Evaluation\"]}\n\n[user] For this role, provide the AI system prompt and model type.\n\nRespond with JSON like this example:\n{\"prompt\": \"You are an expert database administrator. You help teams optimize queries, design schemas, and ensure data integrity...\", \"model\": \"reasoning\"}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- The \"prompt\" should be a detailed system prompt (at least 30 characters)\n- \"model\" should be \"reasoning\" for analytical tasks or \"semantic\" for creative tasks",
                    "rawResponse": "{\"prompt\":\"You are a Senior Database Performance Engineer AI assistant. Your mission is to help development teams diagnose and resolve complex database performance issues. You will analyze query execution plans, recommend indexing strategies, suggest schema redesigns, evaluate the need for read replicas or time‑series databases, and guide safe migrations. Provide clear, step‑by‑step optimization recommendations, explain trade‑offs, and generate example SQL statements or configuration snippets. Communicate technical details in a way that engineers of varying experience can understand, and always prioritize data integrity and minimal downtime.\",\"model\":\"reasoning\"}",
                    "parsedResponse": {
                      "prompt": "You are a Senior Database Performance Engineer AI assistant. Your mission is to help development teams diagnose and resolve complex database performance issues. You will analyze query execution plans, recommend indexing strategies, suggest schema redesigns, evaluate the need for read replicas or time‑series databases, and guide safe migrations. Provide clear, step‑by‑step optimization recommendations, explain trade‑offs, and generate example SQL statements or configuration snippets. Communicate technical details in a way that engineers of varying experience can understand, and always prioritize data integrity and minimal downtime.",
                      "model": "reasoning"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              }
            ],
            "totalDurationMs": 17074,
            "finalResponse": {
              "recommendation": "I recommend hiring a Senior Database Performance Engineer because the team lacks deep expertise in query optimization, indexing strategies, schema redesign, and evaluating potential database migrations needed to resolve the slow dashboard queries affecting enterprise customers.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Senior Database Performance Engineer",
                  "reason": "Provides deep expertise to analyse query plans, redesign schema, create optimal indexes, and evaluate migration options, directly addressing the slow dashboard queries that risk enterprise churn",
                  "skills": [
                    "PostgreSQL",
                    "Query Optimization",
                    "Advanced Indexing Strategies",
                    "Database Schema Design",
                    "Performance Monitoring & Profiling",
                    "Read‑Replica Architecture",
                    "Time‑Series Database Evaluation"
                  ],
                  "prompt": "You are a Senior Database Performance Engineer AI assistant. Your mission is to help development teams diagnose and resolve complex database performance issues. You will analyze query execution plans, recommend indexing strategies, suggest schema redesigns, evaluate the need for read replicas or time‑series databases, and guide safe migrations. Provide clear, step‑by‑step optimization recommendations, explain trade‑offs, and generate example SQL statements or configuration snippets. Communicate technical details in a way that engineers of varying experience can understand, and always prioritize data integrity and minimal downtime.",
                  "model": "reasoning"
                }
              }
            }
          }
        ],
        "summary": {
          "successRate": 100,
          "firstAttemptSuccessRate": 100,
          "afterRetry1SuccessRate": 100,
          "afterRetry2SuccessRate": 100,
          "afterRetry3SuccessRate": 100,
          "averageDurationMs": 17264,
          "averageAttempts": 3,
          "averageAttemptsPerSuccess": 3,
          "averageTokensPerSuccess": 3478.3333333333335,
          "totalTokensUsed": 10435
        }
      }
    },
    "groq-kimi-k2": {
      "1": {
        "runs": [
          {
            "runNumber": 1,
            "success": true,
            "attempts": [
              {
                "attemptNumber": 1,
                "timestamp": "2025-11-29T17:32:11.290Z",
                "success": true,
                "durationMs": 6557,
                "inputTokens": 1018,
                "outputTokens": 318,
                "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation above, recommend a team member who could help solve their problem.\n\nRespond ONLY with valid JSON like this example:\n{\n  \"recommendation\": \"I think you need to hire a [role] because [explanation of how they address the team's problem]...\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Job Title Here\",\n      \"reason\": \"Why this role addresses the team's skill gap\",\n      \"skills\": [\"skill1\", \"skill2\", \"skill3\"],\n      \"prompt\": \"You are an expert in [domain]. You help teams by [description of approach]...\",\n      \"model\": \"reasoning\"\n    }\n  }\n}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks or backticks\n- The \"recommendation\" field should start with \"I think you need to hire...\"\n- Skills array should have 3-7 specific technical skills\n- \"model\" should be \"reasoning\" for analytical tasks or \"semantic\" for creative tasks\n- Set \"action\" to null if no recommendation is appropriate",
                "rawResponse": "{\n  \"recommendation\": \"I think you need to hire a Database Performance Engineer because your team is clearly struggling with complex query optimization, schema design, and performance tuning. They have the right instincts about the problem areas but lack the deep expertise to implement solutions safely. This role would analyze your slow queries, optimize indexes, redesign schemas if needed, and help you scale your database architecture without breaking existing functionality.\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Database Performance Engineer\",\n      \"reason\": \"The team has identified database performance as the root cause but lacks expertise in query optimization, indexing strategies, and schema design for large datasets. They need someone who can analyze execution plans, optimize complex joins, and determine if architectural changes are needed.\",\n      \"skills\": [\"Query optimization and execution plan analysis\", \"Database indexing strategies and performance tuning\", \"Schema design for large-scale datasets\", \"Database scaling and sharding strategies\", \"Time-series database evaluation and migration\", \"Complex join optimization and subquery rewriting\", \"Database monitoring and bottleneck identification\"],\n      \"prompt\": \"You are an expert Database Performance Engineer specializing in optimizing database queries and schemas for large-scale applications. You help teams by analyzing slow queries using EXPLAIN plans, identifying bottlenecks, designing optimal indexes, and recommending schema changes. You understand when to optimize existing infrastructure versus when to migrate to specialized databases like TimescaleDB. You prioritize solutions that maintain data integrity while dramatically improving performance.\",\n      \"model\": \"reasoning\"\n    }\n  }\n}",
                "parsedResponse": {
                  "recommendation": "I think you need to hire a Database Performance Engineer because your team is clearly struggling with complex query optimization, schema design, and performance tuning. They have the right instincts about the problem areas but lack the deep expertise to implement solutions safely. This role would analyze your slow queries, optimize indexes, redesign schemas if needed, and help you scale your database architecture without breaking existing functionality.",
                  "action": {
                    "type": "create_actor",
                    "actor": {
                      "title": "Database Performance Engineer",
                      "reason": "The team has identified database performance as the root cause but lacks expertise in query optimization, indexing strategies, and schema design for large datasets. They need someone who can analyze execution plans, optimize complex joins, and determine if architectural changes are needed.",
                      "skills": [
                        "Query optimization and execution plan analysis",
                        "Database indexing strategies and performance tuning",
                        "Schema design for large-scale datasets",
                        "Database scaling and sharding strategies",
                        "Time-series database evaluation and migration",
                        "Complex join optimization and subquery rewriting",
                        "Database monitoring and bottleneck identification"
                      ],
                      "prompt": "You are an expert Database Performance Engineer specializing in optimizing database queries and schemas for large-scale applications. You help teams by analyzing slow queries using EXPLAIN plans, identifying bottlenecks, designing optimal indexes, and recommending schema changes. You understand when to optimize existing infrastructure versus when to migrate to specialized databases like TimescaleDB. You prioritize solutions that maintain data integrity while dramatically improving performance.",
                      "model": "reasoning"
                    }
                  }
                },
                "validationErrors": [],
                "errorMessage": null
              }
            ],
            "totalDurationMs": 6557,
            "finalResponse": {
              "recommendation": "I think you need to hire a Database Performance Engineer because your team is clearly struggling with complex query optimization, schema design, and performance tuning. They have the right instincts about the problem areas but lack the deep expertise to implement solutions safely. This role would analyze your slow queries, optimize indexes, redesign schemas if needed, and help you scale your database architecture without breaking existing functionality.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Performance Engineer",
                  "reason": "The team has identified database performance as the root cause but lacks expertise in query optimization, indexing strategies, and schema design for large datasets. They need someone who can analyze execution plans, optimize complex joins, and determine if architectural changes are needed.",
                  "skills": [
                    "Query optimization and execution plan analysis",
                    "Database indexing strategies and performance tuning",
                    "Schema design for large-scale datasets",
                    "Database scaling and sharding strategies",
                    "Time-series database evaluation and migration",
                    "Complex join optimization and subquery rewriting",
                    "Database monitoring and bottleneck identification"
                  ],
                  "prompt": "You are an expert Database Performance Engineer specializing in optimizing database queries and schemas for large-scale applications. You help teams by analyzing slow queries using EXPLAIN plans, identifying bottlenecks, designing optimal indexes, and recommending schema changes. You understand when to optimize existing infrastructure versus when to migrate to specialized databases like TimescaleDB. You prioritize solutions that maintain data integrity while dramatically improving performance.",
                  "model": "reasoning"
                }
              }
            }
          },
          {
            "runNumber": 2,
            "success": true,
            "attempts": [
              {
                "attemptNumber": 1,
                "timestamp": "2025-11-29T17:32:17.667Z",
                "success": true,
                "durationMs": 6377,
                "inputTokens": 1018,
                "outputTokens": 291,
                "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation above, recommend a team member who could help solve their problem.\n\nRespond ONLY with valid JSON like this example:\n{\n  \"recommendation\": \"I think you need to hire a [role] because [explanation of how they address the team's problem]...\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Job Title Here\",\n      \"reason\": \"Why this role addresses the team's skill gap\",\n      \"skills\": [\"skill1\", \"skill2\", \"skill3\"],\n      \"prompt\": \"You are an expert in [domain]. You help teams by [description of approach]...\",\n      \"model\": \"reasoning\"\n    }\n  }\n}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks or backticks\n- The \"recommendation\" field should start with \"I think you need to hire...\"\n- Skills array should have 3-7 specific technical skills\n- \"model\" should be \"reasoning\" for analytical tasks or \"semantic\" for creative tasks\n- Set \"action\" to null if no recommendation is appropriate",
                "rawResponse": "{\n  \"recommendation\": \"I think you need to hire a Database Performance Engineer because your team is clearly struggling with a complex database optimization problem that's beyond their current expertise. They need someone who can analyze query execution plans, design proper indexing strategies, optimize table structures, and determine whether architectural changes like read replicas or different database engines are warranted. This specialist can quickly identify why the 4-table join is causing sequential scans and implement targeted solutions before your enterprise customers churn.\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Database Performance Engineer\",\n      \"reason\": \"The team lacks deep database optimization expertise needed to solve complex query performance issues affecting enterprise customers\",\n      \"skills\": [\"Query Plan Analysis\", \"Database Indexing Strategies\", \"Schema Optimization\", \"Performance Tuning\", \"Database Architecture Design\", \"Read Replica Configuration\", \"Time-series Database Evaluation\"],\n      \"prompt\": \"You are an expert Database Performance Engineer specializing in optimizing complex queries and database architectures. You help teams by analyzing slow queries using EXPLAIN plans, identifying bottlenecks in multi-table joins, designing optimal indexing strategies, and recommending schema changes or architectural improvements. You focus on practical solutions that balance performance gains with implementation complexity, and you can quickly determine whether issues require query optimization, schema redesign, or infrastructure changes like read replicas or database migrations.\",\n      \"model\": \"reasoning\"\n    }\n  }\n}",
                "parsedResponse": {
                  "recommendation": "I think you need to hire a Database Performance Engineer because your team is clearly struggling with a complex database optimization problem that's beyond their current expertise. They need someone who can analyze query execution plans, design proper indexing strategies, optimize table structures, and determine whether architectural changes like read replicas or different database engines are warranted. This specialist can quickly identify why the 4-table join is causing sequential scans and implement targeted solutions before your enterprise customers churn.",
                  "action": {
                    "type": "create_actor",
                    "actor": {
                      "title": "Database Performance Engineer",
                      "reason": "The team lacks deep database optimization expertise needed to solve complex query performance issues affecting enterprise customers",
                      "skills": [
                        "Query Plan Analysis",
                        "Database Indexing Strategies",
                        "Schema Optimization",
                        "Performance Tuning",
                        "Database Architecture Design",
                        "Read Replica Configuration",
                        "Time-series Database Evaluation"
                      ],
                      "prompt": "You are an expert Database Performance Engineer specializing in optimizing complex queries and database architectures. You help teams by analyzing slow queries using EXPLAIN plans, identifying bottlenecks in multi-table joins, designing optimal indexing strategies, and recommending schema changes or architectural improvements. You focus on practical solutions that balance performance gains with implementation complexity, and you can quickly determine whether issues require query optimization, schema redesign, or infrastructure changes like read replicas or database migrations.",
                      "model": "reasoning"
                    }
                  }
                },
                "validationErrors": [],
                "errorMessage": null
              }
            ],
            "totalDurationMs": 6378,
            "finalResponse": {
              "recommendation": "I think you need to hire a Database Performance Engineer because your team is clearly struggling with a complex database optimization problem that's beyond their current expertise. They need someone who can analyze query execution plans, design proper indexing strategies, optimize table structures, and determine whether architectural changes like read replicas or different database engines are warranted. This specialist can quickly identify why the 4-table join is causing sequential scans and implement targeted solutions before your enterprise customers churn.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Performance Engineer",
                  "reason": "The team lacks deep database optimization expertise needed to solve complex query performance issues affecting enterprise customers",
                  "skills": [
                    "Query Plan Analysis",
                    "Database Indexing Strategies",
                    "Schema Optimization",
                    "Performance Tuning",
                    "Database Architecture Design",
                    "Read Replica Configuration",
                    "Time-series Database Evaluation"
                  ],
                  "prompt": "You are an expert Database Performance Engineer specializing in optimizing complex queries and database architectures. You help teams by analyzing slow queries using EXPLAIN plans, identifying bottlenecks in multi-table joins, designing optimal indexing strategies, and recommending schema changes or architectural improvements. You focus on practical solutions that balance performance gains with implementation complexity, and you can quickly determine whether issues require query optimization, schema redesign, or infrastructure changes like read replicas or database migrations.",
                  "model": "reasoning"
                }
              }
            }
          },
          {
            "runNumber": 3,
            "success": true,
            "attempts": [
              {
                "attemptNumber": 1,
                "timestamp": "2025-11-29T17:32:24.290Z",
                "success": true,
                "durationMs": 6622,
                "inputTokens": 1018,
                "outputTokens": 366,
                "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation above, recommend a team member who could help solve their problem.\n\nRespond ONLY with valid JSON like this example:\n{\n  \"recommendation\": \"I think you need to hire a [role] because [explanation of how they address the team's problem]...\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Job Title Here\",\n      \"reason\": \"Why this role addresses the team's skill gap\",\n      \"skills\": [\"skill1\", \"skill2\", \"skill3\"],\n      \"prompt\": \"You are an expert in [domain]. You help teams by [description of approach]...\",\n      \"model\": \"reasoning\"\n    }\n  }\n}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks or backticks\n- The \"recommendation\" field should start with \"I think you need to hire...\"\n- Skills array should have 3-7 specific technical skills\n- \"model\" should be \"reasoning\" for analytical tasks or \"semantic\" for creative tasks\n- Set \"action\" to null if no recommendation is appropriate",
                "rawResponse": "{\n  \"recommendation\": \"I think you need to hire a Database Performance Engineer because your team is clearly struggling with complex query optimization, schema design, and performance tuning. They have the right instincts about indexes, query structure, and potential architectural changes, but lack the deep expertise to implement solutions confidently. A Database Performance Engineer can analyze your specific query patterns, identify the root cause of the sequential scan bottleneck, design optimal indexing strategies, and determine whether you need schema changes, partitioning, or a different database architecture without the risky guesswork.\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Database Performance Engineer\",\n      \"reason\": \"The team has database knowledge gaps preventing them from solving critical performance issues affecting enterprise customers. They need someone who can analyze complex query execution plans, optimize multi-table joins, design proper indexing strategies, and make informed decisions about schema changes or database migrations.\",\n      \"skills\": [\"Query optimization and execution plan analysis\", \"Database indexing strategies and performance tuning\", \"Schema design and normalization/denormalization\", \"Database partitioning and sharding\", \"Read replica configuration and load balancing\", \"Time-series database evaluation (TimescaleDB, InfluxDB)\", \"Database migration planning and execution\"],\n      \"prompt\": \"You are an expert Database Performance Engineer with 10+ years optimizing high-traffic database systems. You help teams by analyzing slow queries using EXPLAIN plans, identifying bottlenecks in complex joins and aggregations, designing optimal indexing strategies, and recommending schema changes or database architectures. You prioritize solutions that minimize risk and downtime while maximizing performance gains. When suggesting changes, you always consider the impact on existing functionality and provide step-by-step implementation plans with rollback strategies.\",\n      \"model\": \"reasoning\"\n    }\n  }\n}",
                "parsedResponse": {
                  "recommendation": "I think you need to hire a Database Performance Engineer because your team is clearly struggling with complex query optimization, schema design, and performance tuning. They have the right instincts about indexes, query structure, and potential architectural changes, but lack the deep expertise to implement solutions confidently. A Database Performance Engineer can analyze your specific query patterns, identify the root cause of the sequential scan bottleneck, design optimal indexing strategies, and determine whether you need schema changes, partitioning, or a different database architecture without the risky guesswork.",
                  "action": {
                    "type": "create_actor",
                    "actor": {
                      "title": "Database Performance Engineer",
                      "reason": "The team has database knowledge gaps preventing them from solving critical performance issues affecting enterprise customers. They need someone who can analyze complex query execution plans, optimize multi-table joins, design proper indexing strategies, and make informed decisions about schema changes or database migrations.",
                      "skills": [
                        "Query optimization and execution plan analysis",
                        "Database indexing strategies and performance tuning",
                        "Schema design and normalization/denormalization",
                        "Database partitioning and sharding",
                        "Read replica configuration and load balancing",
                        "Time-series database evaluation (TimescaleDB, InfluxDB)",
                        "Database migration planning and execution"
                      ],
                      "prompt": "You are an expert Database Performance Engineer with 10+ years optimizing high-traffic database systems. You help teams by analyzing slow queries using EXPLAIN plans, identifying bottlenecks in complex joins and aggregations, designing optimal indexing strategies, and recommending schema changes or database architectures. You prioritize solutions that minimize risk and downtime while maximizing performance gains. When suggesting changes, you always consider the impact on existing functionality and provide step-by-step implementation plans with rollback strategies.",
                      "model": "reasoning"
                    }
                  }
                },
                "validationErrors": [],
                "errorMessage": null
              }
            ],
            "totalDurationMs": 6622,
            "finalResponse": {
              "recommendation": "I think you need to hire a Database Performance Engineer because your team is clearly struggling with complex query optimization, schema design, and performance tuning. They have the right instincts about indexes, query structure, and potential architectural changes, but lack the deep expertise to implement solutions confidently. A Database Performance Engineer can analyze your specific query patterns, identify the root cause of the sequential scan bottleneck, design optimal indexing strategies, and determine whether you need schema changes, partitioning, or a different database architecture without the risky guesswork.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Performance Engineer",
                  "reason": "The team has database knowledge gaps preventing them from solving critical performance issues affecting enterprise customers. They need someone who can analyze complex query execution plans, optimize multi-table joins, design proper indexing strategies, and make informed decisions about schema changes or database migrations.",
                  "skills": [
                    "Query optimization and execution plan analysis",
                    "Database indexing strategies and performance tuning",
                    "Schema design and normalization/denormalization",
                    "Database partitioning and sharding",
                    "Read replica configuration and load balancing",
                    "Time-series database evaluation (TimescaleDB, InfluxDB)",
                    "Database migration planning and execution"
                  ],
                  "prompt": "You are an expert Database Performance Engineer with 10+ years optimizing high-traffic database systems. You help teams by analyzing slow queries using EXPLAIN plans, identifying bottlenecks in complex joins and aggregations, designing optimal indexing strategies, and recommending schema changes or database architectures. You prioritize solutions that minimize risk and downtime while maximizing performance gains. When suggesting changes, you always consider the impact on existing functionality and provide step-by-step implementation plans with rollback strategies.",
                  "model": "reasoning"
                }
              }
            }
          }
        ],
        "summary": {
          "successRate": 100,
          "firstAttemptSuccessRate": 100,
          "afterRetry1SuccessRate": 100,
          "afterRetry2SuccessRate": 100,
          "afterRetry3SuccessRate": 100,
          "averageDurationMs": 6519,
          "averageAttempts": 1,
          "averageAttemptsPerSuccess": 1,
          "averageTokensPerSuccess": 1343,
          "totalTokensUsed": 4029
        }
      },
      "3": {
        "runs": [
          {
            "runNumber": 1,
            "success": true,
            "attempts": [],
            "steps": [
              {
                "stepNumber": 1,
                "stepName": "Recommendation",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:32:30.055Z",
                    "success": true,
                    "durationMs": 5765,
                    "inputTokens": 882,
                    "outputTokens": 80,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation, what type of team member should this team add?\n\nRespond with JSON like this example:\n{\"recommendation\": \"I recommend hiring a [role] because [reason]...\", \"action\": \"create_actor\"}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- The \"recommendation\" should explain your hiring recommendation (at least 20 characters)\n- Set \"action\" to \"create_actor\" if recommending someone, or null if not",
                    "rawResponse": "{\"recommendation\": \"I recommend hiring a Database Performance Engineer because the team is stuck on a critical query that takes 8-12 seconds and none of them can read execution plans, design optimal indexes, or decide if schema changes or a different engine (e.g. TimescaleDB) are needed to hit the end-of-month deadline and prevent churn.\", \"action\": \"create_actor\"}",
                    "parsedResponse": {
                      "recommendation": "I recommend hiring a Database Performance Engineer because the team is stuck on a critical query that takes 8-12 seconds and none of them can read execution plans, design optimal indexes, or decide if schema changes or a different engine (e.g. TimescaleDB) are needed to hit the end-of-month deadline and prevent churn.",
                      "action": "create_actor"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 2,
                "stepName": "Details",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:32:35.736Z",
                    "success": true,
                    "durationMs": 5681,
                    "inputTokens": 965,
                    "outputTokens": 88,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Database Performance Engineer because the team is stuck on a critical query that takes 8-12 seconds and none of them can read execution plans, design optimal indexes, or decide if schema changes or a different engine (e.g. TimescaleDB) are needed to hit the end-of-month deadline and prevent churn.\",\"action\":\"create_actor\"}\n\n[user] For the role you recommended, provide their details.\n\nRespond with JSON like this example:\n{\"title\": \"Database Administrator\", \"reason\": \"The team needs database expertise to optimize their slow queries and design scalable schemas\", \"skills\": [\"PostgreSQL\", \"Query Optimization\", \"Database Design\"]}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- Provide 3-7 specific technical skills\n- The \"reason\" should explain how this role addresses the team's problem (at least 20 characters)",
                    "rawResponse": "{\"title\":\"Database Performance Engineer\",\"reason\":\"The team has a critical 8-12 second dashboard query causing enterprise churn threats and lacks expertise to analyse execution plans, design optimal indexes, or decide on schema changes vs engine migration\",\"skills\":[\"PostgreSQL query optimisation\",\"Reading EXPLAIN ANALYZE plans\",\"Index design for multi-table joins\",\"Schema denormalisation strategies\",\"Time-series database evaluation\",\"Read-replica and partitioning setup\"]}",
                    "parsedResponse": {
                      "title": "Database Performance Engineer",
                      "reason": "The team has a critical 8-12 second dashboard query causing enterprise churn threats and lacks expertise to analyse execution plans, design optimal indexes, or decide on schema changes vs engine migration",
                      "skills": [
                        "PostgreSQL query optimisation",
                        "Reading EXPLAIN ANALYZE plans",
                        "Index design for multi-table joins",
                        "Schema denormalisation strategies",
                        "Time-series database evaluation",
                        "Read-replica and partitioning setup"
                      ]
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 3,
                "stepName": "AI Config",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:32:41.664Z",
                    "success": true,
                    "durationMs": 5928,
                    "inputTokens": 1060,
                    "outputTokens": 92,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Database Performance Engineer because the team is stuck on a critical query that takes 8-12 seconds and none of them can read execution plans, design optimal indexes, or decide if schema changes or a different engine (e.g. TimescaleDB) are needed to hit the end-of-month deadline and prevent churn.\",\"action\":\"create_actor\"}\n\n[assistant] {\"title\":\"Database Performance Engineer\",\"reason\":\"The team has a critical 8-12 second dashboard query causing enterprise churn threats and lacks expertise to analyse execution plans, design optimal indexes, or decide on schema changes vs engine migration\",\"skills\":[\"PostgreSQL query optimisation\",\"Reading EXPLAIN ANALYZE plans\",\"Index design for multi-table joins\",\"Schema denormalisation strategies\",\"Time-series database evaluation\",\"Read-replica and partitioning setup\"]}\n\n[user] For this role, provide the AI system prompt and model type.\n\nRespond with JSON like this example:\n{\"prompt\": \"You are an expert database administrator. You help teams optimize queries, design schemas, and ensure data integrity...\", \"model\": \"reasoning\"}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- The \"prompt\" should be a detailed system prompt (at least 30 characters)\n- \"model\" should be \"reasoning\" for analytical tasks or \"semantic\" for creative tasks",
                    "rawResponse": "{\"prompt\":\"You are a senior database performance engineer with deep expertise in PostgreSQL internals, query planning, and time-series workloads. Your job is to diagnose slow queries, design optimal indexes, and recommend schema or engine changes. Always ask for EXPLAIN ANALYZE output, table/column definitions, row counts, and access patterns before proposing solutions. Prioritise low-risk, high-impact fixes that can ship before deadlines.\",\"model\":\"reasoning\"}",
                    "parsedResponse": {
                      "prompt": "You are a senior database performance engineer with deep expertise in PostgreSQL internals, query planning, and time-series workloads. Your job is to diagnose slow queries, design optimal indexes, and recommend schema or engine changes. Always ask for EXPLAIN ANALYZE output, table/column definitions, row counts, and access patterns before proposing solutions. Prioritise low-risk, high-impact fixes that can ship before deadlines.",
                      "model": "reasoning"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              }
            ],
            "totalDurationMs": 17374,
            "finalResponse": {
              "recommendation": "I recommend hiring a Database Performance Engineer because the team is stuck on a critical query that takes 8-12 seconds and none of them can read execution plans, design optimal indexes, or decide if schema changes or a different engine (e.g. TimescaleDB) are needed to hit the end-of-month deadline and prevent churn.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Performance Engineer",
                  "reason": "The team has a critical 8-12 second dashboard query causing enterprise churn threats and lacks expertise to analyse execution plans, design optimal indexes, or decide on schema changes vs engine migration",
                  "skills": [
                    "PostgreSQL query optimisation",
                    "Reading EXPLAIN ANALYZE plans",
                    "Index design for multi-table joins",
                    "Schema denormalisation strategies",
                    "Time-series database evaluation",
                    "Read-replica and partitioning setup"
                  ],
                  "prompt": "You are a senior database performance engineer with deep expertise in PostgreSQL internals, query planning, and time-series workloads. Your job is to diagnose slow queries, design optimal indexes, and recommend schema or engine changes. Always ask for EXPLAIN ANALYZE output, table/column definitions, row counts, and access patterns before proposing solutions. Prioritise low-risk, high-impact fixes that can ship before deadlines.",
                  "model": "reasoning"
                }
              }
            }
          },
          {
            "runNumber": 2,
            "success": true,
            "attempts": [],
            "steps": [
              {
                "stepNumber": 1,
                "stepName": "Recommendation",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:32:47.418Z",
                    "success": true,
                    "durationMs": 5754,
                    "inputTokens": 882,
                    "outputTokens": 111,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation, what type of team member should this team add?\n\nRespond with JSON like this example:\n{\"recommendation\": \"I recommend hiring a [role] because [reason]...\", \"action\": \"create_actor\"}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- The \"recommendation\" should explain your hiring recommendation (at least 20 characters)\n- Set \"action\" to \"create_actor\" if recommending someone, or null if not",
                    "rawResponse": "{\"recommendation\": \"I recommend hiring a Database Performance Engineer because the team is stuck on a critical 8-12 second dashboard query issue affecting enterprise customers. They need someone who can analyse complex query plans across 4-table joins, optimise indexing strategies, redesign schema for time-series/event data, and evaluate if a migration to TimescaleDB or read-replicas is warranted. This specialist will have deep expertise in PostgreSQL internals, query optimisation, and scaling strategies for large datasets (50k+ records).\", \"action\": \"create_actor\"}",
                    "parsedResponse": {
                      "recommendation": "I recommend hiring a Database Performance Engineer because the team is stuck on a critical 8-12 second dashboard query issue affecting enterprise customers. They need someone who can analyse complex query plans across 4-table joins, optimise indexing strategies, redesign schema for time-series/event data, and evaluate if a migration to TimescaleDB or read-replicas is warranted. This specialist will have deep expertise in PostgreSQL internals, query optimisation, and scaling strategies for large datasets (50k+ records).",
                      "action": "create_actor"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 2,
                "stepName": "Details",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:32:53.407Z",
                    "success": true,
                    "durationMs": 5989,
                    "inputTokens": 995,
                    "outputTokens": 81,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Database Performance Engineer because the team is stuck on a critical 8-12 second dashboard query issue affecting enterprise customers. They need someone who can analyse complex query plans across 4-table joins, optimise indexing strategies, redesign schema for time-series/event data, and evaluate if a migration to TimescaleDB or read-replicas is warranted. This specialist will have deep expertise in PostgreSQL internals, query optimisation, and scaling strategies for large datasets (50k+ records).\",\"action\":\"create_actor\"}\n\n[user] For the role you recommended, provide their details.\n\nRespond with JSON like this example:\n{\"title\": \"Database Administrator\", \"reason\": \"The team needs database expertise to optimize their slow queries and design scalable schemas\", \"skills\": [\"PostgreSQL\", \"Query Optimization\", \"Database Design\"]}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- Provide 3-7 specific technical skills\n- The \"reason\" should explain how this role addresses the team's problem (at least 20 characters)",
                    "rawResponse": "{\"title\": \"Database Performance Engineer\", \"reason\": \"The team needs specialized expertise to diagnose and fix complex multi-table join performance issues affecting enterprise customers\", \"skills\": [\"PostgreSQL Query Optimization\", \"EXPLAIN ANALYZE Interpretation\", \"Index Strategy Design\", \"Time-Series Database Architecture\", \"Read Replica Configuration\", \"Schema Normalization/Denormalization\", \"Database Migration Planning\"]}",
                    "parsedResponse": {
                      "title": "Database Performance Engineer",
                      "reason": "The team needs specialized expertise to diagnose and fix complex multi-table join performance issues affecting enterprise customers",
                      "skills": [
                        "PostgreSQL Query Optimization",
                        "EXPLAIN ANALYZE Interpretation",
                        "Index Strategy Design",
                        "Time-Series Database Architecture",
                        "Read Replica Configuration",
                        "Schema Normalization/Denormalization",
                        "Database Migration Planning"
                      ]
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 3,
                "stepName": "AI Config",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:32:58.958Z",
                    "success": true,
                    "durationMs": 5551,
                    "inputTokens": 1072,
                    "outputTokens": 86,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Database Performance Engineer because the team is stuck on a critical 8-12 second dashboard query issue affecting enterprise customers. They need someone who can analyse complex query plans across 4-table joins, optimise indexing strategies, redesign schema for time-series/event data, and evaluate if a migration to TimescaleDB or read-replicas is warranted. This specialist will have deep expertise in PostgreSQL internals, query optimisation, and scaling strategies for large datasets (50k+ records).\",\"action\":\"create_actor\"}\n\n[assistant] {\"title\":\"Database Performance Engineer\",\"reason\":\"The team needs specialized expertise to diagnose and fix complex multi-table join performance issues affecting enterprise customers\",\"skills\":[\"PostgreSQL Query Optimization\",\"EXPLAIN ANALYZE Interpretation\",\"Index Strategy Design\",\"Time-Series Database Architecture\",\"Read Replica Configuration\",\"Schema Normalization/Denormalization\",\"Database Migration Planning\"]}\n\n[user] For this role, provide the AI system prompt and model type.\n\nRespond with JSON like this example:\n{\"prompt\": \"You are an expert database administrator. You help teams optimize queries, design schemas, and ensure data integrity...\", \"model\": \"reasoning\"}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- The \"prompt\" should be a detailed system prompt (at least 30 characters)\n- \"model\" should be \"reasoning\" for analytical tasks or \"semantic\" for creative tasks",
                    "rawResponse": "{\"prompt\": \"You are a Database Performance Engineer with deep expertise in PostgreSQL optimization, query execution plans, and scaling strategies for large datasets. Analyze complex multi-table joins, identify bottlenecks in sequential scans, design targeted indexing strategies, and recommend schema changes or database migrations. Focus on measurable performance improvements for time-series and event data while maintaining data integrity and minimizing downtime for enterprise customers.\", \"model\": \"reasoning\"}",
                    "parsedResponse": {
                      "prompt": "You are a Database Performance Engineer with deep expertise in PostgreSQL optimization, query execution plans, and scaling strategies for large datasets. Analyze complex multi-table joins, identify bottlenecks in sequential scans, design targeted indexing strategies, and recommend schema changes or database migrations. Focus on measurable performance improvements for time-series and event data while maintaining data integrity and minimizing downtime for enterprise customers.",
                      "model": "reasoning"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              }
            ],
            "totalDurationMs": 17295,
            "finalResponse": {
              "recommendation": "I recommend hiring a Database Performance Engineer because the team is stuck on a critical 8-12 second dashboard query issue affecting enterprise customers. They need someone who can analyse complex query plans across 4-table joins, optimise indexing strategies, redesign schema for time-series/event data, and evaluate if a migration to TimescaleDB or read-replicas is warranted. This specialist will have deep expertise in PostgreSQL internals, query optimisation, and scaling strategies for large datasets (50k+ records).",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Performance Engineer",
                  "reason": "The team needs specialized expertise to diagnose and fix complex multi-table join performance issues affecting enterprise customers",
                  "skills": [
                    "PostgreSQL Query Optimization",
                    "EXPLAIN ANALYZE Interpretation",
                    "Index Strategy Design",
                    "Time-Series Database Architecture",
                    "Read Replica Configuration",
                    "Schema Normalization/Denormalization",
                    "Database Migration Planning"
                  ],
                  "prompt": "You are a Database Performance Engineer with deep expertise in PostgreSQL optimization, query execution plans, and scaling strategies for large datasets. Analyze complex multi-table joins, identify bottlenecks in sequential scans, design targeted indexing strategies, and recommend schema changes or database migrations. Focus on measurable performance improvements for time-series and event data while maintaining data integrity and minimizing downtime for enterprise customers.",
                  "model": "reasoning"
                }
              }
            }
          },
          {
            "runNumber": 3,
            "success": true,
            "attempts": [],
            "steps": [
              {
                "stepNumber": 1,
                "stepName": "Recommendation",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:33:04.748Z",
                    "success": true,
                    "durationMs": 5789,
                    "inputTokens": 882,
                    "outputTokens": 80,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation, what type of team member should this team add?\n\nRespond with JSON like this example:\n{\"recommendation\": \"I recommend hiring a [role] because [reason]...\", \"action\": \"create_actor\"}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- The \"recommendation\" should explain your hiring recommendation (at least 20 characters)\n- Set \"action\" to \"create_actor\" if recommending someone, or null if not",
                    "rawResponse": "{\"recommendation\": \"I recommend hiring a Database Performance Engineer because the team is stuck on a critical query that takes 8-12 seconds and none of them can read execution plans, design optimal indexes, or decide if schema changes or a different engine (e.g. TimescaleDB) are needed to hit the end-of-month deadline and prevent churn.\", \"action\": \"create_actor\"}",
                    "parsedResponse": {
                      "recommendation": "I recommend hiring a Database Performance Engineer because the team is stuck on a critical query that takes 8-12 seconds and none of them can read execution plans, design optimal indexes, or decide if schema changes or a different engine (e.g. TimescaleDB) are needed to hit the end-of-month deadline and prevent churn.",
                      "action": "create_actor"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 2,
                "stepName": "Details",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:33:10.448Z",
                    "success": true,
                    "durationMs": 5700,
                    "inputTokens": 965,
                    "outputTokens": 81,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Database Performance Engineer because the team is stuck on a critical query that takes 8-12 seconds and none of them can read execution plans, design optimal indexes, or decide if schema changes or a different engine (e.g. TimescaleDB) are needed to hit the end-of-month deadline and prevent churn.\",\"action\":\"create_actor\"}\n\n[user] For the role you recommended, provide their details.\n\nRespond with JSON like this example:\n{\"title\": \"Database Administrator\", \"reason\": \"The team needs database expertise to optimize their slow queries and design scalable schemas\", \"skills\": [\"PostgreSQL\", \"Query Optimization\", \"Database Design\"]}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- Provide 3-7 specific technical skills\n- The \"reason\" should explain how this role addresses the team's problem (at least 20 characters)",
                    "rawResponse": "{\"title\":\"Database Performance Engineer\",\"reason\":\"The team has a critical 8-12 second dashboard query causing enterprise churn threats and lacks expertise to analyse execution plans, design optimal indexes, or decide on schema changes vs engine migration\",\"skills\":[\"PostgreSQL query tuning\",\"EXPLAIN ANALYZE interpretation\",\"Index strategy design\",\"Schema optimisation\",\"Time-series databases\",\"Read-replica architecture\",\"Database benchmarking\"]}",
                    "parsedResponse": {
                      "title": "Database Performance Engineer",
                      "reason": "The team has a critical 8-12 second dashboard query causing enterprise churn threats and lacks expertise to analyse execution plans, design optimal indexes, or decide on schema changes vs engine migration",
                      "skills": [
                        "PostgreSQL query tuning",
                        "EXPLAIN ANALYZE interpretation",
                        "Index strategy design",
                        "Schema optimisation",
                        "Time-series databases",
                        "Read-replica architecture",
                        "Database benchmarking"
                      ]
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 3,
                "stepName": "AI Config",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:33:15.975Z",
                    "success": true,
                    "durationMs": 5527,
                    "inputTokens": 1053,
                    "outputTokens": 62,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Database Performance Engineer because the team is stuck on a critical query that takes 8-12 seconds and none of them can read execution plans, design optimal indexes, or decide if schema changes or a different engine (e.g. TimescaleDB) are needed to hit the end-of-month deadline and prevent churn.\",\"action\":\"create_actor\"}\n\n[assistant] {\"title\":\"Database Performance Engineer\",\"reason\":\"The team has a critical 8-12 second dashboard query causing enterprise churn threats and lacks expertise to analyse execution plans, design optimal indexes, or decide on schema changes vs engine migration\",\"skills\":[\"PostgreSQL query tuning\",\"EXPLAIN ANALYZE interpretation\",\"Index strategy design\",\"Schema optimisation\",\"Time-series databases\",\"Read-replica architecture\",\"Database benchmarking\"]}\n\n[user] For this role, provide the AI system prompt and model type.\n\nRespond with JSON like this example:\n{\"prompt\": \"You are an expert database administrator. You help teams optimize queries, design schemas, and ensure data integrity...\", \"model\": \"reasoning\"}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- The \"prompt\" should be a detailed system prompt (at least 30 characters)\n- \"model\" should be \"reasoning\" for analytical tasks or \"semantic\" for creative tasks",
                    "rawResponse": "{\"prompt\":\"You are a senior database performance engineer with 10+ years optimising PostgreSQL and time-series workloads. Analyse execution plans, design indexes, refactor schemas, and recommend architecture changes to achieve sub-second query times while preserving data integrity and minimising migration risk.\",\"model\":\"reasoning\"}",
                    "parsedResponse": {
                      "prompt": "You are a senior database performance engineer with 10+ years optimising PostgreSQL and time-series workloads. Analyse execution plans, design indexes, refactor schemas, and recommend architecture changes to achieve sub-second query times while preserving data integrity and minimising migration risk.",
                      "model": "reasoning"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              }
            ],
            "totalDurationMs": 17016,
            "finalResponse": {
              "recommendation": "I recommend hiring a Database Performance Engineer because the team is stuck on a critical query that takes 8-12 seconds and none of them can read execution plans, design optimal indexes, or decide if schema changes or a different engine (e.g. TimescaleDB) are needed to hit the end-of-month deadline and prevent churn.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Performance Engineer",
                  "reason": "The team has a critical 8-12 second dashboard query causing enterprise churn threats and lacks expertise to analyse execution plans, design optimal indexes, or decide on schema changes vs engine migration",
                  "skills": [
                    "PostgreSQL query tuning",
                    "EXPLAIN ANALYZE interpretation",
                    "Index strategy design",
                    "Schema optimisation",
                    "Time-series databases",
                    "Read-replica architecture",
                    "Database benchmarking"
                  ],
                  "prompt": "You are a senior database performance engineer with 10+ years optimising PostgreSQL and time-series workloads. Analyse execution plans, design indexes, refactor schemas, and recommend architecture changes to achieve sub-second query times while preserving data integrity and minimising migration risk.",
                  "model": "reasoning"
                }
              }
            }
          }
        ],
        "summary": {
          "successRate": 100,
          "firstAttemptSuccessRate": 100,
          "afterRetry1SuccessRate": 100,
          "afterRetry2SuccessRate": 100,
          "afterRetry3SuccessRate": 100,
          "averageDurationMs": 17228.333333333332,
          "averageAttempts": 3,
          "averageAttemptsPerSuccess": 3,
          "averageTokensPerSuccess": 3172.3333333333335,
          "totalTokensUsed": 9517
        }
      }
    },
    "groq-llama-3.3-70b": {
      "1": {
        "runs": [
          {
            "runNumber": 1,
            "success": true,
            "attempts": [
              {
                "attemptNumber": 1,
                "timestamp": "2025-11-29T17:33:21.753Z",
                "success": true,
                "durationMs": 5778,
                "inputTokens": 1065,
                "outputTokens": 182,
                "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation above, recommend a team member who could help solve their problem.\n\nRespond ONLY with valid JSON like this example:\n{\n  \"recommendation\": \"I think you need to hire a [role] because [explanation of how they address the team's problem]...\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Job Title Here\",\n      \"reason\": \"Why this role addresses the team's skill gap\",\n      \"skills\": [\"skill1\", \"skill2\", \"skill3\"],\n      \"prompt\": \"You are an expert in [domain]. You help teams by [description of approach]...\",\n      \"model\": \"reasoning\"\n    }\n  }\n}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks or backticks\n- The \"recommendation\" field should start with \"I think you need to hire...\"\n- Skills array should have 3-7 specific technical skills\n- \"model\" should be \"reasoning\" for analytical tasks or \"semantic\" for creative tasks\n- Set \"action\" to null if no recommendation is appropriate",
                "rawResponse": "{\n  \"recommendation\": \"I think you need to hire a Database Performance Specialist because they can analyze the query plans, optimize the schema, set up proper indexing strategies, and advise on whether a different database architecture is needed to address the slow load times on the dashboard.\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Database Performance Specialist\",\n      \"reason\": \"This role addresses the team's skill gap in database optimization and performance tuning\",\n      \"skills\": [\"Database Query Optimization\", \"Indexing Strategies\", \"Database Schema Design\", \"Database Migration Planning\", \"TimescaleDB\"],\n      \"prompt\": \"You are an expert in database performance optimization. You help teams by analyzing query plans, optimizing database schemas, and implementing efficient indexing strategies to improve data retrieval speeds.\",\n      \"model\": \"reasoning\"\n    }\n  }\n}",
                "parsedResponse": {
                  "recommendation": "I think you need to hire a Database Performance Specialist because they can analyze the query plans, optimize the schema, set up proper indexing strategies, and advise on whether a different database architecture is needed to address the slow load times on the dashboard.",
                  "action": {
                    "type": "create_actor",
                    "actor": {
                      "title": "Database Performance Specialist",
                      "reason": "This role addresses the team's skill gap in database optimization and performance tuning",
                      "skills": [
                        "Database Query Optimization",
                        "Indexing Strategies",
                        "Database Schema Design",
                        "Database Migration Planning",
                        "TimescaleDB"
                      ],
                      "prompt": "You are an expert in database performance optimization. You help teams by analyzing query plans, optimizing database schemas, and implementing efficient indexing strategies to improve data retrieval speeds.",
                      "model": "reasoning"
                    }
                  }
                },
                "validationErrors": [],
                "errorMessage": null
              }
            ],
            "totalDurationMs": 5778,
            "finalResponse": {
              "recommendation": "I think you need to hire a Database Performance Specialist because they can analyze the query plans, optimize the schema, set up proper indexing strategies, and advise on whether a different database architecture is needed to address the slow load times on the dashboard.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Performance Specialist",
                  "reason": "This role addresses the team's skill gap in database optimization and performance tuning",
                  "skills": [
                    "Database Query Optimization",
                    "Indexing Strategies",
                    "Database Schema Design",
                    "Database Migration Planning",
                    "TimescaleDB"
                  ],
                  "prompt": "You are an expert in database performance optimization. You help teams by analyzing query plans, optimizing database schemas, and implementing efficient indexing strategies to improve data retrieval speeds.",
                  "model": "reasoning"
                }
              }
            }
          },
          {
            "runNumber": 2,
            "success": true,
            "attempts": [
              {
                "attemptNumber": 1,
                "timestamp": "2025-11-29T17:33:27.549Z",
                "success": true,
                "durationMs": 5796,
                "inputTokens": 1065,
                "outputTokens": 197,
                "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation above, recommend a team member who could help solve their problem.\n\nRespond ONLY with valid JSON like this example:\n{\n  \"recommendation\": \"I think you need to hire a [role] because [explanation of how they address the team's problem]...\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Job Title Here\",\n      \"reason\": \"Why this role addresses the team's skill gap\",\n      \"skills\": [\"skill1\", \"skill2\", \"skill3\"],\n      \"prompt\": \"You are an expert in [domain]. You help teams by [description of approach]...\",\n      \"model\": \"reasoning\"\n    }\n  }\n}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks or backticks\n- The \"recommendation\" field should start with \"I think you need to hire...\"\n- Skills array should have 3-7 specific technical skills\n- \"model\" should be \"reasoning\" for analytical tasks or \"semantic\" for creative tasks\n- Set \"action\" to null if no recommendation is appropriate",
                "rawResponse": "{\n  \"recommendation\": \"I think you need to hire a Database Performance Specialist because they can analyse the query plans, optimise the schema, set up proper indexing strategies, and advise on whether a different database architecture is needed to solve the slow load times issue on the dashboard.\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Database Performance Specialist\",\n      \"reason\": \"This role addresses the team's skill gap in database performance optimisation and architecture\",\n      \"skills\": [\"Database Query Optimisation\", \"Schema Design\", \"Indexing Strategies\", \"Database Architecture\", \"SQL Performance Tuning\", \"Database Migration Planning\"],\n      \"prompt\": \"You are an expert in database performance optimisation. You help teams by analysing query plans, optimising database schemas, and advising on database architecture to improve data retrieval efficiency and overall system performance.\",\n      \"model\": \"reasoning\"\n    }\n  }\n}",
                "parsedResponse": {
                  "recommendation": "I think you need to hire a Database Performance Specialist because they can analyse the query plans, optimise the schema, set up proper indexing strategies, and advise on whether a different database architecture is needed to solve the slow load times issue on the dashboard.",
                  "action": {
                    "type": "create_actor",
                    "actor": {
                      "title": "Database Performance Specialist",
                      "reason": "This role addresses the team's skill gap in database performance optimisation and architecture",
                      "skills": [
                        "Database Query Optimisation",
                        "Schema Design",
                        "Indexing Strategies",
                        "Database Architecture",
                        "SQL Performance Tuning",
                        "Database Migration Planning"
                      ],
                      "prompt": "You are an expert in database performance optimisation. You help teams by analysing query plans, optimising database schemas, and advising on database architecture to improve data retrieval efficiency and overall system performance.",
                      "model": "reasoning"
                    }
                  }
                },
                "validationErrors": [],
                "errorMessage": null
              }
            ],
            "totalDurationMs": 5796,
            "finalResponse": {
              "recommendation": "I think you need to hire a Database Performance Specialist because they can analyse the query plans, optimise the schema, set up proper indexing strategies, and advise on whether a different database architecture is needed to solve the slow load times issue on the dashboard.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Performance Specialist",
                  "reason": "This role addresses the team's skill gap in database performance optimisation and architecture",
                  "skills": [
                    "Database Query Optimisation",
                    "Schema Design",
                    "Indexing Strategies",
                    "Database Architecture",
                    "SQL Performance Tuning",
                    "Database Migration Planning"
                  ],
                  "prompt": "You are an expert in database performance optimisation. You help teams by analysing query plans, optimising database schemas, and advising on database architecture to improve data retrieval efficiency and overall system performance.",
                  "model": "reasoning"
                }
              }
            }
          },
          {
            "runNumber": 3,
            "success": true,
            "attempts": [
              {
                "attemptNumber": 1,
                "timestamp": "2025-11-29T17:33:33.335Z",
                "success": true,
                "durationMs": 5786,
                "inputTokens": 1065,
                "outputTokens": 188,
                "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation above, recommend a team member who could help solve their problem.\n\nRespond ONLY with valid JSON like this example:\n{\n  \"recommendation\": \"I think you need to hire a [role] because [explanation of how they address the team's problem]...\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Job Title Here\",\n      \"reason\": \"Why this role addresses the team's skill gap\",\n      \"skills\": [\"skill1\", \"skill2\", \"skill3\"],\n      \"prompt\": \"You are an expert in [domain]. You help teams by [description of approach]...\",\n      \"model\": \"reasoning\"\n    }\n  }\n}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks or backticks\n- The \"recommendation\" field should start with \"I think you need to hire...\"\n- Skills array should have 3-7 specific technical skills\n- \"model\" should be \"reasoning\" for analytical tasks or \"semantic\" for creative tasks\n- Set \"action\" to null if no recommendation is appropriate",
                "rawResponse": "{\n  \"recommendation\": \"I think you need to hire a Database Performance Specialist because they can analyze the query plans, optimize the schema, set up proper indexing strategies, and advise on whether a different database architecture is needed to address the slow load times on the dashboard.\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Database Performance Specialist\",\n      \"reason\": \"This role addresses the team's skill gap by providing expertise in database optimization and performance tuning.\",\n      \"skills\": [\"Database Query Optimization\", \"Schema Design\", \"Indexing Strategies\", \"Database Architecture\", \"SQL Performance Tuning\", \"Database Migration Planning\"],\n      \"prompt\": \"You are an expert in database performance optimization. You help teams by analyzing query plans, optimizing database schemas, and implementing efficient indexing strategies to improve database performance.\",\n      \"model\": \"reasoning\"\n    }\n  }\n}",
                "parsedResponse": {
                  "recommendation": "I think you need to hire a Database Performance Specialist because they can analyze the query plans, optimize the schema, set up proper indexing strategies, and advise on whether a different database architecture is needed to address the slow load times on the dashboard.",
                  "action": {
                    "type": "create_actor",
                    "actor": {
                      "title": "Database Performance Specialist",
                      "reason": "This role addresses the team's skill gap by providing expertise in database optimization and performance tuning.",
                      "skills": [
                        "Database Query Optimization",
                        "Schema Design",
                        "Indexing Strategies",
                        "Database Architecture",
                        "SQL Performance Tuning",
                        "Database Migration Planning"
                      ],
                      "prompt": "You are an expert in database performance optimization. You help teams by analyzing query plans, optimizing database schemas, and implementing efficient indexing strategies to improve database performance.",
                      "model": "reasoning"
                    }
                  }
                },
                "validationErrors": [],
                "errorMessage": null
              }
            ],
            "totalDurationMs": 5786,
            "finalResponse": {
              "recommendation": "I think you need to hire a Database Performance Specialist because they can analyze the query plans, optimize the schema, set up proper indexing strategies, and advise on whether a different database architecture is needed to address the slow load times on the dashboard.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Performance Specialist",
                  "reason": "This role addresses the team's skill gap by providing expertise in database optimization and performance tuning.",
                  "skills": [
                    "Database Query Optimization",
                    "Schema Design",
                    "Indexing Strategies",
                    "Database Architecture",
                    "SQL Performance Tuning",
                    "Database Migration Planning"
                  ],
                  "prompt": "You are an expert in database performance optimization. You help teams by analyzing query plans, optimizing database schemas, and implementing efficient indexing strategies to improve database performance.",
                  "model": "reasoning"
                }
              }
            }
          }
        ],
        "summary": {
          "successRate": 100,
          "firstAttemptSuccessRate": 100,
          "afterRetry1SuccessRate": 100,
          "afterRetry2SuccessRate": 100,
          "afterRetry3SuccessRate": 100,
          "averageDurationMs": 5786.666666666667,
          "averageAttempts": 1,
          "averageAttemptsPerSuccess": 1,
          "averageTokensPerSuccess": 1254,
          "totalTokensUsed": 3762
        }
      },
      "3": {
        "runs": [
          {
            "runNumber": 1,
            "success": true,
            "attempts": [],
            "steps": [
              {
                "stepNumber": 1,
                "stepName": "Recommendation",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:33:39.497Z",
                    "success": true,
                    "durationMs": 6163,
                    "inputTokens": 929,
                    "outputTokens": 134,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation, what type of team member should this team add?\n\nRespond with JSON like this example:\n{\"recommendation\": \"I recommend hiring a [role] because [reason]...\", \"action\": \"create_actor\"}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- The \"recommendation\" should explain your hiring recommendation (at least 20 characters)\n- Set \"action\" to \"create_actor\" if recommending someone, or null if not",
                    "rawResponse": "{\"recommendation\": \"I recommend hiring a Database Performance Specialist because the team is struggling with slow database query performance, and they lack the expertise to optimize the schema, indexing, and query plans, which is critical to resolving the issue with the dashboard load times and preventing potential customer churn.\", \"action\": \"create_actor\", \"role\": \"Database Performance Specialist\", \"skills\": \"database performance optimization, query plan analysis, schema design, indexing strategies, database architecture\", \"system_prompt\": \"Configure an AI assistant to analyze database query plans, provide optimization recommendations, and advise on database architecture, with a focus on performance and scalability.\", \"capabilities\": \"reasoning\"}",
                    "parsedResponse": {
                      "recommendation": "I recommend hiring a Database Performance Specialist because the team is struggling with slow database query performance, and they lack the expertise to optimize the schema, indexing, and query plans, which is critical to resolving the issue with the dashboard load times and preventing potential customer churn.",
                      "action": "create_actor"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 2,
                "stepName": "Details",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:33:45.317Z",
                    "success": true,
                    "durationMs": 5819,
                    "inputTokens": 1004,
                    "outputTokens": 129,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Database Performance Specialist because the team is struggling with slow database query performance, and they lack the expertise to optimize the schema, indexing, and query plans, which is critical to resolving the issue with the dashboard load times and preventing potential customer churn.\",\"action\":\"create_actor\"}\n\n[user] For the role you recommended, provide their details.\n\nRespond with JSON like this example:\n{\"title\": \"Database Administrator\", \"reason\": \"The team needs database expertise to optimize their slow queries and design scalable schemas\", \"skills\": [\"PostgreSQL\", \"Query Optimization\", \"Database Design\"]}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- Provide 3-7 specific technical skills\n- The \"reason\" should explain how this role addresses the team's problem (at least 20 characters)",
                    "rawResponse": "{\"title\": \"Database Performance Specialist\", \"reason\": \"The team needs an expert to analyze and optimize the slow database queries, redesign the schema for better performance, and advise on potential database architecture changes to improve the overall system efficiency and prevent customer churn due to slow dashboard load times\", \"skills\": [\"PostgreSQL\", \"Query Optimization\", \"Database Design\", \"Indexing Strategies\", \"Database Migration Planning\", \"TimescaleDB\"], \"prompt\": \"Configure an AI assistant to provide guidance on database performance optimization, query plan analysis, and schema design, with a focus on PostgreSQL and TimescaleDB\", \"capabilities\": \"reasoning\"}",
                    "parsedResponse": {
                      "title": "Database Performance Specialist",
                      "reason": "The team needs an expert to analyze and optimize the slow database queries, redesign the schema for better performance, and advise on potential database architecture changes to improve the overall system efficiency and prevent customer churn due to slow dashboard load times",
                      "skills": [
                        "PostgreSQL",
                        "Query Optimization",
                        "Database Design",
                        "Indexing Strategies",
                        "Database Migration Planning",
                        "TimescaleDB"
                      ]
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 3,
                "stepName": "AI Config",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:33:50.907Z",
                    "success": true,
                    "durationMs": 5590,
                    "inputTokens": 1085,
                    "outputTokens": 70,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Database Performance Specialist because the team is struggling with slow database query performance, and they lack the expertise to optimize the schema, indexing, and query plans, which is critical to resolving the issue with the dashboard load times and preventing potential customer churn.\",\"action\":\"create_actor\"}\n\n[assistant] {\"title\":\"Database Performance Specialist\",\"reason\":\"The team needs an expert to analyze and optimize the slow database queries, redesign the schema for better performance, and advise on potential database architecture changes to improve the overall system efficiency and prevent customer churn due to slow dashboard load times\",\"skills\":[\"PostgreSQL\",\"Query Optimization\",\"Database Design\",\"Indexing Strategies\",\"Database Migration Planning\",\"TimescaleDB\"]}\n\n[user] For this role, provide the AI system prompt and model type.\n\nRespond with JSON like this example:\n{\"prompt\": \"You are an expert database administrator. You help teams optimize queries, design schemas, and ensure data integrity...\", \"model\": \"reasoning\"}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- The \"prompt\" should be a detailed system prompt (at least 30 characters)\n- \"model\" should be \"reasoning\" for analytical tasks or \"semantic\" for creative tasks",
                    "rawResponse": "{\"prompt\": \"You are an expert database administrator. You help teams optimize queries, design schemas, and ensure data integrity. Analyze the provided database query plans, identify performance bottlenecks, and recommend indexing strategies, schema redesigns, or database architecture changes to improve query execution times and overall system efficiency.\", \"model\": \"reasoning\"}",
                    "parsedResponse": {
                      "prompt": "You are an expert database administrator. You help teams optimize queries, design schemas, and ensure data integrity. Analyze the provided database query plans, identify performance bottlenecks, and recommend indexing strategies, schema redesigns, or database architecture changes to improve query execution times and overall system efficiency.",
                      "model": "reasoning"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              }
            ],
            "totalDurationMs": 17572,
            "finalResponse": {
              "recommendation": "I recommend hiring a Database Performance Specialist because the team is struggling with slow database query performance, and they lack the expertise to optimize the schema, indexing, and query plans, which is critical to resolving the issue with the dashboard load times and preventing potential customer churn.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Performance Specialist",
                  "reason": "The team needs an expert to analyze and optimize the slow database queries, redesign the schema for better performance, and advise on potential database architecture changes to improve the overall system efficiency and prevent customer churn due to slow dashboard load times",
                  "skills": [
                    "PostgreSQL",
                    "Query Optimization",
                    "Database Design",
                    "Indexing Strategies",
                    "Database Migration Planning",
                    "TimescaleDB"
                  ],
                  "prompt": "You are an expert database administrator. You help teams optimize queries, design schemas, and ensure data integrity. Analyze the provided database query plans, identify performance bottlenecks, and recommend indexing strategies, schema redesigns, or database architecture changes to improve query execution times and overall system efficiency.",
                  "model": "reasoning"
                }
              }
            }
          },
          {
            "runNumber": 2,
            "success": true,
            "attempts": [],
            "steps": [
              {
                "stepNumber": 1,
                "stepName": "Recommendation",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:33:56.587Z",
                    "success": true,
                    "durationMs": 5680,
                    "inputTokens": 929,
                    "outputTokens": 130,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation, what type of team member should this team add?\n\nRespond with JSON like this example:\n{\"recommendation\": \"I recommend hiring a [role] because [reason]...\", \"action\": \"create_actor\"}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- The \"recommendation\" should explain your hiring recommendation (at least 20 characters)\n- Set \"action\" to \"create_actor\" if recommending someone, or null if not",
                    "rawResponse": "{\"recommendation\": \"I recommend hiring a Database Performance Specialist because the team is struggling with slow load times on the dashboard, and they lack the expertise to optimize the database query, schema, and indexing strategies, which is crucial to resolving the issue and preventing customer churn.\", \"action\": \"create_actor\", \"role_details\": {\"job_title\": \"Database Performance Specialist\", \"skills_required\": [\"database query optimization\", \"schema design\", \"indexing strategies\", \"database architecture\"], \"system_prompt\": \"Configure an AI assistant to analyze database query plans, provide optimization recommendations, and advise on database architecture changes.\", \"capabilities\": \"reasoning\"}}",
                    "parsedResponse": {
                      "recommendation": "I recommend hiring a Database Performance Specialist because the team is struggling with slow load times on the dashboard, and they lack the expertise to optimize the database query, schema, and indexing strategies, which is crucial to resolving the issue and preventing customer churn.",
                      "action": "create_actor"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 2,
                "stepName": "Details",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:34:02.235Z",
                    "success": true,
                    "durationMs": 5648,
                    "inputTokens": 1001,
                    "outputTokens": 102,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Database Performance Specialist because the team is struggling with slow load times on the dashboard, and they lack the expertise to optimize the database query, schema, and indexing strategies, which is crucial to resolving the issue and preventing customer churn.\",\"action\":\"create_actor\"}\n\n[user] For the role you recommended, provide their details.\n\nRespond with JSON like this example:\n{\"title\": \"Database Administrator\", \"reason\": \"The team needs database expertise to optimize their slow queries and design scalable schemas\", \"skills\": [\"PostgreSQL\", \"Query Optimization\", \"Database Design\"]}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- Provide 3-7 specific technical skills\n- The \"reason\" should explain how this role addresses the team's problem (at least 20 characters)",
                    "rawResponse": "{\"title\": \"Database Performance Specialist\", \"reason\": \"The team needs expertise to analyze and optimize slow database queries, design efficient schema structures, and advise on suitable database architectures to resolve the slow load times issue and prevent customer churn\", \"skills\": [\"PostgreSQL\", \"Query Optimization\", \"Database Design\", \"Indexing Strategies\", \"Database Migration\", \"TimescaleDB\"], \"prompt\": \"Configure an AI assistant to analyze database query plans and provide optimization recommendations\", \"capabilities\": \"reasoning\"}",
                    "parsedResponse": {
                      "title": "Database Performance Specialist",
                      "reason": "The team needs expertise to analyze and optimize slow database queries, design efficient schema structures, and advise on suitable database architectures to resolve the slow load times issue and prevent customer churn",
                      "skills": [
                        "PostgreSQL",
                        "Query Optimization",
                        "Database Design",
                        "Indexing Strategies",
                        "Database Migration",
                        "TimescaleDB"
                      ]
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 3,
                "stepName": "AI Config",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:34:07.738Z",
                    "success": true,
                    "durationMs": 5503,
                    "inputTokens": 1071,
                    "outputTokens": 69,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Database Performance Specialist because the team is struggling with slow load times on the dashboard, and they lack the expertise to optimize the database query, schema, and indexing strategies, which is crucial to resolving the issue and preventing customer churn.\",\"action\":\"create_actor\"}\n\n[assistant] {\"title\":\"Database Performance Specialist\",\"reason\":\"The team needs expertise to analyze and optimize slow database queries, design efficient schema structures, and advise on suitable database architectures to resolve the slow load times issue and prevent customer churn\",\"skills\":[\"PostgreSQL\",\"Query Optimization\",\"Database Design\",\"Indexing Strategies\",\"Database Migration\",\"TimescaleDB\"]}\n\n[user] For this role, provide the AI system prompt and model type.\n\nRespond with JSON like this example:\n{\"prompt\": \"You are an expert database administrator. You help teams optimize queries, design schemas, and ensure data integrity...\", \"model\": \"reasoning\"}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- The \"prompt\" should be a detailed system prompt (at least 30 characters)\n- \"model\" should be \"reasoning\" for analytical tasks or \"semantic\" for creative tasks",
                    "rawResponse": "{\"prompt\": \"You are an expert database administrator. You help teams optimize queries, design schemas, and ensure data integrity. Analyze the provided database query plans, identify performance bottlenecks, and recommend indexing strategies, schema changes, or database architecture adjustments to improve query execution times and overall system performance.\", \"model\": \"reasoning\"}",
                    "parsedResponse": {
                      "prompt": "You are an expert database administrator. You help teams optimize queries, design schemas, and ensure data integrity. Analyze the provided database query plans, identify performance bottlenecks, and recommend indexing strategies, schema changes, or database architecture adjustments to improve query execution times and overall system performance.",
                      "model": "reasoning"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              }
            ],
            "totalDurationMs": 16831,
            "finalResponse": {
              "recommendation": "I recommend hiring a Database Performance Specialist because the team is struggling with slow load times on the dashboard, and they lack the expertise to optimize the database query, schema, and indexing strategies, which is crucial to resolving the issue and preventing customer churn.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Performance Specialist",
                  "reason": "The team needs expertise to analyze and optimize slow database queries, design efficient schema structures, and advise on suitable database architectures to resolve the slow load times issue and prevent customer churn",
                  "skills": [
                    "PostgreSQL",
                    "Query Optimization",
                    "Database Design",
                    "Indexing Strategies",
                    "Database Migration",
                    "TimescaleDB"
                  ],
                  "prompt": "You are an expert database administrator. You help teams optimize queries, design schemas, and ensure data integrity. Analyze the provided database query plans, identify performance bottlenecks, and recommend indexing strategies, schema changes, or database architecture adjustments to improve query execution times and overall system performance.",
                  "model": "reasoning"
                }
              }
            }
          },
          {
            "runNumber": 3,
            "success": true,
            "attempts": [],
            "steps": [
              {
                "stepNumber": 1,
                "stepName": "Recommendation",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:34:13.477Z",
                    "success": true,
                    "durationMs": 5739,
                    "inputTokens": 929,
                    "outputTokens": 139,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation, what type of team member should this team add?\n\nRespond with JSON like this example:\n{\"recommendation\": \"I recommend hiring a [role] because [reason]...\", \"action\": \"create_actor\"}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- The \"recommendation\" should explain your hiring recommendation (at least 20 characters)\n- Set \"action\" to \"create_actor\" if recommending someone, or null if not",
                    "rawResponse": "{\"recommendation\": \"I recommend hiring a Database Performance Specialist because the team is struggling with slow load times on the dashboard, and they lack the expertise to properly analyze and optimize the database queries, schema, and indexing strategies, which is crucial to resolving the issue and preventing customer churn.\", \"action\": \"create_actor\", \"role\": \"Database Performance Specialist\", \"skills\": \"database performance optimization, query analysis, schema design, indexing strategies, database architecture\", \"system_prompt\": \"Configure an AI assistant to analyze database query plans, optimize schema, and provide indexing strategies, and advise on database architecture, with reasoning capabilities to provide analytical and logical solutions\", \"capabilities\": \"reasoning\"}",
                    "parsedResponse": {
                      "recommendation": "I recommend hiring a Database Performance Specialist because the team is struggling with slow load times on the dashboard, and they lack the expertise to properly analyze and optimize the database queries, schema, and indexing strategies, which is crucial to resolving the issue and preventing customer churn.",
                      "action": "create_actor"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 2,
                "stepName": "Details",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:34:19.020Z",
                    "success": true,
                    "durationMs": 5543,
                    "inputTokens": 1004,
                    "outputTokens": 98,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Database Performance Specialist because the team is struggling with slow load times on the dashboard, and they lack the expertise to properly analyze and optimize the database queries, schema, and indexing strategies, which is crucial to resolving the issue and preventing customer churn.\",\"action\":\"create_actor\"}\n\n[user] For the role you recommended, provide their details.\n\nRespond with JSON like this example:\n{\"title\": \"Database Administrator\", \"reason\": \"The team needs database expertise to optimize their slow queries and design scalable schemas\", \"skills\": [\"PostgreSQL\", \"Query Optimization\", \"Database Design\"]}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- Provide 3-7 specific technical skills\n- The \"reason\" should explain how this role addresses the team's problem (at least 20 characters)",
                    "rawResponse": "{\"title\": \"Database Performance Specialist\", \"reason\": \"The team needs expertise to analyze and optimize slow database queries, design efficient schema, and implement proper indexing strategies to improve dashboard load times and prevent customer churn\", \"skills\": [\"PostgreSQL\", \"Query Optimization\", \"Database Design\", \"Indexing Strategies\", \"Database Migration\", \"TimescaleDB\"], \"prompt\": \"Configure an AI assistant to analyze database query plans and provide optimization recommendations\", \"capabilities\": \"reasoning\"}",
                    "parsedResponse": {
                      "title": "Database Performance Specialist",
                      "reason": "The team needs expertise to analyze and optimize slow database queries, design efficient schema, and implement proper indexing strategies to improve dashboard load times and prevent customer churn",
                      "skills": [
                        "PostgreSQL",
                        "Query Optimization",
                        "Database Design",
                        "Indexing Strategies",
                        "Database Migration",
                        "TimescaleDB"
                      ]
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 3,
                "stepName": "AI Config",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:34:24.515Z",
                    "success": true,
                    "durationMs": 5495,
                    "inputTokens": 1070,
                    "outputTokens": 68,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Database Performance Specialist because the team is struggling with slow load times on the dashboard, and they lack the expertise to properly analyze and optimize the database queries, schema, and indexing strategies, which is crucial to resolving the issue and preventing customer churn.\",\"action\":\"create_actor\"}\n\n[assistant] {\"title\":\"Database Performance Specialist\",\"reason\":\"The team needs expertise to analyze and optimize slow database queries, design efficient schema, and implement proper indexing strategies to improve dashboard load times and prevent customer churn\",\"skills\":[\"PostgreSQL\",\"Query Optimization\",\"Database Design\",\"Indexing Strategies\",\"Database Migration\",\"TimescaleDB\"]}\n\n[user] For this role, provide the AI system prompt and model type.\n\nRespond with JSON like this example:\n{\"prompt\": \"You are an expert database administrator. You help teams optimize queries, design schemas, and ensure data integrity...\", \"model\": \"reasoning\"}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- The \"prompt\" should be a detailed system prompt (at least 30 characters)\n- \"model\" should be \"reasoning\" for analytical tasks or \"semantic\" for creative tasks",
                    "rawResponse": "{\"prompt\": \"You are an expert database administrator. You help teams optimize queries, design schemas, and ensure data integrity. Analyze the provided database query plans, identify performance bottlenecks, and recommend indexing strategies, schema changes, or database migrations to improve query execution times and overall system performance.\", \"model\": \"reasoning\"}",
                    "parsedResponse": {
                      "prompt": "You are an expert database administrator. You help teams optimize queries, design schemas, and ensure data integrity. Analyze the provided database query plans, identify performance bottlenecks, and recommend indexing strategies, schema changes, or database migrations to improve query execution times and overall system performance.",
                      "model": "reasoning"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              }
            ],
            "totalDurationMs": 16777,
            "finalResponse": {
              "recommendation": "I recommend hiring a Database Performance Specialist because the team is struggling with slow load times on the dashboard, and they lack the expertise to properly analyze and optimize the database queries, schema, and indexing strategies, which is crucial to resolving the issue and preventing customer churn.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Performance Specialist",
                  "reason": "The team needs expertise to analyze and optimize slow database queries, design efficient schema, and implement proper indexing strategies to improve dashboard load times and prevent customer churn",
                  "skills": [
                    "PostgreSQL",
                    "Query Optimization",
                    "Database Design",
                    "Indexing Strategies",
                    "Database Migration",
                    "TimescaleDB"
                  ],
                  "prompt": "You are an expert database administrator. You help teams optimize queries, design schemas, and ensure data integrity. Analyze the provided database query plans, identify performance bottlenecks, and recommend indexing strategies, schema changes, or database migrations to improve query execution times and overall system performance.",
                  "model": "reasoning"
                }
              }
            }
          }
        ],
        "summary": {
          "successRate": 100,
          "firstAttemptSuccessRate": 100,
          "afterRetry1SuccessRate": 100,
          "afterRetry2SuccessRate": 100,
          "afterRetry3SuccessRate": 100,
          "averageDurationMs": 17060,
          "averageAttempts": 3,
          "averageAttemptsPerSuccess": 3,
          "averageTokensPerSuccess": 3320.3333333333335,
          "totalTokensUsed": 9961
        }
      }
    },
    "openrouter-qwen3-235b": {
      "1": {
        "runs": [
          {
            "runNumber": 1,
            "success": true,
            "attempts": [
              {
                "attemptNumber": 1,
                "timestamp": "2025-11-29T17:34:39.120Z",
                "success": true,
                "durationMs": 14605,
                "inputTokens": 1041,
                "outputTokens": 507,
                "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation above, recommend a team member who could help solve their problem.\n\nRespond ONLY with valid JSON like this example:\n{\n  \"recommendation\": \"I think you need to hire a [role] because [explanation of how they address the team's problem]...\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Job Title Here\",\n      \"reason\": \"Why this role addresses the team's skill gap\",\n      \"skills\": [\"skill1\", \"skill2\", \"skill3\"],\n      \"prompt\": \"You are an expert in [domain]. You help teams by [description of approach]...\",\n      \"model\": \"reasoning\"\n    }\n  }\n}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks or backticks\n- The \"recommendation\" field should start with \"I think you need to hire...\"\n- Skills array should have 3-7 specific technical skills\n- \"model\" should be \"reasoning\" for analytical tasks or \"semantic\" for creative tasks\n- Set \"action\" to null if no recommendation is appropriate",
                "rawResponse": "{\n  \"recommendation\": \"I think you need to hire a Database Performance Engineer because they would have the expertise to analyze query execution plans, optimize schema design, and implement indexing strategies that address the root cause of slow dashboard queries.\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Database Performance Engineer\",\n      \"reason\": \"The team lacks deep database optimization expertise and needs someone who can systematically analyze disk I/O bottlenecks, redesign inefficient joins/aggregations, and implement performant indexing strategies without breaking existing queries.\",\n      \"skills\": [\n        \"Query execution plan analysis (EXPLAIN ANALYZE)\",\n        \"Index optimization and design\",\n        \"Schema normalization/denormalization techniques\",\n        \"Time-series database architecture\",\n        \"Disk I/O performance tuning\",\n        \"Database migration strategy\",\n        \"SQL query optimization\"\n      ],\n      \"prompt\": \"You are an expert in database performance engineering. You help teams by analyzing slow queries, interpreting execution plans, designing efficient indexing strategies, and recommending architectural changes to improve database performance while maintaining data integrity.\",\n      \"model\": \"reasoning\"\n    }\n  }\n}",
                "parsedResponse": {
                  "recommendation": "I think you need to hire a Database Performance Engineer because they would have the expertise to analyze query execution plans, optimize schema design, and implement indexing strategies that address the root cause of slow dashboard queries.",
                  "action": {
                    "type": "create_actor",
                    "actor": {
                      "title": "Database Performance Engineer",
                      "reason": "The team lacks deep database optimization expertise and needs someone who can systematically analyze disk I/O bottlenecks, redesign inefficient joins/aggregations, and implement performant indexing strategies without breaking existing queries.",
                      "skills": [
                        "Query execution plan analysis (EXPLAIN ANALYZE)",
                        "Index optimization and design",
                        "Schema normalization/denormalization techniques",
                        "Time-series database architecture",
                        "Disk I/O performance tuning",
                        "Database migration strategy",
                        "SQL query optimization"
                      ],
                      "prompt": "You are an expert in database performance engineering. You help teams by analyzing slow queries, interpreting execution plans, designing efficient indexing strategies, and recommending architectural changes to improve database performance while maintaining data integrity.",
                      "model": "reasoning"
                    }
                  }
                },
                "validationErrors": [],
                "errorMessage": null
              }
            ],
            "totalDurationMs": 14605,
            "finalResponse": {
              "recommendation": "I think you need to hire a Database Performance Engineer because they would have the expertise to analyze query execution plans, optimize schema design, and implement indexing strategies that address the root cause of slow dashboard queries.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Performance Engineer",
                  "reason": "The team lacks deep database optimization expertise and needs someone who can systematically analyze disk I/O bottlenecks, redesign inefficient joins/aggregations, and implement performant indexing strategies without breaking existing queries.",
                  "skills": [
                    "Query execution plan analysis (EXPLAIN ANALYZE)",
                    "Index optimization and design",
                    "Schema normalization/denormalization techniques",
                    "Time-series database architecture",
                    "Disk I/O performance tuning",
                    "Database migration strategy",
                    "SQL query optimization"
                  ],
                  "prompt": "You are an expert in database performance engineering. You help teams by analyzing slow queries, interpreting execution plans, designing efficient indexing strategies, and recommending architectural changes to improve database performance while maintaining data integrity.",
                  "model": "reasoning"
                }
              }
            }
          },
          {
            "runNumber": 2,
            "success": true,
            "attempts": [
              {
                "attemptNumber": 1,
                "timestamp": "2025-11-29T17:34:51.437Z",
                "success": true,
                "durationMs": 12317,
                "inputTokens": 1041,
                "outputTokens": 592,
                "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation above, recommend a team member who could help solve their problem.\n\nRespond ONLY with valid JSON like this example:\n{\n  \"recommendation\": \"I think you need to hire a [role] because [explanation of how they address the team's problem]...\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Job Title Here\",\n      \"reason\": \"Why this role addresses the team's skill gap\",\n      \"skills\": [\"skill1\", \"skill2\", \"skill3\"],\n      \"prompt\": \"You are an expert in [domain]. You help teams by [description of approach]...\",\n      \"model\": \"reasoning\"\n    }\n  }\n}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks or backticks\n- The \"recommendation\" field should start with \"I think you need to hire...\"\n- Skills array should have 3-7 specific technical skills\n- \"model\" should be \"reasoning\" for analytical tasks or \"semantic\" for creative tasks\n- Set \"action\" to null if no recommendation is appropriate",
                "rawResponse": "{\n  \"recommendation\": \"I think you need to hire a Database Optimization Specialist because they would have the expertise to analyze query execution plans, identify bottlenecks in the storage engine, and implement structural improvements that none of the current team members have the specialized knowledge to resolve.\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Database Optimization Specialist\",\n      \"reason\": \"The team lacks deep database internals expertise needed to resolve sequential scan bottlenecks, design optimal indexing strategies, and evaluate storage engine alternatives while maintaining real-time data requirements\",\n      \"skills\": [\n        \"Query execution plan analysis\",\n        \"Index optimization for complex joins\",\n        \"Database schema redesign\",\n        \"Storage engine performance tuning\",\n        \"Time-series database architecture\",\n        \"Migration strategy planning\",\n        \"Disk I/O pattern optimization\"\n      ],\n      \"prompt\": \"You are a database optimization expert with deep knowledge of query execution internals. You help teams by analyzing EXPLAIN ANALYZE outputs, identifying indexing inefficiencies, redesigning schemas for performance, and recommending storage solutions that balance speed with data freshness requirements.\",\n      \"model\": \"reasoning\"\n    }\n  }\n}",
                "parsedResponse": {
                  "recommendation": "I think you need to hire a Database Optimization Specialist because they would have the expertise to analyze query execution plans, identify bottlenecks in the storage engine, and implement structural improvements that none of the current team members have the specialized knowledge to resolve.",
                  "action": {
                    "type": "create_actor",
                    "actor": {
                      "title": "Database Optimization Specialist",
                      "reason": "The team lacks deep database internals expertise needed to resolve sequential scan bottlenecks, design optimal indexing strategies, and evaluate storage engine alternatives while maintaining real-time data requirements",
                      "skills": [
                        "Query execution plan analysis",
                        "Index optimization for complex joins",
                        "Database schema redesign",
                        "Storage engine performance tuning",
                        "Time-series database architecture",
                        "Migration strategy planning",
                        "Disk I/O pattern optimization"
                      ],
                      "prompt": "You are a database optimization expert with deep knowledge of query execution internals. You help teams by analyzing EXPLAIN ANALYZE outputs, identifying indexing inefficiencies, redesigning schemas for performance, and recommending storage solutions that balance speed with data freshness requirements.",
                      "model": "reasoning"
                    }
                  }
                },
                "validationErrors": [],
                "errorMessage": null
              }
            ],
            "totalDurationMs": 12317,
            "finalResponse": {
              "recommendation": "I think you need to hire a Database Optimization Specialist because they would have the expertise to analyze query execution plans, identify bottlenecks in the storage engine, and implement structural improvements that none of the current team members have the specialized knowledge to resolve.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Optimization Specialist",
                  "reason": "The team lacks deep database internals expertise needed to resolve sequential scan bottlenecks, design optimal indexing strategies, and evaluate storage engine alternatives while maintaining real-time data requirements",
                  "skills": [
                    "Query execution plan analysis",
                    "Index optimization for complex joins",
                    "Database schema redesign",
                    "Storage engine performance tuning",
                    "Time-series database architecture",
                    "Migration strategy planning",
                    "Disk I/O pattern optimization"
                  ],
                  "prompt": "You are a database optimization expert with deep knowledge of query execution internals. You help teams by analyzing EXPLAIN ANALYZE outputs, identifying indexing inefficiencies, redesigning schemas for performance, and recommending storage solutions that balance speed with data freshness requirements.",
                  "model": "reasoning"
                }
              }
            }
          },
          {
            "runNumber": 3,
            "success": true,
            "attempts": [
              {
                "attemptNumber": 1,
                "timestamp": "2025-11-29T17:35:06.002Z",
                "success": true,
                "durationMs": 14565,
                "inputTokens": 1041,
                "outputTokens": 496,
                "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation above, recommend a team member who could help solve their problem.\n\nRespond ONLY with valid JSON like this example:\n{\n  \"recommendation\": \"I think you need to hire a [role] because [explanation of how they address the team's problem]...\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Job Title Here\",\n      \"reason\": \"Why this role addresses the team's skill gap\",\n      \"skills\": [\"skill1\", \"skill2\", \"skill3\"],\n      \"prompt\": \"You are an expert in [domain]. You help teams by [description of approach]...\",\n      \"model\": \"reasoning\"\n    }\n  }\n}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks or backticks\n- The \"recommendation\" field should start with \"I think you need to hire...\"\n- Skills array should have 3-7 specific technical skills\n- \"model\" should be \"reasoning\" for analytical tasks or \"semantic\" for creative tasks\n- Set \"action\" to null if no recommendation is appropriate",
                "rawResponse": "{\n  \"recommendation\": \"I think you need to hire a Database Optimization Specialist because they would have the expertise to analyze query execution plans, redesign inefficient schema structures, implement advanced indexing strategies, and evaluate whether a specialized database like TimescaleDB would better suit your time-series data needs.\",\n  \"action\": {\n    \"type\": \"create_actor\",\n    \"actor\": {\n      \"title\": \"Database Optimization Specialist\",\n      \"reason\": \"The team lacks deep database expertise and is struggling with query performance despite basic optimization attempts. This role would provide specialized skills in query plan analysis, schema redesign, and database architecture evaluation to resolve the root cause of slow dashboard loads.\",\n      \"skills\": [\n        \"Query execution plan analysis (EXPLAIN ANALYZE)\",\n        \"Advanced indexing strategies (partial, composite, BRIN indexes)\",\n        \"Time-series database optimization\",\n        \"Schema normalization/denormalization tradeoffs\",\n        \"Database engine selection (PostgreSQL vs TimescaleDB vs alternatives)\",\n        \"Performance benchmarking and load testing\",\n        \"Query rewrite optimization for complex joins\"\n      ],\n      \"prompt\": \"You are a database optimization expert specializing in high-performance query execution. You analyze EXPLAIN ANALYZE output, design optimal indexing strategies, evaluate schema changes, and recommend database engine choices based on workload patterns. You prioritize solutions that maintain real-time data requirements while improving query throughput.\",\n      \"model\": \"reasoning\"\n    }\n  }\n}",
                "parsedResponse": {
                  "recommendation": "I think you need to hire a Database Optimization Specialist because they would have the expertise to analyze query execution plans, redesign inefficient schema structures, implement advanced indexing strategies, and evaluate whether a specialized database like TimescaleDB would better suit your time-series data needs.",
                  "action": {
                    "type": "create_actor",
                    "actor": {
                      "title": "Database Optimization Specialist",
                      "reason": "The team lacks deep database expertise and is struggling with query performance despite basic optimization attempts. This role would provide specialized skills in query plan analysis, schema redesign, and database architecture evaluation to resolve the root cause of slow dashboard loads.",
                      "skills": [
                        "Query execution plan analysis (EXPLAIN ANALYZE)",
                        "Advanced indexing strategies (partial, composite, BRIN indexes)",
                        "Time-series database optimization",
                        "Schema normalization/denormalization tradeoffs",
                        "Database engine selection (PostgreSQL vs TimescaleDB vs alternatives)",
                        "Performance benchmarking and load testing",
                        "Query rewrite optimization for complex joins"
                      ],
                      "prompt": "You are a database optimization expert specializing in high-performance query execution. You analyze EXPLAIN ANALYZE output, design optimal indexing strategies, evaluate schema changes, and recommend database engine choices based on workload patterns. You prioritize solutions that maintain real-time data requirements while improving query throughput.",
                      "model": "reasoning"
                    }
                  }
                },
                "validationErrors": [],
                "errorMessage": null
              }
            ],
            "totalDurationMs": 14565,
            "finalResponse": {
              "recommendation": "I think you need to hire a Database Optimization Specialist because they would have the expertise to analyze query execution plans, redesign inefficient schema structures, implement advanced indexing strategies, and evaluate whether a specialized database like TimescaleDB would better suit your time-series data needs.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Optimization Specialist",
                  "reason": "The team lacks deep database expertise and is struggling with query performance despite basic optimization attempts. This role would provide specialized skills in query plan analysis, schema redesign, and database architecture evaluation to resolve the root cause of slow dashboard loads.",
                  "skills": [
                    "Query execution plan analysis (EXPLAIN ANALYZE)",
                    "Advanced indexing strategies (partial, composite, BRIN indexes)",
                    "Time-series database optimization",
                    "Schema normalization/denormalization tradeoffs",
                    "Database engine selection (PostgreSQL vs TimescaleDB vs alternatives)",
                    "Performance benchmarking and load testing",
                    "Query rewrite optimization for complex joins"
                  ],
                  "prompt": "You are a database optimization expert specializing in high-performance query execution. You analyze EXPLAIN ANALYZE output, design optimal indexing strategies, evaluate schema changes, and recommend database engine choices based on workload patterns. You prioritize solutions that maintain real-time data requirements while improving query throughput.",
                  "model": "reasoning"
                }
              }
            }
          }
        ],
        "summary": {
          "successRate": 100,
          "firstAttemptSuccessRate": 100,
          "afterRetry1SuccessRate": 100,
          "afterRetry2SuccessRate": 100,
          "afterRetry3SuccessRate": 100,
          "averageDurationMs": 13829,
          "averageAttempts": 1,
          "averageAttemptsPerSuccess": 1,
          "averageTokensPerSuccess": 1572.6666666666667,
          "totalTokensUsed": 4718
        }
      },
      "3": {
        "runs": [
          {
            "runNumber": 1,
            "success": true,
            "attempts": [],
            "steps": [
              {
                "stepNumber": 1,
                "stepName": "Recommendation",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:35:20.569Z",
                    "success": true,
                    "durationMs": 14567,
                    "inputTokens": 906,
                    "outputTokens": 349,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation, what type of team member should this team add?\n\nRespond with JSON like this example:\n{\"recommendation\": \"I recommend hiring a [role] because [reason]...\", \"action\": \"create_actor\"}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- The \"recommendation\" should explain your hiring recommendation (at least 20 characters)\n- Set \"action\" to \"create_actor\" if recommending someone, or null if not",
                    "rawResponse": "{\"recommendation\": \"I recommend hiring a Database Optimization Specialist because the team needs expert-level skills in query performance tuning, schema optimization, and indexing strategies to resolve the slow dashboard queries. The current team lacks deep database expertise and requires someone who can analyze EXPLAIN plans, redesign inefficient joins/aggregations, and evaluate time-series database solutions like TimescaleDB.\", \"action\": \"create_actor\"}",
                    "parsedResponse": {
                      "recommendation": "I recommend hiring a Database Optimization Specialist because the team needs expert-level skills in query performance tuning, schema optimization, and indexing strategies to resolve the slow dashboard queries. The current team lacks deep database expertise and requires someone who can analyze EXPLAIN plans, redesign inefficient joins/aggregations, and evaluate time-series database solutions like TimescaleDB.",
                      "action": "create_actor"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 2,
                "stepName": "Details",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:35:53.286Z",
                    "success": true,
                    "durationMs": 32717,
                    "inputTokens": 1001,
                    "outputTokens": 1036,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Database Optimization Specialist because the team needs expert-level skills in query performance tuning, schema optimization, and indexing strategies to resolve the slow dashboard queries. The current team lacks deep database expertise and requires someone who can analyze EXPLAIN plans, redesign inefficient joins/aggregations, and evaluate time-series database solutions like TimescaleDB.\",\"action\":\"create_actor\"}\n\n[user] For the role you recommended, provide their details.\n\nRespond with JSON like this example:\n{\"title\": \"Database Administrator\", \"reason\": \"The team needs database expertise to optimize their slow queries and design scalable schemas\", \"skills\": [\"PostgreSQL\", \"Query Optimization\", \"Database Design\"]}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- Provide 3-7 specific technical skills\n- The \"reason\" should explain how this role addresses the team's problem (at least 20 characters)",
                    "rawResponse": "{\"title\": \"Database Optimization Specialist\", \"reason\": \"This role will resolve slow dashboard queries by optimizing database performance, redesigning inefficient schemas, and implementing effective indexing strategies to prevent customer churn\", \"skills\": [\"PostgreSQL\", \"Query Optimization\", \"Indexing Strategies\", \"Schema Design\", \"Time-Series Database Optimization\"]}",
                    "parsedResponse": {
                      "title": "Database Optimization Specialist",
                      "reason": "This role will resolve slow dashboard queries by optimizing database performance, redesigning inefficient schemas, and implementing effective indexing strategies to prevent customer churn",
                      "skills": [
                        "PostgreSQL",
                        "Query Optimization",
                        "Indexing Strategies",
                        "Schema Design",
                        "Time-Series Database Optimization"
                      ]
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 3,
                "stepName": "AI Config",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:36:08.162Z",
                    "success": false,
                    "durationMs": 14876,
                    "inputTokens": 1056,
                    "outputTokens": 122,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Database Optimization Specialist because the team needs expert-level skills in query performance tuning, schema optimization, and indexing strategies to resolve the slow dashboard queries. The current team lacks deep database expertise and requires someone who can analyze EXPLAIN plans, redesign inefficient joins/aggregations, and evaluate time-series database solutions like TimescaleDB.\",\"action\":\"create_actor\"}\n\n[assistant] {\"title\":\"Database Optimization Specialist\",\"reason\":\"This role will resolve slow dashboard queries by optimizing database performance, redesigning inefficient schemas, and implementing effective indexing strategies to prevent customer churn\",\"skills\":[\"PostgreSQL\",\"Query Optimization\",\"Indexing Strategies\",\"Schema Design\",\"Time-Series Database Optimization\"]}\n\n[user] For this role, provide the AI system prompt and model type.\n\nRespond with JSON like this example:\n{\"prompt\": \"You are an expert database administrator. You help teams optimize queries, design schemas, and ensure data integrity...\", \"model\": \"reasoning\"}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- The \"prompt\" should be a detailed system prompt (at least 30 characters)\n- \"model\" should be \"reasoning\" for analytical tasks or \"semantic\" for creative tasks",
                    "rawResponse": "",
                    "parsedResponse": null,
                    "validationErrors": [
                      {
                        "path": [],
                        "message": "Invalid JSON: Unexpected end of JSON input",
                        "code": "invalid_json"
                      }
                    ],
                    "errorMessage": null
                  },
                  {
                    "attemptNumber": 2,
                    "timestamp": "2025-11-29T17:36:18.293Z",
                    "success": true,
                    "durationMs": 10131,
                    "inputTokens": 1159,
                    "outputTokens": 336,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Database Optimization Specialist because the team needs expert-level skills in query performance tuning, schema optimization, and indexing strategies to resolve the slow dashboard queries. The current team lacks deep database expertise and requires someone who can analyze EXPLAIN plans, redesign inefficient joins/aggregations, and evaluate time-series database solutions like TimescaleDB.\",\"action\":\"create_actor\"}\n\n[assistant] {\"title\":\"Database Optimization Specialist\",\"reason\":\"This role will resolve slow dashboard queries by optimizing database performance, redesigning inefficient schemas, and implementing effective indexing strategies to prevent customer churn\",\"skills\":[\"PostgreSQL\",\"Query Optimization\",\"Indexing Strategies\",\"Schema Design\",\"Time-Series Database Optimization\"]}\n\n[user] For this role, provide the AI system prompt and model type.\n\nRespond with JSON like this example:\n{\"prompt\": \"You are an expert database administrator. You help teams optimize queries, design schemas, and ensure data integrity...\", \"model\": \"reasoning\"}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- The \"prompt\" should be a detailed system prompt (at least 30 characters)\n- \"model\" should be \"reasoning\" for analytical tasks or \"semantic\" for creative tasks\n\n[assistant] \n\n[user] <validation_retry>\nYour previous response failed JSON validation:\n\n<previous_response>\n\n</previous_response>\n\n<validation_errors>\n• root: Invalid JSON: Unexpected end of JSON input\n</validation_errors>\n\n<instructions>\n1. Review the specific validation errors above\n2. Identify what needs to be fixed in your response\n3. Generate a corrected response that addresses each error\n</instructions>\n\nProvide a corrected JSON response. Return ONLY valid JSON with no additional text, explanations, or markdown formatting.\n</validation_retry>",
                    "rawResponse": "{\"prompt\": \"You are a database optimization expert specializing in query performance tuning, schema design, and indexing strategies. You help teams analyze slow queries, interpret EXPLAIN plans, optimize JOIN operations, and implement time-series database solutions. You provide actionable recommendations for improving database efficiency while maintaining data integrity.\", \"model\": \"reasoning\"}",
                    "parsedResponse": {
                      "prompt": "You are a database optimization expert specializing in query performance tuning, schema design, and indexing strategies. You help teams analyze slow queries, interpret EXPLAIN plans, optimize JOIN operations, and implement time-series database solutions. You provide actionable recommendations for improving database efficiency while maintaining data integrity.",
                      "model": "reasoning"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              }
            ],
            "totalDurationMs": 72291,
            "finalResponse": {
              "recommendation": "I recommend hiring a Database Optimization Specialist because the team needs expert-level skills in query performance tuning, schema optimization, and indexing strategies to resolve the slow dashboard queries. The current team lacks deep database expertise and requires someone who can analyze EXPLAIN plans, redesign inefficient joins/aggregations, and evaluate time-series database solutions like TimescaleDB.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Optimization Specialist",
                  "reason": "This role will resolve slow dashboard queries by optimizing database performance, redesigning inefficient schemas, and implementing effective indexing strategies to prevent customer churn",
                  "skills": [
                    "PostgreSQL",
                    "Query Optimization",
                    "Indexing Strategies",
                    "Schema Design",
                    "Time-Series Database Optimization"
                  ],
                  "prompt": "You are a database optimization expert specializing in query performance tuning, schema design, and indexing strategies. You help teams analyze slow queries, interpret EXPLAIN plans, optimize JOIN operations, and implement time-series database solutions. You provide actionable recommendations for improving database efficiency while maintaining data integrity.",
                  "model": "reasoning"
                }
              }
            }
          },
          {
            "runNumber": 2,
            "success": true,
            "attempts": [],
            "steps": [
              {
                "stepNumber": 1,
                "stepName": "Recommendation",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:36:31.086Z",
                    "success": true,
                    "durationMs": 12793,
                    "inputTokens": 906,
                    "outputTokens": 372,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation, what type of team member should this team add?\n\nRespond with JSON like this example:\n{\"recommendation\": \"I recommend hiring a [role] because [reason]...\", \"action\": \"create_actor\"}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- The \"recommendation\" should explain your hiring recommendation (at least 20 characters)\n- Set \"action\" to \"create_actor\" if recommending someone, or null if not",
                    "rawResponse": "{\"recommendation\": \"I recommend hiring a Database Performance Engineer because the team lacks deep expertise in query optimization, schema design, and database architecture needed to resolve critical performance bottlenecks in their dashboard queries.\", \"action\": \"create_actor\"}",
                    "parsedResponse": {
                      "recommendation": "I recommend hiring a Database Performance Engineer because the team lacks deep expertise in query optimization, schema design, and database architecture needed to resolve critical performance bottlenecks in their dashboard queries.",
                      "action": "create_actor"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 2,
                "stepName": "Details",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:36:39.132Z",
                    "success": false,
                    "durationMs": 8046,
                    "inputTokens": 970,
                    "outputTokens": 103,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Database Performance Engineer because the team lacks deep expertise in query optimization, schema design, and database architecture needed to resolve critical performance bottlenecks in their dashboard queries.\",\"action\":\"create_actor\"}\n\n[user] For the role you recommended, provide their details.\n\nRespond with JSON like this example:\n{\"title\": \"Database Administrator\", \"reason\": \"The team needs database expertise to optimize their slow queries and design scalable schemas\", \"skills\": [\"PostgreSQL\", \"Query Optimization\", \"Database Design\"]}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- Provide 3-7 specific technical skills\n- The \"reason\" should explain how this role addresses the team's problem (at least 20 characters)",
                    "rawResponse": "",
                    "parsedResponse": null,
                    "validationErrors": [
                      {
                        "path": [],
                        "message": "Invalid JSON: Unexpected end of JSON input",
                        "code": "invalid_json"
                      }
                    ],
                    "errorMessage": null
                  },
                  {
                    "attemptNumber": 2,
                    "timestamp": "2025-11-29T17:36:50.633Z",
                    "success": true,
                    "durationMs": 11501,
                    "inputTokens": 1072,
                    "outputTokens": 376,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Database Performance Engineer because the team lacks deep expertise in query optimization, schema design, and database architecture needed to resolve critical performance bottlenecks in their dashboard queries.\",\"action\":\"create_actor\"}\n\n[user] For the role you recommended, provide their details.\n\nRespond with JSON like this example:\n{\"title\": \"Database Administrator\", \"reason\": \"The team needs database expertise to optimize their slow queries and design scalable schemas\", \"skills\": [\"PostgreSQL\", \"Query Optimization\", \"Database Design\"]}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- Provide 3-7 specific technical skills\n- The \"reason\" should explain how this role addresses the team's problem (at least 20 characters)\n\n[assistant] \n\n[user] <validation_retry>\nYour previous response failed JSON validation:\n\n<previous_response>\n\n</previous_response>\n\n<validation_errors>\n• root: Invalid JSON: Unexpected end of JSON input\n</validation_errors>\n\n<instructions>\n1. Review the specific validation errors above\n2. Identify what needs to be fixed in your response\n3. Generate a corrected response that addresses each error\n</instructions>\n\nProvide a corrected JSON response. Return ONLY valid JSON with no additional text, explanations, or markdown formatting.\n</validation_retry>",
                    "rawResponse": "{\"title\": \"Database Performance Engineer\", \"reason\": \"The team lacks deep expertise in query optimization, schema design, and database architecture needed to resolve critical performance bottlenecks in their dashboard queries.\", \"skills\": [\"PostgreSQL\", \"Query Optimization\", \"Database Design\", \"Execution Plans\", \"Indexing Strategies\", \"Caching Solutions\"]}",
                    "parsedResponse": {
                      "title": "Database Performance Engineer",
                      "reason": "The team lacks deep expertise in query optimization, schema design, and database architecture needed to resolve critical performance bottlenecks in their dashboard queries.",
                      "skills": [
                        "PostgreSQL",
                        "Query Optimization",
                        "Database Design",
                        "Execution Plans",
                        "Indexing Strategies",
                        "Caching Solutions"
                      ]
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 3,
                "stepName": "AI Config",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:37:04.810Z",
                    "success": true,
                    "durationMs": 14177,
                    "inputTokens": 1028,
                    "outputTokens": 419,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Database Performance Engineer because the team lacks deep expertise in query optimization, schema design, and database architecture needed to resolve critical performance bottlenecks in their dashboard queries.\",\"action\":\"create_actor\"}\n\n[assistant] {\"title\":\"Database Performance Engineer\",\"reason\":\"The team lacks deep expertise in query optimization, schema design, and database architecture needed to resolve critical performance bottlenecks in their dashboard queries.\",\"skills\":[\"PostgreSQL\",\"Query Optimization\",\"Database Design\",\"Execution Plans\",\"Indexing Strategies\",\"Caching Solutions\"]}\n\n[user] For this role, provide the AI system prompt and model type.\n\nRespond with JSON like this example:\n{\"prompt\": \"You are an expert database administrator. You help teams optimize queries, design schemas, and ensure data integrity...\", \"model\": \"reasoning\"}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- The \"prompt\" should be a detailed system prompt (at least 30 characters)\n- \"model\" should be \"reasoning\" for analytical tasks or \"semantic\" for creative tasks",
                    "rawResponse": "{\"prompt\": \"You are a Database Performance Engineer specializing in optimizing complex queries, analyzing execution plans, and designing efficient database schemas. You help teams identify bottlenecks in PostgreSQL databases, implement effective indexing strategies, evaluate caching solutions, and determine when architectural changes or database migrations are necessary. You provide actionable recommendations based on deep analysis of query performance metrics and system resource usage.\", \"model\": \"reasoning\"}",
                    "parsedResponse": {
                      "prompt": "You are a Database Performance Engineer specializing in optimizing complex queries, analyzing execution plans, and designing efficient database schemas. You help teams identify bottlenecks in PostgreSQL databases, implement effective indexing strategies, evaluate caching solutions, and determine when architectural changes or database migrations are necessary. You provide actionable recommendations based on deep analysis of query performance metrics and system resource usage.",
                      "model": "reasoning"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              }
            ],
            "totalDurationMs": 46518,
            "finalResponse": {
              "recommendation": "I recommend hiring a Database Performance Engineer because the team lacks deep expertise in query optimization, schema design, and database architecture needed to resolve critical performance bottlenecks in their dashboard queries.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Performance Engineer",
                  "reason": "The team lacks deep expertise in query optimization, schema design, and database architecture needed to resolve critical performance bottlenecks in their dashboard queries.",
                  "skills": [
                    "PostgreSQL",
                    "Query Optimization",
                    "Database Design",
                    "Execution Plans",
                    "Indexing Strategies",
                    "Caching Solutions"
                  ],
                  "prompt": "You are a Database Performance Engineer specializing in optimizing complex queries, analyzing execution plans, and designing efficient database schemas. You help teams identify bottlenecks in PostgreSQL databases, implement effective indexing strategies, evaluate caching solutions, and determine when architectural changes or database migrations are necessary. You provide actionable recommendations based on deep analysis of query performance metrics and system resource usage.",
                  "model": "reasoning"
                }
              }
            }
          },
          {
            "runNumber": 3,
            "success": true,
            "attempts": [],
            "steps": [
              {
                "stepNumber": 1,
                "stepName": "Recommendation",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:37:18.098Z",
                    "success": true,
                    "durationMs": 13287,
                    "inputTokens": 906,
                    "outputTokens": 345,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[user] Based on the conversation, what type of team member should this team add?\n\nRespond with JSON like this example:\n{\"recommendation\": \"I recommend hiring a [role] because [reason]...\", \"action\": \"create_actor\"}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- The \"recommendation\" should explain your hiring recommendation (at least 20 characters)\n- Set \"action\" to \"create_actor\" if recommending someone, or null if not",
                    "rawResponse": "{\"recommendation\": \"I recommend hiring a Database Performance Engineer because the team needs an expert to optimize slow queries, redesign schema/indexes, and evaluate database architecture options like TimescaleDB migration. This role requires deep SQL optimization skills, query execution plan analysis, and time-series data expertise to resolve the root cause of the performance bottlenecks.\", \"action\": \"create_actor\"}",
                    "parsedResponse": {
                      "recommendation": "I recommend hiring a Database Performance Engineer because the team needs an expert to optimize slow queries, redesign schema/indexes, and evaluate database architecture options like TimescaleDB migration. This role requires deep SQL optimization skills, query execution plan analysis, and time-series data expertise to resolve the root cause of the performance bottlenecks.",
                      "action": "create_actor"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 2,
                "stepName": "Details",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:37:28.179Z",
                    "success": true,
                    "durationMs": 10081,
                    "inputTokens": 998,
                    "outputTokens": 368,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Database Performance Engineer because the team needs an expert to optimize slow queries, redesign schema/indexes, and evaluate database architecture options like TimescaleDB migration. This role requires deep SQL optimization skills, query execution plan analysis, and time-series data expertise to resolve the root cause of the performance bottlenecks.\",\"action\":\"create_actor\"}\n\n[user] For the role you recommended, provide their details.\n\nRespond with JSON like this example:\n{\"title\": \"Database Administrator\", \"reason\": \"The team needs database expertise to optimize their slow queries and design scalable schemas\", \"skills\": [\"PostgreSQL\", \"Query Optimization\", \"Database Design\"]}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- Provide 3-7 specific technical skills\n- The \"reason\" should explain how this role addresses the team's problem (at least 20 characters)",
                    "rawResponse": "{\"title\": \"Database Performance Engineer\", \"reason\": \"Resolves slow query performance and optimizes database architecture to prevent customer churn from dashboard latency issues\", \"skills\": [\"PostgreSQL\", \"Query Optimization\", \"Time-Series Database Optimization\", \"Indexing Strategies\", \"Execution Plan Analysis\"]}",
                    "parsedResponse": {
                      "title": "Database Performance Engineer",
                      "reason": "Resolves slow query performance and optimizes database architecture to prevent customer churn from dashboard latency issues",
                      "skills": [
                        "PostgreSQL",
                        "Query Optimization",
                        "Time-Series Database Optimization",
                        "Indexing Strategies",
                        "Execution Plan Analysis"
                      ]
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              },
              {
                "stepNumber": 3,
                "stepName": "AI Config",
                "success": true,
                "attempts": [
                  {
                    "attemptNumber": 1,
                    "timestamp": "2025-11-29T17:37:36.570Z",
                    "success": false,
                    "durationMs": 8391,
                    "inputTokens": 1046,
                    "outputTokens": 100,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Database Performance Engineer because the team needs an expert to optimize slow queries, redesign schema/indexes, and evaluate database architecture options like TimescaleDB migration. This role requires deep SQL optimization skills, query execution plan analysis, and time-series data expertise to resolve the root cause of the performance bottlenecks.\",\"action\":\"create_actor\"}\n\n[assistant] {\"title\":\"Database Performance Engineer\",\"reason\":\"Resolves slow query performance and optimizes database architecture to prevent customer churn from dashboard latency issues\",\"skills\":[\"PostgreSQL\",\"Query Optimization\",\"Time-Series Database Optimization\",\"Indexing Strategies\",\"Execution Plan Analysis\"]}\n\n[user] For this role, provide the AI system prompt and model type.\n\nRespond with JSON like this example:\n{\"prompt\": \"You are an expert database administrator. You help teams optimize queries, design schemas, and ensure data integrity...\", \"model\": \"reasoning\"}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- The \"prompt\" should be a detailed system prompt (at least 30 characters)\n- \"model\" should be \"reasoning\" for analytical tasks or \"semantic\" for creative tasks",
                    "rawResponse": "",
                    "parsedResponse": null,
                    "validationErrors": [
                      {
                        "path": [],
                        "message": "Invalid JSON: Unexpected end of JSON input",
                        "code": "invalid_json"
                      }
                    ],
                    "errorMessage": null
                  },
                  {
                    "attemptNumber": 2,
                    "timestamp": "2025-11-29T17:37:44.608Z",
                    "success": false,
                    "durationMs": 8038,
                    "inputTokens": 1149,
                    "outputTokens": 89,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Database Performance Engineer because the team needs an expert to optimize slow queries, redesign schema/indexes, and evaluate database architecture options like TimescaleDB migration. This role requires deep SQL optimization skills, query execution plan analysis, and time-series data expertise to resolve the root cause of the performance bottlenecks.\",\"action\":\"create_actor\"}\n\n[assistant] {\"title\":\"Database Performance Engineer\",\"reason\":\"Resolves slow query performance and optimizes database architecture to prevent customer churn from dashboard latency issues\",\"skills\":[\"PostgreSQL\",\"Query Optimization\",\"Time-Series Database Optimization\",\"Indexing Strategies\",\"Execution Plan Analysis\"]}\n\n[user] For this role, provide the AI system prompt and model type.\n\nRespond with JSON like this example:\n{\"prompt\": \"You are an expert database administrator. You help teams optimize queries, design schemas, and ensure data integrity...\", \"model\": \"reasoning\"}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- The \"prompt\" should be a detailed system prompt (at least 30 characters)\n- \"model\" should be \"reasoning\" for analytical tasks or \"semantic\" for creative tasks\n\n[assistant] \n\n[user] <validation_retry>\nYour previous response failed JSON validation:\n\n<previous_response>\n\n</previous_response>\n\n<validation_errors>\n• root: Invalid JSON: Unexpected end of JSON input\n</validation_errors>\n\n<instructions>\n1. Review the specific validation errors above\n2. Identify what needs to be fixed in your response\n3. Generate a corrected response that addresses each error\n</instructions>\n\nProvide a corrected JSON response. Return ONLY valid JSON with no additional text, explanations, or markdown formatting.\n</validation_retry>",
                    "rawResponse": "",
                    "parsedResponse": null,
                    "validationErrors": [
                      {
                        "path": [],
                        "message": "Invalid JSON: Unexpected end of JSON input",
                        "code": "invalid_json"
                      }
                    ],
                    "errorMessage": null
                  },
                  {
                    "attemptNumber": 3,
                    "timestamp": "2025-11-29T17:37:58.585Z",
                    "success": true,
                    "durationMs": 13977,
                    "inputTokens": 1251,
                    "outputTokens": 412,
                    "prompt": "[system] You are a recruiter AI assistant. Your job is to analyse team conversations and recommend new team members who could help solve problems the team is facing.\n\nWhen you identify a skill gap in the team, recommend a specific role that would fill that gap. Provide:\n- A clear job title\n- An explanation of why this role is needed\n- The specific skills required\n- A system prompt that could be used to configure an AI assistant for this role\n- Whether the role requires \"reasoning\" (analytical/logical) or \"semantic\" (creative/conversational) capabilities\n\nBe specific and practical in your recommendations.\n\n[user] Here is a conversation between team members:\n\nCasey: Hey team, we've got a problem. Three enterprise customers are complaining about slow load times on the dashboard. One of them is threatening to churn if we don't fix it by end of month.\n\nAlex: I've been looking into it. The main dashboard query is taking 8-12 seconds on accounts with more than 50k records. It's definitely a database issue.\n\nJordan: I added some basic indexes last week but it didn't help much. The query is joining across 4 tables and aggregating a lot of data.\n\nSam: From the frontend side, I can add loading skeletons and pagination, but that's just masking the problem. Users are going to notice the wait regardless.\n\nMorgan: I checked the database server metrics. CPU and memory look fine, but I'm seeing a lot of disk I/O. Not sure what that means for query performance though.\n\nAlex: I tried rewriting the query to use subqueries instead of joins, but it actually made it slower. I'm kind of out of ideas here.\n\nJordan: Should we look at caching? We could cache the dashboard data in Redis and refresh it every few minutes.\n\nCasey: The customers want real-time data, or at least near real-time. A few minutes delay isn't going to work for their use case.\n\nSam: What about lazy loading sections of the dashboard? We could load the critical metrics first and the rest async.\n\nAlex: That helps with perceived performance, but the underlying query is still slow. And some customers have dashboards with all sections visible - they'd still see the delay.\n\nMorgan: I could spin up a read replica to offload the dashboard queries from the primary database. Would that help?\n\nJordan: It might reduce load on the primary, but the query itself would still be slow. We need to optimise the actual query execution.\n\nCasey: What about the table structure itself? Maybe we need to redesign how we're storing this data?\n\nAlex: That's crossed my mind. But honestly, I'm not confident about making schema changes without knowing exactly what's causing the bottleneck. We could make it worse.\n\nJordan: I looked at EXPLAIN ANALYZE on the query. There's a sequential scan on the events table that takes most of the time. But I'm not sure how to fix it without breaking other queries that depend on that table.\n\nMorgan: Should we consider moving to a different database? I've heard TimescaleDB is good for time-series data, and a lot of our data is event-based.\n\nAlex: That's a huge migration. We'd need someone who really knows what they're doing to evaluate whether it's worth it and plan the migration properly.\n\nSam: It feels like we're all guessing at this point. None of us are database experts. We know enough to be dangerous but not enough to fix this properly.\n\nCasey: I agree. We've been circling on this for two weeks now. Maybe we need to bring in someone who specialises in this stuff?\n\nAlex: Yeah, I think that's the right call. We need someone who can analyse the query plans, optimise the schema, set up proper indexing strategies, and maybe advise on whether we need a different database architecture altogether.\n\n[assistant] {\"recommendation\":\"I recommend hiring a Database Performance Engineer because the team needs an expert to optimize slow queries, redesign schema/indexes, and evaluate database architecture options like TimescaleDB migration. This role requires deep SQL optimization skills, query execution plan analysis, and time-series data expertise to resolve the root cause of the performance bottlenecks.\",\"action\":\"create_actor\"}\n\n[assistant] {\"title\":\"Database Performance Engineer\",\"reason\":\"Resolves slow query performance and optimizes database architecture to prevent customer churn from dashboard latency issues\",\"skills\":[\"PostgreSQL\",\"Query Optimization\",\"Time-Series Database Optimization\",\"Indexing Strategies\",\"Execution Plan Analysis\"]}\n\n[user] For this role, provide the AI system prompt and model type.\n\nRespond with JSON like this example:\n{\"prompt\": \"You are an expert database administrator. You help teams optimize queries, design schemas, and ensure data integrity...\", \"model\": \"reasoning\"}\n\nImportant:\n- Return ONLY valid JSON, no markdown code blocks\n- The \"prompt\" should be a detailed system prompt (at least 30 characters)\n- \"model\" should be \"reasoning\" for analytical tasks or \"semantic\" for creative tasks\n\n[assistant] \n\n[user] <validation_retry>\nYour previous response failed JSON validation:\n\n<previous_response>\n\n</previous_response>\n\n<validation_errors>\n• root: Invalid JSON: Unexpected end of JSON input\n</validation_errors>\n\n<instructions>\n1. Review the specific validation errors above\n2. Identify what needs to be fixed in your response\n3. Generate a corrected response that addresses each error\n</instructions>\n\nProvide a corrected JSON response. Return ONLY valid JSON with no additional text, explanations, or markdown formatting.\n</validation_retry>\n\n[assistant] \n\n[user] <validation_retry>\nYour previous response failed JSON validation:\n\n<previous_response>\n\n</previous_response>\n\n<validation_errors>\n• root: Invalid JSON: Unexpected end of JSON input\n</validation_errors>\n\n<instructions>\n1. Review the specific validation errors above\n2. Identify what needs to be fixed in your response\n3. Generate a corrected response that addresses each error\n</instructions>\n\nProvide a corrected JSON response. Return ONLY valid JSON with no additional text, explanations, or markdown formatting.\n</validation_retry>",
                    "rawResponse": "{\"prompt\":\"You are a Database Performance Engineer specializing in PostgreSQL optimization. You analyze query execution plans, design efficient indexing strategies, optimize time-series data storage, and evaluate database architecture improvements to resolve performance bottlenecks.\",\"model\":\"reasoning\"}",
                    "parsedResponse": {
                      "prompt": "You are a Database Performance Engineer specializing in PostgreSQL optimization. You analyze query execution plans, design efficient indexing strategies, optimize time-series data storage, and evaluate database architecture improvements to resolve performance bottlenecks.",
                      "model": "reasoning"
                    },
                    "validationErrors": [],
                    "errorMessage": null
                  }
                ]
              }
            ],
            "totalDurationMs": 53774,
            "finalResponse": {
              "recommendation": "I recommend hiring a Database Performance Engineer because the team needs an expert to optimize slow queries, redesign schema/indexes, and evaluate database architecture options like TimescaleDB migration. This role requires deep SQL optimization skills, query execution plan analysis, and time-series data expertise to resolve the root cause of the performance bottlenecks.",
              "action": {
                "type": "create_actor",
                "actor": {
                  "title": "Database Performance Engineer",
                  "reason": "Resolves slow query performance and optimizes database architecture to prevent customer churn from dashboard latency issues",
                  "skills": [
                    "PostgreSQL",
                    "Query Optimization",
                    "Time-Series Database Optimization",
                    "Indexing Strategies",
                    "Execution Plan Analysis"
                  ],
                  "prompt": "You are a Database Performance Engineer specializing in PostgreSQL optimization. You analyze query execution plans, design efficient indexing strategies, optimize time-series data storage, and evaluate database architecture improvements to resolve performance bottlenecks.",
                  "model": "reasoning"
                }
              }
            }
          }
        ],
        "summary": {
          "successRate": 100,
          "firstAttemptSuccessRate": 0,
          "afterRetry1SuccessRate": 66.66666666666666,
          "afterRetry2SuccessRate": 100,
          "afterRetry3SuccessRate": 100,
          "averageDurationMs": 57527.666666666664,
          "averageAttempts": 4.333333333333333,
          "averageAttemptsPerSuccess": 4.333333333333333,
          "averageTokensPerSuccess": 5958.333333333333,
          "totalTokensUsed": 17875
        }
      }
    }
  }
}